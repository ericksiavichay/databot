{"docstore/data": {"16537838-427b-47f6-b13c-9b9369bfa58c": {"__data__": {"id_": "16537838-427b-47f6-b13c-9b9369bfa58c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "82f54fd0-4345-4257-b87a-e8171e872c18", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/"}, "hash": "234ea92bf32be5f771c7c26473b14f454f36c47fa85baf8d0049f131c4e1f91a"}}, "hash": "172ade911e9a3f5c6de016416f7dce1f43534c2b9fca23aa66e2e62c16c047e0", "text": "Arize AI - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookArize AIML & LLM Observability Platform for real-time monitoring, analysis, and explainabilityArize is the machine learning observability platform for ML practitioners to monitor, troubleshoot, and explain models. Data Science and ML Engineering teams of all sizes (from individuals to enterprises) use Arize to:Evaluate, monitor, and troubleshoot LLM applicationsMonitor real-time model performance, with support for delayed ground truth/feedbackRoot cause model failures/performance degradation using tracing and explainabilityConduct multi-model performance comparisonsSurface drift, data quality, and model fairness/bias metrics Arize Product DemoWhat am I logging to Arize?The Arize platform logs model inferences across training, validation and production environments. Check out how Arize and ML Observability fit into your ML workflow here. How Does Arize Fit Into ML StackYour ML Stack might already include a feature store, model store, and serving layer. Once your models are deployed into production, ML Observability provides deep understanding of your model\u2019s performance, and root causing exactly why it\u2019s behaving in certain ways. This is where an inference/evaluation store can help.ML Canonical Stack featuring Feature, Model, and Evaluation StorePlatform and Model Agnostic Arize is an open platform that works with your machine learning infrastructure, and can be deployed as SaaS or on-premise.Open Platform designed to work across platforms and model frameworksNextWhat is ML Observability?Last modified 12d agoOn this pageArize Product DemoWhat am I logging to Arize?How Does Arize Fit Into ML StackPlatform and Model Agnostic SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3365, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "01ef153a-e560-4b71-a464-39e9b343843d": {"__data__": {"id_": "01ef153a-e560-4b71-a464-39e9b343843d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/examples"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3d360d67-7dd2-4612-aba2-675723a6e48e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/examples"}, "hash": "810607d65ef4c461e574f16658d7986cd02048e4e1d514eeeb8b1aa1e110618c"}}, "hash": "bb74296c19ffc71965573ff17f01fd0d62fb28b90d1da22726db792d112c450d", "text": "All Tutorials/Notebooks - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAll Tutorials/NotebooksExample tutorials of how to use and troubleshoot with Arize.Access tutorials of what's possible with Arize below:1.\u200bModel Type Examples\u200b2.\u200bExplainability Tutorials\u200b3.\u200bCloud Storage Examples\u200bModel Type ExamplesYour model type determines which performance metrics are available to you. Learn more about model types here.Model TypePandas BatchPython Single RecordCSVParquet Binary Classification (Only Classification Metrics)\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload\u200b File\n*Open Parquet Reader Here\u200bBinary Classification (Classification, AUC/Log Loss Metrics) \u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload File\n*Open Parquet Reader Here\u200bBinary Classification (Classification, AUC/Log Loss, Regression) \u200bColab Link\u200b\u200bColab Link\u200b\u200bDownload File\u200b\u200bDownload File\n*Open Parquet Reader Here\u200bMulticlass Classification (Only Classification Metrics)\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bMulticlass Classification (Classification, AUC/Log Loss Metrics)\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bRegression\u200bColab Link\u0000\u0000\u200b\u200bColab Link\u200b\u200bDownload File\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bTimeseries Forecasting \u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bRanking with Relevance Score\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bRanking with Single Label\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bRanking with Multiple Labels\u200bColab Link\u200b\u200bColab Link\u200b\u200b\u200bDownload \u200bFile\n*Open Parquet Reader Here\u200bNLP Classification \u200bColab Link\u200b\u200b\u200b\u200bNLP Named Entity Recognition (NER)\u200bColab Link\u200b\u200b\u200b\u200bCV Classification \u200bColab Link\u200b\u200b\u200b\u200bTabular Classification w/ Embeddings \u200bColab Link\u200b\u200b\u200b\u200bObject Detection\u200bColab Link\u200b\u200b\u200b\u200bLarge Language Models (LLMs)\u200bColab Link\u200b\u200b\u200b\u200bExplainability TutorialsExamples for logging explainability metrics. Click here for more information on how to log feature importance and use explainability.SHAP: Guide to Getting Started\u200bColab Link\u200bSHAP: Neural Network on Tabular Data\u200bColab Link\u200bSurrogate Model Explainability\u200bColab Link\u200bOne Hot Encoding Decomposition\u200bColab Link\u200bCloud Storage ExamplesGoogle Cloud Services\u200bLink\u200bAmazon Web Services\u200bLink\u200bAzure File Import\u200bLink\u200bBenchmark TestSending 10 Million Inferences to Arize in 90 Seconds\u200bColab Link\u200bLogging Predictions, Actuals, SHAP ValuesTutorials on how to log predictions, actuals, and feature importance.Logging Predictions Only\u200bColab Link\u200bLogging Predictions First, Then Logging Delayed Actuals\u200bColab LInk\u200bLogging Predictions First, Then Logging SHAPs After\u200bColab Link\u200bLogging Predictions and Actuals Together\u200bColab Link\u200bLogging Predictions and SHAP Together\u200bColab Link\u200bLogging Predictions, Actuals, and SHAP Together\u200bColab Link\u200bLogging PySpark DataFrames\u200bColab Link\u200bExample Integrations with Common ML/Data PlatformsArize integrates with platforms across the MLOps toolchain. Don't see a platform you use? Reach out to add yours or ask our team to help!  ML PlatformDescriptionExample IntegrationBlogAlgorithmia MLOps platform with APIs to serve, host and manages models\u200bColab Link\u200b\u200bBlog\u200bAzure ML & DatabricksUsing Arize in an Azure ML Databricks workflow\u200bColab Link\u200b\u200bBento MLUse Bento\u2019s ML service platform to turn ML models into production-worthy prediction services\u200bTutorial Blog\u200b\u200bCMLIntegrate Arize into the CI/CD workflow - Run checks on every new model version \u200bExample here\u200b\u200bDeepnoteDeepnote is a Data Science Collaboration Platform\u200bDeepnote Link\u200b\u200bFeastMonitor & Troubleshoot any data inconsistency issue with feature stores Arize.\u200bColab Link\u200b\u200bBlog Google Cloud ML (Vertex AI)Integrate Arize with Vertex AIAvailable on Request\u200bBlog\u200bHugging FaceUse Arize to monitor embeddings generated from Hugging Face NLP or Transformer models\u200bOverview\nNLP Classification\nNLP NER \nImage Classification \u200b\u200bBlog\u200bKafkaUse Arize Pandas SDK to consumes micro-batches of predictions\u200bExample here\u200b\u200bBlog\u200bLangchainEffectively monitor the performance of your LLM agents\u200bColab Link\u200b\u200bMLFlowIntegrating Arize and MLflow to track the model across experimentation and deployment\u200bColab Link\u200b\u200bBlog\u200bNeptuneIntegrate Arize on models built using Neptune\u200bColab Link\u200b\u200bBlog\u200bOpenAI Build unstructured models with OpenAI\u200bColab Link (NLP)\u200b\u200bBlog\u200bPaperspaceIntegrate Arize on models built using Paperspace\u200b\u200bBlog\u200bPySparkTo log Spark DataFrames, which have rdds as their underlying structure, we will use mapInPandas to log them to arize.\u200bColab Link\u200b\u200bRay Serve (Anyscale)Arize can be easily integrated with Ray Serve with at single entry point during ray.serve.deployment\u200bOverview\n\u200bBlog\u200bSagemaker \u200b\u200bBatch\nReal-Time\u200b\u200bSpellCombine Spell model servers with Arize model observability\u200bOverview\nColab Link\u200b\u200bBlog\u200bUbiOpsArize platform can easily integrate with UbiOps to enable model observability, explainability, and monitoring.\u200bColab Link\u200b\u200bBlog\u200bWeights & Biases Integrating Arize and W&B to track the model across experimentation and deployment\u200bColab Link\u200b\u200bCommon Industry Use Cases Common Industry Use CasesPreviousQuickstartNext - Sending Data GuidesWhat Is A Model SchemaLast modified 12d agoOn this pageModel Type ExamplesExplainability TutorialsCloud Storage ExamplesBenchmark TestLogging Predictions, Actuals, SHAP ValuesExample Integrations with Common ML/Data PlatformsCommon Industry Use Cases SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6948, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7ae33b07-61b4-43e7-bc70-15e0582330cb": {"__data__": {"id_": "7ae33b07-61b4-43e7-bc70-15e0582330cb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "98af1be0-3d4c-49eb-a413-f30e8680dd9b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "hash": "c6ee4e8eb4b3210ef23c17cc7badff5d91c5d229a54228a774cbf3c44c384788"}, "3": {"node_id": "265905fd-1d66-4b59-a686-3a8cad2818ba", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "hash": "8df63de31bdeb4a09010788c42f107b969b6ad72cf9926d257479b24aca9faa9"}}, "hash": "fbbc136e20d97f2ca89462d489b636b3b049d46a47a5204523d281bb4b7bd278", "text": "Quickstart - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookQuickstartLearn how to get started using Arize!Quickstart OverviewArize integrates with your ML stack, no matter where your data is hostedStep 1: Upload Sample Data Via SDK!pip install arizeTo easily get started, we'll prepare a simple Classification Model dataset from SciKit learn to send via the Python SDK. Install arize, import dependencies, and attach your SPACE_KEY and API_KEY\u200bfrom arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, Schema, Metrics\u200bAPI_KEY = 'YOUR API KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)Step 2: Download DatasetFor this example, download the load_breast_cancer dataset, assign the dataset to a variable, and preview the data to better understand what we're working with.from sklearn.datasets import load_breast_cancerbreast_cancer_dataset = load_breast_cancer()Step 3: Extract Features, Predictions, and ActualsThe dataset contains all the information we need to create a Pandas dataframe. For any dataset, extract the features, predictions, and actuals data. For this example:breast_cancer_features = breast_cancer_dataset['data'] # feature databreast_cancer_feature_names = breast_cancer_dataset['feature_names'] # feature namesbreast_cancer_targets = breast_cancer_dataset['target'] # actual databreast_cancer_target_names = breast_cancer_dataset['target_names'] # actual labelsAssign breast_cancer_taget_names to their corresponding breast_cancer_targets to use as a human-comprehensible list of actual labels.  target_name_transcription = [] # this will become our list of actuals\u200bfor i in breast_cancer_targets:   target_name_transcription.append(breast_cancer_target_names[i])Create a Pandas dataframe to use the Arize Python Pandas logger with our predefined features and actuals(target_name_transcription). Note: We've duplicated the actual_label column to create a prediction_label column for simplicities sake. Data will not populate in the Arize platform without a record of prediction data. import pandas as pd\u200bdf = pd.DataFrame(breast_cancer_features, columns=breast_cancer_feature_names)df['actual_label'] = target_name_transcriptiondf['prediction_label'] = target_name_transcription\u200b# this is optional, but makes this example more interesting in the platformdf['prediction_label'] = df['prediction_label'].iloc[::-1].reset_index(drop=True) Step 4: Log Data to ArizeDefine the Schema so Arize knows what your columns correspond to.schema = Schema(    actual_label_column_name=\"actual_label\",    prediction_label_column_name=\"prediction_label\",    feature_column_names=[ 'mean radius', 'mean texture', 'mean perimeter', 'mean area', 'mean smoothness', 'mean compactness', 'mean concavity', 'mean concave points', 'mean symmetry', 'mean fractal dimension', 'radius error', 'texture error', 'perimeter error', 'area error', 'smoothness error', 'compactness error', 'concavity error', 'concave points error', 'symmetry error', 'fractal dimension error', 'worst radius', 'worst texture', 'worst perimeter', 'worst area', 'worst smoothness', 'worst compactness', 'worst concavity', 'worst concave points', 'worst symmetry', 'worst fractal dimension' ])\u200bLog the model data.response = arize_client.log(    dataframe=df,    schema=schema,    model_id='breast_cancer_dataset',     model_version='v1',    model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION],     environment=Environments.PRODUCTION) Step 4.5: \u2615 Get a cup of coffeeIt usually takes ~10 minutes for Arize to populate data throughout the platform. We recommend grabbing a quick cup of coffee (or tea) in the meantime!Step 5: Visualize Model Performance Now that you've uploaded some data to Arize, check it out on the platform. Navigate to the 'Performance Tracing' tab within your model. Here, you'll see an interactive performance-over-time chart and a performance breakdown visualization. Performance Breakdown & Performance InsightsStep 6: Setup One-Click MonitoringCreate monitors to keep an eye on key performance, drift, and data quality metrics. Navigate to the 'Monitors' tab and enable relevant prebuilt monitors for your use case.Prebuilt monitors in the Monitor's Setup tabStep 7: Relax (With Alerting Notifications On)!Configure alerts on the 'Config' page within the monitor's tab to keep you posted when your model changes unexpectedly. Use our various alerting integrations or alert via emailExtra Credit: Create A Dashboard We get it - ML observability is a lot of fun! Keep an eye on key model health metrics with dashboards for a single pane of glass view of your model. Create a custom dashboard, use a pre-built template, and simply copy and paste the dashboard URL to share with your team! Example dashbaord with key performance metricsUp Next: Connect to Production Data PipelineConnect your Cloud Storage Blob or Data Warehouse to automatically sync model data with Arize!  \u200bGoogle Cloud Storage\u200b\u200bAWS S3\u200b\u200bAzure Blob Storage\u200b\u200bGoogle BigQuery\u200bLooking for more examples? Check out our examples page!All Tutorials/NotebooksPreviousWhat is LLM Observability?NextAll Tutorials/NotebooksLast modified 12d agoOn this pageQuickstart OverviewStep 1: Upload Sample Data Via SDKStep 2: Download DatasetStep 3: Extract Features, Predictions, and ActualsStep 4: Log Data to ArizeStep 5: Visualize Model Performance Step 6: Setup One-Click MonitoringStep 7: Relax (With Alerting Notifications On)!Extra Credit: Create A Dashboard Up Next: Connect to Production Data PipelineSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook", "start_char_idx": 0, "end_char_idx": 7102, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "265905fd-1d66-4b59-a686-3a8cad2818ba": {"__data__": {"id_": "265905fd-1d66-4b59-a686-3a8cad2818ba", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "98af1be0-3d4c-49eb-a413-f30e8680dd9b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "hash": "c6ee4e8eb4b3210ef23c17cc7badff5d91c5d229a54228a774cbf3c44c384788"}, "2": {"node_id": "7ae33b07-61b4-43e7-bc70-15e0582330cb", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}, "hash": "fbbc136e20d97f2ca89462d489b636b3b049d46a47a5204523d281bb4b7bd278"}}, "hash": "8df63de31bdeb4a09010788c42f107b969b6ad72cf9926d257479b24aca9faa9", "text": "A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7103, "end_char_idx": 7236, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7e2469e5-2c7f-4d10-8c9d-5362b2567373": {"__data__": {"id_": "7e2469e5-2c7f-4d10-8c9d-5362b2567373", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/what-is-llm-observability"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8d84b686-a210-47bf-b536-ec508234da98", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/what-is-llm-observability"}, "hash": "1285bb7c43f126638f78f0067f2251ba05bdc08f4749e23ad15bf982401995ca"}}, "hash": "f94de6ef0546ed44ea4ea5fec4184ac3cd4d3a810ff1b45544e37f8be0db0cbb", "text": "What is LLM Observability? - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookWhat is LLM Observability?Introducing Arize support for LLM use casesLLMs are Growing FastThe use of GPT-4 as a replacement for various model tasks is growing daily. What many teams consider a model today, may just be a prompt & response pair in the future. Where Problems Emerge in LLM DeploymentsAs teams deploy LLM\u2019s to production the same challenges around performance and task measurement do still exist. Similar to ML Observability, LLM Observability doesn't just stop at surfacing poor product experiences, but enables practitioners to root cause to improve it.Across this flow, there are multiple areas where teams often run into issues or challenges with LLMs. Collecting/Generating Evaluation is Hard: Collecting and aggregating user feedback to find what responses are bad is important. If you don't back user feedback, there are ways of using generating LLM-assisted evaluations. LLM Hallucinations/Bad Responses: A big concern many teams have are the risks associated with models hallucinating, and providing incorrect responses shared as factual information.Bad Retrieval: If using RAG, it\u2019s hard to locate if you there was a bad retrieval, and if so, where in the process an issue occurred.Bad Prompts and Prompt Templates: Knowing what prompt templates perform well and which perform poorly.Tracing where the chain failed: And if incorporating agents, it's difficult to or get visibility into how the agent is performing and where the chain failed.\nArize Provides Observability Across the LLM Stack Arize helps teams work backwards from the output to pinpoint where exactly the issue is stemming from across their LLM stack.\u200bArize Collects &/or Generates Evaluations: Arize helps collect all the responses and user feedback, or help generate them, so teams can look at clusters of bad responses for further troubleshooting and analysis\u200bTroubleshoot Bad Retrieval: Teams can troubleshoot for search and retrieval with vector stores. Such as did it actually pull all the relevant context? Is there even enough relevant context?Catch LLM Hallucinations/Bad Responses: Understand why hallucinations are occurring, by easily finding bad responses, uncovering trends, and understanding where improvements need to be made. Uncover Bad Prompts and Prompt Templates: With analysis of the prompt template, teams can understand which are performing better than others. Coming soon.Trace where the chain failed: With agent tracing and spans, teams can understand what calls failed, or where in the span issues occurred. Coming soon.Fine tune LLMs: For teams that are fine tuning, Arize has workflows to understand things such as what types of phrases or inputs does the model typically provide a bad response on? Teams can use that to then do the fine tuning. Coming soon.PreviousWhat is ML Observability?NextQuickstartLast modified 12d agoOn this pageLLMs are Growing FastWhere Problems Emerge in LLM Deployments\nArize Provides Observability Across the LLM Stack SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4701, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9dc8bc2b-c8d0-4d9f-8c44-add385a0a9dc": {"__data__": {"id_": "9dc8bc2b-c8d0-4d9f-8c44-add385a0a9dc", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/what-is-ml-observability"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5c23863b-67de-4bd9-89dd-e8c18578c41a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/what-is-ml-observability"}, "hash": "b3946a96b32bdbff95c4ee5f60ea27a545fe54ae96e5fd3bb5a734df1fe2ed36"}}, "hash": "c322d7ef89e454f553e5815605aa383fada7731769e9b36bf6a020fc2b298ab9", "text": "What is ML Observability? - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookWhat is ML Observability?Resources for Best Practices in ML ObservabilityML Observability is the practice of obtaining a deep understanding into your model\u2019s data and performance across its lifecycle. Observability doesn't just stop at surfacing a red or green light, but enables ML practitioners to root cause/explain why a model is behaving a certain way in order to improve it. Check out how Arize works across the ML Lifecycle to get the most out of ML Observability. Arize across the ML Workflow ML Observability: Resources\u200bML Observability: Industry Certification\u200b\u200bML Observability: Advanced Course\u200b\u200bML Observability 101 Intro Video\u200b\u200bML Observability 101: Ebook\u200b\u200bModel Performance Management (Paper)\u200b\u200bWhat To Look for In An ML Observability Platform (Buyer's Checklist)\u200b\u200bA Guide To Automated Model Retraining\u200b\u200bCentral ML: Best Practices for Ramping Up on ML Observability\u200bML observability in contextML Observability: Fundamentals\u200bWhat Is Observability?\u200b\u200bML Observability: The Essentials\u200b\u200bTracing In Machine Learning\u200b\u200bModel Evaluation Metrics\u200b\u200bBinary Cross Entropy\u200b\u200bPrecision\u200b\u200bRecall\u200b\u200bF1 Score\u200b\u200bCalibration Curve\u200b\u200bPR AUC\u200b\u200bAUC ROC\u200b\u200bMean Absolute Percentage Error (MAPE)\u200b\u200bNormalized Discounted Cumulative Gain (NDCG)\u200b\u200bOther Rank Aware Evaluation Metrics\u200b\u200bDrift Metrics\u200b\u200bData Binning\u200b\u200bPopulation Stability Index (PSI)\u200b\u200bKL Divergence\u200b\u200bJensen Shannon Divergence\u200b\u200bKolmogorov Smirnov Test\u200b\u200bFairness & Bias Metrics\u200b\u200bBias Tracing\u200b\u200bData Quality\u200b\u200bSolving Data Quality With ML Observability \u200bService Monitoring Metrics\u200b\u200bML Service-Level Performance Monitoring Essentials\u200b\u200bExplainability\u200b\u200bExplainability Techniques\u200b\u200bMonitoring Image and Language Models and Embeddings\u200b\u200bKNN Algorithm\u200b\u200bTokenization\u200b\u200bEmbedding Versioning\u200b\u200bDimensionality Reduction\u200b\u200bMonitoring Embedding/Vector Drift\u200b\u200bBERT\u200b\u200bBleu Score and Other Large Language Model Metrics\u200bPreviousArize AINextWhat is LLM Observability?Last modified 12d agoOn this pageML Observability: ResourcesML Observability: FundamentalsWhat Is Observability?Model Evaluation MetricsDrift MetricsFairness & Bias MetricsData QualityService Monitoring MetricsExplainabilityMonitoring Image and Language Models and EmbeddingsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3882, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b5c3549b-fda1-4621-8306-672e4588c767": {"__data__": {"id_": "b5c3549b-fda1-4621-8306-672e4588c767", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/active-learning-and-fine-tuning/export-data-to-notebook"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "71f363f4-b3b0-4460-addc-41487e65ad6f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/active-learning-and-fine-tuning/export-data-to-notebook"}, "hash": "4cfebe0e77c38e1aacaacb31689b90421244a8bb5dc42f2e3b93020334f542b4"}}, "hash": "09522e8c04966c8fa23b0f0a9cedb198c1ca0b25059b30ea0ef6f8c4a3961704", "text": "Export Data to Notebook - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookExport Data to NotebookEasily share data when you discover interesting insights so your data science team can perform further investigation or kickoff retraining workflows.Oftentimes, the team that notices an issue in their model, for example a prompt/response LLM model, may not be the same team that continues the investigations or kicks off retraining workflows. To help connect teams and workflows, Arize enables continued analysis of production data in a notebook environment for fine tuning workflows. For example, a user may have noticed in Arize that this prompt template is not performing well. Prompt Template: \"You are an agent created to accurately translate sentences into the desired language.\"With a few lines of Python code, users can export this data into Phoenix or a Jupyter notebook for further analysis. This allows team members, such as data scientists, who may not have access to production data today, an easy way to access relevant product data for further analysis in an environment they are familiar with. They can then easily augment and fine tune the data and verify improved performance, before deploying back to production. \u200bPhoenix is Arize's open source ML observability library designed for the notebook, helping visualize, troubleshoot, and monitor your LLM, CV, NLP and tabular models.There are two ways export data for further investigation:1.The easiest way is to click the export button on the Embeddings and Datasets pages. This will produce a code snippet that you can copy into a Python environment and install Phoenix. This code snippet will include the date range you have selected in the Arize platform, in addition to the datasets you have selected.Export button on Embeddings tabExport to Phoenix example2.Users can also query Arize for data directly using the Arize Python export client. We recommend doing this once you're more comfortable with the in-platform export functionality, as you will need to manually enter in the data ranges and datasets you want to export.os.environ['ARIZE_API_KEY'] = ARIZE_API_KEY\u200bfrom datetime import datetime\u200bfrom arize.exporter import ArizeExportClientfrom arize.utils.types import Environments\u200bclient = ArizeExportClient()\u200bprimary_df = client.export_model_to_df(    space_id='U3BhY2U6NzU0',    model_id='test_home_prices_LLM',    environment=Environments.PRODUCTION,    start_time=datetime.fromisoformat('2023-02-11T07:00:00.000+00:00'),    end_time=datetime.fromisoformat('2023-03-14T00:59:59.999+00:00'),)LLM (Large Language Models) - PreviousOpen AI Cluster SummarizationNext - dashboardsCreate A DashboardLast modified 1mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4346, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "247c7d24-f82c-47e4-97fb-c7744424e847": {"__data__": {"id_": "247c7d24-f82c-47e4-97fb-c7744424e847", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/admin/1.-setting-up-your-account"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "86e579ca-b483-40af-8171-1294e02480f4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/admin/1.-setting-up-your-account"}, "hash": "d08c42fca54c45ca67ee4da0cd3a18f37a611a1312e3b7367b2a5e83a5f5839e"}}, "hash": "5c6ba60282e2640e822c522c4ecb6bfb0fe56c33b04b63f203f6b2ce273dd1c6", "text": "SSO & RBAC (Role Based Access Control) - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSSO & RBAC (Role Based Access Control)\u200bSingle Sign On \u200bRole Based Access Control (RBAC)\u200b\u200bInvite Users\u200bSingle Sign OnArize supports Single Sign-On via SAML2. Configure your Identity Provider with the following information about the Arize Service:1.SSO URL / ACS (Assertion Consumer Service) : https://app.arize.com/auth/v2/saml2.URI / EntityID: https://app.arize.com3.UserName / NameID format: urn:oasis:names:tc:SAML:1.1:nameid-format:emailAddressIf needed for your Identity Provider, Arize SAML metadata.xml can be downloaded from https://app.arize.com/auth/v2/saml/metadataOnce configured in your Identity Provider, send Arize your IdP metadata URL, or the metadata.xml directly.Role Based Access ControlArize supports full role based access control. Using organizations and spaces, users can be restricted to only have access to data they are permitted. Your Arize account can consist of multiple organizations and spaces. AccountYou are a member of one Arize account. An account consists of one or more organizations.Admin - Has full access to all entities in the account.Member - Access is determined by organization and space roles.ActionAdminMemberUser managementInvite users, remove users, and change user roles\u2705\u274cCreate organizations\u2705\u274cOrganizationsOrganizations represent a single business unit and help you silo work across different areas of your business. Within your account, you can be a member of multiple Organizations. An Organization may consist of one or more spaces.Admin - Has full access to all entities in the organization.Member - Has partial access at the organizational level. Can create spaces and integration keys. They can only edit or delete integration keys they create. Space access is determined by space role.Read-only Member - Has read-only access to the organization. Cannot create spaces nor integration keys. Public space access is read-only unless added to the space. Private space access is determined by space role.ActionAdminMemberRead-only MemberOrganization Member managementInvite and remove members and change their roles\u2705\u274c\u274cCreate spaces\u2705\u2705\u274cView public spaces\u2705\u2705\u2705Edit public spaces\u2705\u2705\u274c (unless explicitly added)View private spaces\u2705If added to space: \u2705If not: \u274cIf added to space: \u2705If not: \u274cCreate integration keys\u2705\u2705\u274cEdit / delete integration keys\u2705If creator: \u2705\nIf not: \u274c\u274cSpacesSpaces represent an environment for groups of models. You can be a member of multiple spaces across multiple organizations within your account. Spaces can either be public or private. Public Spaces are visible to all members (regardless of role) of the parent organization. Private spaces are only visible to explicitly invited members of the space.Admin - Has full access to all entities in the space.Member - Has write access to entities associated to models (e.g., monitors) but does not have access to API keys, model creation, or membership management.Read-only Member - Has read-only access to entities in the space.ActionAdminMemberRead-only MemberAccess to SDK API Key\u2705\u274c\u274cSpace Member managementInvite and remove members and change their roles\u2705\u274c\u274cDelete models\u2705\u274c\u274cCreate and delete file import jobs\u2705\u274c\u274cUpdate model settings\u2705\u2705\u274cCreate/Edit Dashboards\u2705\u2705\u274cCreate/Edit Monitors\u2705\u2705\u274cCreate/Edit Projects \u2705\u2705\u274cView model entities (monitors, dashboards etc.)\u2705\u2705\u2705Invite UsersWant to invite team members? 1.Go to 'Account Settings'  --> Members --> Add Members2.Go to 'Org Settings'  --> Members --> Add Members3.Go to 'Space Settings'  --> Members --> Add MembersWhen adding a member, you will select their permission level for your Account, Organization, and Space. Adding a user to a workspaceJIT User ProvisioningTo enable just-in-time user provisioning, you must also provide an attribute Name or http://schemas.xmlsoap.org/ws/2005/05/identity/claims/name that maps to the full name of the user. Arize also supports automated user role assignment alongside JIT user provisioning to allow you to enforce role based access control.  You can declare a mapping between values of a specified SAML user attribute defined within your idP and each value's corresponding Arize user role assignment.  After this has been configured, the Arize platform, when provisioning a new user via SSO, will automatically assign the appropriate Arize roles for the user according your role mapping configuration. Contact support to make these configuration mappings. Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousInstallationNext - ResourcesProduct FAQLast modified 1mo agoOn this pageSingle Sign OnRole Based Access ControlAccountOrganizationsSpacesInvite UsersJIT User ProvisioningSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6361, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c55e5ace-c87b-4d96-a750-b3ee3d539dec": {"__data__": {"id_": "c55e5ace-c87b-4d96-a750-b3ee3d539dec", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eff4c1f1-6201-45e5-8636-6227b8232e63", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics"}, "hash": "415c5f309b1d8bede42452a37e45054ece0532d01fa7f01eda51aabff45ae806"}}, "hash": "98d40a02be9a174d4b472b0c1d1361b56ccd19eb7ae88e139bf2cfae64b80188", "text": "Custom Metrics Query Language - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCustom Metrics Query LanguageDefine metrics tailored to your ML needsCustom Metrics OverviewCustom metrics allow you to define a metric tailored to your ML needs. Define metrics such as business KPIs, custom performance calculations, weighted averages, etc. Use custom metrics across the platform in dashboards, monitors, and performance tracing.Derive new metrics using a combination of existing model dimensions and functions using a SQL-like query language. This allows you to combine your model's features, tags, predictions, and actuals using aggregations, operators, and metric functions.Use this page to learn: 1.\u200bThe Arize Query Language \u200b2.\u200bHow to set up a custom metric \u200b3.\u200bHow to use your custom metric Arize Query LanguageCustom metrics are defined using a bespoke easy-to-use SQL-like syntax. While the Arize query language and SQL are very similar, the Arize query language deviates from SQL by handling time granularity and time ranges within the Arize platform. This allows you to easily switch time ranges and granularities without changing your query. Custom Metric ExampleThis example will compare constructing a custom metric in SQL versus the Arize SQL-like query language. Using a loan model, we'll calculate the average dollar loss as a percentage of total loan volume. Additionally, we want to filter for loan amounts greater than $1000, and where the state is 'CA'. We want to aggregate the result daily. For more example use cases, please refer to our examples page here. SQL:SELECT\tdate_trunc('day', timestamp) AS ts, SUM(loan_amount - repayment_amount) / SUM(loan_amount) AS avg_lossFROM \tAuto_loans_modelWHERE state = 'CA'AND loan_amount > 1000AND timestamp > '2022-01-01' AND timestamp < now()GROUP BY 1 \u200bArize Query Language: SELECTSUM(loan_amount - repayment_amount) / SUM(loan_amount)FROM modelWHERE state = 'CA'AND loan_amount > 1000Expressing the same example with the Arize query language looks similar to SQL but is simplified in comparison by removing time granularity and timestamps. The time parameters are handled automatically for you by the Arize date picker. Learn more about our custom syntax here. \u200bNavigating to the Custom Metric EditorNavigate to the custom metric editor in the top navigation bar of any model. Click on 'Custom Metrics' to uncover the editor. Custom Metric Editor The custom metric editor allows you to write your queries with syntax validation and auto-completion of dimension names. You will be able to preview your query before saving it.Name and describe your new metric to adequately convey your new metric's purpose when using Arize collaboratively. Documentation Similar to a SQL editor, use the documentation panel to familiarize yourself with the custom syntax via the syntax reference and model schema explorer. Using A Custom MetricCustom metrics have the same functionality as any other metric within the Arize platform. Use custom metrics in monitors, dashboards, and performance tracing to ensure your model works as expected. DashboardsUse custom metrics in a dashboard to focus your troubleshooting efforts in one place.Custom Metrics are supported in the 'Time Series' widget. Add a custom metric to the plot by selecting the model for your custom metric. Under 'Metric', select 'Custom Metric', and select the metric you want to add. MonitorsMonitor custom metrics to get alerted when something goes awry. From the 'Custom Metrics' page, navigate to the '+ actions' and click 'Create Monitor'. From the performance metric selector, click on 'Custom Metric' to pick from your list of saved custom metrics. From there, follow the monitor setup workflow.Performance TracingUtilize custom metrics on the performance tracing page to drill into problematic features and slices that affect your metric. From the 'Performance Tracing' page, click on the metric selector and select 'Custom Metric' to pick from your list of saved custom metrics. API Reference - PreviousRest APINextCustom Metric SyntaxLast modified 6mo agoOn this pageCustom Metrics OverviewArize Query LanguageNavigating to the Custom Metric EditorUsing A Custom MetricSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5891, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cdded5de-231c-428b-94be-fbd288802449": {"__data__": {"id_": "cdded5de-231c-428b-94be-fbd288802449", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3a76cf24-098f-4dcd-b7a0-274532106c03", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference"}, "hash": "476e8f580ecdcbfeafddaa1f7190794d46a9f1c9b7522c84c309f25a0ec7dba5"}}, "hash": "06c68d3eccfe120a509dae5c088ac1876005bf2ccb1a2ba471a1dfa536a429e7", "text": "Data API - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData APIPython referenceDashboard and Widget APIData API - UI Visualization\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookData APIData APIs DocumentationArize enables teams to continue analysis of their production data in notebooks. With a few lines of Python code, users can export their data into Phoenix or a Jupyter notebook for further analysis. There are two ways to do this:1.The easiest way is to click the export button on the Embeddings, Datasets, or Performance tracing pages. This will produce a code snippet that you can copy into a Python environment. This code snippet will include the date range you have selected in the Arize platform, in addition to the datasets you have selected.Export button the Datasets tabExport button on Embeddings tabExport to Phoenix example2.Users can also query Arize for data directly using the Arize Python export client. We recommend doing this once you're more comfortable with the in-platform export functionality, as you will need to manually enter in the data ranges and datasets you want to export.os.environ['ARIZE_API_KEY'] = ARIZE_API_KEY\u200bfrom datetime import datetime\u200bfrom arize.exporter import ArizeExportClientfrom arize.utils.types import Environments\u200bclient = ArizeExportClient()\u200bprimary_df = client.export_model_to_df(    space_id='U3BhY2U6NzU0',    model_name='test_home_prices_LLM',    environment=Environments.PRODUCTION,    start_time=datetime.fromisoformat('2023-02-11T07:00:00.000+00:00'),    end_time=datetime.fromisoformat('2023-03-14T00:59:59.999+00:00'),)For more examples and code, visit our reference section for the export API.Resources \u200bPython Export API reference\u200bQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousAPI ChangelogNextPython referenceLast modified 1mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3447, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9895aa09-ee4e-4f00-bd2b-8f6a8546d668": {"__data__": {"id_": "9895aa09-ee4e-4f00-bd2b-8f6a8546d668", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0c20e5d0-ee35-499b-a786-9fd2a19b56b3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "hash": "5ed34f8ec197f489d521fcd1d14076adaa3e4fcd418fb78f6ab3b6d935208f3d"}, "3": {"node_id": "9626e825-0139-4faf-85f1-49bf41ebc6b0", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "hash": "df8dcb92da0d4e0ff4e0c53e93e23812012d7136a48ecbff2e86af5d80192cb9"}}, "hash": "027c61ef8d1b0238e261651c491bb17815f61c8174c8fb9db1a8f8245c3a8ccf", "text": "Python Single Record - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPython Single RecordStream Logging API- Designed for record by record sending of data to ArizeThis API is designed for record-by-record data ingestion. It is not designed for a large set of data. Check out the arize.pandas for a faster experience for batch logging.\u200b\u200b\u200b The most commonly used functions/objects are: \u200bClient \u2014 Initialize to begin logging model data to Arize\u200blog \u2014 Log inferences record-by-recordInstall the Packagepip install arizeInitialize Arize ClientInitialize Arize Clientto begin logging model inferences.from arize.api import Client\u200b# create Arize clientSPACE_KEY = \"YOUR_SPACE_KEY\" API_KEY = \"YOUR_API_KEY\" \u200barize_client = Client(space_key=SPACE_KEY, api_key=API_KEY) Single Record ExamplesFor examples and interactive notebooks, see https://docs.arize.com/arize/examples\u200bExample 1: Logging Features, Tags, and Predictions Only# example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11, } # example tagstags = { 'age': 30, 'zip_code': '94610', 'device_os': 'iOS', 'server_node_id': 12, }\u200b# example embeddingsembedding_features = { 'image_embedding': Embedding(            vector=np.array([1.0, 2, 3]),            link_to_data='https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png', ), 'nlp_embedding_sentence': Embedding(            vector=pd.Series([4.0, 5.0, 6.0, 7.0]),            data='This is a test sentence', ), 'nlp_embedding_tokens': Embedding(            vector=pd.Series([4.0, 5.0, 6.0, 7.0]),            data=['This', 'is', 'a', 'sample', 'token', 'array'], ), }\u200b# log the predictionresponse = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882,    prediction_label=('Fraud',.4)    features=features,    embedding_features=embedding_features    tags=tags)\u200b# Listen to response code to ensure successful deliveryres = response.result()if res.status_code == 200: print('Success sending Prediction!')else: print(f'Log failed with response code {res.status_code}, {res.text}')Example 2: Logging Features & Predictions First, Then Delayed Actuals# example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11, }\u200b# log the features & predictionresponse = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882,    features=features,    prediction_label=('Fraud',.4),    tags=tags)\u200bres = response.result()if res.status_code == 200: print('Success sending Prediction!')else: print(f'Log failed with response code {res.status_code}, {res.text}')\u200b# log the actualactual_response = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    actual_label=('Fraud',1),    tags=tags)\u200b# Listen to response code to ensure successful deliveryres = actual_response.result()if res.status_code == 200: print('Success sending Actual!')else: print(f'Log failed with response code {res.status_code}, {res.text}')\u200bExample 3: Logging Features, Predictions and Actuals Together# example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11, }\u200b# log the prediction, actual, and featuresresponse = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882,    features=features,    prediction_label=('False', .4),    actual_label=('True', 1),    tags=tags)\u200b# Listen to response code to ensure successful deliveryres = response.result()if res.status_code == 200: print('Success sending Prediction and Actual!')else: print(f'Log failed with response code {res.status_code}, {res.text}')Example", "start_char_idx": 0, "end_char_idx": 5957, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9626e825-0139-4faf-85f1-49bf41ebc6b0": {"__data__": {"id_": "9626e825-0139-4faf-85f1-49bf41ebc6b0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0c20e5d0-ee35-499b-a786-9fd2a19b56b3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "hash": "5ed34f8ec197f489d521fcd1d14076adaa3e4fcd418fb78f6ab3b6d935208f3d"}, "2": {"node_id": "9895aa09-ee4e-4f00-bd2b-8f6a8546d668", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}, "hash": "027c61ef8d1b0238e261651c491bb17815f61c8174c8fb9db1a8f8245c3a8ccf"}}, "hash": "df8dcb92da0d4e0ff4e0c53e93e23812012d7136a48ecbff2e86af5d80192cb9", "text": "4: Logging Predictions, Actuals, and SHAP Togethe# example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11, }\u200b# example SHAP values shaps = { 'state': 0.23, 'city': 0.31, 'merchant_name': 0.10, 'pos_approved': 0.02, 'item_count': 0.06, 'merchant_type': 0.11, 'charge_amount': 0.29, }\u200b# log the prediction, actual, features, and shapresponse = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882,    features=features,    prediction_label=('False', .4),    actual_label=('True',1),    tags=tags,    shap_values=shaps) # Listen to response code to ensure successful deliveryres = response.result()if res.status_code == 200: print('Success sending Prediction, Actual, and SHAPs!')else: print(f'Log failed with response code {res.status_code}, {res.text}')Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousutils.types.EnvironmentsNextClientLast modified 1mo agoOn this pageInstall the PackageInitialize Arize ClientSingle Record ExamplesExample 1: Logging Features, Tags, and Predictions OnlyExample 2: Logging Features & Predictions First, Then Delayed ActualsExample 3: Logging Features, Predictions and Actuals TogetherExample 4: Logging Predictions, Actuals, and SHAP TogetheSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 5958, "end_char_idx": 7713, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7445d565-1130-444b-900b-088601916ed9": {"__data__": {"id_": "7445d565-1130-444b-900b-088601916ed9", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "77ad6520-d54e-4fcb-b3c7-f1013fac33ba", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas"}, "hash": "00def47035a815cb670ad8210268c23296914714642ddfcbf74a523d5ba52548"}}, "hash": "b988591d1203814d4431fca22822c6ff4556f029dfbaa5c373b780c6df905e65", "text": "Python Pandas (batch) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)ClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsPython Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPython Pandas (batch)Batch Logging - Designed for sending batches of data to ArizeUse the arize Python library to monitor machine learning predictions with a few lines of code in a Jupyter Notebook or a python server that batch processes backend data.\u200b\u200b\u200b The most commonly used functions/objects are:\u200bClient \u2014 Initialize to to begin logging model data to Arize\u200bSchema \u2014 Organize and map column names containing model data within your Pandas dataframe.\u200blog \u2014 Log inferences within a dataframe to Arize via a POST request.Python Pandas ExampleFor examples and interactive notebooks, see https://docs.arize.com/arize/examples\u200b# install and import dependencies !pip install -q arize\u200bimport datetime\u200bfrom arize.pandas.logger import Clientfrom arize.utils.types import ModelTypes, Environments, Schema, Metricsimport numpy as npimport pandas as pd\u200b# create Arize clientSPACE_KEY = \"SPACE_KEY\" API_KEY = \"API_KEY\" arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b#define schema schema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"predicted_label\",    actual_label_column_name=\"actual_label\",    feature_column_names=feature_column_names)\u200b#log dataresponse = arize_client.log(    dataframe=df,    schema=schema,    model_id=\"binary-classification-metrics-only-batch-ingestion-tutorial\",    model_version=\"1.0.0\",    model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION],    validate=True,    environment=Environments.PRODUCTION)Follow this example in Google Colab: Google ColaboratoryInstall the Packagepip install arize #Install the Arize SDKpip install arize[AutoEmbeddings] # Install extra dependencies to autogenerate embeddingspip install arize[LLM_Evaluation] # Install extra dependencies to compute LLM evaluation metricsInitialize Arize ClientInitialize Arize Client , Schema , ModelTypes, Environments, and Metrics to begin logging a Pandas dataframe: from arize.pandas.logger import Clientfrom arize.utils.types import ModelTypes, Environments, Schema, MetricsConvert Mixed-Type Columns To FloatData ingestion rejects datasets with mixed type columns. These columns should be converted to Float before sending. Below is an example of a mixed type column in Pandas an how to convert it.import pandas as pd\u200b# Example Series with mixed typesmixed = pd.Series([1, \"\", 2]) # it has numbers and stringsmixed.dtype # dtype('O')\u200b# It should be converted to float# Replace \"\" with NaNmixed = mixed.replace(\"\", float(\"NaN\"))mixed.dtype # dtype('float64')Benchmark TestsThe ability to ingest data with low latency is important to many customers. Below is a benchmarking colab that demonstrates the efficiency with which Arize uploads data from a Python environment.Sending 10 Million Inferences to Arize in 90 Seconds\u200bColab Link\u200bExplainability & Fairness - PreviousBias Tracing (Fairness)NextClientLast modified 1mo agoOn this pagePython Pandas ExampleInstall the PackageInitialize Arize ClientConvert Mixed-Type Columns To FloatBenchmark TestsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4954, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "70fe58b2-cc22-4b22-b879-6096c39a4de1": {"__data__": {"id_": "70fe58b2-cc22-4b22-b879-6096c39a4de1", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fb71ff94-13dd-4d4a-b987-1adb6f991e76", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api"}, "hash": "5198cd4c94e69d0328f41e86187bdd5db6e9ca218a1a951a954f32c4d3085ad4"}}, "hash": "d01d108bfcda5edf69a15607457c28f6e9fcad1942e87914d8144ee66a9f36a2", "text": "GraphQL API - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGraphQL APIWhat is GraphQL? GraphQL is a query language for APIs that provides a programmatic way of accessing (query) and modifying (mutation) entities within the Arize platform, offering precise and flexible queries for an in-depth integration with your existing tooling and infrastructure. For a brief overview of GraphQL itself, please consult our introduction.Queries on the Arize GraphQL API are available to all accounts. Mutations are available to enterprise-grade customers. To upgrade your account contact [email\u00a0protected].Why Use The Arize GraphQL API?The Arize GraphQL API enables customers to integrate Arize with their internal systems for a repeatable and consistent setup. Use the API to: Bulk create custom monitors with complex filters or baselinesExport existing monitor configuration, make edits, and bring edits back into ArizeBuild automation by integrating Arize with internal servicesGraphQL Benefits for the Arize APIWe picked GraphQL as our query language for our API for a few key reasons: 1.GraphQL operates with well-defined schemas and types which allow users to automatically document the API and validate queries and mutations without relying on the server.  2.GraphQL enables users to specify their returned data in a single query. Users get to precisely define the data they want \u2014 which means querying less to get what you need. This saves time, reduces computational load, and lessens network expenses. 3.GraphQL is Language agnostic. This means you can implement our GraphQL API in your preferred language for a more intuitive understanding. We would love to hear from you! Please reach out to [email\u00a0protected] and join our community slack. Let's build great things together.About GraphQLThe GraphQL data query language is:A specification. The spec determines the validity of the schema on the API server. The schema determines the validity of client calls.Strongly Typed. The schema defines an API's type system and all object relationships.Introspective. A client can query the schema for details about the schema.Hierarchical. The shape of a GraphQL call mirrors the shape of the JSON data it returns. Nested fields let you query for and receive only the data you specify in a single round trip.An application layer. GraphQL is not a storage model or a database query language. The graph refers to graph structures defined in the schema, where nodes define objects and edges define relationships between objects. The API traverses and returns application data based on the schema definitions, independent of how the data is stored.PreviousCustom Metric ExamplesNextHow To Use GraphQLLast modified 2mo agoOn this pageWhat is GraphQL? Why Use The Arize GraphQL API?About GraphQLSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4601, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e6e0149f-3d72-4cc8-bf4e-95b01c65c98a": {"__data__": {"id_": "e6e0149f-3d72-4cc8-bf4e-95b01c65c98a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1b9cac92-fee0-4d19-8dbb-2e52ccdf7389", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk"}, "hash": "2c5c0059d8ef3490c33caff274dc0ee073e2fe4f0749cfc3828902bf9d913f3c"}}, "hash": "7a78733388a6132855ca50622f13836dd45dc1320e622d8eb2a3c56729cc6a82", "text": "Java SDK - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookJava SDKArize AI for Model Monitoring, Troubleshooting, and ExplainabilityOur Java client can be used to instrument production services to observe your machine learning models and their features, predicted labels, and actual labels over time with a few lines of code. Requires Java 8 LTS or above.ArtifactsFor Maven projects, you can import the artifacts as shown below. The latest version can be found on the maven repository for com.arize.<!-- The client --><dependency>  <groupId>com.arize</groupId>  <artifactId>arize-api-client</artifactId>  <version>2.0.3</version></dependency>Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousutils.types.EnvironmentsNextConstructorLast modified 1yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2508, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4d698582-91a2-405d-a0c6-56e04ac5c27c": {"__data__": {"id_": "4d698582-91a2-405d-a0c6-56e04ac5c27c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "36dc69a0-c0e1-4f3f-b321-7ec72b93edd3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk"}, "hash": "d0b10bfdd1d182ea4fc30d2e5d5302b8d5d7eada4172b52160d07d1c50a3deff"}}, "hash": "8182354bd2b48f2a5d767e33a162c81578902a0c66f01c28e35ef0a5d836738d", "text": "R SDK - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKClient$new()Client$log()Rest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookR SDKArize AI for Model Monitoring, Troubleshooting, and ExplainabilityUse the Arize R package to monitor machine learning predictions to observe your machine learning models and their features, predicted labels, and actual labels with just few lines of code.Installing the package\u200binstall.packages(\"devtools\")devtools::install_github(\"Arize-ai/client_r\")library(arize)Arize R SDK requires R Version >= R 4.1.2Instrumenting your model\u200bClient$new()- initialize the client used to publish predictionsPreviouslogTrainingRecordsNextClient$new()Last modified 1yr agoOn this pageInstalling the packageInstrumenting your modelSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2355, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4eeb734c-9289-4434-8524-fa7eb97b4c0f": {"__data__": {"id_": "4eeb734c-9289-4434-8524-fa7eb97b4c0f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "53f4e49e-24fb-49ff-a938-e2dee493548b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "76a136af6aa4af4ca2da326f8f800a4efb15c657c1bb11e4cf213ae266162c3f"}, "3": {"node_id": "89122fbf-9cbf-44c7-8ae0-52b1f0123d96", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "69e3e22ca11cfa1ae172e22fe2d91ad09a2564d51eda5c0474db3cbe2d4e9b9a"}}, "hash": "af68175d65cd6a3032dc558b42e023718a3c0c37e76c9b9021cd718d06525a6f", "text": "Rest API - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRest APIArize AI for Model Monitoring, Troubleshooting, and ExplainabilityOverviewArize's APIs are the main ingresses for data which powers our platform. Most applications will use an existing SDK in the language of your choice, but it's important to know what the underlying API looks like first in case you want to work in a language without a current SDK implementation.AuthenticationArize uses API keys in conjunction with a Space key in order to authenticate request. You will receive your keys once you sign up for our product.\n\nYour API and Space keys are the keys to your data castle so be sure to keep them secure. Do not share your keys in public forums including Github, StackOverflow, logs, etc.\n\nThe API key is authenticated via auth header, use -H 'Authorization: API_KEY_VALUE' while the Space key is included on the body of the requestResponse CodesArize uses conventional HTTP response codes to convey resulting success or failure of a given request. Codes in the 2XX range indicate success, 4XX range indicate content failure, 5XX indicate errors with Arize's edge servers.Status CodeMessageReason200OKSuccess403cannot access request headersFailure when accessing incoming request's headers403must provide authorization header\u0000Missing Authorization header403unable to validate authorization headerSpace key is not valid403invalid api-keyAPI Key is not valid400log must include prediction or actualPrediction or Actual is a required field and it's not present400invalid feature typeFeature data type is not supported400timestamp must range from now back to T-90 daysRecord timestamp can only be backdated up to 90 days500Internal service error, contact ArizeInternal error processing messages - Contact ArizeFull RecordTo send an individual prediction record, you should hit Arize's log API\nhttps://api.arize.com/v1/log Supported label typesLabeldata type\"numeric\"double\"score categorical\"Tuple (string, float)Request Example (numeric label)curl --request POST 'https://api.arize.com/v1/log' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"model_id\":\"example_model_id\",   \"prediction_id\":\"ef00f52c-d6d4-4e48-84cd-70166b3f423f\",   \"prediction\":{      \"timestamp\":\"2020-10-02T00:37:30.208687Z\",   //Optional, defaults to now()      \"model_version\":\"v0.1\",      \"label\":{         \"numeric\":0.1      },      \"features\":{         \"feature_1_float\":{            \"double\":0.6604474844066184         },         \"feature_2_str\":{            \"string\":\"str val\"         },         \"feature_4_bool\":{            \"string\":\"True\"         },         \"feature_2_float\":{            \"double\":0.02876647860632975         },         \"feature_3_float\":{            \"double\":0.3358383777892534         },         \"feature_0_np_ll\":{            \"int\":\"77\"         },         \"feature_3_bool\":{            \"string\":\"True\"         },         \"feature_1_str\":{            \"string\":\"str val\"         },         \"feature_1_np_ll\":{            \"int\":\"1\"         },         \"feature_4_float\":{            \"double\":0.9681327640084113         },         \"image_embedding\":{            \"embedding\":{               \"vector\":[                  1.0,                  2.0,                  3.0               ],               \"link_to_data\":\"https://my-bucket.s3.us-west-2.amazonaws.com/puppy.png\"            }         },         \"feature_2_bool\":{            \"string\":\"True\"         },         \"feature_2_np_ll\":{            \"int\":\"91\"         },         \"feature_0_str\":{            \"string\":\"str val\"         },         \"feature_4_np\":{            \"double\":0.543297819558724         },         \"feature_1_bool\":{            \"string\":\"True\"         },         \"feature_3_np\":{            \"double\":0.5149428483266209         },        ", "start_char_idx": 0, "end_char_idx": 5212, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "89122fbf-9cbf-44c7-8ae0-52b1f0123d96": {"__data__": {"id_": "89122fbf-9cbf-44c7-8ae0-52b1f0123d96", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "53f4e49e-24fb-49ff-a938-e2dee493548b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "76a136af6aa4af4ca2da326f8f800a4efb15c657c1bb11e4cf213ae266162c3f"}, "2": {"node_id": "4eeb734c-9289-4434-8524-fa7eb97b4c0f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "af68175d65cd6a3032dc558b42e023718a3c0c37e76c9b9021cd718d06525a6f"}, "3": {"node_id": "855bff49-bbd1-4c04-881f-a3e0b60cc0d8", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "89f2849900e1d26cdbdfbebce48d33cdf736068cb5700dadfbcc093530cd3fc0"}}, "hash": "69e3e22ca11cfa1ae172e22fe2d91ad09a2564d51eda5c0474db3cbe2d4e9b9a", "text": "\"feature_4_str\":{            \"string\":\"str val\"         },         \"nlp_embedding_sentence\":{            \"embedding\":{               \"vector\":[                  4.0,                  5.0,                  6.0,                  7.0               ],               \"link_to_data\":\"\",               \"raw_data\":{                  \"tokenArray\":{                     \"tokens\":[                        \"This is a test sentence\"                     ]                  }               }            }         },         \"feature_2_np\":{            \"double\":0.29966708188607294         },         \"feature_3_np_ll\":{            \"int\":\"46\"         },         \"feature_1_np\":{            \"double\":0.8751167134832335         },         \"feature_0_np\":{            \"double\":0.3854629460534247         },         \"feature_0_bool\":{            \"string\":\"True\"         },         \"feature_4_np_ll\":{            \"int\":\"74\"         },         \"feature_0_float\":{            \"double\":0.5696514798125208         },         \"feature_3_str\":{            \"string\":\"str val\"         },         \"nlp_embedding_tokens\":{            \"embedding\":{               \"vector\":[                  4.0,                  5.0,                  6.0,                  7.0               ],               \"link_to_data\":\"\",               \"raw_data\":{                  \"tokenArray\":{                     \"tokens\":[                        \"This\",                        \"is\",                        \"a\",                        \"test\",                        \"token\",                        \"array\"                     ]                  }               }            }         }      },      \"tags\":{         \"tag_str\":{            \"string\":\"arize\"         },         \"tag_int\":{            \"int\":\"0\"         },         \"tag_double\":{            \"double\":20.2         },         \"tag_bool\":{            \"string\":\"True\"         }      }   },   \"actual\":{      \"label\":{         \"numeric\":0.1      },      \"tags\":{         \"tag_str\":{            \"string\":\"arize\"         },         \"tag_int\":{            \"int\":\"0\"         },         \"tag_double\":{            \"double\":20.2         },         \"tag_bool\":{            \"string\":\"True\"         }      }   },   \"space_key\":\"YOUR SPACE KEY HERE\",   \"environment_params\":{      \"production\":{       }   }}'ActualTo send an individual actual record, you should hit Arize's log API\nhttps://api.arize.com/v1/log Supported label typesLabeldata type\"numeric\"double\"score categorical\"Tuple (string, float)Request Example (score categorical label)curl --request POST 'https://api.arize.com/v1/log' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"model_id\":\"example_model_id\",                          //Required   \"prediction_id\":\"027ed30c-6333-4eab-9492-61e117b1b46f\", //Required   \"actual\":{                                              //Required      \"label\":{         \"score_categorical\":{            \"score_category\":{               \"category\":\"orange\",               \"score\":1.0            }       ", "start_char_idx": 5213, "end_char_idx": 8210, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "855bff49-bbd1-4c04-881f-a3e0b60cc0d8": {"__data__": {"id_": "855bff49-bbd1-4c04-881f-a3e0b60cc0d8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "53f4e49e-24fb-49ff-a938-e2dee493548b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "76a136af6aa4af4ca2da326f8f800a4efb15c657c1bb11e4cf213ae266162c3f"}, "2": {"node_id": "89122fbf-9cbf-44c7-8ae0-52b1f0123d96", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}, "hash": "69e3e22ca11cfa1ae172e22fe2d91ad09a2564d51eda5c0474db3cbe2d4e9b9a"}}, "hash": "89f2849900e1d26cdbdfbebce48d33cdf736068cb5700dadfbcc093530cd3fc0", "text": " }      }   },   \"space_key\":\"YOUR SPACE KEY HERE\",                      //Required   \"environment_params\":{                                  //Required      \"production\":{       }   }}'Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousClient$log()Next - API ReferenceCustom Metrics Query LanguageLast modified 11mo agoOn this pageOverviewAuthenticationResponse CodesFull RecordSupported label typesRequest Example (numeric label)ActualSupported label typesRequest Example (score categorical label)SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8211, "end_char_idx": 8973, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a3729128-ddbe-4853-a579-c22f14a80a61": {"__data__": {"id_": "a3729128-ddbe-4853-a579-c22f14a80a61", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c90e974b-5a83-477f-8f98-8f25edaca229", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards"}, "hash": "6e4c35254bb6da1e3073e03510ee4c82ea7849864ed704448048e2f4f3cd1daa"}}, "hash": "c73a0c9fdbdbfac0434170d897e29accc9d5d4afcda22a134646c65c2a5feaca", "text": "Create A Dashboard - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesWidgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCreate A DashboardPowerful Analytical Workbench for ML EngineersOverviewPre-configured dashboard templates enable teams to quickly view the health of their models, while  customized dashboards allow for ad hoc analysis. Using dashboard visualizations of statistical distributions and performance heatmaps help focus teams on troubleshooting efforts.Creating a Dashboard The dashboards in Arize are designed to allow teams to deeply analyze and troubleshoot their models. We offer templates that make it quick and easy to launch dashboards for every model you want to monitor. There are two main ways to create dashboards in the system:Use a Template: This is a great starting point if you want a general visualization of the health of your models - most users start with dashboard templates, which they can then customize to suit their specific needs. TemplatesStart from a Blank Dashboard: Alternatively, you can build dashboards from scratch if you already have a good sense of the model dimensions you want to monitor and the type of analysis you wish to performDashboard WidgetsDashboards are comprised of widgets designed for different types of analysis across your training, validation, and production environments:Distribution Widget for analyzing data distribution changes over Feature, Prediction, and Actuals.Distribution WidgetsTimeseries Widget for analyzing time-based data. There are two chart types available for this widget:Data Metrics - input value over time displayed as Count, Average, or Percent / Percent ErrorEvaluation Metrics - Accuracy, Precision, Recall, F1, Sensitivity, Specificity, False Positive Rate, False Negative Rate, MAE, MSE, RMSE, or MAPETimeseries WidgetsStatistic Widget for getting an aggregate statistic. Data Metrics and Evaluation Metrics charts are also available for this widget. Statistic WidgetsAdding a widget to a DashboardTo add a widget, simply:Click the Edit Dashboard icon in the top right corner.Select or drag and drop the widget onto an area of the dashboard.You can easily change the size of each widget once it's on the dashboard, and you can drag and drop to new areas of the dashboard. Slicing and Filtering DashboardsYou can slice and filter dashboards by any model, model version, and model dimension, including feature, prediction score/class, or actual score/class.Compare Across Model EnvironmentsYou can set up a widget to compare across model environments (e.g. Production vs. Validation).Comparing Production vs. Validation Data in Dashboard WidgetTo set up a production vs. validation distribution graph in your dashboard:1: Create a Dashboard > Click Edit Dashboard > Add a New Widget to the Dashboard, and select 'Distribution Widget' 2: Set up Production Distribution for this feature in Plot 1. Production data in the dashboard is displayed relative to the date picker selection. The date picker always adjusts production data. 3: Set up Validation Distribution for this feature in Plot 2. The model environment drop down for the validation data allows selection of the batch name. We support multiple batches for the validation data. Once the batch is chosen, the platform automatically shows the date for that batch of data. This fixed batch of data can then be compared against production data of any time frame.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelActive Learning and Fine Tuning - PreviousExport Data to NotebookNextTemplatesLast modified 7mo agoOn this pageOverviewCreating a Dashboard Dashboard WidgetsSlicing and Filtering DashboardsCompare Across Model EnvironmentsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5335, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "06be9478-5ebb-45aa-b718-fb778db962b8": {"__data__": {"id_": "06be9478-5ebb-45aa-b718-fb778db962b8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7b4639f8-7766-4ee0-aa4f-0ce22a947005", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data"}, "hash": "3bf50a4ac0a76ffaa559aba3aeb9f5faa15a57e447c65c339ddedfae05bf47e5"}}, "hash": "3d69851027472c8bee569175b94d152ba321cba10d83bdbcac9ee17efd3d23c7", "text": "Generate Embeddings - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsHow to Generate Your Own EmbeddingLet Arize Generate Your EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGenerate EmbeddingsWhat is an Embedding? Embeddings are vector representations of data. Embeddings are everywhere in modern deep learning, such as transformers, recommendation engines, layers of deep neural networks, encoders, and decoders.Why Embeddings for Analyzing Deep Learning Models?Data drift in unstructured data like images is complicated to measure. The measures typically used for drift in structured data do not extend to unstructured data. The general challenge with measuring unstructured data drift is that you need to understand the change in relationships inside the unstructured data itself. How to Generate Embeddings Arize supports 2 approaches - bring your own embeddings or have Arize generate them for you. \u200bBring/Generate Your Own Embedding\u200b\u200bLet Arize Generate Your Embeddings\u200bWhy are Embeddings So Important?Embeddings are foundational because:1.They can represent images, audio signals, and even large chunks of structured data.2.They provide a common mathematical representation of your data3.They compress your data4.They preserve relationships within your data5.They are the output of deep learning layers providing comprehensible linear views into complex non-linear relationships learned by modelsExample of Image, image embedding, and the embedding projection to 2-D\u200bAdditional ResourcesCheck out our tutorials on how to send embeddings to Arize for different use cases. Getting Started: Quick GuidesCategoryCodeMulti-Class Sentiment Classification NLP\u200bColab Link\u200bNamed Entity RecognitionNLP\u200bColab Link\u200bImage Classification CV\u200bColab Link\u200bLearn more about embeddings and troubleshooting with Arize:Blog: Monitor Unstructured Data with Arize\u200bBlog: Getting Started With Embeddings is Easier Than You Think\u200bTalk: Embedding Usage and Visualization In Modern ML Systems\u200bQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelTracing - PreviousData Quality TroubleshootingNextHow to Generate Your Own EmbeddingLast modified 12d agoOn this pageWhat is an Embedding? Why Embeddings for Analyzing Deep Learning Models?How to Generate Embeddings Why are Embeddings So Important?Additional ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3941, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d5bc9414-232e-4e2e-afb8-0d425453d245": {"__data__": {"id_": "d5bc9414-232e-4e2e-afb8-0d425453d245", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1fd5a0ad-5fd4-418d-99ba-1926a61187ab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "hash": "85d0b8a328207a0e02417a2ba420222106f5aa8a6b3da3d2b77dc0ab319d6c41"}, "3": {"node_id": "f74e2cbd-87c0-4073-b110-d72e4c56cf4d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "hash": "1c144545b58b04941b18149470536c8d6c3e126489b08bc3b0d3dd4a45fb6d54"}}, "hash": "fea41e9ca7019a32bebadb90bec7bbdbe14efc2af863417393c0ca75fc5e5e87", "text": "Embedding & Cluster Analyzer - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbedding & Cluster AnalyzerWhat is an Embedding Projector ? Embedding Projectors are a great tool in visualizing and interpreting embeddings. In order to do so, we have to apply an algorithm to reduce the dimensionality of the embeddings to 2D/3D. UMAP (Uniform Manifold Approximation and Projection) is a dimensionality reduction technique that belongs to the neighbor graph category. Arize uses it to create a lower dimensional representation (2D or 3D) of your dataset, represented by embedding vectors. Learn more about UMAP in comparison to other neighbor graph algorithms here. How to use UMAP?1.Select your data and Generate UMAPSelect a point on the drift visualization at the top of the page and generate UMAP to visualize the point in time selected\u200b2.Investigate your worst drifted clustersClusters are groups of related points in the point cloud. The closer points or clusters are to each other, the more similar they are. Clusters allow you to easily visualize data that differs from your baseline but also allows you to visualize the global and local structure of your data.You can select a specific cluster to further investigate and view the data associated with the cluster3.Investigate the data points that belong in that cluster \u200bWhen you select a cluster, Arize surfaces the data associated (shown on the right) and you can further investigate any data point by clicking \"View Details\"4.Colorize/Filter your data UMAP enables users to identify patterns or the structure in the data to explain where model can be improved by applying colorizations and filtersHow to Colorize and Filter Points in UMAPUsers can colorize and filter the UMAP visualization:By Dataset: points will be colored based on if they belong to the baseline or primary dataset.By Prediction Label/Score: points will be colored according to the prediction label/score obtained from the model.By Actual Label/Score: points will be colored according to the actual label/score obtained from the model.By Correctness: points will be colored based on whether or not the prediction was correct (i.e., does the prediction label match the actual label).By Confusion Matrix: after selecting a positive class, points will be colored by their confusion matrix value (true positive, true negative, false positive, or false negative).By Tag: identify patterns or insights in slices of data by choosing to color by tag.By Feature: Identify patterns or insights in slices of data by choosing to color by feature.How to Configure your UMAP Generation? Users can configure their UMAP generation by these parameters:Dimensions: choose between a 2D or a 3D plot. nNeighbors: controls how UMAP balances local versus global structure in the data. More specifically, it controls the definition of the local region, i.e., how many neighbors UMAP will look at to define a local region. It balances the focus from global to local structure. The lower/higher the value of nNeighbors, the more focus we put on the local/global structure of the dataset. Allowed values range from 5 to 100. Learn more here.minDist: provides the minimum distance apart that points are allowed to be in the low dimensional representation. Allowed values range from 0.0 to 0.99. Learn more here.Sample size: the number of points in the UMAP plot per dataset.  For example, if you select 500 there will be 1000 points total in the plot. Allowed values range from 300 to 2500.What is Clustering?Clustering is the process of grouping similar data points together. The goal of clustering is to find patterns and structure in a data set and to divide the data points into groups, or clusters, that share certain characteristics.How does Arize cluster the UMAP points?Our clustering algorithm is an unsupervised learning technique, which means that it works on unlabelled data and finds patterns on its own. How can clustering help me?Clusters help you find patterns and structure in your dataset. Users are able to troubleshoot performance degradation by examining the underlaying data in the form of clusters and use these insights to improve your models performance.  Examples:you might realize that your model is confusing two classes that are similar (i.e sandals and sneakers)  you have a cluster with a drift score close to -1, meaning that model is seeing production data that is unlike the trainingThe drift score measures the reference data coverage present in a given cluster or point cloud. A score of -1 means that the cluster only contains primary, or production, data. A score of 1 means that the cluster only contains only baseline data. A score of 0 means the cluster is equally composed of baseline and primary data. The white and blue bars represent the count in each dataset in that cluster. In this example, the cluster contains 16 points in production, and 55 points in the baseline dataset.Cluster MetricsAfter choosing your desired cluster metric (e.g. euclidean distance, accuracy, custom metric, etc.), Arize automatically surfaces the clusters you should focus on for model improvement / troubleshooting so you can quickly find the root cause. Arize automatically surfaces clusters of bad responses to focus on improvementYou can select the metric you want to use, and how you want the clusters to be sorted. Select how to sort the clusters by evaluation score and datasetHow do I use clusters to improve my model?Download Clusters LocallyOnce a cluster that is impacting model performance has been identified, users can download the data in the cluster for active learning. This data includes all the information needed for labeling workflows. These clusters are highly focused groups of datapoints, enabling labeling teams to be more precise in their efforts. Download cluster of datapointsExample CSVExport Data into Notebook EnvironmentArize enables teams to continue analysis of their production data in notebooks. With a few lines of Python code, users can export their data into Phoenix or a Jupyter notebook for further analysis. Export to PhoenixLearn more here.Embeddings - PreviousEmbedding DriftNext - EmbeddingsEmbeddings for Tabular Data (Multivariate Drift)Last modified 12d agoOn this pageWhat is an Embedding Projector ? How to use UMAP?How to Colorize and Filter Points in UMAPHow to Configure your UMAP Generation? What is Clustering?How does Arize cluster the", "start_char_idx": 0, "end_char_idx": 7851, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f74e2cbd-87c0-4073-b110-d72e4c56cf4d": {"__data__": {"id_": "f74e2cbd-87c0-4073-b110-d72e4c56cf4d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1fd5a0ad-5fd4-418d-99ba-1926a61187ab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "hash": "85d0b8a328207a0e02417a2ba420222106f5aa8a6b3da3d2b77dc0ab319d6c41"}, "2": {"node_id": "d5bc9414-232e-4e2e-afb8-0d425453d245", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}, "hash": "fea41e9ca7019a32bebadb90bec7bbdbe14efc2af863417393c0ca75fc5e5e87"}}, "hash": "1c144545b58b04941b18149470536c8d6c3e126489b08bc3b0d3dd4a45fb6d54", "text": "UMAP points?How can clustering help me?Cluster MetricsHow do I use clusters to improve my model?SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7852, "end_char_idx": 8172, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1e29a976-7e19-44be-9bbe-67ebb85099e1": {"__data__": {"id_": "1e29a976-7e19-44be-9bbe-67ebb85099e1", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-drift"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eeb925f8-fa80-41ae-bf1b-f2a0ec1c93e7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-drift"}, "hash": "34ce9b8d5738d38dbd496bb886ccd1438079897de715bf65dfd02c5b894f6c08"}}, "hash": "25b434f7f7f674f2d0e6a73de031e6b0e9b9390a185a9af0207326c8ec21da46", "text": "Embedding Drift - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbedding DriftTrack change for unstructured dataWhat is Embedding DriftThe challenge with measuring unstructured data drift is that you need to understand the change in relationships inside the unstructured data itself. Drift helps you understand this. Examples of what Drift can identify:1.New set of images you didn't train on shows up in production2.New entities showing up in a new version of the model 3.Issues with data quality changes (blurry, spotted, lightened, darkened, rotated, or cropped images)4.Changes in terminology in the data or changes to the context or meaning of wordsHow is Embedding Drift CalculatedOnce you set up a baseline, Arize compares embedding vectors between different periods of time to determine the occurrence of drift. To do so, Arize computes the Euclidean distance between the primary dataset\u2019s centroid and the baseline's, thus allowing you to detect if drift has happened and when it has occurred. Example Scenario:Let us have two samples of vectors:Sample A: [1, 2, 3]; [4, 5, 6]; [7, 8, 9] .Sample B: [-1, 2,4]; [11, 6, 0]The centroid vectors are: [4, 5, 6], and [5, 4, 2], respectively. We then calculate the Euclidean Distance as follows:(x1\u2212y1)2+(x2\u2212y2)2+(x3\u2212y3)2=(4\u22125)2+(5\u22124)2+(6\u22122)2\u22484.24\\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + (x_3 - y_3)^2}=\\sqrt{(4-5)^2+(5-4)^2+(6-2)^2}\\approx4.24(x1\u200b\u2212y1\u200b)2+(x2\u200b\u2212y2\u200b)2+(x3\u200b\u2212y3\u200b)2\u200b=(4\u22125)2+(5\u22124)2+(6\u22122)2\u200b\u22484.24The above picture shows two groups of vectors \u2013- one for the baseline, and the other for production. Both euclidean and cosine distances are greater when the two vectors are further apart. This is monitored as the embedding drift. What do you need to calculate Drift?Arize uses the raw embedding vectors it receives to track the drift of your unstructured input data. To calculate the Euclidean distance, we need two sets of data: Primary Dataset -> The dataset we will measure drift on. This can be any dataset that you have ingested into ArizeBaseline --> Defaults to the configured model baseline. This is what we will compare the Primary Dataset toChoose from the drop downs at the top of the page to adjust you primary and baseline datasets.Note: The grey bars in the above image are the data traffic. Low volumes of data are not reliable for calculating drift. Try changing the time range or adding more data. Using Arize to Track Embedding Drift Generally speaking, when your Euclidean distance is low, there is a strong overlap between the production and baseline datasets. When problematic or new data is introduced into the dataset, the Euclidean distance will increase indicating that drift has occurred. We can take this one step further by generating the UMAP to visualize these differences in embeddings. Drift in datasetIn the example above, we can see (in the plot on the top of the page) that there's a week where there's an increase in this distance, signaling a drift on the input dataset that requires further investigation. In other words, this shows that during that time, the production data that was sent to our model was different than the model baseline. Set up an Embedding Drift MonitorYou can also set up drift monitors to track embedding drift. This allows you to automate drift tracking and receive alerts when your embeddings have drifted. See Drift Monitors for more details.PreviousLet Arize Generate Your EmbeddingsNext - EmbeddingsEmbedding & Cluster AnalyzerLast modified 16m agoOn this pageWhat is Embedding DriftHow is Embedding Drift CalculatedWhat do you need to calculate Drift?Using Arize to Track Embedding Drift Set up an Embedding Drift MonitorSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5303, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f2ec490d-f288-44e5-b4f5-13d924f9b747": {"__data__": {"id_": "f2ec490d-f288-44e5-b4f5-13d924f9b747", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0696252c-9e64-4ef9-9b60-99c42cbaebf2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-faq"}, "hash": "9014ff578a1a4a9721844aba82bf188daf495aa2ab00c9c77aaaff55fa03dc0c"}}, "hash": "e61a878c0ca3c922fcb8155a44007bcd4510aafbc30e30c83bed26e8f4dffe7b", "text": "Embeddings FAQ - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbeddings FAQIngestionHow do you generate the embeddings? There are many ways to extract embeddings depending on your use-case and your model. You can either generate your own embeddings or let Arize generate them for you. How do you send the embeddings to Arize?Examples can be found here:Image ClassificationNatural Language Processing (NLP)The UMAP views says \"Duplicate Prediction IDs found in Dataset.\". What does that mean? The UMAP visualization requires each datapoint's prediction ID to be unique. If there are are multiple predictions sent with the same prediction ID, the UMAP visualization cannot fetch all of the columns (features, tags, etc) of that datapoint. Since certain fields of this datapoint cannot be fetched, some color by options will be restricted. How do I view my private AWS S3 images in Arize?Navigate here for step-by-step instructions to enable access to view private AWS S3 image links. Do all vectors from the same embedding feature need to have the same dimensionality?Different embedding features can have vectors with different dimensionality. However, Arize currently only supports one vector dimensionality per embedding feature. We are working to support multiple dimensionalities within the same embedding feature.Should the embedding vector contain numeric values? Are strings allowed?The vector attribute of Arize's embedding object must be an array of floats. Strings are not allowed.Should the embedding column name be included in the feature_column_names , or just the embedding_feature_column_names?Regular features and embedding features are ingested into Arize in two different list of column names. In short, embedding column names should not be included in feature_column_names. Check out our resources to learn more.DriftWhy Euclidean distance?Euclidean distance identifies movements of embeddings across many use cases in testing. There will be support for more metrics, i.e., cosine similarity, as the ecosystem develops. Learn more on monitoring embedding drift here.How is Euclidean distance calculated?See our glossary page on Euclidean distance.Is Euclidean distance calculated using the original embeddings or the UMAP projections?Inside of the Arize platform, Euclidean distance is calculated using the original embeddings, not the UMAP projections. For visualization purposes, we take a sample from those embeddings and, using UMAP, project them into a 2D, or 3D space. What use-cases can Euclidean distance apply to?Any use cases where embeddings or the ability to extract embeddings can be used. A few examples are computer vision, natural language processing, deep learning, hierarchical embedding use cases.How can you monitor drift in embeddings?You can set a euclidean distance monitor using the UI or through our Monitors API. By creating a monitor and selecting the embeddings feature of interest, Arize can track and monitor your embeddings for drift. \n\nVisualizationWhy UMAP?UMAP was chosen to visualize and understand large, high-dimensional datasets, as it maintains local & global structures and it scales better than other dimension reduction techniques (learn more here). See here to learn more about using UMAP in Arize.Arize has the fortune to count Dr. Leland McInnes (one of the creators of UMAP) from the Tutte Institute for Mathematics and Computing as an advisor. He continues to help us develop capabilities in the space. \u200bEmbeddings - PreviousEmbeddings for Tabular Data (Multivariate Drift)Next - LLM (Large Language Models)LLM EvaluationsLast modified 2mo agoOn this pageIngestionDriftVisualizationSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]comResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5310, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b26a5040-6cf0-4d67-a9c0-fafc4d5b016e": {"__data__": {"id_": "b26a5040-6cf0-4d67-a9c0-fafc4d5b016e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-for-tabular-data-multivariate-drift"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "99580bf8-b48b-40b7-8fc1-b0c96da65aa0", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-for-tabular-data-multivariate-drift"}, "hash": "62088896ac0e505abafd5843c31578d3a47e377c57b9d9d5915cd8a7ec8dcd0b"}}, "hash": "53c0c0dd173b4f93fa630264decb6af1ef335a83b0a74da4353fa9cff0791489", "text": "Embeddings for Tabular Data (Multivariate Drift) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbeddings for Tabular Data (Multivariate Drift)Use Embeddings to Catch Multivariate Drift in Tabular DataCheck out an example of how to create tabular embeddings here!  Google ColaboratoryGoogle Colab for Generating Embeddings from Tabular DataWhat are Tabular Embeddings?Tabular Embeddings are embeddings that are generated from a row of tabular data. Each row of your dataframe will be represented by 1 embedding vector. Why is it useful?We can use our embeddings from tabular data to monitor multivariate drift. Multivariate drift catches drift across combinations of multiple features that may not be present when looking at a single feature level. Conceptual Example: There's an abnormal increase of tall people with small shoe size, but not obvious just looking at increase in average height or decrease in shoe size. Steps to Generate Tabular EmbeddingsVisual for how to generate Tabular Embeddings1.Select the columns in your data that you want to convert to embeddings. If you're not sure which columns would work best, start with using all of your feature and prediction columns. In addition, we suggest not selecting columns that contain incomprehensible strings, e.g., hashed fields, user ids, etc.Example Row: age (feature 1)state (feature 2)credit_score10\"CA\"5602.(Optional) You can also provide a dictionary mapping your column names to more verbose versions of them. This helps the embedding generator understand what each column means, in case the dataframe has column names that are not found in the vocabulary. For example: delinq_6mnths can be mapped to delinquencies_in_the_last_6_months. This won't change the column names of your dataframe.3.Choose a model type for generating embeddings. Read about supported models here. In this example, we've chosen distilbert-base-uncased for performance and simplicity. 4.Generate the embedding and assign it to a new column in your dataframe. In this example we named it \"tabular_embedding_vector\". 5.Log the whole dataframe to Arize. This means Arize will receive your data in both tabular and embedding formatting, which will assist in debugging and analysis in the platform. An example is presented below but refer to our SDK documentation for a complete list of attributes.from arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200b# Instantiate the embeddding generatorgenerator = EmbeddingGeneratorForTabularFeatures(    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512)\u200b# Select the columns from your dataframe to considerselected_cols = [...]\u200b# (Optional) Provide a mapping for more verbose column namescolumn_name_map = {...: ...}\u200b# Generate tabular embeddings and assign them to a new columndf[\"tabular_embedding_vector\"] = generator.generate_embeddings(    df,    selected_columns=selected_cols,    col_name_map=column_name_map # (OPTIONAL, can remove))\u200b# Create embedding features dictionarytabular_embedding_features = { # Dictionary keys will be name of embedding feature in the app \"arize_tabular_embedding\": EmbeddingColumnNames(        vector_column_name=\"tabular_embedding_vector\", ),}\u200b# Log to Arize using the Arize pandas loggerresponse = arize_client.log(    dataframe=df,    model_id=\"tabular-model-with-embeddings\",    model_version=\"1.0\",    model_type=ModelTypes.REGRESSION,    metrics_validation=[Metrics.REGRESSION],    environment=Environments.PRODUCTION,    schema = Schema(        prediction_id_column_name=\"prediction_id\",        timestamp_column_name=\"prediction_ts\",        prediction_label_column_name=\"prediction_label\",        actual_label_column_name=\"actual_label\",        feature_column_names=feature_cols,        embedding_feature_column_names=tabular_embedding_features, ))Viewing your tabular embeddingsOnce your embedding is logged to Arize, you can monitor for multivariate drift. To learn more about Embedding Drift, visit here.Monitoring an Embedding Generated from Tabular DataClick on a point on the drift over time graph above to visualize data points using UMAP. To learn more about UMAP, visit here. Embeddings - PreviousEmbedding & Cluster AnalyzerNext - EmbeddingsEmbeddings FAQLast modified 15m agoOn this pageWhat are Tabular Embeddings?Why is it useful?Steps to Generate Tabular EmbeddingsViewing your tabular embeddingsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6019, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5f2be5fa-22e9-4765-93c5-da142387689f": {"__data__": {"id_": "5f2be5fa-22e9-4765-93c5-da142387689f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/11.-bias-tracing-fairness"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "167257c2-2997-4bf1-83d7-302d1f1bd863", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/11.-bias-tracing-fairness"}, "hash": "16c40b0255c9a982c21ec572b8a80fd2649b82884d1d69c7ee56bd128f5e1505"}}, "hash": "fce4a452d08c8329494ac7f76091d15c6b235a2e0d1d617ddbfa01c7f57953e8", "text": "Bias Tracing (Fairness) - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookBias Tracing (Fairness)Navigate to the Fairness tab on your model to identify and ensure that model bias issues across sensitive attributes such as race and sex are caught before broadly impacting marginalized groups.Bias Tracing OverviewArize Bias Tracing helps teams analyze and take action on fairness metrics. The solution enables teams to make multidimensional comparisons, automatically surfacing and quickly uncovering the features and cohorts likely contributing to algorithmic bias.Troubleshooting Model BiasTo evaluate how your model is behaving on any protected attribute, you select a sensitive group (e.g. Asian) and a base group (e.g. all other values \u2013 African American, LatinX, Caucasian, etc.) along with a fairness metric, you can begin to see whether a model is biased against a protected group using the four-fifths (\u2158) rule. The four-fifths rule is a threshold that is used by regulatory agencies like the United States Equal Employment Opportunity Commission to help in identifying adverse treatment of protected classes. Leveraging the four-fifths rule, teams can measure whether their model falls outside of the 0.8-1.25 threshold, which means algorithmic bias may be present in their model.To evaluate model bias, navigate to the Fairness tab and select inputs to evaluate on.SetupMetrics\u200bRecall Parity: measures how \"sensitive\" the model is for one group compared to another, or the model\u2019s ability to predict true positives correctly.\u200bFalse Positive Rate Parity: measures whether a model incorrectly predicts the positive class for the sensitive group as compared to the base group.\u200bDisparate Impact: a quantitative measure of the adverse treatment of protected classesAttribute: any of your model's protected categorical features (e.g. income class, race, sex)Base Group: unprotected group (e.g. Caucasian), will be used in understanding parity against sensitive groupSensitive Group: protected group (e.g. Black), group you are evaluating to see if algorithmic bias is present forYou can select an individual base and sensitive group or multiple values for each group, depending on your teams' goals.Fairness Over TimeOnce you have selected your metric, attribute, base, and sensitive groups, you will be presented with a visualization of your model's fairness metric over time, along with a stacked histogram displaying your model's overall traffic, traffic for the base group, and traffic for sensitive group. The traffic histogram allows you to better understand if your fairness metric is impacted by a lack of adequate representation of a sensitive class (or overrepresentation by a base class) relative to the total traffic. To zoom in to a particular time range where bias may have been higher or lower, drag/highlight your cursor over a section of the Fairness over Time chart.4/5ths RuleTo understand the fairness metric value for the period of time you are evaluating, many companies use the four-fifths rule. The 4/5ths rule is a threshold that is used by regulatory agencies like the United States Equal Employment Opportunity Commission to help in identifying adverse treatment of protected classes. When leveraging the four-fifths rule, you can measure whether your model falls outside of the 0.8-1.25 threshold, which means algorithmic bias against the selected sensitive group may be present in your model.At 0.8854, Recall Parity falls within the 4/5ths rule for this modelFairness BreakdownScrolling below the Fairness over Time chart, you will see the Fairness Breakdown, by Features or Tags. By clicking on the caret next to a listed feature, you can dig even deeper to see which segment within each feature or tag of the model is contributing to the bias of your model. Each bar represents the Fairness metric for base and sensitive groups calculated only on a subsection of your dataset where the segment is true. The darker red a segment is, the more bias is present. By scrolling through you can easily uncover the problematic segments where bias may be more present, and take action. Compare Bias Across DatasetsTo compare fairness and bias across model versions or environments (e.g. training vs. production) and evaluate which model performs better for certain groups. you add click on \"Add Comparison\" and add an additional dataset. This can help answer questions such as \"Were we seeing this bias in training?\" or \"Does my latest model version exhibit more or less bias than the last?\"Add FiltersYou can layer additional filters across features, tags, prediction scores/values, and actual scores/values to evaluate your model's bias on a more granular level and drill down into where the issue may be stemming from. To quickly add a problematic segment as a filter for deeper troubleshooting, you can apply a it as a filter directly from the Fairness Breakdown.Additional ResourcesBlog: Introducting Arize Bias Tracing\u200bPreviousSurrogate ModelNext - API ReferencePython Pandas (batch)Last modified 7mo agoOn this pageBias Tracing OverviewTroubleshooting Model BiasSetupFairness Over Time4/5ths RuleFairness BreakdownCompare Bias Across DatasetsAdd FiltersAdditional ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6862, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9004e605-a439-49f0-9d39-8e599f050890": {"__data__": {"id_": "9004e605-a439-49f0-9d39-8e599f050890", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cbe5f483-f119-42e5-ac40-fad812cce4b6", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability"}, "hash": "5a636996885dc29ab7779f713460ac8906b193ead377f7ef43ec67cae89e14e3"}}, "hash": "be7d3780f959b454f72f55dc2490211e2c465266fd0326ac1a3fcc0ccc1ddce3", "text": "Model Explainability - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilitySHAPSurrogate ModelBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookModel ExplainabilityThe Arize platform can help you understand why your model produced its predictions.Sending Feature ImportanceArize supports 2 methods for ingesting and visualizing feature importanceMethod\u200bUser Calculated SHAP\u200bMethod\u200bSurrogate Model\u200bAnalyzing Feature Importance Values Global Feature ImportanceBy default, the model Explainability tab will show the global feature importance values across all predictions within the specified time range.Cohort Feature ImportanceThe dropdown filters at the top of the page allow you to understand the importance of your model's features across a cohort or subset of your predictions. Select a cohort of predictions using the model version, feature and prediction label filters:Compare Feature ImportanceCompare two production datasets to easily visualize a change in feature importance between different datasets and versions.Local Feature ImportanceIf you need per-prediction explainability: The ability to get an explanation for a single prediction based on a prediction ID lookup -- please reach out to your Arize support team for examples on enabling per-prediction visibility into your account.Using Explainability to Troubleshoot DriftOn the model's Drift tab, sort feature drift by Prediction Drift Impact and Feature Importance. Using Explainability to Troubleshoot PerformanceOn the model's performance tab, sort performance breakdown by Feature Importance. Additional ResourcesBlog: What Are Global, Cohort and Local Model Explainability?\u200bBlog: Overcoming AI's Transparency Paradox\u200bQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousStatistic WidgetsNextSHAPLast modified 7mo agoOn this pageSending Feature ImportanceAnalyzing Feature Importance Values Global Feature ImportanceCohort Feature ImportanceCompare Feature ImportanceLocal Feature ImportanceUsing Explainability to Troubleshoot DriftUsing Explainability to Troubleshoot PerformanceAdditional ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3711, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "33b31146-0848-405f-813c-040328c82436": {"__data__": {"id_": "33b31146-0848-405f-813c-040328c82436", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/catching-hallucinations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3561f72d-ce9b-48a9-b812-15cca731c1ce", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/catching-hallucinations"}, "hash": "fe722fe9e1bd01df9c502ccae5b01124ff5f43f2f61d326ace8b2b433f197a2f"}}, "hash": "56dcbc5700eaa32c4bf301341d76ce3d0475df7ab23f99d3279abd74837597ea", "text": "LLM Evaluations - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookLLM EvaluationsTypes of Evaluation Metrics\u200bUser FeedbackEnd user feedback (ex: Thumbs up/Thumbs down) on the LLM response.\u200bLLM-Assisted EvaluationUse a second LLM call to evaluate the LLM response or context relevance. We recommend using the OpenAI Evals Library to find various templates.\u200bTask-Based MetricsDifferent metrics for different tasks (Ex: Rouge for summarization, Bleu for translation)While end user feedback is considered most valuable, it is often much harder to come by. Either the sample size of users leaving feedback is small, or there is no format for the user to leave their feedback. A great alternative when end user feedback is not available, is LLM-assisted evaluation. In this scenario, a secondary LLM is called to evaluate the response of your LLM application or context relevance in RAG. OpenAI Evals Library contains various templates to get started with LLM assisted evaluations. An additional type of evaluation is available if the LLM is completing a certain task such as summarization or translation. In these cases, there are specific evaluation metrics for each of these tasks (e.g. rouge, bleu, meteor). LLM-Assisted Evaluation Use CasesThere are two use cases for LLM-assisted evaluation:Final Response: The first evaluation many want to get, especially when user feedback is not available, is an evaluation of the final response. Did the response my LLM gave answer the user's query correctly and sufficiently? The secondary LLM is sent the user's query and the response, and scores how well the response answered the question. This evaluation helps highlight where the bad responses / hallucinations are occurring for further analysis. Context Relevance: In RAG use cases, an important question to ask when analyzing performance is, how relevant was the context my LLM retrieved to the user's query? In this instance, a secondary LLM is given the user query alongside the context retrieved, and asked to rank or score the relevance of the context. This can help identify if the root cause of a bad response in a retrieval system is that there isn't enough relevant context in a knowledge base or the most similar document was not the most relevant document.How to Log Evaluation MetricsWhat's After Evaluation?Depending on what the accuracy of the task is, there's a lot of immediate improvement that can be realized from leveraging prompt-engineering. As teams hit a wall with prompt engineering, fine tuning can be an option for improvement. Image by Andrej KarpathyEmbeddings - PreviousEmbeddings FAQNext - LLM (Large Language Models)Troubleshoot Retrieval with Vector StoresLast modified 11d agoOn this pageTypes of Evaluation MetricsLLM-Assisted Evaluation Use CasesHow to Log Evaluation MetricsWhat's After Evaluation?SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4485, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b8e0d1c1-5f3f-436b-9805-2e683ee021cb": {"__data__": {"id_": "b8e0d1c1-5f3f-436b-9805-2e683ee021cb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/open-ai-cluster-summarization"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ae09c232-a55e-46d1-aad4-bab40a8a4d9b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/open-ai-cluster-summarization"}, "hash": "5ca1f8df4c70ecf59eee7053b0c9d0db61a59f4a7b39578480725a62fc198a34"}}, "hash": "17b51f2355a146ce0f74cfa4f4da57a1f8563fc65dac7bb8357a718631efdb5d", "text": "Open AI Cluster Summarization - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookOpen AI Cluster SummarizationUse GPT to summarize clusters of your embeddingsWith the overwhelming amount of text data processed by large language models (LLMs) every day, it's challenging to manually comb through each prompt for analysis and insights. The Cluster Summary feature in Arize tackles this problem head-on by automatically grouping related prompts or responses together, turning unwieldy data sets into easily understandable clusters.How does this work?Arize sends the raw text from your prompt or response embeddings to Open AI, and uses the LLM selected to generate a summary. Different models may provide different quality of responses, with more functionality coming here soon.How do I set this up?Navigate to the integrations menu from the side panel and add your Open AI key to begin using cluster summarization.Note: By adding this key, your data may be sent to Open AI for certain actions within Arize (i.e. generating cluster summary) and your account will be billed for usage.Why use this feature?1.Efficient Analysis: By summarizing and grouping raw text prompts, you can analyze your data more efficiently. No need to go through each prompt manually, saving your team valuable time.2.Identify Patterns: Uncover underlying patterns or trends that might otherwise be overlooked. This can provide valuable insights into what your users are asking or discussing most often.3.Focus Improvement Efforts: Identify clusters that generate low-quality responses or hallucinations from your LLM. By pinpointing these problematic areas, you can focus your improvement efforts where they're needed most.4.Enhanced Understanding: Gain a deeper understanding of your LLM's performance. With a high-level view of the prompts being fed into your model, you can better appreciate how it interprets and responds to different types of input.LLM (Large Language Models) - PreviousTroubleshoot Retrieval with Vector StoresNext - Active Learning and Fine TuningExport Data to NotebookLast modified 20d agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3743, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "beef5aa9-1cac-4fed-82e5-da5d6802916a": {"__data__": {"id_": "beef5aa9-1cac-4fed-82e5-da5d6802916a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2b73a05e-d4e5-4f5f-bc68-117b5b5602e6", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "hash": "a347d750f8b6b52f46449752e70b7c2d47e2765658a8566b03a45b1645a35704"}, "3": {"node_id": "198511ca-f268-41ea-add3-4adea38e02d3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "hash": "4d22a7152526a4b14a84e437b7928b89737b7f4b65dae442b357813e0f0f9511"}}, "hash": "749f8ab41b5abd7346a6b8e4448b351fbb87d729a0ee704fb78238004bcc77ae", "text": "Troubleshoot Retrieval with Vector Stores - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookTroubleshoot Retrieval with Vector StoresExample Notebook: Google Colab\u200bVector Stores enable teams to connect their own data to LLMs. A common application is chatbots looking across a company's knowledge base/context to answer specific questions. How Search and Retrieval WorksHere's an example of what retrieval looks like for a Chatbot Application. A user asked a specific question, an embedding was generated for the query, all relevant context in the knowledge base was pulled in, and then added into the prompt to the LLM.Common Problems with Search and Retrieval Systems When the application using RAG doesn't give a good response, it can be because of different reasons. The common issues we see are There wasn't enough documents to answer the question The document retrieved wasn't good enough to answer Arize helps evaluate how good retrieval is and identify where it went wrong. Logging data to Arize for Search and Retrieval TracingArize logs both a sample of the knowledge base and the production prompt/response pairs of the deployed application. Here's a high level view of what is logged: Step 1: Logging a Sample of the Knowledge BaseThe first thing we need is to collect some sample from your vector store, to be able to compare against later. This is to able to see if some sections are not being retrieved, or some sections are getting a lot of traffic where you might want to beef up your context or documents in that area.Example Dataframe of Knowledge Base:  knowledge-base.dfdoc_chunk_IDdoc_chunkdoc_chunk_embedding123The Variety Theater in Cleveland, once a ...[-0.0051908623, -0.05508642, -0.28958365, -0.2...Current  Logging Approach:# Logging the Sample of the Corpus/Knowledge Base \u200bfrom arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, EmbeddingColumnNames\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b# Declare embedding feature columnsprompt_columns=EmbeddingColumnNames(    vector_column_name=\"doc_chunk_embedding\",    data_column_name=\"doc_chunk\"),response_columns=EmbeddingColumnNames(    vector_column_name=\"doc_chunk_embedding\",    data_column_name=\"doc_chunk\")\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"doc_chunk_ID\",    prompt_column_names=prompt_columns,    response_column_names=response_columns)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=\"llm-retrieval-example\",     model_type=ModelTypes.GENERATIVE_LLM,    environment=Environments.TRAINING, # MAKE THIS A DIFFERENT ENVIRONMENT    schema=schema,    dataframe= knowledge-base.df             # Refers to the above dataframe with the example row )\u200bComing Soon - Native support for Knowledge Base# Logging the Sample of the Corpus/Knowledge Base\u200bfrom arize.pandas.logger import Client, Schemafrom arize.utils.types import EmbeddingColumnNames\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200bresponse = arize_client.log_knowledge_base(  model_id = \"llm-retrieval-example\"  context_column_names = EmbeddingColumnNames(        data_column_name=\"doc_chunk\",        vector_column_name=\"doc_chunk_embedding\", )  context_id_column_name = \"doc_chunk_ID\"  dataframe= knowledge-base.df             # Refers to the above dataframe with the example row )Step 2: Logging Production Prompt/Responses to Arize We also will be logging the prompt/response pairs from the deployed application. Example Dataframe: prompts-response.dfprediction-IDuser-queryquery-vectordocumentdocument-vectorresponseresponse vectoruser feedbackdd824bd3-2097...What is the Variety Theater in Cleveland?[-0.5686951, -0.7092256, -0.34603243, -0.4858...The Variety Theater in Cleveland, once a ...[-0.1869151, -0.2092136, -0.1660343, -0.3258...The Variety Theater is ... [-0.18691051, -0.2092136, -0.16603243, -0.3258...thumbs-down# Logging the production prompt and response pairs\u200b# Declare embedding feature columnsprompt_columns=EmbeddingColumnNames(    vector_column_name=\"query-vector\",    data_column_name=\"user-query\"),response_columns=EmbeddingColumnNames(    vector_column_name=\"response vector\",    data_column_name=\"response\")\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"prediction-ID\",    prompt_column_names=prompt_columns,    response_column_names=response_columns)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=\"llm-retrieval-example\",     model_type=ModelTypes.GENERATIVE_LLM,    environment=Environments.PRODUCTION,     schema=schema,    dataframe= prompts-response.df    # Refers to the above dataframe with the example row )Tracing Search and Retrieval Systems with Arize Issue #1: Bad ResponseThe first issue we see, and often the easiest to uncover", "start_char_idx": 0, "end_char_idx": 6417, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "198511ca-f268-41ea-add3-4adea38e02d3": {"__data__": {"id_": "198511ca-f268-41ea-add3-4adea38e02d3", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2b73a05e-d4e5-4f5f-bc68-117b5b5602e6", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "hash": "a347d750f8b6b52f46449752e70b7c2d47e2765658a8566b03a45b1645a35704"}, "2": {"node_id": "beef5aa9-1cac-4fed-82e5-da5d6802916a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}, "hash": "749f8ab41b5abd7346a6b8e4448b351fbb87d729a0ee704fb78238004bcc77ae"}}, "hash": "4d22a7152526a4b14a84e437b7928b89737b7f4b65dae442b357813e0f0f9511", "text": "is bad responses.By logging the user feedback to Arize, we will automatically surface up any clusters that received poor feedback.Create a custom metric in Arize to capture user feedbackArize will automatically surface up clusters with the worst user feedbackBad responses are often the result of something else going on. Your LLM is likely not giving a poor response for no reason. Next, we will show you how to trace it back to the root of the problem.Issue #2: Don't Have Any Documents Close EnoughMaybe, it wasn\u2019t able to find any documents that were close enough to the query embedding. This means that users are asking questions about context that is missing from your knowledge base. Arize can help you identify if there is context that is missing from your knowledge base. By visualizing query density, you can understand what topics you need to add additional documentation for in order to improve your chatbots responses. Visualize Query Density (Euclidean or Cosine Distance)By setting my \"production\" dataset as the user queries, and the \"baseline\" dataset as the context I have in my vector store, I can see if there are clusters of user query embeddings that have no nearby context embeddings, as seen in the example above. Issue #3: Most Similar != Most Relevant DocumentThere is also the possibility that the document that was retrieved was considered most similar, had the closest embedding to the query, but wasn\u2019t actually the most relevant document to answer the user\u2019s question appropriately.Arize can help uncover when irrelevant context is being retrieved with LLM assisted ranking metrics.By ranking the the relevance of the context retrieved, we can help you identify areas to dig into to improve the retrieval.In order to catch these instances where the most relevant context might not be the most \u201csimilar\u201d Arize sends the user query and context retrieved to GPT-4, or another LLM, and asks it to rank or provide a score on the relevance of the context retrieved. In the example above, both of the pieces of context retrieved got an \"irrelevant\" score or  [email\u00a0protected] ranking of 0. We can also see this coincides with receiving negative user feedback on the response. Troubleshooting Tip:Found a problematic cluster you want to dig into, but don't want to manually sift through all of the prompts and responses? Use our Open AI Cluster Summarization tool to quickly get a summary of the selected cluster for quick analysis.\nLearn more about Cluster Summarization here. \u200b\u200bLLM (Large Language Models) - PreviousLLM EvaluationsNext - LLM (Large Language Models)Open AI Cluster SummarizationLast modified 11d agoOn this pageHow Search and Retrieval WorksCommon Problems with Search and Retrieval SystemsLogging data to Arize for Search and Retrieval TracingStep 1: Logging a Sample of the Knowledge BaseStep 2: Logging Production Prompt/Responses to Arize Tracing Search and Retrieval Systems with Arize Issue #1: Bad ResponseIssue #2: Don't Have Any Documents Close EnoughIssue #3: Most Similar != Most Relevant DocumentSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6418, "end_char_idx": 9692, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cf297e09-02dd-4eb6-8cc3-936c00a04a25": {"__data__": {"id_": "cf297e09-02dd-4eb6-8cc3-936c00a04a25", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "550e9121-8508-4271-84fe-3a9d2600ec97", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "833acb3bd12e2babf75d5ac5f61cbca6cbbcdb1db05530be1fd399f89226a76e"}, "3": {"node_id": "ab96b404-fd90-4d9d-b5f6-59e477f555e8", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "1162e729fdddaf3236d734d84ea1d8c08a12771c18fab9ac2e23d8c8dffccd34"}}, "hash": "8094b6f6111a3b6ccb3e7bbc85e28cca90a3221c64f57a4b495f91054dffe806", "text": "Binary Classification - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookBinary ClassificationHow to log your model schema for binary classification modelsBinary Classification CasesBinary Classification CasesExpected FieldsPerformance Metrics\u200bCase 1: Supports Only Classification Metrics\u200bprediction label, actual labelAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, Specificity\u200bCase 2: Supports Classification, AUC, Log Loss Metrics\u200bprediction score, prediction label, actual labelAUC, PR-AUC, Log Loss, Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, Specificity\u200bCase 3: Supports Classification, AUC, Log Loss, and Regression Metrics \u200bprediction label, actual label, prediction score, actual score Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, Specificity, MAPE, MAE, RMSE, MSE, R-Squared, Mean Error, AUC, PR-AUC, Log Loss\u200bCase 4: Supports AUC & Log Loss Metrics\u200bprediction score, actual labelAUC, PR-AUC, Log Loss\u200bCase 5: Supports Only Regression Metrics\u200bprediction score, actual scoreMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorClick here for all valid model types and metric combinations. Case #1 - Supports Only Classification Metrics Python Pandas BatchPython Single RecordData ConnectorGoogle ColaboratoryExample Rowstatepos_approvedzip_codeageprediction_labelactual_labelprediction_tscaTrue1234525not_fraudfraud1618590882Code Exampleschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    actual_label_column_name=\"actual_label\",    feature_column_names=[\"state\", \"pos_approved\"],    tag_column_names=[\"zip_code\", \"age\"])\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION],    environment=Environments.PRODUCTION,    dataframe=example_dataframe,    schema=schema)For more details on Python Batch API Reference, visit here: Python Pandas (batch)Google ColaboratoryCode Examplefeatures = { 'state': 'ca', 'pos_approved': True } tags = { 'zip_code': '12345', 'age': '25' }\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    environment=Environments.PRODUCTION,    features=features,    tags=tags,    prediction_label=\"not fraud\",    actual_label=\"fraud\")For more information on Python Single Record Logging API Reference, visit here:Python Single RecordDownload an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/binary-classification-assets/binary_classification_metrics_only_batch_ingestion_data.parquetstorage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryCase #2 - Supports Classification & AUC/Log Loss Metrics Python Pandas Python Single RecordData ConnectorGoogle ColaboratoryExample Rowstatepos_approvedzip_codeageprediction_labelactual_labelprediction_scoreprediction_tsacaTrue1234525not_fraudfraud0.31618590882Code Exampleschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    prediction_score_column_name=\"prediction_score\",    actual_label_column_name=\"actual_label\",    feature_column_names=[\"state\", \"pos_approved\"],    tag_column_names=[\"zip_code\", \"age\"])\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS],    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)For more details on Python Batch API Reference, visit here: Python Pandas (batch)Google ColaboratoryCode Examplefeatures = { 'state': 'ca', 'pos_approved': True, 'item_count': 10 } tags = { 'zip_code': '12345', 'age': '25' }\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    environment=Environments.PRODUCTION,    features=features,    tags=tags,    prediction_label=(\"not fraud\", 0.3),    actual_label=\"fraud\")For more information on Python Single Record Logging API Reference, visit here:Python Single RecordDownload an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/binary-classification-assets/binary_classification_auc_log_loss_batch_ingestion_data.parquetstorage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryCase #3 - Supports Classification, AUC/Log Loss, & Regression MetricsPython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample", "start_char_idx": 0, "end_char_idx": 6342, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ab96b404-fd90-4d9d-b5f6-59e477f555e8": {"__data__": {"id_": "ab96b404-fd90-4d9d-b5f6-59e477f555e8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "550e9121-8508-4271-84fe-3a9d2600ec97", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "833acb3bd12e2babf75d5ac5f61cbca6cbbcdb1db05530be1fd399f89226a76e"}, "2": {"node_id": "cf297e09-02dd-4eb6-8cc3-936c00a04a25", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "8094b6f6111a3b6ccb3e7bbc85e28cca90a3221c64f57a4b495f91054dffe806"}, "3": {"node_id": "9b7a162e-e493-4dde-b04c-3b413752ba13", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "4fe66fd2efc99a25b7800c08c0064c1abe8ef15fb4a2e28114d7b7241db2235c"}}, "hash": "1162e729fdddaf3236d734d84ea1d8c08a12771c18fab9ac2e23d8c8dffccd34", "text": "Rowstatepos_approvedzip_codeageprediction_labelactual_labelprediction_scoreactual_scoreprediction_tscaTrue1234525not_fraudfraud0.311618590882Code Exampleschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    prediction_score_column_name=\"prediction_score\",    actual_label_column_name=\"actual_label\",    actual_score_column_name=\"actual_score\",    feature_column_names=[\"state\", \"pos_approved\"],    tag_column_names=[\"zip_code\",\"age\"])\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION, Metrics.REGRESSION, Metrics.AUC_LOG_LOSS],    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)For more details on Python Pandas API Reference, visit here:  Python Pandas (batch)Google ColaboratoryCode Examplefeatures = { 'state': 'ca', 'pos_approved': True }\u200btags = { 'zip_code': '12345', 'age': '25' } response = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    environment=Environments.PRODUCTION,    prediction_label=(\"not fraud\", 0.3)    features=features,    tags=tags,    actual_label=(\"fraud\", 1))For more information on Python Single Record Logging API Reference, visit here:Python Single RecordDownload an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/binary-classification-assets/binary_classification_auc_log_loss_regression_batch_ingestion_data.parquetstorage.cloud.google.comDownload an example CSV file: https://storage.cloud.google.com/arize-assets/fixtures/Tags-Demo-Data/churn_prediction_production.csvstorage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryCase 4: Supports AUC & Log Loss MetricsPython PandasPython Single RecordExample Rowstatepos_approvedzip_codeageactual_labelprediction_scoreprediction_tscaTrue1234525fraud0.31618590882Code Exampleschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_score_column_name=\"prediction_score\",    actual_label_column_name=\"actual_label\",    feature_column_names=[\"state\", \"pos_approved\"],    tag_column_names=[\"zip_code\",\"age\"])\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION, Metrics.REGRESSION, Metrics.AUC_LOG_LOSS],    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)For more details on Python Pandas API Reference, visit here:  Python Pandas (batch)To declareprediction_score ONLY, pass a tuple of an empty string and your prediction_score through the prediction_label argument. Code Example features = { 'state': 'ca', 'pos_approved': True }\u200btags = { 'zip_code': '12345', 'age': '25' } response = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    environment=Environments.PRODUCTION,    features=features,    tags=tags,    prediction_label=(\"\", 0.3),    actual_label=\"fraud\",)For more information on Python Single Record Logging API Reference, visit here:Python Single RecordCase 5: Supports Only Regression MetricsPython PandasPython Single RecordExample Rowstatepos_approvedzip_codeageprediction_scoreactual_scoreprediction_tscaTrue12345250.311618590882Code Exampleschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_score_column_name=\"prediction_score\",    actual_score_column_name=\"actual_score\",    feature_column_names=[\"state\", \"pos_approved\"],    tag_column_names=[\"zip_code\",\"age\"])\u200bresponse = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION, Metrics.REGRESSION, Metrics.AUC_LOG_LOSS],    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)For more details on Python Pandas API Reference, visit here:  Python Pandas (batch)To declareprediction_score ONLY, pass a tuple of an empty string and your prediction_score through the prediction_label argument. \n\nTo declareactual_score ONLY, pass a tuple of an empty string and your actual_score through the actual_label argument. Code Examplefeatures = { 'state': 'ca', 'pos_approved': True }\u200btags = { 'zip_code': '12345', 'age': '25' } response = arize_client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.BINARY_CLASSIFICATION,    environment=Environments.PRODUCTION,    features=features,    tags=tags,    prediction_label=(\"\", 0.3),    actual_label=(\"\", 1.0))For more information on Python Single Record Logging API Reference, visit here:Python Single RecordDefault ActualsFor some use cases, it may be important to treat a prediction for which no corresponding actual label has been logged yet as having a default negative class actual label. For example, consider tracking advertisement conversion rates for an ad clickthrough rate model, where the positive class is click and the negative class is no_click. For ad conversion purposes, a prediction without a corresponding actual label for an ad placement is equivalent to logging an explicit no_click actual label for the prediction. In both cases, the result is the same: a user has not converted by clicking on the ad.\n\nFor AUC-ROC, PR-AUC, and Log Loss performance metrics, Arize supports treating predictions without an explicit actual label as having the negative class actual label by default. In the above example, a click prediction without an actual would be treated as a false positive, because the missing actual for the prediction would, by default, be assigned to the no_click negative class. This feature can be enabled for monitors and dashboards via the model performance config section of your model's config page.  Quick DefinitionsPrediction Label: The classification label of this event (Cardinality = 2)Actual Label: The ground truth label (Cardinality = 2)Prediction Score: The likelihood of the event (Probability between 0 to 1)Actual", "start_char_idx": 6343, "end_char_idx": 12756, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9b7a162e-e493-4dde-b04c-3b413752ba13": {"__data__": {"id_": "9b7a162e-e493-4dde-b04c-3b413752ba13", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "550e9121-8508-4271-84fe-3a9d2600ec97", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "833acb3bd12e2babf75d5ac5f61cbca6cbbcdb1db05530be1fd399f89226a76e"}, "2": {"node_id": "ab96b404-fd90-4d9d-b5f6-59e477f555e8", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}, "hash": "1162e729fdddaf3236d734d84ea1d8c08a12771c18fab9ac2e23d8c8dffccd34"}}, "hash": "4fe66fd2efc99a25b7800c08c0064c1abe8ef15fb4a2e28114d7b7241db2235c", "text": "Score: The ground truth score (0 or 1)Model Types - PreviousLarge Language Models (LLM)Next - Model TypesMulti-Class ClassificationLast modified 1mo agoOn this pageBinary Classification CasesCase #1 - Supports Only Classification Metrics Case #2 - Supports Classification & AUC/Log Loss Metrics Case #3 - Supports Classification, AUC/Log Loss, & Regression MetricsCase 4: Supports AUC & Log Loss MetricsCase 5: Supports Only Regression MetricsDefault ActualsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 12757, "end_char_idx": 13439, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e1276b66-2ff3-4c48-995d-706670ea733b": {"__data__": {"id_": "e1276b66-2ff3-4c48-995d-706670ea733b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b7e72b75-e1cc-474b-9b89-7c3b8b383c76", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "hash": "11543303663381c37775e00309632bb82e5322c76bc3b5a5cf6d9f61cec87471"}, "3": {"node_id": "d8fcb14f-709e-4907-88ef-32cadbeea2a7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "hash": "4ce525add7816e1f5597eec5a10c6be7d0d3f80a19a7bf62cf5c6834311025ad"}}, "hash": "f047356a2bdaa6d410cd44a468fdb9e8fe4912a61868bc61e84192092d3ef64b", "text": "Image Classification - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookImage ClassificationHow to log your model schema for image classification modelsImage Classification Model OverviewImage classification models take an image as input and return a predicted label for the image. *all classification variant specifications apply to the Image Classification model type, with the addition of embeddingsPerformance MetricsAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityCode ExampleThe EmbeddingColumnNames class constructs your embedding objects. You can log them into the platform using a dictionary that maps the embedding feature names to the embedding objects. See our API reference for more details.Navigate here for step-by-step instructions to view private AWS S3 image links. Python PandasPython Single Record UI Import JSON InputInput for APIExample Rowimage_vectorimage_linkprediction_labelactual_labelprediction_scoreactual_scoreTimestamp[1.0, 2, 3]\"https://link-to-my-image.png\"carbus0.311618590882from arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, EmbeddingColumnNames\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b\u200b# Declare which columns are the feature columnsfeature_column_names=[ \"MERCHANT_TYPE\",  \"ENTRY_MODE\",  \"STATE\",  \"MEAN_AMOUNT\",  \"STD_AMOUNT\",  \"TX_AMOUNT\",]\u200b# Declare embedding feature columnsembedding_feature_column_names = { # Dictionary keys will be the name of the embedding feature in the app \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"image_vector\", # column name of the vectors, required        link_to_data_column_name=\"image_link\", # column name of the link to the images, optional )}\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"PREDICTION\",    prediction_score_column_name=\"PREDICTION_SCORE\",    actual_label_column_name=\"ACTUAL\",    actual_score_column_name=\"ACTUAL_SCORE\",    feature_column_names=feature_column_names,    embedding_feature_column_names=embedding_feature_column_names,)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=\"sample-model-1\",    model_version= \"v1\",    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)Google ColaboratoryImage Classification Embedding FeaturesArize supports logging the embedding features associated with the image the model is acting on and the image itself using the EmbeddingColumnNames object. The vector_column_name should be the name of the column where the embedding vectors are stored. The embedding vector is the dense vector representation of the unstructured input. \u26a0 Note: embedding features are not sparse vectors.The link_to_data_column_name should be the name of the column where the URL links to the source images, that your model classifies, are stored.{  \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"image_vector\",         link_to_data_column_name=\"image_link\"  ) }See here for more information on embeddings and options for generating them.from arize.api import Clientfrom arize.utils.types import ModelTypes, Environments, Embedding\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b# Example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11,} # Example embedding featuresembedding_features = { \"image_embedding\": Embedding(            vector=np.array([1.0, 2, 3]),            link_to_data=\"https://link-to-my-image.png\", ),}\u200b# Log data into the Arize platformresponse = arize.log(    model_id='sample-model-1',     model_version='v1\",     model_type=ModelTypes.SCORE_CATEGORICAL,     environment=Environments.PRODUCTION,    features=features    prediction_label=\"not fraud\",    prediction_score = 0.3    actual_label=\"fraud\",    actual_score = 1    features=features,    embedding_features=embedding_features )CV Embedding FeaturesArize supports logging the embedding features associated with the image the model is acting on and the image itself using the Embedding object.The embedding vector is the dense vector representation of the unstructured input. \u26a0 Note: embedding features are not sparse vectors.The embedding link_to_data is used to pass URL links to the source image your model is classifying.{  \"embedding_display_name\": Embedding(            vector=np.array([1.0, 2, 3]),            link_to_data=\"https://link-to-my-image.png\", ) }See here for more information on embeddings and options for generating them. When configuring an embedding in the UI using File Import \"embedding_features\": [{ \"my_feature\": // #required, my_feature is the name of the feature {           vector: \"vector_col\", // #required, vector_col is the column name of the vector ", "start_char_idx": 0, "end_char_idx": 6561, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d8fcb14f-709e-4907-88ef-32cadbeea2a7": {"__data__": {"id_": "d8fcb14f-709e-4907-88ef-32cadbeea2a7", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b7e72b75-e1cc-474b-9b89-7c3b8b383c76", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "hash": "11543303663381c37775e00309632bb82e5322c76bc3b5a5cf6d9f61cec87471"}, "2": {"node_id": "e1276b66-2ff3-4c48-995d-706670ea733b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}, "hash": "f047356a2bdaa6d410cd44a468fdb9e8fe4912a61868bc61e84192092d3ef64b"}}, "hash": "4ce525add7816e1f5597eec5a10c6be7d0d3f80a19a7bf62cf5c6834311025ad", "text": "         raw_data: \"raw_data_col\", // #optional           link_to_data: \"link_to_data_col\" // #optional }}]Example file schema with embedding features{  \"prediction_id\": \"prediction_id\",  \"timestamp\": \"timestamp\",  \"tags\": \"tag/\",  \"prediction_score\": \"prediction_score\",  \"prediction_label\": \"prediction_label\",  \"actual_label\": \"actual_label\",  \"actual_score\": \"actual_score\",  \"shap_values\": \"shap/\",  \"version\": \"version\", // lookup the column \"version\" in the file  \"batch_id\": \"batch_id\",  \"exclude\": [    \"<column1 name>\",    \"<column2 name>\"  ],  \"embedding_features\": [    {      \"embedding_1\": {        \"vector\": \"vector_column_1\"        \"raw_data\": \"raw_data_column_1\",        \"link_to_data\": \"link_to_data_column\"      }    }  ]}When configuring an embedding in the UI using the API\"embeddingFeatures\": [{ \"featureName\": \"my_feature\", \"vectorCol\": \"vector_col\", \"rawDataCol\": \"raw_data_col\", \"linkToDataCol\": \"link_to_data_col\"}]Example file schema with embedding featuresprediction_id: prediction_idtimestamp: timestampfeatures: feature/tags: tag/prediction_score: prediction_scoreprediction_label: prediction_labelactual_label: actual_labelactual_score: actual_scoreshap_values: shap/version: version // lookup the column \"version\" in the filebatch_id: batch_idexclude: // leave empty to omit column exclusionsembedding_features: // leave empty to omit embeddingsModel Types - PreviousNatural Language Processing (NLP)Next - Model TypesObject DetectionLast modified 1mo agoOn this pageImage Classification Model OverviewCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6562, "end_char_idx": 8332, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1091a6e9-52c6-4420-beb3-852ab28b58d7": {"__data__": {"id_": "1091a6e9-52c6-4420-beb3-852ab28b58d7", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a8129ed-98b1-4192-88ed-62a44704b630", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "hash": "e9946fe006776a001748007d193ce68857882a45da095bb423558f00ef873f79"}, "3": {"node_id": "b87ee96d-2344-4211-9144-53cb4d16ee45", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "hash": "d0130964dfba6770fc65287b9f84af429138d407eebdd128e8defd9c3400258f"}}, "hash": "a8811f44caeed0769d586802cd9c9b29a0b21e36fa99a3d614534c10557a2b9d", "text": "Large Language Models (LLM) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookLarge Language Models (LLM)How to log your model schema for LLM use casesLLM Model OverviewLLM Use CasesModel TypeExpected FieldsSummarizationModelTypes.GENERATIVE_LLMprompt_column_name , response_column_nameQuestion AnsweringModelTypes.GENERATIVE_LLMprompt_column_name, response_column_nameStep-by-Step Guide To Upload LLMsGoogle ColaboratoryLogging LLM Code ExamplePython PandasPython Single RecordExample Row documentsummaryreference_summarydocument_vectorsummary_vectorScareBLEUrogueLprediction_idprediction_tsIt was once the edgiest place in town, attracting the  ...The Variety Theater in Cleveland, once a ...Cleveland's Variety Theater was a renowned rock ...[-0.0051908623, -0.05508642, -0.28958365, -0.2...[-0.18691051, -0.2092136, -0.16603243, -0.3258...5.3903280.216561 dd824bd3-2097...2023-04-05 20:33:22.006650000from arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, EmbeddingColumnNames\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b# Declare embedding feature columnsprompt_columns=EmbeddingColumnNames(    vector_column_name=\"document_vector\",    data_column_name=\"document\"),response_columns=EmbeddingColumnNames(    vector_column_name=\"summary_vector\",    data_column_name=\"summary\")\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    tag_column_names=[\"sacreBLEU\", \"rouge1\", \"rouge2\", \"rougeL\", \"rougeLsum\"],    prompt_column_names=prompt_columns,    response_column_names=response_columns)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=demo-generative-ai-text-summarization,     model_version= \"v1\",    model_type=ModelTypes.GENERATIVE_LLM,    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)Generate Evaluation Metrics (Optional)Use Arize to generate LLM evaluation metrics using the Python SDK. Supported metrics include BLEU, SacreBLEU, GoogleBLEU, ROUGE, and METEOR.To get access to these metrics, install the extra dependencies viapip install arize[LLM_Evaluation]Learn how to generate LLM evaluation metrics here.Generate Embeddings Vectors (Optional)GENERATIVE_LLM models require prompt_column_names and response_column_names using the EmbeddingColumnNames class to send the raw text and the embedding vector associated with it. If you don't have embedding vectors yet, import the EmbeddingGenerator to generate your embeddings. Learn more here. If you already have your own embeddings, you can skip this.pip install arize[AutoEmbeddings]\u200b# Generate embeddings vectorsfrom arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200bgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.NLP.SUMMARIZATION,    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512,    batch_size=100)df[\"document_vector\"] = generator.generate_embeddings(text_col=df[\"document\"])df[\"summary_vector\"] = generator.generate_embeddings(text_col=df[\"summary\"])Prompt & Response EmbeddingsThe above example demonstrates how to obtain Arize-generated embedding vectors. Use the EmbeddingColumnNames object to define the prompt_column_names and response_column_names required in your model schema. The vector_column_name should be the name of the column where the embedding vectors are stored. The embedding vector is the dense vector representation of the unstructured input. \u26a0 Note: embedding features are not sparse vectors.The data_column_name should be the name of the column where the raw text associated with the vector is stored. It is the field typically chosen for NLP use cases. The column can contain both strings (full sentences) or a list of strings (token arrays). # Declare embedding feature columnsprompt_columns=EmbeddingColumnNames(    vector_column_name=\"document_vector\",    data_column_name=\"document\"),response_columns=EmbeddingColumnNames(    vector_column_name=\"summary_vector\",    data_column_name=\"summary\")See here for more information on embeddings and options for generating them.from arize.api import Clientfrom arize.utils.types import ModelTypes, Environments, Embedding\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b# example features# features = { 'feature_name': feature_value, ...}\u200b# example tagstags = { 'step': 0, 'task_type': 'Q&A', 'conversation_id': '0a9c', 'api_call_duration': 6.238615, 'response_len': 73, 'prompt_len': 88, 'prompt_template': \"You are an agent engineered to provide concise and precise answers to any question.\"}\u200bprompt = Embedding(    vector= [0.10031, -0.06012, -0.00259, -0.08568, ...],    data=\"! Why does the UI have to be so clunky and unintuitive?! It's like every time I try to navigate through the options,", "start_char_idx": 0, "end_char_idx": 6381, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b87ee96d-2344-4211-9144-53cb4d16ee45": {"__data__": {"id_": "b87ee96d-2344-4211-9144-53cb4d16ee45", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8a8129ed-98b1-4192-88ed-62a44704b630", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "hash": "e9946fe006776a001748007d193ce68857882a45da095bb423558f00ef873f79"}, "2": {"node_id": "1091a6e9-52c6-4420-beb3-852ab28b58d7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}, "hash": "a8811f44caeed0769d586802cd9c9b29a0b21e36fa99a3d614534c10557a2b9d"}}, "hash": "d0130964dfba6770fc65287b9f84af429138d407eebdd128e8defd9c3400258f", "text": "I end up getting lost in a sea of confusing menus and poorly labeled buttons. And don't even get me started on the color scheme - who thought neon green on black was a good idea? At this point, I'm ready to throw my computer out the window and switch to a different product altogether. Come on, developers - make things simpler for us already!\")response = Embedding(    vector= [-0.11366, -0.20642, -0.03115, -0.18099,...],    data=\"I'm sorry to hear that you're experiencing difficulties with the UI. As an AI language model, I don't have the capability to change the UI, but I suggest looking into user guides, tutorials or support forums to help navigate through the menus more easily. Additionally, you could provide feedback to the developers on the UI, either through in-product feedback tools or their website. They may take into account your suggestions in future updates.\")\u200b# Log data into the Arize platformresponse = arize_client.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.GENERATIVE_LLM,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882, # prediction_label will default to 1 if not sent    actual_label=1, # 1 represents a thumbs up, the user liked the response of the model    features=features,    tags=tags,    prompt=prompt,    response=response,)Prompt & Response EmbeddingsUse the Embedding object to create the prompt(containing the document_vector) and the response(containing the summary_vector). Both prompt and response are required for GENERATIVE_LLM model type.The embedding vector is the dense vector representation of the unstructured input.  \u26a0 Note: embedding features are not sparse vectors.The embedding data is the raw text data associated with the vector.# Build prompt & response embeddingsprompt = Embedding(    vector= [0.10031, -0.06012, -0.00259, -0.08568, ...],    data=\"! Why does the UI have to be so clunky and unintuitive?! It's like every time I try to navigate through the options, I end up getting lost in a sea of confusing menus and poorly labeled buttons. And don't even get me started on the color scheme - who thought neon green on black was a good idea? At this point, I'm ready to throw my computer out the window and switch to a different product altogether. Come on, developers - make things simpler for us already!\")response = Embedding(    vector= [-0.11366, -0.20642, -0.03115, -0.18099,...],    data=\"I'm sorry to hear that you're experiencing difficulties with the UI. As an AI language model, I don't have the capability to change the UI, but I suggest looking into user guides, tutorials or support forums to help navigate through the menus more easily. Additionally, you could provide feedback to the developers on the UI, either through in-product feedback tools or their website. They may take into account your suggestions in future updates.\")See here for more information on embeddings and options for generating them. Sending Data Methods - PreviousSnowflakeNext - Model TypesBinary ClassificationLast modified 12d agoOn this pageLLM Model OverviewLogging LLM Code ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6382, "end_char_idx": 9753, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ba8b0bfd-f43f-48cf-9ee3-bf03a0355bc4": {"__data__": {"id_": "ba8b0bfd-f43f-48cf-9ee3-bf03a0355bc4", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b39574db-5e18-4917-8641-5ac1cdbd767a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "hash": "ccb9806b509ca90a3976f48fe437e33e5346ce2e538c2744ae421d5970f29417"}, "3": {"node_id": "24851f7b-8d9e-4777-a679-1387840a511c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "hash": "c20a8bc9b2a7b498a8025de58e7ba3a76d976ebd8b996aa3a40993e9c4c8a66e"}}, "hash": "1ba1a5454844576144a3f84c4dc0f2ae841772cee9075c2ea5081bf19dc61075", "text": "Multi-Class Classification - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookMulti-Class ClassificationHow to log your model schema for multiclass classification modelsMulti-class Classification CasesMulti-class classification cases differ based on your model's score and label availability. The case determines the performance metrics available. VariantExpected FieldsPerformance MetricsAllowed Metric FamiliesArize RepresentationCase 1: Supports Only Classification Metricsprediction label, actual labelAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityClassification1 inference can be represented regardless of prediction label cardinalityCase 2: Support Classification & AUC Metricsprediction label, actual label, prediction score, actual scoreAUC, PR-AUC, Log Loss, Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityClassification, AUC/LogLossrequires 1 inference per prediction label cardinality\u200bCase #1 : Supports Only Classification Metrics \u200bPython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample RowClasstierzip_codeprediction_labelactual_labeltimestamp1'gold'12345\"economy\"\"business\"8970299402'platinum'542321\"business\"\"business\"8970299403'silver'12312\"first\"\"business\"897029940Code Exampleschema=Schema(      prediction_id_column_name='prediction_id',      prediction_label_column_name='prediction_label',      actual_label_column_name='actual_label',      feature_column_names=['tier']      tag_column_names=['zip_code'])\u200bresponse = arize_client.log(   dataframe=sample_df,   schema=schema,   model_id='sample-model-1',   model_version='1.0',   model_type=ModelTypes.SCORE_CATEGORICAL,   environment=Environments.PRODUCTION)\u200bFor more details on Python Batch API Reference, visit here: Python Pandas (batch)Google ColaboratoryCode Example# Predicting likelihood of Economy, Business, or First Class\"\"\"example_record = {   \"prediction_scores\":{      \"economy_class\":0.81,      \"business_class\":0.42,      \"first_class\":0.35   },   \"prediction\": \"economy_class\",   \"actual\": \"business_class\"}\"\"\"\u200b# Logging only the predicted label and the actual label response = arize_client.log(    model_id='sample-model-1',    model_version='1.0',    environment=Environments.PRODUCTION,    model_type=ModelTypes.SCORE_CATEGORICAL,    prediction_id= \"1\",    prediction_label= \"economy_class\",    actual_label= \"business_class\",)\u200bFor more information on Python Single Record Logging API Reference, visit here:Python Single RecordDownload an example Parquet file:\nOpen parquet reader here.https://storage.googleapis.com/arize-assets/documentation-sample-data/data-ingestion/multiclass-classification-assets/multiclass-sample-data.parquetLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQuery\u200b\u200bCase #2: Supports Classification & AUC Metrics\u200bPython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample RowClasstierprediction_label_for_economyactual_labelprediction_score_for_economyactual_scoretimestamp1'gold'\"economy\"\"business\"0.810897029940Classtierprediction_label_for_economyactual_labelprediction_score_for_economyactual_scoretimestamp1'gold'\"economy\"\"business\"0.810897029940Classtierprediction_label_for_firstactual_labelprediction_score_for_firstactual_scoretimestamp3'silver'\"first\"\"business\"0.350897029940Code Example #Logging probability of Economy Classschema=Schema(      prediction_id_column_name='prediction_id',      prediction_label_column_name='prediction_label_for_economy',      prediction_score_column_name='prediction_score_for_economy',      actual_label_column_name='actual_label')response = arize_client.log(   dataframe=sample_df,   schema=schema,   model_id='sample-model-1',   model_version='1.0',   model_type=ModelTypes.MULTICLASS_CLASSIFICATION,   metrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS],   environment=Environments.PRODUCTION)\u200b#Logging probability of Business Classschema=Schema(      prediction_id_column_name='prediction_id',      prediction_label_column_name='prediction_label_for_business',      prediction_score_column_name='prediction_score_for_business',      actual_label_column_name='actual_label')response = arize_client.log(   dataframe=sample_df,   schema=schema,   model_id='sample-model-1',   model_version='1.0',   model_type=ModelTypes.MULTICLASS_CLASSIFICATION,   metrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS],   environment=Environments.PRODUCTION)\u200b#Logging probability of First Classschema=Schema(      prediction_id_column_name='prediction_id',      prediction_label_column_name='prediction_label_for_first',      prediction_score_column_name='prediction_score_for_first',      actual_label_column_name='actual_label')response = arize_client.log(   dataframe=sample_df,   schema=schema,   model_id='sample-model-1',   model_version='1.0', ", "start_char_idx": 0, "end_char_idx": 6295, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "24851f7b-8d9e-4777-a679-1387840a511c": {"__data__": {"id_": "24851f7b-8d9e-4777-a679-1387840a511c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b39574db-5e18-4917-8641-5ac1cdbd767a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "hash": "ccb9806b509ca90a3976f48fe437e33e5346ce2e538c2744ae421d5970f29417"}, "2": {"node_id": "ba8b0bfd-f43f-48cf-9ee3-bf03a0355bc4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}, "hash": "1ba1a5454844576144a3f84c4dc0f2ae841772cee9075c2ea5081bf19dc61075"}}, "hash": "c20a8bc9b2a7b498a8025de58e7ba3a76d976ebd8b996aa3a40993e9c4c8a66e", "text": " model_type=ModelTypes.MULTICLASS_CLASSIFICATION,   metrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS],   environment=Environments.PRODUCTION)Arize expects the DataFrame's index to be sorted and begin at 0. If you perform operations that might affect the index prior to logging data, reset the index as follows:dataframe = dataframe.reset_index(drop=True)\u200bFor more details on Python Batch API Reference, visit here: Python Pandas (batch)Google ColaboratoryCode Example# Predicting Economy Class, Business Class, First Class\"\"\"example_record = {   \"prediction_scores\": {      \"economy_class\":0.81,      \"business_class\":0.42,      \"first_class\":0.35   },   \"predicted_class\": \"economy_class\",   \"actual\": \"business_class\"}\"\"\"\u200b# Prediction #1 - Logging probability of Economy Classresponse = arize_client.log(       model_id='sample-model-1',        model_version='1.0',       model_type=ModelTypes.SCORE_CATEGORICAL,       environment=Environments.PRODUCTION,       prediction_id=\"1-economy\",        prediction_label= \"economy\",       prediction_score=0.81,       actual_label= \"business_class\"       actual_score=0)\u200b# Prediction #2 - Logging probability of Business Classresponse = arize_client.log(       model_id='sample-model-1',        model_version='1.0',       model_type=ModelTypes.SCORE_CATEGORICAL,       environment=Environments.PRODUCTION,       prediction_id=\"1-business\",        prediction_label=\"business\",       prediction_score=0.42       actual_label=\"business\",       actual_score=1)\u200b# Prediction #3 - Logging probability of First Classresponse = arize_client.log(       model_id='sample-model-1',        model_version='1.0',       model_type=ModelTypes.SCORE_CATEGORICAL,       environment=Environments.PRODUCTION,       prediction_id=\"1-first\",        prediction_label=\"first\",        prediction_score=0.35,       actual_label=\"business\",       actual_score=0)\u200bFor more information on Python Single Record Logging API Reference, visit here:Python Single RecordDownload an example Parquet file:\nOpen parquet reader here.https://storage.googleapis.com/arize-assets/documentation-sample-data/data-ingestion/multiclass-classification-assets/multiclass-sample-data.parquetLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryQuick DefinitionsPrediction Label: The classification label of this event (Cardinality > 2)Actual Label: The ground truth label (Cardinality > 2)Prediction Score: The likelihood of that prediction class (1 per cardinality of prediction label)  Actual Score: The ground truth score of that class (1 per cardinality of prediction label)  Model Types - PreviousBinary ClassificationNext - Model TypesRegressionLast modified 11d agoOn this pageMulti-class Classification CasesCase #1 : Supports Only Classification Metrics Case #2: Supports Classification & AUC MetricsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6296, "end_char_idx": 9407, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "93b509dd-c543-49e1-ba3d-4f63437a8457": {"__data__": {"id_": "93b509dd-c543-49e1-ba3d-4f63437a8457", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47377e5f-9894-429c-a4a1-dbc0d0dd406b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "hash": "ff78029c26f5996bc03296fbd8c32012cbfe9c6e54b8dff65014894a8054e251"}, "3": {"node_id": "f2bcef10-15a7-49d7-8c60-ef8d33c95c53", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "hash": "e9c6ff9a4fff2fe7e476439e7d13dfe286403b59299d753c880f9da32600621a"}}, "hash": "c77f01448f98c0b35ed1a143d07f801d2e281fcaddaf9b3b3419d8a8e94199bc", "text": "Natural Language Processing (NLP) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookNatural Language Processing (NLP)How to log your model schema for text classification use casesNLP Model Overview\u200bText Classification Models predict the categories a piece of text might belong to. NLP CasesExpected FieldsPerformance Metrics\u200bNLP Classification\u200b*prediction label, actual label, prediction score, actual scoreAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, Specificity\u200bNLP NER\u200b*prediction label, actual label, prediction score, actual scoreAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, Specificity*all classification variant specifications apply to the NLP model type, with the addition of embeddingsCode ExampleThe EmbeddingColumnNames class constructs your embedding objects. You can log them into the platform using a dictionary that maps the embedding feature names to the embedding objects. See our API reference for more details.Python PandasPython Single RecordUI Import JSON Input Import for APIExample Row text_vectortextprediction_labelactual_labelprediction_scoreactual_scoreTimestamp[4.0, 5.0, 6.0, 7.0]\"This is a test sentence\"positiveneutral0.311618590882from arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, EmbeddingColumnNames\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b\u200b# Declare which columns are the feature columnsfeature_column_names=[ \"MERCHANT_TYPE\",  \"ENTRY_MODE\",  \"STATE\",  \"MEAN_AMOUNT\",  \"STD_AMOUNT\",  \"TX_AMOUNT\",]\u200b# Declare embedding feature columnsembedding_feature_column_names = { # Dictionary keys will be the name of the embedding feature in the app \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"text_vector\", # column name of the vectors, required        data_column_name=\"text\", # column name of the raw data vectors are representing, optional )}\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"PREDICTION\",    prediction_score_column_name=\"PREDICTION_SCORE\",    actual_label_column_name=\"ACTUAL\",    actual_score_column_name=\"ACTUAL_SCORE\",    feature_column_names=feature_column_names,    embedding_feature_column_names=embedding_feature_column_names,)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=\"sample-model-1\",    model_version= \"v1\",    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)Google ColaboratoryNLP Embedding Features Arize supports logging the embedding features associated with the text the model is acting on and the text itself using the EmbeddingColumnNames object. The vector_column_name should be the name of the column where the embedding vectors are stored. The embedding vector is the dense vector representation of the unstructured input. \u26a0 Note: embedding features are not sparse vectors.The data_column_name should be the name of the column where the raw text associated with the vector is stored. It is the field typically chosen for NLP use cases. The column can contain both strings (full sentences) or a list of strings (token arrays). {  \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"text_vector\",         data_column_name=\"text\"  ) }See here for more information on embeddings and options for generating them.from arize.api import Clientfrom arize.utils.types import ModelTypes, Environments, Embedding\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200b# Example featuresfeatures = { 'state': 'ca', 'city': 'berkeley', 'merchant_name': 'Peets Coffee', 'pos_approved': True, 'item_count': 10, 'merchant_type': 'coffee shop', 'charge_amount': 20.11,} # Example embedding featuresembedding_features = { \"nlp_embedding\": Embedding(            vector=np.array([4.0, 5.0, 6.0, 7.0]),            data=\"This is a test sentence\", ),}\u200b# Log data into the Arize platformresponse = arize.log(    model_id='sample-model-1',     model_version='v1\",     model_type=ModelTypes.SCORE_CATEGORICAL,     environment=Environments.PRODUCTION,    features=features    prediction_label=\"not fraud\",    prediction_score = 0.3    actual_label=\"fraud\",    actual_score = 1    features=features,    embedding_features=embedding_features )NLP Embedding Features Arize supports logging the embedding features associated with the text the model is acting on and the text itself using the Embedding object.The embedding vector is the dense vector representation of the unstructured input.  \u26a0 Note: embedding features are not sparse vectors.The embedding data is the raw data associated with the vector. It is the field typically chosen for NLP use cases since you can introduce both strings (full sentences) or a list of strings (token arrays). {  \"embeddinEmbeddingg_display_name\": EmbeddingColumnNames(        vector=np.array([4.0, 5.0, 6.0, 7.0]),  ", "start_char_idx": 0, "end_char_idx": 6545, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f2bcef10-15a7-49d7-8c60-ef8d33c95c53": {"__data__": {"id_": "f2bcef10-15a7-49d7-8c60-ef8d33c95c53", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "47377e5f-9894-429c-a4a1-dbc0d0dd406b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "hash": "ff78029c26f5996bc03296fbd8c32012cbfe9c6e54b8dff65014894a8054e251"}, "2": {"node_id": "93b509dd-c543-49e1-ba3d-4f63437a8457", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}, "hash": "c77f01448f98c0b35ed1a143d07f801d2e281fcaddaf9b3b3419d8a8e94199bc"}}, "hash": "e9c6ff9a4fff2fe7e476439e7d13dfe286403b59299d753c880f9da32600621a", "text": "     data=\"This is a test sentence\", ) }See here for more information on embeddings and options for generating them. When configuring an embedding in the UI using File Import \"embedding_features\": [{ \"my_feature\": #required, my_feature is the name of the feature {           vector: \"vector_col\", #required, vector_col is the column name of the vector           raw_data: \"raw_data_col\", #optional           link_to_data: \"link_to_data_col\" #optional }}]Example file schema with embedding features{ \"prediction_id\": \"prediction_id\", \"timestamp\": \"timestamp\", \"tags\": \"tag/\", \"prediction_score\": \"prediction_score\", \"prediction_label\": \"prediction_label\", \"actual_label\": \"actual_label\", \"actual_score\": \"actual_score\", \"shap_values\": \"shap/\", \"version\": \"version\", #lookup the column \"version\" in the file \"batch_id\": \"batch_id\", \"exclude\": [ \"<column1 name>\", \"<column2 name>\" ], \"embedding_features\": [ { \"embedding_1\": { \"vector\": \"vector_column_1\" \"raw_data\": \"raw_data_column_1\", \"link_to_data\": \"link_to_data_column\" } } ]}When configuring an embedding in the UI using the API\"embeddingFeatures\": [{ \"featureName\": \"my_feature\", \"vectorCol\": \"vector_col\", \"rawDataCol\": \"raw_data_col\", \"linkToDataCol\": \"link_to_data_col\"}]Example file schema with embedding featuresprediction_id: prediction_idtimestamp: timestampfeatures: feature/tags: tag/prediction_score: prediction_scoreprediction_label: prediction_labelactual_label: actual_labelactual_score: actual_scoreshap_values: shap/version: version #lookup the column \"version\" in the filebatch_id: batch_idexclude: #leave empty to omit column exclusionsembedding_features: #leave empty to omit embeddingsPreviousCollaborative FilteringNext - Model TypesImage ClassificationLast modified 12d agoOn this pageNLP Model OverviewCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6546, "end_char_idx": 8561, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "16677c61-fdb5-4197-924b-be5f956e5a2b": {"__data__": {"id_": "16677c61-fdb5-4197-924b-be5f956e5a2b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/object-detection"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ac472271-e567-4a83-a75a-9d01c41090df", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/object-detection"}, "hash": "cd45dcbdbd017ea3650678ec112003e3ea5f24bb9ed68a293c31724924f85269"}}, "hash": "0514e71d1e8cda444b15c08787608a44f2e1bed7c7eec2951956ad70af2bc618", "text": "Object Detection - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookObject DetectionHow to declare your model schema and log data for object detection modelsObject detection model type support is in early release. Reach out to [email\u00a0protected] for access. Object Detection Model OverviewObject detection models identify and locate objects within images or videos by assigning them specific bounding boxes.Applicable Metrics: Accuracy, Euclidian Distance (embeddings)Click here for all valid model types and metric combinations. Object Detection Code ExamplePython BatchExample Rowimage_vectorimage_linkprediction_bboxes\tactual_bboxesprediction_categoriesactual_categoriesactual_super_categoriesprediction_scoresTimestamp[0.24713118374347687, 0.7061651349067688, 1.12...\"https://link-to-my-image.png\"[[50.43, 109.49, 538.21...[[55.39, 107.72, 539.25, 362.9], [554.41, 194....[bus][bus, person, person][vehicle, person, person][0.9997552]1618590882embedding_feature_column_names={ \"image_embedding\": EmbeddingColumnNames(        vector_column_name=\"image_vector\",        link_to_data_column_name=\"url\" )}object_detection_prediction_column_names=ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name=\"prediction_bboxes\",    categories_column_name=\"prediction_categories\",    scores_column_name=\"prediction_scores\")object_detection_actual_column_names=ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name=\"actual_bboxes\",    categories_column_name=\"actual_categories\",)\u200b# Defina the Schema, including embedding informationschema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    tag_column_names=tags,    embedding_feature_column_names=embedding_feature_column_names,    object_detection_prediction_column_names=object_detection_prediction_column_names,    object_detection_actual_column_names=object_detection_actual_column_names,)\u200bresponse = arize_client.log(    model_id= \"CV-object-detection\",    model_version= \"v1\",    model_type=ModelTypes.OBJECT_DETECTION,    environment=Environments.PRODUCTION,    dataframe=df,    schema=schema)Google ColaboratoryFor more details on Python Batch API Reference, visit here: Python Pandas (batch)Object Detection Prediction & Actual ValuesArize supports logging object detection prediction and actual values using the ObjectDetectionColumnNames object, which can be assigned to the prediction/actual schema parameters, object_detection_prediction_column_names and object_detection_actual_column_names.Object prediction or actual declaration is required to use the object detection model type in Arize. class ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name: str    categories_column_name: str    scores_column_name: Optional[str] = None # actual ground truth labels wont have scores)Embedding FeaturesIn addition to object detection prediction and actual values, Arize supports logging the embedding features associated with the images in an object detection model using the EmbeddingColumnNames object.The vector_column_name should be the name of the column where the embedding vectors are stored. The embedding vector is the dense vector representation of the unstructured input. \u26a0 Note: embedding features are not sparse vectors.The link_to_data_column_name should be the name of the column where the URL links to the source images are stored.{  \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"image_vector\",         link_to_data_column_name=\"image_link\"  ) }See here for more information on embeddings and options for generating them.Model Types - PreviousImage ClassificationNext - MonitorsGet Started With MonitorsLast modified 1mo agoOn this pageObject Detection Model OverviewObject Detection Code ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5441, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d50b4666-97f6-4277-9db1-6bea12e17e6a": {"__data__": {"id_": "d50b4666-97f6-4277-9db1-6bea12e17e6a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "414b333b-aa29-4e5b-b413-386f76d75009", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "caec94bc7216d72fb29e6a61b9c5d7aa1af2ff6b911dc6aebb5579d8ac7c6d14"}, "3": {"node_id": "173378f1-c1a7-419d-a969-bb83da7e026a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "613b93e7d1ef3f4e8abdac1783df008a2a1f0767f174fd468ec39ea73c7af5ad"}}, "hash": "de7b04b42aa776e43fe4dde37b5b04139e60d3b2827cf87b567eef21ffab10b2", "text": "Ranking - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingCollaborative FilteringNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRankingHow to log your model schema for ranking modelsRanking Model OverviewThere are four key ranking model use cases to consider:Search RankingCollaborative Filtering Recommender SystemsContent Filtering Recommender SystemsClassification-Based Ranking Models Different metrics are used for ranking model evaluation based on your model use case, score, and label availability. The case determines the available performance metrics. Click here for all valid model types and metric combinations. Ranking CasesExample Use CaseExpected FieldsPerformance Metrics\u200bCase 1: Ranking with Relevance Score\u200bModel predicts score used to rankrank, relevance score\u200bNDCG\u200b\u200bCase 2: Ranking with Single Label\u200bModel predicts binary actions a user can take which is used to rank rank, relevance_labels\u200bNDCG, GroupAUC, MAP, MRR\u200b\u200bCase 3: Ranking with Multiple Labels\u200bModel predicts multiple actions a user can take which is used to rank rank, relevance_labels (list of strings)\u200bNDCG, GroupAUC, MAP, MRR \u200b\u200bRanking + AUC and LogLoss\u200bModel can also be evaluated using AUC + LogLossRanking Case 2 or 3, prediction score\u200bNDCG, GroupAUC, MAP, MRR, AUC, PR-AUC, Log Loss\u200bGeneral Ranking Model Schema Ranking models have a few unique model schema fields that help Arize effectively monitor, trace, and visualize your ranking model data. Prediction Group ID: A subgroup of prediction data. Max 100 ranked items within each groupRank: Unique value within each prediction group (1-100)Relevancy Score/Label: Ground truth score/label associated with the modelCase 1: Ranking with Relevance ScoreIn the ranking model context, a relevance score is the numerical score used to rank items in a list. For example, the higher the relevance_score, the more important the item is. Relevancy scores often represent probabilities of an engagement or action such as probability of a click or purchase. rank and relevance_score are required to compute rank-aware evaluation metrics on your model. Ranking Model FieldsData TypeExamplerankint from 1-1001relevance_scorenumeric (float | int)0.5prediction_group_idstring limited to 128 characters148Code ExamplePython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample Rowstatepricesearch_idrankrelevance_scoreprediction_tsca9814810.51618590882schema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_group_id_column_name = \"search_id\",    rank_column_name = \"rank\",    relevance_score_column_name = \"relevance_score\",    feature_column_names=[\"state\", \"price\"])\u200bresponse = arize_client.log(    dataframe=df,    model_id=\"ranking-relevance-score-batch-ingestion-tutorial\",    model_version=\"1.0\",    model_type=ModelTypes.RANKING,    metrics_validation=[Metrics.RANKING],    environment=Environments.PRODUCTION,    schema=schema,)For more details on Python Batch API Reference, visit here: Python Pandas (batch)Google Colaboratory# import extra dependenciesfrom arize.utils.types import Environments, ModelTypes, Schema, RankingPredictionLabel, RankingActualLabel\u200b# define prediction label argumentspred_label = RankingPredictionLabel(    group_id=\"148\",     rank=1,     score=0.155441 )\u200b# define actual label argumentact_label = RankingActualLabel(    relevance_score=0)\u200b# log data to Arizeresponse = arize_client.log(    model_id=\"demo-ranking-with-relevance-score\",    model_version=\"v1\",    environment=Environments.PRODUCTION,    model_type=ModelTypes.RANKING,    prediction_id=\"311103e3-a493-40ea-a21a-e457d617c956\",    prediction_label=pred_label,    actual_label=act_label,    features=features)Download an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/ranking-assets/ranking-relevance-score-sample-data.parquet?authuser=0storage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryCase 2: Ranking with Single Label Since relevance_score is required to compute rank-aware evaluation metrics, Arize uses an attribution model to create a relevance_score based on your positive class and relevance_labels. Learn more about our attribution model here.Ranking Model FieldsData TypeExamplerankint from 1-1001relevance_labelsstring\u201cclick\u201dprediction_group_idstring limited to 128 characters148Code ExamplePython PandasPython Single RecordData ConnectorsGoogle ColaboratoryExample Rowstatepricesearch_idrankactual_relevancyprediction_tsca981481\"not relevant\"1618590882schema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_group_id_column_name = \"search_id\",    rank_column_name = \"rank\",    relevance_labels_column_name = \"actual_relevancy\",    feature_column_names=[\"state\", \"price\"])\u200bresponse = arize_client.log(    dataframe=df,    model_id=\"ranking-single-label-batch-ingestion-tutorial\",    model_version=\"1.0\",    model_type=ModelTypes.RANKING,    metrics_validation=[Metrics.RANKING, Metrics.RANKING_LABEL],    environment=Environments.PRODUCTION,    schema=schema,)For more details on Python Batch API Reference, visit here: Python Pandas (batch)Google Colaboratory# import extra dependenciesfrom arize.utils.types", "start_char_idx": 0, "end_char_idx": 6750, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "173378f1-c1a7-419d-a969-bb83da7e026a": {"__data__": {"id_": "173378f1-c1a7-419d-a969-bb83da7e026a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "414b333b-aa29-4e5b-b413-386f76d75009", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "caec94bc7216d72fb29e6a61b9c5d7aa1af2ff6b911dc6aebb5579d8ac7c6d14"}, "2": {"node_id": "d50b4666-97f6-4277-9db1-6bea12e17e6a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "de7b04b42aa776e43fe4dde37b5b04139e60d3b2827cf87b567eef21ffab10b2"}, "3": {"node_id": "29f053dc-3e4b-4871-8e91-ba18e5c36cea", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "d49a512c1f59a7e8137cc6a8c9d54da025414ce830ea6af427d4050bf4b536bf"}}, "hash": "613b93e7d1ef3f4e8abdac1783df008a2a1f0767f174fd468ec39ea73c7af5ad", "text": "import Environments, ModelTypes, Schema, RankingPredictionLabel, RankingActualLabel\u200b# define prediction label argumentspred_label = RankingPredictionLabel(    group_id=\"148\",     rank=1,     label=\"relevant\" )\u200b# define actual label argumentact_label = RankingActualLabel(    relevance_labels=[\"Not relevant\"])\u200b# log data to Arizeresponse = arize_client.log(    model_id=\"demo-ranking-with-single-label\",    model_version=\"v1\",    environment=Environments.PRODUCTION,    model_type=ModelTypes.RANKING,    prediction_id=\"311103e3-a493-40ea-a21a-e457d617c956\",    prediction_label=pred_label,    actual_label=act_label,    features=features)Download an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/ranking-assets/ranking-single-label-sample-data.parquet?authuser=0storage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryCase 3: Ranking with Multiple Labels In this case, each prediction on an item within a list is sent as an individual event while the possible relevance_labels can be multi-label (list) as ground truth can contain multiple events for an individual group or list.Since relevance_score is required to compute rank-aware evaluation metrics, Arize uses an attribution model to create a relevance_score based on your positive class and relevance_labels. Learn more about our attribution model here.Ranking Model FieldsData TypeExamplerankint from 1-1001relevance_labelslist of strings[\u201cclick\u201d, \u201cfavorite\u201d, \u201cbuy\u201d]prediction_group_idstring limited to 128 characters148Code ExamplePython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample Rowstatepricesearch_idrankattributionsprediction_tsca981481\"click, favorite, buy\"1618590882schema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_group_id_column_name = \"search_id\",    rank_column_name = \"rank\",    relevance_labels_column_name = \"attributions\"    feature_column_names=[\"state\", \"price\"])\u200bresponse = arize_client.log(    dataframe=df,    model_id=\"ranking-multiple-labels-batch-ingestion-tutorial\",    model_version=\"1.0\",    model_type=ModelTypes.RANKING,    metrics_validation=[Metrics.RANKING, Metrics.RANKING_LABEL],    environment=Environments.PRODUCTION,    schema=schema,)For more details on Python Batch API Reference, visit here: Python Pandas (batch)Google Colaboratory# import extra dependenciesfrom arize.utils.types import Environments, ModelTypes, Schema, RankingPredictionLabel, RankingActualLabel\u200b# define prediction label argumentspred_label = RankingPredictionLabel(    group_id=\"148\",     rank=2,     label=\"click\" )\u200b# define actual label argumentact_label = RankingActualLabel(    relevance_labels=[\"book\", \"click\"],    relevance_score=0)\u200b# log data to Arizeresponse = arize_client.log(    model_id=\"demo-ranking-with-multiple-labels\",    model_version=\"v1\",    environment=Environments.PRODUCTION,    model_type=ModelTypes.RANKING,    prediction_id=\"dd19bee3-e7f4-4207-aef9-3abdad2a9be0\",    prediction_label=pred_label,    actual_label=act_label,    features=features)Download an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/ranking-assets/ranking-multiple-labels-sample-data.parquet?authuser=0storage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryRanking Single or Multi-Label + AUC and LogLossFor ranked lists based on a prediction of the action a user can take across single or multiple possible actions. AUC and LogLoss are computed based on prediction_score and relevance_labels (or default relevance_labels in the case of multi-label).Ranking Model FieldsData TypeExamplerankint from 1-1001prediction_scorefloat0.5prediction_group_idstring limited to 128 characters148Ranking Performance MetricsRank-aware evaluation metrics: NDCG @k (MAP @K & MRR coming soon)Evaluation metrics: AUC, PR-AUC, LogLossNDCG @k Normalized discounted cumulative gain (NDCG) is a rank-aware evaluation metric that measures a model's ability to rank query results in the order of the highest relevance (graded relevance). You can read more about how NDCG is computed here. What is @k?The k value determines the metric computation up to position k in a list.Selecting Relevance Score or Label - Attribution ModelA relevance score is required to calculate rank-aware evaluation metrics. If your relevance_score is unavailable, the Arize platform will calculate a relevance_score using a simple attribution model with a prediction label and a relevance label. Arize computes a binary relevance value (0/1) based on the default positive class.Positive class \"buy\" and relevance label is \"buy\" --> relevance will be attributed to 1.Positive class \"buy\" and relevance label is else --> relevance will be attributed to 0.Positive class \"buy\" and relevance labels are [\"buy\", \"click\", \"scroll\"] --> relevance will be attributed to sum([1,0,0])Ranking Quick DefinitionsRanking model: Assigns a rank to each item in a prediction group (also known as a batch or query), across many possible groups.Arize supports pointwise, pairwise, and listwise ranking modelsPrediction Group: A group of predictions within which items are ranked.Example: A user of a hotel booking site types in a search term (\u201cskiing\u201d) and is presented with a list of results representing a single queryRank: The predicted rank of an item in a prediction group (Integer between 1-100).Example: Each item in the search prediction group has a rank determined by the model (i.e. Aspen is assigned rank=1, Tahoe is assigned rank=2, etc. based on input features and query features to the model)Relevance Score (i.e. Actual Scores): The ground truth relevance score (numeric). Higher scores denote higher relevance.Example: Each item in the search prediction group has a score determined by the action a user took on the item (i.e. \u201cclicking\u201d on an item indicates relevance score = 0.5, purchasing an item indicates relevance score = 1)Rank-Aware Evaluation Metric: A rank-aware evaluation metric is an evaluation metric that gauges rank order and relevancy of predictions. Rank-aware evaluation metrics include NDCG, MRR, and MAP. Note that MRR and MAP also require relevance_labels to be provided to be computed.Model Types - PreviousTimeseries ForecastingNextCollaborative FilteringLast modified 2mo agoOn this pageRanking Model OverviewGeneral Ranking Model Schema Case 1: Ranking with Relevance ScoreCase 2:", "start_char_idx": 6751, "end_char_idx": 13420, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "29f053dc-3e4b-4871-8e91-ba18e5c36cea": {"__data__": {"id_": "29f053dc-3e4b-4871-8e91-ba18e5c36cea", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "414b333b-aa29-4e5b-b413-386f76d75009", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "caec94bc7216d72fb29e6a61b9c5d7aa1af2ff6b911dc6aebb5579d8ac7c6d14"}, "2": {"node_id": "173378f1-c1a7-419d-a969-bb83da7e026a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}, "hash": "613b93e7d1ef3f4e8abdac1783df008a2a1f0767f174fd468ec39ea73c7af5ad"}}, "hash": "d49a512c1f59a7e8137cc6a8c9d54da025414ce830ea6af427d4050bf4b536bf", "text": "Ranking with Single Label Case 3: Ranking with Multiple Labels Ranking Single or Multi-Label + AUC and LogLossRanking Performance MetricsNDCG @k Selecting Relevance Score or Label - Attribution ModelRanking Quick DefinitionsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 13421, "end_char_idx": 13869, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "65555ce6-8473-4fa6-9138-3ec6a81fc09f": {"__data__": {"id_": "65555ce6-8473-4fa6-9138-3ec6a81fc09f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/regression"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b2b7670a-e539-4d40-850f-6f81029442dd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/regression"}, "hash": "b06d251499409b86a41cba4203653c53ef8098c6004c6ef90a2a1345acbea9df"}}, "hash": "7fd0ce7172f839e6e1e7e8724fec06a229a271c740e8122100c5f89bf2fd0d7f", "text": "Regression - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRegressionHow to log your model schema for regression modelsRegression Model OverviewRegression models have a continuous, numeric output. (Examples: click-through rates, sales forecasting, customer lifetime value, ETA models, etc.)Performance MetricsMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorAllowed Metric Families: RegressionClick here for all valid model types and metric combinations. Regression Code ExamplePython PandasPython Single RecordData ConnectorGoogle ColaboratoryExample Rowprice (float)pos_approved (bool)zip_codeageprediction_scoreactual_scoreprediction_ts88.5False1234525100901671572541# Declare the schema of the dataframe you're sending (feature columns, predictions, timestamp, actuals) schema = Schema(    prediction_id_column_name=\"prediction_id\",    timestamp_column_name=\"prediction_ts\",    prediction_score_column_name=\"prediction_score\",    actual_score_column_name=\"actual_score\",    feature_column_names=[\"price\", \"pos_approved\"],    tag_column_names=[\"zip_code\", \"age\"])# Log the dataframe with the schema mappingresponse = client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.REGRESSION,    metrics_validation=[Metrics.REGRESSION],    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema)Google Colaboratoryfeatures = { 'score': '88.5', 'pos_approved': False, } tags = { 'zip_code': '12345' 'age': '25' }\u200bresponse = client.log(    model_id='sample-model-1',     model_version='v1',     model_type=ModelTypes.REGRESSION,    environment=Environments.PRODUCTION,    features = features,     tags=tags    prediction_label=100,    actual_label=90)Download an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/regression-assets/regression_data.parquetstorage.cloud.google.comDownload an example CSV file: https://storage.googleapis.com/arize-assets/fixtures/demand_forecast_prod.csvLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryQuick DefinitionsPrediction Label: The numeric value of the prediction (float | int)Actual Label: The numeric value of the actual (float | int)Model Types - PreviousMulti-Class ClassificationNext - Model TypesTimeseries ForecastingLast modified 4mo agoOn this pageRegression Model OverviewRegression Code ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4111, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7fda9c3d-8ad9-4946-89cd-01817e8a9782": {"__data__": {"id_": "7fda9c3d-8ad9-4946-89cd-01817e8a9782", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/timeseries-forecasting"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "7ffed025-161a-4fb2-8640-980f9c8e8ed3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/timeseries-forecasting"}, "hash": "7e0e1d4e37eb3d9efd248246dd0a84e5936743ac7c06abde1f926fd196c30bcb"}}, "hash": "019fb5ccecdbe4f91ceb1df628a85b444b591d211570a074a5a442a6da248259", "text": "Timeseries Forecasting - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookTimeseries ForecastingTimeseries Forecasting OverviewTimeseries forecasting models are characterized by three fields:forecast timestamp: the date and time of the predicted event or observation and is passed into the timestamp field. (data type: integer unix timestamp in seconds)run_date: the date on which the model was run and the prediction was generated and is optionally passed in as a tag. (recommended data type: str or integer unix timestamp)lag: the number of days between the forecast timestamp and run date and is optionally passed in as a tag (recommended data type: int)You will likely need to extend your model's delayed actuals join window. Reach out to [email\u00a0protected] for help with this.For example, if you run a model on Monday to predict the temperature on Friday, the run date would be Monday's date, the forecast timestamp would be a timestamp for a time on Friday and the lag would be four days.Performance MetricsMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorAllowed Metric Families: RegressionClick here for all valid model types and metric combinations. Timeseries Code ExamplePython BatchPython Single RecordData ConnectorGoogle ColaboratoryExample Rowstatepos_approvedrun_datelagpredicted_thermalreported_thermalforecast_tscatrue'12_16_2022'374.580.21671572541schema = Schema(    prediction_id_column_name=\"prediction_id\",    feature_column_names=feature_column_names,    timestamp_column_name=\"forecast_ts\",    prediction_label_column_name=\"predicted_thermal\",    actual_label_column_name=\"reported_thermal\",    feature_column_names=[\"state\", \"pos_approved\"]    tag_column_names=[ \"run_date\", \"lag\", ],)\u200bresponse = arize_client.log(    dataframe=df,    schema=schema,    model_id=\"time-series-batch-ingestion-tutorial\",    model_version=\"1.0.0\",    model_type=ModelTypes.REGRESSION,    metrics_validation=[Metrics.REGRESSION],    environment=Environments.PRODUCTION )Google Colaboratoryfeatures = { 'state': 'ca', 'pos_approved': True}\u200btags = { 'run_date': '12_16_2022', 'lag': 3} response = arize_client.log(    model_id='sample-model-1'    model_version='1.0.0',    environment=Environments.PRODUCTION,    model_type=ModelTypes.REGRESSION,    prediction_id='1',    prediction_timestamp= 1671572541,    features=features,    prediction_label=74.5,    actual_label=80.2,    tags=tags)Download an example Parquet file:\nOpen parquet reader here.https://storage.cloud.google.com/arize-assets/documentation-sample-data/data-ingestion/time-series-assets/time_series_data.parquetstorage.cloud.google.comLearn how to upload files via various Data Connectors: Google Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryModel Types - PreviousRegressionNext - Model TypesRankingLast modified 4mo agoOn this pageTimeseries Forecasting OverviewPerformance MetricsTimeseries Code ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4537, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4c20d69c-cf97-4b7d-a4b2-b1b16e78f617": {"__data__": {"id_": "4c20d69c-cf97-4b7d-a4b2-b1b16e78f617", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73805f0a-6b4d-4957-9e4b-b3b1eda85abc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "hash": "78ac4f2e8d773441eb1995142adf38f19364d4347171bad63563722fc3a8c04f"}, "3": {"node_id": "f5e46357-54de-4f59-a019-298e8a30a1d7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "hash": "b72c13a8857fe7e6660e4a287c2623a504356617896bfd29412eaa3604d49e9d"}}, "hash": "e4305cd6d1ccb9838d1555c9446a0c53915f16a25741c3b7d6c5afe1ed393a49", "text": "Data Quality Monitors - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookData Quality MonitorsData quality monitoring reference guideWhen To Monitor Data QualityHigh-quality data is fundamental to building reliable, accurate machine learning models and the value of predictions can be significantly compromised by poor data quality. Easily root cause model issues by monitoring key data quality metrics to identify cardinality shifts, data type mismatches, missing data, and more.\ud83c\udfc3 Common Questions:\ud83d\udcdc  How should I monitor if I'm concerned about data pipeline issues?Your data pipeline may occasionally fail or inadvertently drop features. Use count and percent empty monitors to catch these issues. \ud83d\udecd\ufe0f How should I monitor 3rd party/purchased data? 3rd party data is a common culprit of many model performance problems. Use data quality monitors to keep track of quantiles and sum or average values of your 3rd party data.\ud83d\ude85 How should I monitor my features if I frequently retrain my model? Every model retrain has the possibility of  introducing inadvertent changes to features. Use data quality monitors to compare new values and missing values between your production and your training or validation datasets.\ud83d\ude82 How should I monitor my pipeline of ground truth data?Monitor your actuals with percent empty and count to capture any failures or errors in your ground truth. pipeline.\ud83d\udd14 My data quality alerts are too noisy/not noisy enoughEdit your threshold value above or below the default standard deviation value to temper your alerts.Data Quality MetricsMetricDescriptionPercent EmptyThe percent of nulls in your model features. \n\nA high percentage can significantly influence model performance and a sudden increase in null values could indicate a problem in the data collection or preprocessing stages.Cardinality (Count Distinct)The cardinality of your categorical features. \n\nChanges in your feature cardinality could indicate a change in the feature pipeline, or a new or deprecated product feature that your model has not adapted to yet. \u200bCardinality - New Values\u200bCount of new unique values that appear in production but not in the baseline.\n\nIdentify concept drift or changes in the data distribution over time. These new unique values may not have been accounted for during model training and therefore could lead to unreliable predictions. \u200bCardinality - Missing Values\u200bCount of new unique values that appear in the baseline but not in production.\n\nCan indicate changes in data generation processes or an issue with data collection in the production environment.\u200bQuantiles\u200bp99.9, p99, p95, p50\n\nA detailed understanding of the underlying statistical properties of the data and its spread. Any significant shift in these quantiles could indicate a change in the data distribution, and require retraining.SumThe sum of your numeric data over the evaluation window.\n\nDetect anomalies or shifts in the data distribution. Significant changes in the sum might indicate data errors, outliers, or systemic changes in the process of generating the data.CountTraffic count of predictions, features, etc. Can be used with filters.\n\nEnsure aren't any unexpected surges or drops in traffic that could affect performance and provide valuable insights about usage patterns, for better resource management and planning.AverageAverage of your numeric data over the evaluation window.\n\nMay indicate a systematic bias, a change in the data collection process, or an introduction of anomalies, which can adversely impact the performance and signal when your model may need retraining.How To Monitor Data QualityStep 1: Enable Data Quality MonitorsMonitor your data quality based on various metrics for your model use case. You can enable managed data quality monitors automatically and tailor them to your needs or fully customize your data quality monitors. Managed MonitorsMonitors configured by Arize with default settings for your threshold and evaluation window. These are meant to simple to enable and understand, with sensible defaults. Custom MonitorsFully customizable monitors based on various dimensions such as features, tags, evaluation windows, baselines, etc. Managed MonitorCustom MonitorManaged monitors are configured by Arize with default settings. Using Managed MonitorsUse managed monitors if this is your first time monitoring your model, you want to try a new metric, or simplify your setup workflow! From the 'Setup Monitors' tab, enable the applicable data quality monitors based on various data quality metrics. Managed data quality monitors will create a separate data quality monitor based on your desired metric across all applicable features. Enabled monitors are represented in the monitors listing pageEnabled monitors in the monitors listing pageUsing Custom MonitorsSince managed monitors create data quality monitors for all applicable features with default settings, use custom monitors if you want to monitor a specific feature, tag, or model dimension that matters the most to you.From the 'Setup Monitors' or 'Monitor Listing' tab, click 'Create Custom Monitor' to get started. Enable custom data quality monitors from the 'Monitor Listing' tabFrom there, select the dimension category and dimension to monitor in Step 1: Define the MetricCustom monitor pageStep 2: Configure Evaluation WindowAn evaluation window defines the period of time your metric is calculated on (i.e. the previous 30 days). Increase this window to smooth out spiky or seasonal data. Decrease this for your monitors to react faster to sudden changes. A delay window defines is the gap between the evaluation time and the window of data used for the evaluation. A delay window tells Arize how long to delay an evaluation. Change this if you have delayed actuals or predictions, so you evaluate your model on the most up-to-date data. Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with preset basic configurations. Based on the metric and feature monitor you want to edit, edit your monitor's details. These settings apply to all managed monitors of the same type.Managed Monitors Default Configurations: Evaluation Window: 72 hours of production dataDelay Window: 0 hoursFrom the 'Monitors' tab, edit the monitor configurations in the 'Managed Data Quality Monitors' card. Define the various settings that go into calculating and monitoring your metric. Within monitor settings, configure the evaluation window within Step 2: Define the Data.  Custom Monitor DimensionsSetting nameDescriptionEvaluation windowDefault: last 24 hours\n\nIncrease this to smooth out spikes or seasonality. Decrease this to react faster to potential incidents.Evaluation delayDefault: delayed by 0 seconds\n\nThis setting is the gap between the evaluation time and the window of data used for the evaluation. Use this if your predictions or actuals", "start_char_idx": 0, "end_char_idx": 8323, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f5e46357-54de-4f59-a019-298e8a30a1d7": {"__data__": {"id_": "f5e46357-54de-4f59-a019-298e8a30a1d7", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "73805f0a-6b4d-4957-9e4b-b3b1eda85abc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "hash": "78ac4f2e8d773441eb1995142adf38f19364d4347171bad63563722fc3a8c04f"}, "2": {"node_id": "4c20d69c-cf97-4b7d-a4b2-b1b16e78f617", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}, "hash": "e4305cd6d1ccb9838d1555c9446a0c53915f16a25741c3b7d6c5afe1ed393a49"}}, "hash": "b72c13a8857fe7e6660e4a287c2623a504356617896bfd29412eaa3604d49e9d", "text": "have an ingestion lag. Model versionFilter your metric to only use certain model versions. This defaults to include all model versions.FiltersYou can filter using a variety of operators on any dimension in your model. The dimension can be a prediction, actuals, features, or tags. step 2 in custom monitor setupStep 3: Calibrate Alerting Threshold Arize monitors trigger an alert when your monitor crosses a threshold. You can use our dynamic automatic threshold or create a custom threshold. Thresholds trigger notifications, so you can adjust your threshold to be more or less noisy depending on your needs.Automatic ThresholdAutomatic thresholds set a dynamic value for each data point. Arize generates an auto threshold when there are at least 14 days of production data to determine a trend. Custom ThresholdSet the threshold to any value for additional flexibility. The threshold in the monitor preview will update as you change this value, so you can backtest the threshold value against your metric history. Learn more here about how an auto threshold value is calculated.Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with an automatic threshold. If you've had issues in the past, we suggest you take a look at the threshold to make sure the threshold is relevant to your needs. How To Edit Managed Monitor's Threshold In BulkChange the tolerance of an existing automatic threshold by adjusting the number of standard deviations used in the calculation in the 'Managed Data Quality Monitors' card in the 'Config' tab on the Monitors page to edit all of your managed monitor auto thresholds in bulk. Note: this will override any individual managed data quality monitor auto threshold config, but will not change any manual thresholds configured for monitors. How To Edit Managed Monitor's Threshold Per MonitorEdit an individual managed monitor's threshold by referencing the 'Custom Monitor' tab. Define the threshold value that will trigger an alert within Step 3: Define the Alerting.  This section allows you to:Set a specific (custom) threshold if you already know the precise threshold value to useAutomatically create a dynamic threshold. You can edit your auto threshold sensitivity by changing the standard deviation number. Lowering the number of standard deviations will increase the sensitivity, and decreasing the standard deviation number will decrease the sensitivity. Step 4: Set NotificationsYour Monitor Status provides an indication of your model health. Your monitor will either be: Healthy: Sit back and relax! No action is needed No Data: When the monitor does not have recent Triggered: When your monitor crosses the threshold value, indicating a model issueWhen a monitor is triggered, get notified when your model deviates from your threshold. You can send notifications via e-mail, PagerDuty, OpsGenie, or Slack. Learn more about notifications and integrations here. Managed MonitorCustom MonitorAll managed monitors will be set with the default configuration of 'No Contacts Selected'. To get the most out of Arize, set notifications so you are automatically notified when your monitor is triggered. You can edit notifications in bulk edit notifications per monitor for enhanced customizability. How To Set Managed Monitors Notifications In Bulk Configure data quality monitor notifications for all managed monitors for an easy way to fully set up monitors in Arize in the 'Config' tab on the Monitors page. How To Edit Managed Monitor's Notifications Per MonitorSet notifications per monitor to limit notifications, change alerting providers or add individual emails to the alert. Within each monitor, you can add a note and edit the monitor name to better suit naming conventions you may already have. Edit an individual managed monitor's notification setting by referencing the 'Custom Monitor' tabDefine where you alerts are sent in Step 4: Define the AlertingSetting nameDescriptionMonitor NameThe monitor name is used to identify the monitor and will be used in the notification. Send Notifications toChoose your notification contacts. You can select multiple contacts to receive notifications. Learn more here.NotesAdd notes to your monitor to help the alert recipient understand the monitor and quickly debug any issues. Monitors - PreviousDrift MonitorsNext - MonitorsNotifications & IntegrationsLast modified 12d agoOn this pageWhen To Monitor Data QualityData Quality MetricsHow To Monitor Data QualityStep 1: Enable Data Quality MonitorsStep 2: Configure Evaluation WindowStep 3: Calibrate Alerting Threshold Step 4: Set NotificationsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8324, "end_char_idx": 13191, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "84fb1872-054a-4e5f-8788-e33c05c61bed": {"__data__": {"id_": "84fb1872-054a-4e5f-8788-e33c05c61bed", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "3d26d5dbab5fbdffa4d798a35a7ea830b6b76044433613e59b8be7196a0ebea0"}, "3": {"node_id": "84c0925b-728a-47e4-86e1-50cf15a9bf70", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "83e28aa07e28b869229cf96bc9890eddc6cff0613cbeefc639c7ff2cbd897d62"}}, "hash": "056af0836c6d56c186d0035d60059453c7e71beb27c15822f0fae30adea3658a", "text": "Drift Monitors - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDrift MonitorsDrift monitoring reference guideWhen To Monitor Drift Models and their data change over time, this change is known as drift. Monitor model drift in production to catch underlying data distribution changes over to help identify and root cause model issues before they impact your model. Monitoring feature and prediction drift is particularly useful if you receive delayed actuals (ground truth data) to use as a proxy for performance monitoring.\ud83c\udfc3Common Questions:\ud83c\udfce\ufe0f How do I track sudden drift over time?Use a moving window of production data as your model baseline to catch sudden drift. \ud83d\udc0c How do I track gradual drift over time?Use training data as your model baseline to catch gradual drift. \ud83d\udd14 My drift alerts are too noisy/not noisy enoughEdit your threshold value above or below the default standard deviation value to temper your alerts.\ud83d\udd11 Can I monitor a few key features instead of all of them?Create custom drift monitors based on individual features by following the 'Custom Monitors' tab in the guide below. \ud83d\udd0d What are the leading indicators of performance degradation?Measure feature and prediction drift to indicate performance degradation. Arize supports various drift metrics based on your use case.\ud83e\udd16 Can I create drift monitors programmatically?Use the GraphQL API to programmatically create drift monitors. Drift Metrics By Use CaseArize offers various distributional drift metrics to choose from when setting up a monitor. Each metric is tailored to a specific use case; refer to this guide to help choose the appropriate metric for various ML use cases.MetricDescription\u200bPSI\u200bA metric that is less influenced by sample size and offers fewer false positives compared to the Kolmogorov-Smirnov test or Earth Mover's Distance, making it suitable for datasets with expected fluctuations. \n\nHowever, PSI can be affected by the chosen binning strategy. A notable attribute of PSI is its symmetry, confirming its status as a true statistical 'distance'.\u200bEuclidian Distance*Euclidean distance check determines if the group of production data\u2019s average centroid has moved away from the baseline group\n\nFor unstructured data types, learn more here\u200b\u200bKL Divergence\u200bA metric that's less sensitive than others like the Kolmogorov-Smirnov statistic, thereby producing fewer false positives and making it appropriate for datasets with expected fluctuations. While its calculation can be influenced by the chosen binning strategy, it's less affected by sample size.\n\nUnlike PSI, KL divergence is non-symmetric, meaning the divergence from dataset A to B is not the same as from B to A.\u200bJS Distance\u200bSimilar to Kullback-Leibler divergence but has two distinct advantages: it is always finite and symmetric. It offers an interpretable score ranging from 0, indicating identical distributions, to 1, indicating completely different distributions with no overlap. \n\nWhile its sensitivity is moderate compared to PSI and KL and less than KS, its results can still be influenced by the chosen binning strategy.\u200bKS Statistic\u200bA non-parametric metric that does not require assumptions about the underlying data or binning for its calculation, making it a sensitive tool for detecting drift, even in large datasets. \n\nThe return of a smaller p-value from KS signifies a more confident drift detection, though this sensitivity may also result in more false positives. This sensitivity enables it to detect even slight differences in data distribution.How To Monitor DriftStep 1: Enable Drift MonitorsMonitor how your model drift based on various drift metrics for your model use case. You can enable managed drift monitors automatically and tailor them to your needs or fully customize your drift monitors. Managed MonitorsMonitors configured by Arize with default settings for your threshold and evaluation window. These are meant to simple to enable and understand, with sensible defaults. Custom MonitorsFully customizable monitors based on various dimensions such as features, tags, evaluation windows, baselines, etc. Managed MonitorCustom MonitorManaged monitors are configured by Arize with default settings. Using Managed MonitorsUse managed monitors if this is your first time monitoring your model, you want to try a new metric, or simplify your setup workflow! From the 'Setup Monitors' tab, enable the applicable drift monitors based on prediction or feature drift. Enable managed drift monitors from the setup monitors tabManaged drift monitors will create a separate drift monitor based on your desired metric across all applicable features. Managed drift monitors will indicate how many monitors it will enableEnabled monitors are represented in the monitors listing pageEnabled monitors in the monitors listing pageUsing Custom MonitorsSince managed monitors create drift monitors for all applicable features with default settings, use custom monitors if you want to monitor a specific feature, tag, or model dimension that matters the most to you.From the 'Setup Monitors' or 'Monitor Listing' tab, click 'Create Custom Monitor' to get started. Enable custom drift monitors from the 'Monitor Listing' tabFrom there, select the dimension category and dimension to monitor in Step 1: Define the MetricCustom monitor pageStep 2: Configure Evaluation WindowAn evaluation window defines the period of time your metric is calculated on (i.e. the previous 30 days). Increase this window to smooth out spiky or seasonal data. Decrease this for your monitors to react faster to sudden changes. A delay window defines is the gap between the evaluation time and the window of data used for the evaluation. A delay window tells Arize how long to delay an evaluation. Change this if you have delayed actuals or predictions, so you evaluate your model on the most up-to-date data. Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with preset basic configurations. Based on the metric and feature monitor you want to edit, edit your monitor's details. These settings apply to all managed monitors of the same type.Managed Monitors Default Configurations: Evaluation Window: 72 hours of production dataDelay Window: 0 hoursFrom the 'Monitors' tab, edit the monitor configurations in the 'Managed Drift Monitors' card. Define the various settings that go into calculating and monitoring your metric. Within monitor settings, configure the evaluation window within Step 2:", "start_char_idx": 0, "end_char_idx": 7930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "84c0925b-728a-47e4-86e1-50cf15a9bf70": {"__data__": {"id_": "84c0925b-728a-47e4-86e1-50cf15a9bf70", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "3d26d5dbab5fbdffa4d798a35a7ea830b6b76044433613e59b8be7196a0ebea0"}, "2": {"node_id": "84fb1872-054a-4e5f-8788-e33c05c61bed", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "056af0836c6d56c186d0035d60059453c7e71beb27c15822f0fae30adea3658a"}, "3": {"node_id": "80c65da4-a51f-4e75-91cf-50fa6218752b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "637949a073ee677269dd69451d809c210cee3d21664e0dcceff63f4e49b6bf70"}}, "hash": "83e28aa07e28b869229cf96bc9890eddc6cff0613cbeefc639c7ff2cbd897d62", "text": "Define the Data.  Custom Monitor DimensionsSetting nameDescriptionEvaluation windowDefault: last 72 hours\n\nIncrease this to smooth out spikes or seasonality. Decrease this to react faster to potential incidents.Evaluation delayDefault: delayed by 0 seconds\n\nThis setting is the gap between the evaluation time and the window of data used for the evaluation. Use this if your predictions or actuals have an ingestion lag. Model versionFilter your metric to only use certain model versions. This defaults to include all model versions.FiltersYou can filter using a variety of operators on any dimension in your model. The dimension can be a prediction, actuals, features, or tags. step 2 in custom monitor setupStep 3: Configure A Model BaselineA model baseline is the reference dataset to compare your current data to identify model changes, enable analysis, and identify the root cause of performance degradation. A model baseline can be from any environment or time period. Arize requires a set baseline applied at the model level regardless of monitor type (custom or managed monitors). Arize automatically configures all new models with a default baseline, but you can pick a new model baseline to use across all monitors, or set a custom baseline per monitor. Edit Model BaselineEdit Monitor BaselineBy default, all monitors are configured with a model baseline with a moving time range from your model's production data spanning a period of two weeks, delayed by three days. If the default baseline doesn't suit your needs. Arize provides the flexibility to choose a baseline from either production data or pre-production data (training and validation). This baseline will be configured on the model level and can be used for both managed and custom monitors. When To Configure A Baseline With Production DataProduction baselines are helpful if your training or validation data is unavailable or unreliable as a reference pointMoving Production Baseline: A dynamic baseline, adjustable to the current time, allows detection of abrupt changes in feature and model distributions, avoids overlap with drift evaluation windows, and prevents issues associated with fixed, outdated baselines.Fixed Production Baseline: You can choose a fixed time period in production as a baseline. This is useful if you want a fixed reference point but don't have or want to use pre-production data. From the 'Dataset' or 'Config' tab, click on the 'Configure Baseline' button where you will be prompted to pick your baseline from production data. When To Configure A Baseline With Pre-Production DataPre-production baselines use your training or validation datasets. This can be useful for models where production data is expected to be similar to the pre-production data. Automatic Baseline Update: Selects the latest uploaded pre-production dataset as the baseline for training/validation. The newest dataset is determined by the most recent upload, ignoring the date range, version, or batch. Ideal for frequent model training.Choose My Own Dataset: For users who train infrequently, or want the manual step of choosing the baseline when a new pre-production dataset is uploaded, manually choosing the dataset for the baseline is the best option. When selecting this, the baseline will not change until a user goes to the model config to manually change it. From the 'Dataset' or 'Config' tab, click on the 'Configure Baseline' button where you will be prompted to pick your baseline from pre-production datasets.Customize individual drift monitor baselines to identify changes on a feature level using:A different fixed time range: you expect large changes for a specific feature A moving time range: identify fluctuating changes for a feature over timeDifferent versions: compare distribution changes of your current model with versions  This can be configured for both managed and custom monitors by clicking 'Custom Baseline' in Step 2: Define the Data of the edit managed monitor or custom monitor form. Custom baselines can utilize filters in the case of new, changing, or problematic features to see how different features/tags/etc affect your model's distribution. Enable filters by clicking the 'Filter Baseline' button in Step 2: Define the Data.Step 3: Calibrate Alerting Threshold Arize monitors trigger an alert when your monitor crosses a threshold. You can use our dynamic automatic threshold or create a custom threshold. Thresholds trigger notifications, so you can adjust your threshold to be more or less noisy depending on your needs.Automatic ThresholdAutomatic thresholds set a dynamic value for each data point. Arize generates an auto threshold when there are at least 14 days of production data to determine a trend. Custom ThresholdSet the threshold to any value for additional flexibility. The threshold in the monitor preview will update as you change this value, so you can backtest the threshold value against your metric history. Learn more here about how an auto threshold value is calculated.Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with an automatic threshold. If you've had issues in the past, we suggest you take a look at the threshold to make sure the threshold is relevant to your needs. How To Edit Managed Monitor's Threshold In BulkChange the tolerance of an existing automatic threshold by adjusting the number of standard deviations used in the calculation in the 'Managed Drift Monitors' card in the 'Config' tab on the Monitors page to edit all of your managed monitor auto thresholds in bulk. Note: this will override any individual managed drift monitor auto threshold config, but will not change any manual thresholds configured for monitors. How To Edit Managed Monitor's Threshold Per MonitorEdit an individual managed monitor's threshold by referencing the 'Custom Monitor' tab. Define the threshold value that will trigger an alert within Step 3: Define the Alerting.  This section allows you to:Set a specific (custom) threshold if you already know the precise threshold value to useAutomatically create a dynamic threshold. You can edit your auto threshold sensitivity by changing the standard deviation number. Lowering the number of standard deviations will increase the sensitivity, and decreasing the standard deviation number will decrease the sensitivity. Step 4: Set NotificationsYour Monitor Status provides an indication of your model health. Your monitor will either be: Healthy: Sit back and relax! No action is needed No Data: When the monitor does not have recent Triggered: When your monitor crosses the threshold value, indicating a model issueWhen a monitor is triggered, get notified when your model deviates from your threshold. You can send notifications via e-mail, PagerDuty, OpsGenie, or Slack. Learn more about notifications and integrations here. Managed MonitorCustom MonitorAll managed monitors will be set with the default configuration of 'No Contacts Selected'. To get the most out of Arize, set notifications so you are automatically notified when your monitor is triggered. You can edit notifications in bulk edit notifications per monitor for enhanced customizability. How To Set Managed Monitors Notifications In Bulk Configure drift monitor notifications for all managed monitors for an easy way to fully set up monitors in Arize in the 'Config' tab on the Monitors page. How To Edit Managed Monitor's Notifications Per MonitorSet notifications per monitor to limit notifications, change alerting providers or add individual emails to the alert. Within each monitor, you can add a note and edit the monitor name to better suit naming conventions you may already have. Edit an individual managed monitor's notification setting by referencing the 'Custom Monitor' tabDefine where your alerts are sent within Step 4: Define the Notification.Setting nameDescriptionMonitor NameThe monitor name is used to identify the monitor and will be used in the notification. Send Notifications toChoose your notification contacts. You can select multiple contacts to receive notifications. Learn more here.NotesAdd notes to your monitor to help the alert recipient understand the monitor and quickly debug any issues. Monitors - PreviousPerformance MonitorsNext - MonitorsData Quality MonitorsLast modified 12d agoOn this pageWhen To Monitor Drift Drift Metrics By Use CaseHow To Monitor DriftStep 1: Enable Drift MonitorsStep 2: Configure Evaluation WindowStep 3: Configure A Model BaselineStep 3: Calibrate Alerting Threshold Step 4: Set NotificationsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On", "start_char_idx": 7931, "end_char_idx": 16628, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "80c65da4-a51f-4e75-91cf-50fa6218752b": {"__data__": {"id_": "80c65da4-a51f-4e75-91cf-50fa6218752b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "3d26d5dbab5fbdffa4d798a35a7ea830b6b76044433613e59b8be7196a0ebea0"}, "2": {"node_id": "84c0925b-728a-47e4-86e1-50cf15a9bf70", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}, "hash": "83e28aa07e28b869229cf96bc9890eddc6cff0613cbeefc639c7ff2cbd897d62"}}, "hash": "637949a073ee677269dd69451d809c210cee3d21664e0dcceff63f4e49b6bf70", "text": "Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 16629, "end_char_idx": 16738, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d5eeb7a0-87ae-4b66-b9d6-5c79ba5c600b": {"__data__": {"id_": "d5eeb7a0-87ae-4b66-b9d6-5c79ba5c600b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ccf44bc5-eaf7-4cec-89c9-4946b4632f31", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations"}, "hash": "7ded9d438876963d0c8081f58691e9b72a49914741efbfe0b582e81976e61ab5"}}, "hash": "8d5fa15cd4b5974df9deca5ef9384770e96c22c77a0d19fa8bc4c31be47e6e24", "text": "Notifications & Integrations - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookNotifications & IntegrationsOnce you've set your monitors, learn how to decipher their status and set up an alerting system.Monitor StatusMonitors are continuously evaluated according to each monitor's configurations -- an evaluation will result in one of the following statuses for a monitor, ordered by severity:When viewing the health of your model for a monitor type (drift, performance, or data quality), the status shown will be based on the highest severity of any of the model's monitors for that type. For example, if you are monitoring your model with several performance monitors, such as Accuracy and F1-score, and at least one of them has a \"Triggered\" status, the status shown for the model's performance will be \"Triggered\". HealthyNo action is needed!No DataThis shows when the monitor does not have recent data in the evaluation window. This can be resolved by extending the evaluation window or uploading new data to Arize. All live models should be configured to continuously send your model\u2019s latest data in batch or real-time operations to keep monitors up-to-date.TriggeredThe Arize platform offers drift and performance troubleshooting to root cause model issues and pinpoint specific feature values or cohorts of data where the model performing poorly.Monitoring AlertsOnce you set up your monitors, you\u2019ll want to be alerted when your model deviates from its expected ranges.Arize offers alerting integrations for alerting tools and methods. Send an alert via email, slack, OpsGenie, and PagerDuty. Within these tools, you can add configurations to edit your alerting cadence, severity, and alert grouping. Alerting IntegrationsPagerDutySlackAmazon EventBridgeOpsGenieAirflow RetrainMonitors - PreviousData Quality MonitorsNextAmazon EventBridgeLast modified 1mo agoOn this pageMonitor StatusMonitoring AlertsAlerting IntegrationsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3645, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9cd23081-026e-4a39-bcd9-32335c843a28": {"__data__": {"id_": "9cd23081-026e-4a39-bcd9-32335c843a28", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "55fb72cd-945a-4318-b50e-11f2cd4e8919", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "hash": "52b6cf5dfa4ff451e5d4e20e7d947b265c5b893793e5cc12acdc3b97108a4c6e"}, "3": {"node_id": "c08e61a2-8902-4287-b8fe-00fef6186bff", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "hash": "d78e918b2a033020744f03f4ee0ba74ade91b08166e7a74951dc6de5c09ae412"}}, "hash": "1e2c51ea3866809c5f76619abb40230f4f1e235f0f93c9491da323fd48f72589", "text": "Performance Monitors - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPerformance MonitorsPerformance monitoring reference guideWhen To Monitor Performance\u200bPerformance metrics quantify a model's effectiveness in its predictions. Monitor performance metrics when deploying a model in production to flag unexpected changes or drops in performance. Additionally, these metrics are used during the model validation phase, offering insights that guide the improvement and fine-tuning of models to achieve optimal predictive performance.\ud83c\udfc3 Common Questions:\ud83c\udf0a How do I monitor performance without ground truth data?Get a sense of model performance without ground truth data by monitoring feature drift and prediction drift. \ud83d\udd14 My performance alerts are too noisy/not noisy enoughEdit your threshold value above or below the default standard deviation value to temper your alerts. \ud83e\ude9f How do I monitor with delayed ground truth data?Delay a performance evaluation via a delay window. Change this if you have delayed actuals, so you evaluate your model on the most up-to-date data. \ud83c\udfd7\ufe0f What if my performance metric is specific to my team?Create any performance metric to suit your monitoring needs via Custom Metrics. Monitor, troubleshoot, and use custom metrics in dashboards. \ud83d\udcc8 My monitors are overly sensitive or not sensitive enoughIncrease your evaluation window to smooth out spikes or seasonality. Decrease your evaluation window to react faster to potential incidents.\ud83e\udd16 Can I create performance monitors programmatically?Use the GraphQL API to programmatically create performance monitors. Performance Metrics By Use CaseMetrics are batched into Metric Groups that align with model types and their variants. Model TypeMetricsClassification Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityRegressionMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorRanking[email\u00a0protected], [email\u00a0protected]Ranking Labels[email\u00a0protected], MRR AUC/LogLossAUC, PR-AUC, Log LossComputer Vision/ Object DetectionAccuracy, MAP, IoUCustom MetricsNot seeing what you're looking for? Create a metric yourself! How To Monitor PerformanceEasily enable, customize, and alert model performance to ensure your production models stay in tip-top shape. Step 1: Enable Performance MonitorsMonitor how your model performs in production based on metrics applicable to your model use case. You can enable managed performance monitors automatically and tailor them to your needs or fully customize your monitors. Managed MonitorsMonitors configured by Arize with default settings for your threshold and evaluation window. These are meant to simple to enable and understand, with sensible defaults. Custom MonitorsFully customizable monitors based on various dimensions such as features, tags, evaluation windows, thresholds, etc. Managed MonitorsCustom MonitorsManaged monitors are configured by Arize with default settings. Using Managed MonitorsUse managed monitors if this is your first time monitoring your model, you want to try a new metric, or you want to simplify your setup workflow! From the 'Setup Monitors' tab, enable the applicable performance monitors based on relevant metrics for your use case. Enable managed performance monitors from the setup monitors tabEnabled monitors will be represented in the monitors listing pageEnabled monitors in the monitors listing pageUsing Custom MonitorsUse custom monitors if you want to monitor a specific slice of your data or if you want to customize the evaluation windows without affecting other monitors. From the 'Setup Monitors' tab, click 'Create Custom Monitor' to get started. Enable custom performance monitors from the setup monitors tabFrom there, select the performance metric to monitor. Custom monitor pageStep 2: Configure Evaluation WindowAn evaluation window defines the period of time your metric is calculated on (i.e. the previous 24 hours). Increase this window to smooth out spiky or seasonal data. Decrease this for your monitors to react faster to sudden changes. A delay window defines is the gap between the evaluation time and the window of data used for the evaluation. A delay window tells Arize how long to delay an evaluation. Change this if you have delayed actuals or predictions, so you evaluate your model on the most up-to-date data. Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with preset basic configurations. Based on the metric and feature monitor you want to edit, edit your monitor's details. These settings apply to all managed monitors of the same type.Managed Monitors Default Configurations: Evaluation Window: Last 72 hoursDelay Window: No delayFrom the 'Monitors' tab, edit the monitor configurations in the 'Managed Performance Monitors' card. Define the various settings that go into calculating and monitoring your metric. Within monitor settings, configure the evaluation window within Step 2: Define the Data.  Custom Monitor DimensionsSetting nameDescriptionEvaluation windowDefault: last 72 hours\n\nIncrease this to smooth out spikes or seasonality. Decrease this to react faster to potential incidents.Evaluation delayDefault: delayed by 0 seconds\n\nThis setting is the gap between the evaluation time and the window of data used for the evaluation. Use this if your predictions or actuals have an ingestion lag. Model versionFilter your metric to only use certain model versions. This defaults to include all model versions.FiltersYou can filter using a variety of operators on any dimension in your model. The dimension can be a prediction, actuals, features, or tags. Step 2 in custom monitor setup Step 3: Calibrate Performance Threshold Arize monitors trigger an alert when your monitor crosses a threshold. You can use our dynamic automatic threshold or create a custom threshold. Thresholds trigger notifications, so you can adjust your threshold to be more or less noisy depending on your needs.Automatic ThresholdAutomatic thresholds set a dynamic value for each data point. Auto thresholds work best when there are at least 14 days of production data to determine a trend. Custom ThresholdSet the threshold to any value for additional flexibility. The threshold in the monitor preview will update as you change this value, so you can backtest the threshold value against your metric history. Learn more here about how an auto threshold value is calculated.Managed MonitorCustom MonitorManaged monitors create monitors for all applicable features for a given metric with an automatic threshold. If you've had performance issues in the past, we suggest you take a look at the threshold to make sure the threshold is relevant to your needs. How To Edit Managed Monitor's Threshold In BulkChange the tolerance of an existing automatic threshold by adjusting the number of standard deviations used in the calculation in the", "start_char_idx": 0, "end_char_idx": 8309, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c08e61a2-8902-4287-b8fe-00fef6186bff": {"__data__": {"id_": "c08e61a2-8902-4287-b8fe-00fef6186bff", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "55fb72cd-945a-4318-b50e-11f2cd4e8919", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "hash": "52b6cf5dfa4ff451e5d4e20e7d947b265c5b893793e5cc12acdc3b97108a4c6e"}, "2": {"node_id": "9cd23081-026e-4a39-bcd9-32335c843a28", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}, "hash": "1e2c51ea3866809c5f76619abb40230f4f1e235f0f93c9491da323fd48f72589"}}, "hash": "d78e918b2a033020744f03f4ee0ba74ade91b08166e7a74951dc6de5c09ae412", "text": "'Managed Performance Monitors' card to edit all of your managed monitor auto thresholds in bulk. Edit monitor thresholds in bulkNote: this will override any individual managed monitor auto threshold config, but will not change any manual thresholds configured for monitors. How To Edit Managed Monitor's Threshold Per MonitorChange the tolerance of an existing automatic threshold by adjusting the number of standard deviations used in the calculation in the 'Monitor Settings' card or create a new custom threshold to update an individual monitor. From the 'Monitors' page, click on the 'Monitors Listing' to select the monitor you want to edit. Edit monitor threshold individuallyDefine the threshold value that will trigger an alert within Step 3: Define the Alerting.  This section allows to:Set a specific (custom) threshold if you already know the precise threshold value to useAutomatically create a dynamic threshold. You can edit your auto threshold sensitivity by changing the standard deviation number. Lowering the number of standard deviations will increase the sensitivity, and decreasing the standard deviation number will decrease the sensitivity. Step 3 in custom monitor setup Step 4: Set NotificationsYour Monitor Status provides an indication of your model health. Your monitor will either be: Healthy: Sit back and relax! No action is needed No Data: When the monitor does not have recent data in the evaluation windowTriggered: When your monitor crosses the threshold value, indicating a model issueWhen a monitor is triggered, get notified when your model deviates from your threshold. You can send notifications via e-mail, PagerDuty, OpsGenie, or Slack. Learn more about notifications and integrations here. Managed MonitorCustom MonitorAll managed monitors will be set with the default configuration of 'No Contacts Selected'. To get the most out of Arize, set notifications so you are automatically notified when your monitor is triggered. You can edit notifications in bulk edit notifications per monitor for enhanced customizability. How To Set Managed Monitors Notifications In Bulk Configure performance monitor notifications for all managed monitors for an easy way to fully set up monitors in Arize. Edit notifications in bulkHow To Edit Managed Monitor's Notifications Per MonitorSet notifications per monitor to limit notifications, change alerting providers or add individual emails to the alert. Within each monitor, you can add a note and edit the monitor name to better suit naming conventions you may already have. From the 'Monitors' page, click on the 'Monitors Listing' to select the monitor you want to edit. Edit notifications for each monitorDefine where your alerts are sent within Step 4: Define the Notification.Setting nameDescriptionMonitor NameThe monitor name is used to identify the monitor and will be used in the notification. Send Notifications toChoose your notification contacts. You can select multiple contacts to receive notifications. Learn more here.NotesAdd notes to your monitor to help the alert recipient understand the monitor and quickly debug any issues. PreviousChoosing Your MetricsNext - MonitorsDrift MonitorsLast modified 12d agoOn this pageWhen To Monitor PerformancePerformance Metrics By Use CaseHow To Monitor PerformanceStep 1: Enable Performance MonitorsStep 2: Configure Evaluation WindowStep 3: Calibrate Performance Threshold Step 4: Set NotificationsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8310, "end_char_idx": 11970, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "350524d7-b9f8-4b81-a7f9-4b096129edeb": {"__data__": {"id_": "350524d7-b9f8-4b81-a7f9-4b096129edeb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1ac34e7d-2c35-4af3-8e30-0721cfa9e90f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup"}, "hash": "011b8fc1140d332c466edacdab8f7af8960dba257b24da5b31b7d65739e975a2"}}, "hash": "047fcef7937817e7309e6d9c9d5f660744736d69c7a00764207ccc733d9f5407", "text": "Get Started With Monitors - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsChoosing Your MetricsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGet Started With MonitorsLearn how to configure your model in three waysWhy Monitor Your ML Models?Continuous monitoring ensures the accuracy and reliability of ML predictions over time. This is critical because models can drift or degrade in performance due to changes in the underlying data, altering environments, or evolving target variables.Proactively monitor your models with Arize to automatically detect drift, data quality issues, and anomalous performance degradations with highly configurable monitors based on both common KPIs and custom metrics. Top Ways To MonitorMonitoring isn't a one-size-fits-all solution for the variety of ML use cases, business needs, and areas of concern. \u270c\ufe0f Two Types of Drift Use drift monitors to compare production against different baseline datasets. 1. Feature drift captures changes to your data pipeline that can lead to anomalous model behavior. 2.Prediction drift captures changes in the outputs of your model that may require stakeholders to be notified. This is also an excellent way to monitor performance without ground truth values. \ud83d\ude80 Performance Monitor performance metrics based on ground truth data (actuals) for your model type, such as NDCG (ranking), AUC (propensity to click), MAPE (predicting ETAs), and more! \n\n\ud83d\udccc Important Features Monitor key features important to your model with data quality monitors. This can be a powerful tool for root cause analysis workflows. \ud83d\udd0d Leading IndicatorsIf your model receives delayed ground truth, monitor your prediction drift score and feature drift as a proxy for model performance. One-Click MonitoringStart monitoring your models with Arize in one click! Pick from a wide array of different data quality, drift, and model performance metrics to monitor across all applicable features. Enable monitors for 1 performance metric, 1 drift metric, and 1 data quality metrics to get started!Automatically set up monitors via the 'Model Overview' page or 'Monitors' tab.Some monitor types, such as feature drift, will set up monitors across all of your features at once. This way, you can achieve 100% coverage of drift monitoring across all of your features in one click. Automatic ThresholdsAll monitors are configured with an automatic threshold by default. Auto thresholds use a powerful and scalable algorithm that adjusts with your metrics to alert on anomalous behavior but not on small perturbations in the data. Auto thresholds allow you to enable a large number of monitors for wide coverage, without having to tune the threshold for each monitor. Example Recall Monitor With An Auto ThresholdIf you have a precise area to monitor or specific configuration needs, edit and customize your monitor in the UI or programmatically. Metrics: edit based on a wide range of metrics such as F_1, AUC, RMSE, and more Filters: filter your monitor on prediction score, feature, actual class, etc.Evaluation window: change the time window from 1 hour - 30 daysThreshold value: automatic or custom, edit the multiplier within the calculated value Alerts: change your integration or email alerts Programmatic MonitorsUse our public-facing GraphQL API to bulk configure custom monitors within your own infrastructure. Follow the instructions here to query, patch, and create monitors using our programmatic API. mutation createPerformanceMonitorForState($state: String!){ createPerformanceMonitor( input: { modelId: \"model_id\",  operator: lessThan,  performanceMetric: accuracy,  dynamicAutoThreshold: { stdDevMultiplier: 1.2 } filters: [{ dimensionType: featureLabel, operator: equals name: \"stateName\" values: [$state] }], contacts: [{ notificationChannelType: email, emailAddress: \"[email\u00a0protected]\" }] } ) { monitor { id } }}Model Types - PreviousObject DetectionNextChoosing Your MetricsLast modified 12d agoOn this pageWhy Monitor Your ML Models?Top Ways To MonitorOne-Click MonitoringAutomatic ThresholdsProgrammatic MonitorsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5678, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "accb5b15-dea6-4ba5-a525-ce566fc503eb": {"__data__": {"id_": "accb5b15-dea6-4ba5-a525-ce566fc503eb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d3eda5a5-be0f-4567-8beb-90d5658a9b20", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise"}, "hash": "8ce14efb1d5250a7b042f0015d4f705afc583a7093369b90045e26488abd46b2"}}, "hash": "b138f5dd1c26b578641800154621d356d691e4017159b21dcd04efcb961c3e66", "text": "Overview - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverviewRequirementsInstallation\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookOverviewThe enterprise solution for on-prem hosting of ArizeWe also offer Arize On-Prem, which runs a completely scalable infrastructure within your company's AWS, GCP or Azure account. The environment can be provisioned by us or by your company, using a toolset comprised of Terraform and Kubernetes.Talk to our sales team for more detailed setup instructions by reaching out to [email\u00a0protected]\u200bFeaturesKeep your data safe on your own company's networkIntegrate with your company's authentication systemPremier support by the Arize engineering teamSelf-managed or Fully managed by ArizeArchitecture OverviewIn the SAAS or managed deployment of Arize, data is logged or periodically sent to the Arize Hosted Service. In the On-Prem Deployment, Arize can be deployed in the customer's cloud of choice or VPC. SaaS vs VPC / On-PremMore DetailsRequirementsInstallationRequest a licenseContact us at [email\u00a0protected] to discuss options.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousData API - UI VisualizationNextRequirementsLast modified 4mo agoOn this pageFeaturesArchitecture OverviewMore DetailsRequest a licenseSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2898, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "876113dd-2d70-488c-b423-af4381373abc": {"__data__": {"id_": "876113dd-2d70-488c-b423-af4381373abc", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c1353923-f196-45a9-915b-166c5aa69c7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "093aebfbeee3876df96db98d7c048b45c8dce4e45af0dbe15c459e02ae717980"}, "3": {"node_id": "28a9b5b1-2b92-411e-867a-7eff22fc9b9a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "669aafd561bcc6d5cff3656f589bc4c51dada1be089725b89a9b823649defe74"}}, "hash": "3f9a8d25e4aa6f8e913770567c7b40a68c6df14730ddedb72c1e37af9b5bad31", "text": "Glossary - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGlossaryDefinitions of common terms in data science and ML monitoring.Accuracy Accuracy is the measure of the number of correct predictions made by the model. It is derived by calculating the percentage of correct predictions out of overall predictions. accuracy = correct predictions / all predictionsAccuracy = Correct Predictions / All PredictionsExample: There are 100 credit card transactions; 90 transactions are legitimate and 10 transactions are fraudulent. If your model predicts that 95 transactions are legitimate and 5 transactions are fraudulent, its accuracy is: 95% = (90 correct legitimate + 5 correct fraudulent) / 100 transactionsBaseline A baseline is the reference data or benchmark used to compare model performance against for monitoring purposes. Baselines can be training data, validation data, prior time periods of production data, a previous model version, among others.Baseline DistributionA baseline distribution refers to a model dataset used as a reference or comparison to the model\u2019s current (production) distribution. Baseline distributions in Arize AI\u2019s platform can be training datasets, validation datasets, or prior time periods of production.Binary Classification ModelBinary classification refers to machine learning algorithms that have classification tasks that have only and only two class labels. Binary classification involves one \u201cpositive\u201d and one \u201cnegative\u201d class state in general.Binning Data Binning is a way to group a number of continuous values together into smaller cohorts or \u201cbins\u201d. The technique helps reduce the cardinality of data by representing the points in intervals -- for example, age ranges.Calibration\u200bCalibration is the comparison of the actual output and the expected output given by a system. Example: Let's say we are predicting credit card fraud and produce the following prediction/actual pairs (0.1, 0.1), (0.2, 0.1), (0.9, 0.7). Our calibration calculation is as follows:        calibration = average prediction / average actual                           = ((0.1 + 0.2 + 0.9)/3) / ((0.1 + 0.1 + 0.7)/3) = 0.4 / 0.3             = 1.333In this case we see we are on average predicting higher (more fraud) than the ground truth.Canary DeploymentA method of testing a new model or model version where only a small subset of production data flows through this model to verify response performance before making a complete cutover. This technique allows for deeper analysis and understanding of model behavior and can minimize risk that regressions severely impact the business or customers.Cardinality - new and missing valuesCardinality of new and missing values is a measurement of the number of unique values in one dataset that do not appear in another. For new values, it counts the number of unique values in production that don't appear in the baseline. For missing values, it counts the unique values in the baseline that don't appear in production. Assume you have an insurance claims model with a feature for claim type. Their unique values are below:production_claims = {'auto', 'home', 'car'}baseline_claims = {'auto', 'home', 'personal'}The calculation for new values would be as such:new_values = production_claims - baseline_claims = {'car'}count_new_values = len(new_values) = 1You can see that production has a new value compared to the baseline - car. If your baseline is training, this could indicate that your model is seeing an unexpected value in production and may have issues. The calculation for missing values is the reverse of new values:missing_values = baseline_claims - production_claims = {'personal'}count_missing_values = len(missing_values) = 1In this case, production is missing the value personal. This could be normal - it's possible that the company no longer supports this type of claim but the model was trained on a past period when it did. This type of metric is different than purely using cardinality. In this example, both datasets have a cardinality of 3, making it seem like there is no issue. Note that the monitor will alert on the count of new values or the count of missing values. The monitor will also show a list of the actual values that are new or missing. Classification ModelClassification models are used to predict categories or assign a class label. Any given data is classified into a set of categories or groups to determine its further use or for processing needs. Data that can be classified into one category or a second category is known as binary data. For example, fraud or not fraud, male or female.If the set of data can be classified into a number of categories or groups, each based on a different criterion, such data is known as multi-class data. For example, education level, household income. Confusion MatrixA confusion matrix provides a summary of all prediction results of a classification problem. Each result is shown with its corresponding number of correct/incorrect predictions (see True Positive, True Negative, False Positive, False Negative), count values and classification criteria. By providing a neat summary of all possible results, the confusion matrix lets you know the ways your classification model could get confused when making the predictions. It helps identify errors and the type of errors made by the model and thus helps improve the accuracy of the classification model. Current DistributionCurrent Distribution refers to the statistical distribution, or shape, of the dataset being generated by a machine learning model in production. Distribution of datasets in machine learning models are represented in the form of functions that show the relationships between the various observations, visually presented in the form of curves or graphs. Data QualityData quality refers to the integrity and consistency of the data sets used. In monitoring machine learning performance, data quality measures include attributes such as missingness, out of range, P1 and P99, type mismatch, among others.  Deep LearningMachine learning is a subset of AI, and it consists of the techniques that enable computers to figure things out from the data and deliver AI applications. Deep learning, meanwhile, is a subset of machine learning that enables computers to solve more complex problems inspired by the human brain\u2019s network of neurons. Deep Learning ModelA deep learning model normally refers to a neural", "start_char_idx": 0, "end_char_idx": 7858, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "28a9b5b1-2b92-411e-867a-7eff22fc9b9a": {"__data__": {"id_": "28a9b5b1-2b92-411e-867a-7eff22fc9b9a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c1353923-f196-45a9-915b-166c5aa69c7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "093aebfbeee3876df96db98d7c048b45c8dce4e45af0dbe15c459e02ae717980"}, "2": {"node_id": "876113dd-2d70-488c-b423-af4381373abc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "3f9a8d25e4aa6f8e913770567c7b40a68c6df14730ddedb72c1e37af9b5bad31"}, "3": {"node_id": "26cf1656-80fc-472e-8e5f-7b9e63e0732e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "26facdf9c537d200e582d3384f23d73b7b05c9be63949785d1345ebb70bd3334"}}, "hash": "669aafd561bcc6d5cff3656f589bc4c51dada1be089725b89a9b823649defe74", "text": "network, typically with more than two layers).   Deep learning is usually used for computationally dense tasks like computer vision (images) and natural language processing. Disparate Impact Disparate Impact (also called adverse impact) is a quantitative measure of the adverse treatment of protected classes. The calculation is the proportion of the sensitive group that received the positive outcome divided by the proportion of the base group that received the positive outcome.Disparate impact in United States labor law refers to practices in employment, housing, and other areas that adversely affect one group of people of a protected characteristic more than another, even though rules applied by employers or landlords are formally neutral. Although the protected classes vary by statute, most federal civil rights laws protect based on race, color, religion, national origin, and sex as protected traits, and some laws include disability status and other traits as well. (source: Wikipedia)Drift Drift is defined as the change in the data over time. It also means the change in the properties of the target variable, due to unpredictable or unforeseen changes, over the due course of time. Data drift can be described as the change in the distribution of data, between the real-time data and the baseline data that was predicted or set beforehand. Concept drift is the change between the relationship between input and the output given in any situation. Drift can be in any form. It can be gradual, recurring, or sudden. It can be a positive or negative drift. The change in data over time can affect model outcomes, making drift an important metric to monitor when it comes to model performance.EmbeddingIn natural language processing (see definition of \u2018natural language processing), embedding is a term used for the representation of words for text analysis, typically in the form of a real-valued vector that encodes the meaning of the word such that the words that are closer in the vector space are expected to be similar in meaning.Euclidean Distance\u200bEuclidean distance is calculated as the square root of the sum of the squared differences between the components of two vectors.We can use Euclidean distance (like in the image above), to compare two sets of embeddings. We can calculate the centroids of the two sets to see if one centroid may be drifting relative to the other using the Euclidean distance.An example of Euclidean distance between two centroids, x and y, is given below for 2D, 3D, and N-dimensional vectors:Distance2D=(x1\u2212y1)2+(x2\u2212y2)2Distance_{2D} = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2}Distance2D\u200b=(x1\u200b\u2212y1\u200b)2+(x2\u200b\u2212y2\u200b)2\u200bDistance3D=(x1\u2212y1)2+(x2\u2212y2)2+(x3\u2212y3)2Distance_{3D} = \\sqrt{(x_1 - y_1)^2 + (x_2 - y_2)^2 + (x_3 - y_3)^2}Distance3D\u200b=(x1\u200b\u2212y1\u200b)2+(x2\u200b\u2212y2\u200b)2+(x3\u200b\u2212y3\u200b)2\u200bDistanceND=\u2211i=1N(xi\u2212yi)2Distance_{N_D} = \\sqrt{\\sum_{i=1}^{N}(x_i - y_i)^2}DistanceND\u200b\u200b=i=1\u2211N\u200b(xi\u200b\u2212yi\u200b)2\u200bEvaluation Metric The way the performance of a predictive model is quantified and calculated is known as the evaluation metric. It is used to evaluate the accuracy and the performance of the model used.Evaluation Store / Inference StoreA machine learning infrastructure tool to monitor and improve model performance. Think of them as the ledger or log of model activities/inferences. Evaluation stores are used to:Surface up performance metrics in aggregate (or slice) for any model, in any environment\u200a\u2014\u200aproduction, validation, trainingMonitor and identify drift, data quality issues, or anomalous performance degradations using baselinesEnable teams to connect changes in performance to why they occurredProvide a platform to help deliver models continuously with high quality and feedback loops for improvement\u200a\u2014\u200acompare production to trainingProvide an experimentation platform to A/B test model versionsEvaluation WindowThe evaluation window is plot of the period or duration of time against the metric being calculated. For instance, the previous 30 days. Any evaluation metric that can be represented as a duration of time can be visualised as an evaluation window. Explainability \u200bExplainability is defined as the total extent to which the machine learning internal mechanics can be explained in human-understandable terms only. It is simply the process of explaining the reasons behind the machine learning aspects of output data (see definition, \u2018SHAP\u2019).F-scoreMeasure of the harmonic mean of precision and recall. F-score is a result of integrating these parameters into one for a better understanding of the accuracy of the model. F-score can be modified into F, 0.5, 1, & 2 based on the measure of weightage given to precision over recall.False Negative When a model mistakenly predicts a negative class, when the value belongs to the positive class. Example: A model flags a credit card transaction as \u2018not fraud\u2019 when it is actually a fraudulent transaction.False Positive When a model mistakenly predicts a positive class, when the value belongs to the negative class. Example: A model flags a credit card transaction as \u2018fraud\u2019 when it was not actually a fraudulent transaction.False Positive Rate False Positive Rate (FPR) is a the rate of \"false alarms\". In other words, it is a measure of the probability a true negative will be missed. \u200b\u200bFalse Positive Rate Parity False Positive Rate Parity is a measure of the False Positive Rate (FPR) of a sensitive group as compared to a base group. Feature Feature is a term of art for inputs into a model. The label can be used to mean a couple things and are a bit more fluid in use. Normally a label is a target of a prediction but can sometimes be the output of a model. A target of a prediction also can be known as ground truth.Feature Importance Feature importance is a compilation of a class of techniques that take in all the features related to making a model prediction and assign a certain score to each feature to weigh how much or how little it impacted the outcome. These scores can then be used to better understand the internal logic of a model, make necessary changes to the model to improve its accuracy, and also reduce unnecessary inputs.Feature Performance Heat Map A feature performance heat map is a visual representation of the performance of each feature in a given model. It enables users to quickly see slices of performance or features that perform significantly better or worse than others for faster triangulation of issues. Heat maps are especially useful when troubleshooting. Feature StoreA feature store is a machine learning infrastructure tool that handles offline and online feature transformations. Think of them as the interface between your models and data. Feature stores are used to:Serve as the central source for feature transformationsAllow for the same feature transformations to be used in both offline training and online servingEnable team members to share their transformations for experimentationProvide a strong versioning for feature transformation codeGroup AUC\u200bGroup AUC (gAUC) can be used to evaluate the performance of a ranking model in a group setting. A ranking model assigns a score or rank to each item in a dataset, and the goal is to correctly rank items within groups, rather than just items.An example of a use case of gAUC for ranking is a recommendation system where the model is trying to recommend movies to users, but the movies are grouped based on their genre. The gAUC would measure the performance of the ranking model for each group separately and then average the AUCs across groups. This allows you to evaluate the performance of the ranking model for different genres and to detect if the ranking model has any bias towards certain genres.A gAUC of 1 would indicate perfect performance for all groups and a gAUC of 0.5 would indicate a performance no better than random guessing for all groups. A value less than 0.5 would indicate a", "start_char_idx": 7859, "end_char_idx": 15744, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "26cf1656-80fc-472e-8e5f-7b9e63e0732e": {"__data__": {"id_": "26cf1656-80fc-472e-8e5f-7b9e63e0732e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c1353923-f196-45a9-915b-166c5aa69c7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "093aebfbeee3876df96db98d7c048b45c8dce4e45af0dbe15c459e02ae717980"}, "2": {"node_id": "28a9b5b1-2b92-411e-867a-7eff22fc9b9a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "669aafd561bcc6d5cff3656f589bc4c51dada1be089725b89a9b823649defe74"}, "3": {"node_id": "6360467d-c0db-467e-9330-bb180218927e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "fa87b39129f2f5344d0a3d29df236bc898940661e2ab3467fbbade36446d110b"}}, "hash": "26facdf9c537d200e582d3384f23d73b7b05c9be63949785d1345ebb70bd3334", "text": "negative bias for certain groups.It is important to note that for ranking problem the AUC metric is calculated by comparing the predicted rank and not the binary classification.JS Distance \u200bJS Distance is a symmetric derivation of KL divergence, and it is used to measure drift. In addition to being an actual metric (as opposed to KL), it is bounded by . For two distributions P and Q, the formula for JS distance is shown below. Use JS distance to compare distributions with low variance. KL Divergence The Kullback-Leibler Divergence metric is calculated as the difference between one probability distribution from a reference probability distribution. KL divergence is sometimes referred to as \u2018relative entropy\u2019 and best used when one distribution is much smaller in sample and has a large variance.KS Statistic\u200bKS Test Statistic is a drift measurement that quantifies the maximum distance between two cumulative distribution functions. KS test is an efficient and general way to measure if two distributions significantly differ from one another. PSI and rank ordering tests focus more on how to population may have shifted between development and validation periods, while KS statistic is used to assess the predictive capability and performance of the model.LIME LIME, or \u201cLocal Interpretable Model-Agnostic Explanations,\u201d is an explainability method that attempts to provide local ML explainability. At a high level, LIME attempts to understand how perturbations in a model\u2019s inputs affect the end-prediction of the model. Since it makes no assumptions about how the model reaches the prediction, it can be used with any model architecture, hence the \u201cmodel-agnostic\u201d part of LIME. The LIME explainability approach takes a single input value of predictions and perterbs the inputs around those values. It then builds a linear model off of the feature perturbations where the coefficients are the feature importances at this local prediction.Logarithmic Loss\u200bLog-Loss Tracks incorrect labeling of the data class by the model and penalises the model if deviations in probability occur into classifying the labels. Low log loss values equate to high accuracy values.MAEMean Absolute Error is a regressive loss measure looking at the absolute value difference between a model\u2019s predictions and ground truth, averaged out across the dataset. Unlike MSE, MAE is weighted on a linear scale and therefore doesn\u2019t put as much weight on outliers. This provides a more even measure of performance, but means large errors and smaller errors are weighted the same. Something to consider depending on your specific model use case.\u200b\u200b[email\u00a0protected]\u200bMAP (Mean Average Precision) @K is a metric used to evaluate the performance of a ranking model. MAP weighs errors to account for value differences between the top and bottom of the list but is limited to binary relevancy (relevant/non-relevant) and can not account for order-specific details.The higher the [email\u00a0protected] score, the better the ranking algorithm or recommendation system performs.Precision is the fraction of relevant items among the total number of items returned by the system. Average precision is the average of the precision values at each position where a relevant item is retrieved.MAP @ K=5, calculation for a ranking model across 3 searchesMAPE \u200bMean Absolute Percentage Error is one of the most common metrics of model prediction accuracy and the percentage equivalent of MAE. MAPE measures the average magnitude of error produced by a model, or how far off predictions are on average. See MAE for considerations when using this metric.MASE Mean absolute scaled error (MASE) is an accuracy metric for forecasting. It is the mean absolute error of the forecast values, normalized by the naive forecast. The nai\u0308ve forecast refers to a simple forecasting method that uses the demand value of a previous time point as the forecast for the next time point. A lower MASE is considered to have higher accuracy. \u200b\u200bMRR (Mean Reciprocal Rank)MRR (Mean Reciprocal Rank) is a metric used to evaluate the performance of a ranking model. MRR is the summation of relevant predictions within a list divided by the total number of recommendations.MRR calculates the mean of the first relevant recommendation, evaluating how well your algorithm predicts your first relevant item.MSE Mean Square Error a regressive loss measure. The MSE is measured as the difference between the model\u2019s predictions and ground truth, squared and averaged out across the dataset. It is used to check how close the predicted values are to the actual values. As in RMSE, a lower value indicates a better fit, and it heavily penalizes large errors or outliers. \u200b\u200bModel PerformanceThe performance of a machine learning model indicates its usability and ability to provide accurate results. Performance is usually measured in terms of metrics that apply to the specific type of machine model concerned. Here are some common metrics used according to the type of machine model:Regression based machine learning models -  MSPE, MSAE, R Squared and Adjusted R Squared Classification - Precisions-Recall, ROC-AUC, Accuracy, log-lossUnsupervised models - Rand index, Mutual informationModel StoreA machine learning infrastructure tool that serves as central model registry and track experiments. Think of them as the library or catalog of your models. Model stores are used to:Serve as a central repository of all models and model versionsAllow for reproducibility of every model versionTrack lineage of models historyMonitor ThresholdMonitor threshold refers to the value set for a model monitor, beyond which the model\u2019s monitoring status will be triggered accordingly. The threshold value can be set on any specific performance metric such as accuracy, MSE, MAPE, etc. NDCG\u200bNDCG measures a model's ability to rank query results in the order of the highest relevance. Actual relevance scores are usually determined by user interaction. For example, if users tend to click on results ranked high on the list, then the NDCG value will be high. Conversely, if users tend to click on query results that are ranked low on the list, it would mean that the ranking model is doing poorly, and the NDCG value will be low. NDCG values range between 0 and 1 with 1 being the highest. Arize computes NDCG using the standard log2 discount function.Natural Language Processing (NLP)Natural language processing (NLP). The inputs to these models are typically sentences, such as: \u201cThis definition is so informative.\u201d  These inputs are broken up into tokens: \u201cThis\u201d \u201cdefinition\u201d \u201cis\u201d \u201cso\u201d \u201cinformative.\u201d Most commonly, a classification model runs on top of NLP.Percentiles Percentiles help you understand your data quality to account for outlier events and gain a more representative understanding of your data. The Arize platform supports P50, P95, and P99 for data quality monitors:P50 - Median data performanceP95 & P99 - Outlier data performance Performance Impact ScorePerformance Impact Score indicates how a particular slice is performing relative to the average performance, weighted by volume. This is a proprietary metric created by Arize. Slice Performance Impact = \n(Slice Performance - Overall Model Performance) * % of Volume\n\nThe idea here is that you want to understand which slices are performing best or worst, and weight this difference by volume. Performance is weighted by volume because the more volume a particular slice is seen, the more of an impact it can have on the overall performance. Performance Slice A performance slice is a subset of model values of interest in performance analysis and troubleshooting. Slices can be formed from any model dimension, including specific periods of time, set of features, etc. Performance slice analysis is useful when the goal is to understand or troubleshoot a cohort of interest, such as with bias detection, where the generalized dataset might mask statistical nuances. Population Stability Index (PSI) \u200bPopulation Stability Index looks at the magnitude which a variable has changed or shifted in distribution between two samples over the course of a given time. PSI is calculated as:PSI = (%Production -", "start_char_idx": 15745, "end_char_idx": 23933, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6360467d-c0db-467e-9330-bb180218927e": {"__data__": {"id_": "6360467d-c0db-467e-9330-bb180218927e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c1353923-f196-45a9-915b-166c5aa69c7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "093aebfbeee3876df96db98d7c048b45c8dce4e45af0dbe15c459e02ae717980"}, "2": {"node_id": "26cf1656-80fc-472e-8e5f-7b9e63e0732e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "26facdf9c537d200e582d3384f23d73b7b05c9be63949785d1345ebb70bd3334"}, "3": {"node_id": "365e645a-9e22-40be-bea2-777c83512dbf", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "54b8fcfe7740cc8a39f1c5230b11420d7142496922b190a0a00bb9445e7ed332"}}, "hash": "fa87b39129f2f5344d0a3d29df236bc898940661e2ab3467fbbade36446d110b", "text": "%Baseline) x ln(%Production / %Baseline)The larger the PSI, the less similar your distributions are, which allows you to set up thresholding alerts on the drift in your distributions. PSI is a great metric for both numeric and categorical features where distributions are fairly stable.PR AUC Curve The Precision-Recall AUC curve is the correlation between the precision and recall at particular cut-off values, with the cut off values being set according to the particular model.Precision \u200bPrecision is the fraction of values that actually belong to a positive class out of all the values which were predicted to belong to that classPrecision = \n True Positives / (Predicted True Positives + Predicted False Positives)Example: There are 100 credit card transactions; 80 transactions are legitimate (positive class) and 20 transactions are fraudulent. If your model predicts that 85 transactions are legitimate, its precision is: 94.12% = 80 true positives / (80 true positives + 5 false positives)Prediction Drift Impact The product of feature importance and drift (PSI -- population stability index). Prediction Drift Impact = Feature Importance * DriftQuantile Quantiles are the points dividing the range of a probability distribution into intervals with equal probabilities.Ranking ApproachesRanking approaches differ in how many items you consider at a time in training. Pointwise - Single ItemThe total loss is computed as the sum of loss terms defined on each item as the distance between the predicted score and the ground truth. This transforms our task into a classification/regression problem, where we train a model to predict y.Pairwise - Pair of ItemsThe total loss is computed as the sum of loss terms defined on each pair of items. The objective is to predict which two items are more relevant, then compare the prediction to ground truth. This transforms the task into a binary classification problem.Listwise - List of ItemsLoss is directly computed on an entire list of items with respective ranks \u2013 where ranking metrics are directly related to loss.Recall \u200bRecall is the fraction of values predicted to be of a positive class out of all the values that truly belong to the positive class (including false negatives)     recall = predicted true positives / (true positives + false negatives)Recall Parity Recall Parity is defined as the Recall of a sensitive group as compared to the recall of a base group. ROC - AUCThe Receiver Operating Characteristics (ROC) is a probability curve plotted between true positive rate (TPR) and false positive rate (FPR). Area Under the Curve (AUC) is an aggregate measure of performance across all possible classification thresholds. Together, ROC - AUC represents the degree of separability, or how much a model is capable of distinguishing between classes. The higher the AUC (i.e. closer to 1), the better the model is at predicting 0 class as 0, and 1 class as 1. FPR = X = fp / ( tn + fp) => error: when all actuals are negative  TPR = Y = tp / (tp + fn) => error: when all actuals are positive\u200b\u200b\u200b\u200bTo calculate AUC/PR AUC:\nThreshold: We first need to generate a confusion matrix based on the threshold. There are 20 thresholds by default , so there will be 20 confusion matrices as well. \n\nFrom each confusion matrix: we calculate the False Positives Rate (x-axis) and True Positive Rate (y-axis) for AUC. As a result, we will have a set of 20 points (x and y coordinates) for AUC or PR-AUC. \n\n\u200bAUC: The next step is to calculate the area under the curve (AUC) for the 20 points. We first sort the points in order of x-axis increasing, and then a secondary sort on y-axis to make it consistent between runs. According to trapezoidal rule, we find the difference between x values of two consecutive points as delta x, and multiply by the average of y values of two consecutive points to get the area between two consecutive points. Lastly, we do the cumulative sum for all 20 points to get the overall AUC.Regression Regression analysis is a fundamental concept in data science and machine learning. It helps quantify the relationship between the inputs into a model and its outputs. Essentially, it is an estimation of how a variable affects a set of independent variables.RMSE Root Mean Square Error (also known as root mean square deviation, RMSD) is a measure of the average magnitude of error in quantitative data predictions. It can be thought of as the normalized distance between the vector of predicted values and the vector of observed (or actual) values.  \u200b\u200bBecause errors are squared before averaged, this measure gives higher weight to large errors, and therefore useful in cases where you want to penalize models accordingly. Score Models Score models generate a numeric value as its prediction or output. For example, the likelihood that an input belongs to a category. Sensitivity Sensitivity is a measure of the number of positive cases that turned out to be true for a given model. It is also called the true positive rate.sensitivity = predicted true positives / (true positives + false negatives)Shadow DeploymentA method of testing a candidate model for production where production data runs through the model without the model actually returning predictions to the service or customers. Essentially, simulating how the model would perform in the production environment.SHAP \u200bSHAP stands for \u201cShapley Additive Explanations,\u201d a concept derived from game theory and used to explain the output of machine learning models (see definition of \u2018Explainability\u2019). SHAP values help interpret how much a given feature or input contributes, positively or negatively, to the target outcome or prediction. See \u2018Feature Importance\u2019sMAPESymmetric Mean Absolute Percentage Error (sMAPE) is an accuracy metric based on percentage. By dividing by both actual and predicted values and normalizing the relative errors, sMAPE overcomes the asymmetric shortcomings found in MAPE. sMAPE ranges with a lower bound of 0% and an upper bound of 200% (in the Arize platform this is reflected from 0-->2), which enables models that have forecasts higher than actuals to attain more accurate negative percentage error approximations.Specificity Specificity is the fraction of values predicted to be of a negative class out of all the values that truly belong to the negative class (including false positives). This measure is similar to recall, but describes the offset in correcting predicting negative values. It is also called the true negative rate.    specificity = predicted true negatives / (true negatives + false positives)Example: There are 100 credit card transactions; 90 transactions are legitimate and 10 transactions are fraudulent (negative class). If your model predicts that 20 transactions are fraudulent, its recall is: 50% = 10 true negatives / (10 true negatives + 10 false positives)Tabular DataData in a table format, with columns and rows. Inputs of the model in a table format (i.e. an Excel spreadsheet), where columns might be feature inputs (i.e city, state, charge amount). NLP and images do not fit in an excel sheet, since inputs are sentences or images.TagA tag is used to store extra information or metadata  alongside a prediction. They are different than features in that they are not actual inputs in the model.True Negative When a model correctly predicts a negative class, when the value belongs to the negative class. Example: A model flags a credit card transaction as \u2018not fraud\u2019 when it is actually a legitimate transaction.True Positive When a model correctly predicts a positive class, when the value belongs to the positive class. Example: A model flags a credit card transaction as \u2018fraud\u2019 when it is actually a fraudulent transaction.WAPEWeighted Average Percentage Error, also referred to as the MAD/Mean ratio. The WAPE metric is the sum of the absolute error normalized by the sum of actual values. WAPE equally penalizes for under-forecasting or over-forecasting, and does not favor either scenario.WAPE =", "start_char_idx": 23934, "end_char_idx": 31942, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "365e645a-9e22-40be-bea2-777c83512dbf": {"__data__": {"id_": "365e645a-9e22-40be-bea2-777c83512dbf", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c1353923-f196-45a9-915b-166c5aa69c7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "093aebfbeee3876df96db98d7c048b45c8dce4e45af0dbe15c459e02ae717980"}, "2": {"node_id": "6360467d-c0db-467e-9330-bb180218927e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}, "hash": "fa87b39129f2f5344d0a3d29df236bc898940661e2ab3467fbbade36446d110b"}}, "hash": "54b8fcfe7740cc8a39f1c5230b11420d7142496922b190a0a00bb9445e7ed332", "text": "sum(absError)/sum(Actuals)When the total number of sales can be low or the product analyzed has intermittent sales, WAPE is recommended over MAPE. MAPE is commonly used to measure forecasting errors, but it can be deceiving when sales reach numbers close to zero, or in intermittent sales (referenced here). WAPE is a measure that counters this by weighting the error over total sales. WAPE is more robust to outliers than Root Mean Square Error (RMSE) because it uses the absolute error instead of the squared error.Worst Performing SliceWhen using the worst performing slice tool inside of Arize, we can understand which slices have the most affect on the our overall performance. Here we can see the percentage difference between the slice and our overall model performance divided by the overall performance.  \n\nNote this calculation is accounting for volume of particular slices inherently. Worst Performing Slice = \n(Performance Excluding Slice - Overall Performance) / Overall Performance)\n* 100Resources - PreviousProduct FAQNext - ResourcesML PlatformsLast modified 3mo agoOn this pageAccuracy Baseline Baseline DistributionBinary Classification ModelBinning CalibrationCanary DeploymentCardinality - new and missing valuesClassification ModelConfusion MatrixCurrent DistributionData QualityDeep LearningDeep Learning ModelDisparate Impact Drift EmbeddingEuclidean DistanceEvaluation Metric Evaluation Store / Inference StoreEvaluation WindowExplainability F-scoreFalse Negative False Positive False Positive Rate False Positive Rate Parity Feature Feature Importance Feature Performance Heat Map Feature StoreGroup AUCJS Distance KL Divergence KS StatisticLIME Logarithmic LossMAE[email\u00a0protected]MAPE MASE MRR (Mean Reciprocal Rank)MSE Model PerformanceModel StoreMonitor ThresholdNDCGNatural Language Processing (NLP)Percentiles Performance Impact ScorePerformance Slice Population Stability Index (PSI) PR AUC Curve Precision Prediction Drift Impact Quantile Ranking ApproachesRecall Recall Parity ROC - AUCRegression RMSE Score Models Sensitivity Shadow DeploymentSHAP sMAPESpecificity Tabular DataTagTrue Negative True Positive WAPEWorst Performing SliceSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 31943, "end_char_idx": 34336, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d79fa99e-1110-42ca-abce-007ada47b9f6": {"__data__": {"id_": "d79fa99e-1110-42ca-abce-007ada47b9f6", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "aaeff0aa-dfe9-4c80-bb28-181a7a19c0d7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations"}, "hash": "eeb581f8a3df5778de93f79a47f25ea48ecfd639d4d6fffd77ea59a662f19e9c"}}, "hash": "fa2ffaffaf77e2c44b40f180cc6ce900a404e8987cb155e76048b077bd8b45c6", "text": "ML Platforms - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookML PlatformsTutorials and blogs for integrations with the Arize platformInbound IntegrationsAlgorithmiaAlgorithmia is an MLOps platform with APIs to serve, host, and manage models. The Arize platform can easily integrate into Algorithmia to enable model observability, explainability, and monitoring.Azure & DatabricksDatabricks is an open and unified data analytics platform for data engineering, data science, machine learning, and analytics. Surface and fix issues with ML models served on Azure with Arize. BentoMLLeverage Bento\u2019s ML service platform to turn ML models into production-worthy prediction services. Once your model is in production, use Arize\u2019s ML observability platform to attain the necessary visibility to keep your model in production.CML (DVC)DVC version controls ML projects. This tutorial runs through how to use Arize in a Continuous Integration and Continuous Deployment workflow for ML models. DeepnoteDeepnote is a new kind of Jupyter-compatible data science notebook with real-time collaboration and running in the cloud. The Arize platform can easily integrate with Deepnote to enable model observability, explainability, and monitoring while also allowing collaboration between team members.FeastFeast (i.e, Feature Store) is an operational data system for managing and serving machine learning features to models in production. Arize leverages Feast to visualize model performance, understand drift & data quality issues, and share insights as your Evaluation Store.Google Cloud MLHugging FaceHugging Face is a library offers both models on-demand in its Model Hub as well as APIs for you to fine-tune NLP models and serve them directly from Hugging Face.MLflowMLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, model registry. By integrating Arize and MLflow, you will be able to train, manage, and register your models while  actively monitoring performance, data quality, and troubleshooting degradations across your models.NeptuneNeptune logs, stores, displays, and compares all your MLOps metadata for better experiment tracking. Arize leverages Neptune to visualize your production model performance, understand drift & data quality issues.Ray Serve (Anyscale)Ray Serve is an framework agnostic and scalable model serving library built on Ray. Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models with Ray Serve.SageMakerSageMaker enables developers to create, train, and deploy machine-learning models in the cloud. Monitor and observe models deployed on SageMaker with Arize for data quality issues, performance checks, and drift. SpellSpell is an end-to-end ML platform that provides infrastructure for company to deploy and train models. Visualize your model's performance, understand drift & data quality issues, and share insights learned from your models deployed on Spell.UbiOps\u200bUbiOps is an MLOps platform with APIs to deploy and serve models. The Arize platform can easily integrate with UbiOps to enable model observability, explainability, and monitoring.Weights & BiasesWeights and Biases helps you build better model by logging metrics and visualize your experiments before production. Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models.\u200bOutbound IntegrationsPagerDutyArize supports an email integration with PagerDuty. This section reviews how to set it up in PagerDutyOpsGenieArize supports an email integration with OpsGenie for automatic notifications.SlackIntegrate with Slack via Slack's email feature. Set up your model's monitors to automatically notify your Slack channel when a monitor has been triggered.Amazon EventBridgeEvent-driven workflows that connect native AWS services with Arize's monitoring capabilities.\u200bResources - PreviousGlossaryNextAlgorithmiaLast modified 7mo agoOn this pageInbound IntegrationsOutbound IntegrationsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5935, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ef0ed8ee-4bc3-4c84-bc0d-86f2ee5c5a58": {"__data__": {"id_": "ef0ed8ee-4bc3-4c84-bc0d-86f2ee5c5a58", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ddc600fe-68f9-41ff-949a-a76af047f85e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "hash": "27f7579c33b0955f3359f120e0834f9f89b7bb3da54fd2e222ec8dd0dfbd8aad"}, "3": {"node_id": "01e6c4a8-f0fc-4cda-b522-b18af056a8bc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "hash": "170183666ba8a9486a580c4fd4fc9b2b93c7c38a55010a84e23f52b504185bae"}}, "hash": "0f9c9d0134ac31cf4d8d7afe1231670f2beed2c18dd5b058eab9ab30a30cf1f2", "text": "Product FAQ - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookProduct FAQFrequently asked questions about the product1.\u200bWhat type of data types do you support?\u200b2.What model types does Arize support? 3.\u200bHow can Arize surface outliers/anomalies?\u200b4.\u200bWhat performance metrics does Arize support?\u200b5.\u200bWhat happens if a new categorical feature is seen in production?\u200b6.\u200bWhat happens if a new numerical feature is seen in production?\u200b7.\u200bHow does Arize calculate drift?\u200b8.\u200bWhat metrics can be applied to individual features?\u200b9.\u200bHow do you evaluate features?\u200b10.\u200bHow does Arize handle concept drift?\u200b11.\u200bDoes Arize have any security certifications? \u200b12.\u200bHow are automatic thresholds set?\u200b13.\u200bDoes Arize support grouping models into projects? \u200bWhat data types does Arize support?Arize natively supports tabular/structured data types (strings, floats, booleans, etc), as well as embedding support for NLP, Image, and other unstructured data types.What model types does Arize support?Arize natively supports binary classification, multi-class classification, regression, ranking, NLP, and CV model types. Your model type informs the data ingestion format and the performance metrics that can be utilized in the platform. How can Arize surface outliers/anomalies?Arize can surface outlier/anomalous data through:Data Quality checksNumeric Features: Arize will monitor outliers in numeric inputs ranges for your input data.Categorical Features: Arize will monitor outlier categories and the overall cardinality of categorical features.Drift checksIf there are features slices that vary significantly from the set baseline distribution, Arize will alert you through drift detection monitors.Feature Performance HeatmapIf there are outlier slices that are poorly performing, Arize\u2019s feature performance heatmap will automatically surface up the worst performing segments. These slices can also be monitored explicitly for proactively performance degradation detection.What performance metrics does Arize support?Arize supports a comprehensive list of model performance metrics for both numeric and categorical model types. These metrics are available on dashboards as well as monitors. In addition to the out-of-the-gate metrics listed below, Arize also supports model data metrics, custom evaluation metrics, and user defined business impact metrics. Learn more about statistical widgets here and user-defined business impact formulas here.AccuracyMAEPrecisionSensitivityAUCMAPER-SquaredSpecificityF1MSERecallTP/TN/FP/FNLog LossPR-AUCRMSECustom MetricsIn addition to performance metrics, we also support data metrics that allow you to count, average, view percentiles, or calculate percent/count for all features, actuals, and/or predictions. All metrics can be calculated in aggregate, as well as on particular cohorts using applied filters.How can I monitor the impact of a particular feature? You can monitor the model's performance for that particular feature, feature-value combination \u2014also known as a slice. This feature performance heatmap helps visualize the performance of each slice and indicates what slices are the most problematic/performance degrading.What happens if a new categorical feature is seen in production?Arize drift detection can flag when categorical features see a % of unseen categories. For example, if the baseline had 10 categories, but the production/serving distribution differed significantly in number, Arize will trigger an alert. Additionally, Arize captures the percentage of values that fall into these new feature categories not previously seen in the baseline distribution.What happens if a new numerical feature is seen in production?Arize drift detection can show the % of values outside of the baseline range. Arize uses the quantiles of the data to calculate the bins of the distribution. If the baseline range has a larger range than the production/serving environment, the user can see the % of volume where the baseline distribution was outside of the production/serving distribution. If the production/serving distribution was outside the range of the baseline distribution, similarly Arize surfaces the % of volume for values outside the baseline range.How does Arize calculate drift?Arize calculates drift metrics including Population Stability Index, KL Divergence, KS Statistic and JS Distance. Arize computes drift by measuring distribution changes between the model\u2019s production values and a baseline (reference dataset). Users can configure a baseline to be any time window of a:1.Pre-production dataset (training, test, validation) or2.Fixed or moving time period from production (e.g. last 30 days, last 60 days). Baselines are saved in Arize so that users can compare several versions and/or environments against each other across moving or fixed time windows. For more details on baselines, visit here.What metrics can be applied to individual features?Arize supports automated schema detection of models and immediately computes statistics for all features of the model, including: CardinalityAverageFeature TypeMinimum ValueStandard DeviationMissing ValueMaximum ValuePercentilesCustom MetricsHow do you evaluate features?Arize supports feature quality metrics including feature drift, data quality (ex: cardinality, percent empty, type mismatch, out of range, etc.) and feature importance metrics. Additionally, users can compute performance metrics for their model filtered by feature/value combinations (slices).  How does Arize handle concept drift?Concept drift is drift in the actuals or ground truth. To measure concept drift, Arize requires historical actuals which are utilized to set a baseline.How does Arize calculate bins for numeric features?Arize calculates the bins within the drift tab using quantiles and fixed bins from the baseline distribution.The range between two quantile values in the baseline distribution are utilized to calculate a fixed width for binning. That fixed width value will be used to calculate a finite set of bins (currently 8) of a fixed width from the Median value, in both directions (4 in each direction). Lastly, it adds bins to the \"bookends\", one from min value to lowest bin's edge and another from largest bin's edge to maximum value amongst both distributions.This strategy optimizes for reasonable sized bins by calculating a fixed width based on quantile values.Does Arize have any security certifications?Arize is SOC2 Type 2 certified under standards set by the American Institute", "start_char_idx": 0, "end_char_idx": 7915, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "01e6c4a8-f0fc-4cda-b522-b18af056a8bc": {"__data__": {"id_": "01e6c4a8-f0fc-4cda-b522-b18af056a8bc", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ddc600fe-68f9-41ff-949a-a76af047f85e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "hash": "27f7579c33b0955f3359f120e0834f9f89b7bb3da54fd2e222ec8dd0dfbd8aad"}, "2": {"node_id": "ef0ed8ee-4bc3-4c84-bc0d-86f2ee5c5a58", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}, "hash": "0f9c9d0134ac31cf4d8d7afe1231670f2beed2c18dd5b058eab9ab30a30cf1f2"}}, "hash": "170183666ba8a9486a580c4fd4fc9b2b93c7c38a55010a84e23f52b504185bae", "text": "of Certified Public Accountants (AICPA). Arize\u2019s SOC 2 security certification validates that Arize has adequate processes and policies to securely handle both customer and organizational data. Read more about the certification and what it means here. To request a copy of the report, please contact us here.Arize AI has also received certifications from an independent auditor validating that the company\u2019s health information security program is fairly represented and includes the essential elements of HIPAA\u2019s Security Rule and the HITECH Act! Read more here.How are automatic thresholds set?Autothresholds are calculated based on a statistical analysis of data over 14 days. Each day, a data point is collected, and after 14 days, the average (mean) and standard deviation of these data points are computed. The thresholds is then set by adding or subtracting the standard deviation from the average.How do I use the helper function in this part of the documentation?That helper function is for the real-time logger where it returns a future . The pandas logger, from arize.pandas.logger import Client, just returns a response so you can check status with response.status_code.Can I change the Arize dashboard time scale so that it shows the average per hour? Yes, use the Arize date range selector to select a date range less than 3 days, the platform will then switch to hourly. If I have a n-dimensional feature is there way to look at which dimension drifting or which dimension has higher impact on prediction drift?Yes, our current implementation of vector drift looks at the vector drift as a whole, however, you could log the feature space that generated the n-dimensional feature to determine the prediction drift impact.Does Arize support grouping models into projects? Yes! Projects are a way to group models together for easy navigation and comparative analysis. They provide folder-like organization so that you can easily manage and navigate your different models. Models do not have to be of the same type in order to add them to a project.\nOther use cases include:Separating out models by business functionHaving a collection of similarly homogeneous models that only differ by locale or seasonGet started with projects by creating one of your own! Navigate to Projects > Create New Project in order to start. Then fill out the appropriate fields, select the models you want to include, and hit Finish.Admin - PreviousSSO & RBAC (Role Based Access Control)Next - ResourcesGlossaryLast modified 12d agoOn this pageWhat data types does Arize support?What model types does Arize support?How can Arize surface outliers/anomalies?What performance metrics does Arize support?How can I monitor the impact of a particular feature? What happens if a new categorical feature is seen in production?What happens if a new numerical feature is seen in production?How does Arize calculate drift?What metrics can be applied to individual features?How do you evaluate features?How does Arize handle concept drift?How does Arize calculate bins for numeric features?Does Arize have any security certifications?How are automatic thresholds set?How do I use the helper function in this part of the documentation?Can I change the Arize dashboard time scale so that it shows the average per hour? If I have a n-dimensional feature is there way to look at which dimension drifting or which dimension has higher impact on prediction drift?Does Arize support grouping models into projects? SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7916, "end_char_idx": 11623, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b5185e4b-ea1e-409f-a90c-0619c1acea3d": {"__data__": {"id_": "b5185e4b-ea1e-409f-a90c-0619c1acea3d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2a1ecd6b-5648-4099-8050-0aa12cbaa5f1", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases"}, "hash": "16c648a3ff65590f4c38521a783325196beac361fae2fc24bd3d9f2718083b00"}}, "hash": "cf65f6fb692c2fe78f5473831167545dc39443524fe6fa4d8e420bb70564ae03", "text": "Common Industry Use Cases - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookCommon Industry Use CasesUse-case specific examples of how to leverage Arize to troubleshoot your ML models.Learn how to set up proactive monitors for chargebacks (false negative rate) and false positive transactions for your credit card fraud model. FraudTroubleshoot bad data quality, drifting features, and low-performing cohorts of your ad click-through rate model. Click-Through RateIdentify where your demand forecasting model is over/under predicting and for which items/locations your model might require retraining. Demand ForecastingImprove your customer lifetime value model by identifying low-performing cohorts and drifting features. Customer Lifetime ValueLearn how to set up a collaborative filtering model, normally used in recommendation engines, in the Arize platform. Collaborative FilteringLearn how to troubleshoot a search ranking model using a rank-aware evaluation metricSearch RankingContact us at [email\u00a0protected] to contribute an example to the list or request a tutorial!PreviousWeights & BiasesNextClick-Through RateLast modified 8mo agoOn this pageLearn how to set up proactive monitors for chargebacks (false negative rate) and false positive transactions for your credit card fraud model. Troubleshoot bad data quality, drifting features, and low-performing cohorts of your ad click-through rate model. Identify where your demand forecasting model is over/under predicting and for which items/locations your model might require retraining. Improve your customer lifetime value model by identifying low-performing cohorts and drifting features. Learn how to set up a collaborative filtering model, normally used in recommendation engines, in the Arize platform. Learn how to troubleshoot a search ranking model using a rank-aware evaluation metricSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3644, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "641efc54-02c7-4112-b45d-b76d83807040": {"__data__": {"id_": "641efc54-02c7-4112-b45d-b76d83807040", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "028ccb9c-9fa7-4f00-a8d8-0fe2c27533ab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload"}, "hash": "1e366eb318b88bd8005ca49b985ba1538822b0b8165facb0336048568b38aa0d"}}, "hash": "18a82f77eba5786e9e334b2bdf1a4530d345c653623e4de519cdb61950771be5", "text": "FAQ & Troubleshoot Data Upload - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data UploadSending Data FAQ\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython Pandas (batch)Python Single RecordJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookFAQ & Troubleshoot Data UploadHow to troubleshoot common data ingestion issuesCheck The Data Ingestion TabLet's check if Arize has received your model correctly! Navigate to the 'Data Ingestion' tab within your model. You should see bar charts representing the volume of data received for predictions, actuals, and feature importance values. Hover over the bars to ensure the volume represents what's expected. Data Ingestion Visualization It can take ~1 minute for bar charts to appear and ~10 minutes for data to fully load in the 'Data Ingestion' tab and appear across the platform. We suggest grabbing a cup of coffee \u2615 while you wait! \ud83d\udc4d Looks great! Verify Your DataIf you've waited and your data ingestion volume is as expected, perform a quick data ingestion check. Use the checklist to identify any data ingestion errors that must be corrected to use Arize successfully.Verify features and tags on the 'Overview' or 'Datasets' tabData types (numeric & categorical) - If a feature is a wrong data type, verify that the feature is represented correctly in the DataFrame/file/table that was ingested. Check missing values - If a feature or tag has missing values, verify that it is expected. If missing values aren\u2019t expected, check the input DataFrame/file/table to see if the missing values are present there as well. If there are missing values, check your upstream data sources.Verify feature cardinality - Are there features with a cardinality of 1, or an unusually high cardinality? If a feature cardinality appears incorrect, verify the number of unique values for that feature in the input DataFrame/file/table.\u200bVerify predictions and actuals on the 'Data Ingestion' or 'Datasets' tabCardinality of prediction/actual classDistribution of prediction/actual scores The amount of data Arize received is the same amount of predictions sent Arize takes a few minutes to ingest and index all of your data. If the number of predictions differs from what you're expecting to see after waiting a few minutes, check the number of records in your DataFrame or file/table.Verify performance metrics on the 'Performance Tracing' tab If actuals are sent separately, verify that the prediction ID used for the prediction matches the prediction ID used for the actualCheck the prediction time range\u200bExport the dataset from Arize to compare recalculated performance metrics It's typical to accidentally send duplicate prediction IDs - if a prediction is sent with the same prediction ID as another prediction, this will be counted as 2 predictions in Arize.Verify the model type (i.e., ranking, regression, etc.) next to the model\u2019s nameIf the model type is incorrect, check that the correct model type was specified during data ingestion\ud83d\udc4e There's An Error In Data ReceivedIf you're using the Python Pandas SDK, set sync = True in the log call. When sync is set to True, the log call will block, or wait, until the data has been successfully ingested by the platform and immediately return the status of the log. No Data ReceivedIf the 'Data Ingestion' tab indicates no data ingested for the expected ingestion period, but you received a 200 success response via the Python SDK or your import job passes, reach out to Arize support via [email\u00a0protected] or Slack to help troubleshoot. arize.utils.logging | INFO | Success! Check out your data at <link to model>Successful File Import ExampleSome Data Received If the 'Data Ingestion' tab shows values that deviate from what's expected, dig into potential ingestion issues based on what you sent. Check Input Values  Most data ingestion errors come from misnamed columns, missing values, or missing fields for your model type: Prediction labels and scores - Check that you mapped the prediction label and/or prediction score column correctly in the model schema, and ensure the contents of the columns represent expected valuesActual labels and scores - Check that you mapped the actual label and/or prediction score column correctly in the model schema, and ensure the contents of the columns represent expected valuesTags and features - Check that you correctly batched tags and features together in your schema list and the values within each feature/tag column is representative of what you intend to ingest  \u200bModel type and ingestion fields match - Ensure that you upload the expected prediction and actual values based on your model type. There are some model types that require additional fields (i.e. ranking, NLP, and CV model types) Other Potential ProblemsIf your schema looks right, there could be other potential problems with the data receivedTraining and Validation Record ErrorsEnsure Training and Validation records must include both prediction and actual columnsActuals ErrorsThere are a few things that can go wrong if you just send in actuals:If you log delayed actuals, Arize joins delayed actuals with prediction IDs in the platform at 5 AM UTC daily. Ensure you have mapped the correct prediction ID to your actuals. See here for more information about joining predictions and actuals.If you\u2019ve never logged predictions for this model, upload prediction values with corresponding prediction IDs to your actuals to view your model in Arize. Embeddings Features Errors If you upload embeddings with dimensions longer than 1500 length, you may run into problems visualizing data within the platform. Reduce the dimension length and re-upload your data. Rank ErrorsIf you upload multiple of the same ranks for the same prediction group id, you may run into problems visualizing your data within the platform. Revise your data to represent unique ranks for a given prediction group and re-upload your data.  Sending Data Guides - PreviousHow To Send Delayed ActualsNextSending Data FAQLast modified 2mo agoOn this pageCheck The Data Ingestion Tab\ud83d\udc4d Looks great! Verify Your Data\ud83d\udc4e There's An Error In Data ReceivedNo Data ReceivedSome Data Received Other Potential ProblemsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 7687, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cb5e46ac-708e-4b5e-a9d4-87a1a24aa859": {"__data__": {"id_": "cb5e46ac-708e-4b5e-a9d4-87a1a24aa859", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c960851a-f693-4d7d-bfe5-384094fae798", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "hash": "976f89f945002c9f42c7a8befc252dfa376f17e7715ac343c5c815f812863f1c"}, "3": {"node_id": "b9e7625f-b071-4b68-983a-0e89bf14ddea", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "hash": "e77606e6d6f53399291cfa2006ee453f69205caca3fd696095acfed283b10065"}}, "hash": "91a846718b035986dd69a929c39974c00bf53a00296d6856995d9b1cda7ccdf6", "text": "How To Send Delayed Actuals - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookHow To Send Delayed ActualsConnect model predictions to delayed ground truth dataWhat Are Delayed (Latent) Actuals Depending on your model use case, you may experience a delayed feedback loop when collecting ground truth data. We call this data delayed actuals. If your model receives delayed actuals, Arize can automatically connect actuals to predictions sent earlier via the same prediction ID. Sending Delayed Actuals Utilize the Arize joiner to easily match delayed actuals with predictions in the Arize platform. To do this, simply upload your actuals data using the same prediction_id as its corresponding prediction.Example join with a 7-day lookback windowJoiner Cadence & Lookback   The Arize joiner automatically triggers daily at 05:00 UTC to map delayed actuals with their corresponding prediction values up to 14 days from when the prediction was received. This is supported for all data upload methods. Joins are conducted on actuals sent within the join window for the day prior, which is from 00:00 UTC to 23:59 UTC. The Arize support team can extend your 14-day connection window and increase your joiner cadence upon request. Reach out to [email\u00a0protected] for help.Joiner RequirementsFieldDescriptionprediction_id(required) A prediction's unique identifier. The actual's prediction_id must match its corresponding prediction to join the dataactual_score / actual_label \n\nFor ranking models only:\nrelevance_label(required) The ground truth values of your model. The use of score and label varies based on model type\u200bmodel_id(required) When sending delayed actuals, specify the model_id in your schema to match your actuals to the correct model Upload delayed actuals for ranking models with file/table upload via GraphQL or SDK. Native UI upload support coming soon. Reach out to [email\u00a0protected] for help and questions.Example Joins By Upload MethodCloud Storage/ Data LakePython PandasPython Single RecordTo send delayed actuals via GCS, AWS S3, Azure Blob Storage, Google BigQuery, and Snowflake, configure separate data ingestion jobs for predictions and actuals. We recommend naming job prefixes to indicate which job contains predictions or actuals.gs://bucket1/click-thru-rate/prediction/\u251c\u2500\u2500 11-19-2022.parquet \u251c\u2500\u2500 11-20-2022.parquet\u251c\u2500\u2500 11-21-2022.parquetgs://bucket1/click-thru-rate/actuals/\u251c\u2500\u2500 12-1-2022.parquet # same prediction id column, model, and space as the corresponding prediction\u251c\u2500\u2500 12-2-2022.parquet\u2514\u2500\u2500 12-3-2022.parquetMake sure that your prediction ID, model name, and space match with your corresponding predictions when defining the schema for these two data ingestion jobs. Once you configure both jobs, Arize will automatically recognize and sync new prediction and actual data. To validate new data in Arize, visualize the data in the 'Dataset' tab.To log delayed actuals using the Python SDK, simply match the actuals prediction_id_column_name with its corresponding prediction. From there, Arize will automatically identify the join and match the data together. #log predictionsschema = Schema(    prediction_id_column_name=\"prediction_id\",     prediction_label_column_name=\"prediction_label\", ...)# then log actuals schema = Schema(    prediction_id_column_name=\"prediction_id\", #needs to be the same as above    actual_label_column_name=\"actual_label\", ...)To log delayed actuals using the Python Single Record SDK, simply match the actual prediction_id with its corresponding prediction. From there, Arize will automatically identify the join and match the data together. #log the features & predictionresponse = arize.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    model_version='v1',    prediction_timestamp=1618590882,    features=features,    prediction_label=('Fraud',.4),    tags=tags)\u200b#log the actualactual_response = arize.log(    prediction_id='plED4eERDCasd9797ca34',    model_id='sample-model-1',    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    actual_label=('Fraud',1),    tags=tags)Tags with Delayed ActualsTags can be updated via delayed actuals. If tags are sent with actuals, the tag will be joined based on prediciton_id. However, if the actual was sent prior, then resent with an updated tag value, the tag value will not be updated. Tags will remain the same if they are sent with predictions, not actuals. For example, if a user sends Arize a prediction with tags:\"location\": \"New York\"\"month\": \"January\" And actual with tags:\"location\": \"Chicago\"\"fruit\": \"apple\" The resulting tags available will be:\"location\": \"New York\"\"month\": \"January\"\"fruit\": \"apple\"Measure Model Performance Arize only calculates performance metrics on predictions that have actuals, so once your join is represented in Arize, you can utilize performance metrics and the 'Performance Tracing' tab for those predictions. If actuals have not been received yet (delayed actuals), use drift as a proxy metric for model performance to measure and monitor model health. Sending Data Guides - PreviousWhat Is A Model SchemaNext - Sending Data GuidesFAQ & Troubleshoot Data UploadLast modified 12d agoOn this pageWhat Are Delayed (Latent) Actuals Sending Delayed Actuals Joiner Cadence & Lookback   Joiner RequirementsExample Joins By Upload MethodTags with Delayed ActualsMeasure Model Performance SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9", "start_char_idx": 0, "end_char_idx": 7079, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b9e7625f-b071-4b68-983a-0e89bf14ddea": {"__data__": {"id_": "b9e7625f-b071-4b68-983a-0e89bf14ddea", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c960851a-f693-4d7d-bfe5-384094fae798", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "hash": "976f89f945002c9f42c7a8befc252dfa376f17e7715ac343c5c815f812863f1c"}, "2": {"node_id": "cb5e46ac-708e-4b5e-a9d4-87a1a24aa859", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}, "hash": "91a846718b035986dd69a929c39974c00bf53a00296d6856995d9b1cda7ccdf6"}}, "hash": "e77606e6d6f53399291cfa2006ee453f69205caca3fd696095acfed283b10065", "text": "2023 Arize AI, Inc", "start_char_idx": 7080, "end_char_idx": 7098, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e785356a-8805-4591-8a94-5b259257130b": {"__data__": {"id_": "e785356a-8805-4591-8a94-5b259257130b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fc309922-289e-4671-8182-59c0e23c8adb", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "hash": "a3795f2a941c27fa1e58827da7f71a44d7e736f00b8d91fc4d5ca3ac9eecd117"}, "3": {"node_id": "0e88a5c4-ca0f-4b9e-ad78-b6ca6917f996", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "hash": "a5d3baf498151cbeaf757c091a9953c7eac82d66f4b84f2cc6b257b7c00d4b0c"}}, "hash": "ba8d487eb9fe5282f2a38bc3a38f9f5c3b34082270bcd4d05bec5d0ad0fd09f4", "text": "What Is A Model Schema - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookWhat Is A Model SchemaOverview of Arize Model Inference SchemaArize stores model data and this data is organized by via model schema. The Arize model schema consists of model records. Each record can contain the inputs to the model (features), model outputs (predictions), timestamps, latently linked ground truth (actuals), metadata (tags), and model internals (embeddings and/or SHAP).Prediction IDTimestampPredictionActualFeatureTagEmbeddingURL1fcd50f46891637538845No ClaimsNo Claimscafemale[1.27346, -0.2138, ...]\"https://example_ur.jpg\"Your model schema differs based on the data ingestion method and model type. Navigate to model types here.  Model Schema DefinitionsSee below for more details, or click to navigate directly to a definition.1.\u200bModel Name \u200b2.\u200bModel Version \u200b3.\u200bModel Environments\u200b4.\u200bModel Type \u200b5.\u200bPrediction ID 6.\u200bTimestamp\u200b7.\u200bFeatures (Tabular - Structured Data) 8.\u200bEmbedding Features (Unstructured Data)9.\u200bTags \u200b10.\u200bFeature Importance Example SchemaNote: This schema example includes possible inputs using the Python Pandas SDK. Please consult model types for applicable schema parameters relevant to your model.Example Rowprediction_idprediction_tsprediction_labelprediction_scoreactual_labelactual_scorefeature_1tag_1vectortextimage_linkgroup_id_namerankrelevance_scoreactual_relevancy1fcd50f46891637538845No Claims0.4No Claims0.4cafemale[1.27346, -0.2138, ...]\"This is an example text\"\"https://example_ur.jpg\"14840.155441not relevantembedding_feature_column_names = { \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"vector\", # column containing embedding vector (required)        data_column_name=\"text\", # column containing raw text (optional NLP)        link_to_data_column_name=\"image_link\" # column containing image URL links (optional CV) )}\u200bschema = Schema(    prediction_id_column_name=\"prediction id\",    feature_column_names=[\"feature_1\", \"feature_2\", \"feature_3\"],     tag_column_names=[\"tag_1\", \"tag_2\", \"tag_3\"],     timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    prediction_score_column_name=\"prediction_score\",    actual_label_column_name=\"actual_label\",    actual_score_column_name=\"actual_score\",    shap_values_column_names=shap_values_column_names=dict(zip(\"feature_1\", shap_cols)),    embedding_feature_column_names=embedding_feature_column_names,    prediction_group_id_column_name=\"group_id_name\",    rank_column_name=\"rank\",    relevance_score_column_name=\"relevance_score\",    relevance_labels_column_name=\"actual_relevancy\",)  response = arize.log(    dataframe=df,    schema=schema,    environment=Environments.Production,    model_id=\"example_model\",    model_type=ModelTypes.BINARY_CLASSIFICATION    metrics_validation=metrics_validation=[Metrics.CLASSIFICATION, Metrics.REGRESSION, Metrics.AUC_LOG_LOSS]    model_version=\"1.0\"    validate=True ) 1. Model NameA unique identifier for your model. Your model name should have a clear name of the business use case (i.e., fraud-prevention-model)2. Model Version Model versions capture snapshots of a model at different times. New model versions are created after retraining, new weights, or new features. Each version can contain its own training, validation, and production environment.In Arize, you can have as many model versions as you want for a model, just as long as you upload them with the same Model ID. Use multiple model versions for a given model to filter and compare in Arize.3. Model EnvironmentsA model environment refers to the setup or conditions in which a model is developed. Arize supports uploading training, validation, and production environments. In Arize, a model can have multiple sets of environments depending on how many versions you have. Training Environment: Where the model learns from the training data, adjusting its parameters to minimize the error in its predictions.Arize supports multiple training versions for any given model versionValidation Environment: Used to test a model on a separate dataset (validation data) not used in training. This environment helps to fine-tune the model's hyperparameters and prevents overfitting.We support multiple batches of validation data (i.e. batch1, batch2, etc)Production Environment: Where the model is deployed to the real-world and provides predictions or classifications for actual use cases.Production data can help inform retraining efforts, thus creating a new model version. 4. Model Type Arize supports many model types - check out our various Model Types to learn more. 5. Prediction ID A prediction ID is an ID that indicates a unique prediction event. A prediction ID is required to connect predictions with delayed actuals (ground truth). Learn how to send delayed (latent) actuals here. \n\nNote: The maximum character limit for prediction ID is 128 characters6. TimestampThe timestamp indicates when the data will show up in the UI - sent as an integer representing the UNIX Timestamp in seconds. Typically, this is used for the time the prediction was made. However, there are instances such as time series models, where you may want the timestamp to be the date the prediction was made for. The timestamp field defaults to the time you sent the prediction to Arize. Arize supports sending in timestamps up to 2 year historically and 1 year in the future from the current timestamp. 7. Features (Tabular - Structured)Arize captures the feature schema as the first prediction is logged. If the features change over time, the feature schema will adjust to show the new schema. Features are inputs", "start_char_idx": 0, "end_char_idx": 7042, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0e88a5c4-ca0f-4b9e-ad78-b6ca6917f996": {"__data__": {"id_": "0e88a5c4-ca0f-4b9e-ad78-b6ca6917f996", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fc309922-289e-4671-8182-59c0e23c8adb", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "hash": "a3795f2a941c27fa1e58827da7f71a44d7e736f00b8d91fc4d5ca3ac9eecd117"}, "2": {"node_id": "e785356a-8805-4591-8a94-5b259257130b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}, "hash": "ba8d487eb9fe5282f2a38bc3a38f9f5c3b34082270bcd4d05bec5d0ad0fd09f4"}}, "hash": "a5d3baf498151cbeaf757c091a9953c7eac82d66f4b84f2cc6b257b7c00d4b0c", "text": "to the model8. Embedding Features (Unstructured) Arize's embedding objects are composed of 3 different pieces of information: vector (required): the embedding vector itself, representing the unstructured input data. Accepted data types are List[float] and nd.array[float].data (optional): Typically the raw text represented by the embedding vector. Accepted data types are str (for words or sentences) and List[str] (for token arrays).link to data (optional): Typically a URL linking to the data file (image, audio, video...) represented by the embedding vector. Accepted data types are str.Learn more about our embedding features here. 9. TagsTags are a convenient way to group predictions by metadata you find important but don't want to send as an input to the model. (i.e., what server/node was this prediction or actual served on, sensitive categories, model or feature operational metrics). Use tags to group, monitor, slice, and investigate the performance of \u201ccohorts\u201d based on user-defined metadata for the model.Tags can be sent in with predictions or actuals. If tags are sent in with a prediction and it's corresponding actual, Arize merges the tag maps, keeping the prediction tag\u2019s value if the tag keys are identical. Example row of tagslocationmonthfruitNew YorkJanuaryapple#Python single record tags = { 'location':'New York' 'month': 'January' 'fruit': 'apple'}response = arize.log(    model_id='sample-model-1',     model_version='v1',  ...    tags=tags)#Python batch (pandas)schema = Schema(    prediction_id_column_name='prediction_id',  ...    tag_column_names=['location', 'month', 'fruit'])10. Feature Importance  Feature importance is a compilation of a class of techniques that take in all the features related to making a model prediction and assign a certain score to each feature to weigh how much or how little it impacted the outcome.Check out the explainability section to learn more.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousAll Tutorials/NotebooksNext - Sending Data GuidesHow To Send Delayed ActualsLast modified 1mo agoOn this pageModel Schema DefinitionsExample Schema1. Model Name2. Model Version 3. Model Environments4. Model Type 5. Prediction ID 6. Timestamp7. Features (Tabular - Structured)8. Embedding Features (Unstructured) 9. Tags10. Feature Importance  SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7043, "end_char_idx": 9616, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "af4ad4f2-c1e9-4289-90af-0f1e994746e2": {"__data__": {"id_": "af4ad4f2-c1e9-4289-90af-0f1e994746e2", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf2a9af9-7270-47cd-aeea-3b53774d1e2c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "hash": "265256e17df1a42e4df4231e93ca257ddaf34dc309bbde4bdcfddba496c4330f"}, "3": {"node_id": "05bccf93-b57d-4f32-bbb2-2bd57f51b860", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "hash": "d6f536b3a084ca431b02301e49f7d483e0109bd30e03aa12d5a13564c2080aa0"}}, "hash": "03166e91fe52f769d06d66410acd3abc530416d79bb6abcc4e6059c542b802e8", "text": "AWS S3 - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Private Image Link Access Via AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAWS S3Set up an import job to ingest data into Arize from AWS S3If you prefer to use Terraform, jump to Applying Bucket Policy & Tag via Terraform\u200bSet up an import job to log inference files to Arize. Updates to files are checked every 10 seconds. Users generally find a sweet spot around a few hundred thousand to a million rows in each file with the total file limit being 1GB.Select Amazon S3Navigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'AWS S3' card to begin a new file import job. Step 1: Select Amazon S3Enable Access To Individual or Multiple BucketsThere are two ways to setup access permissions with ArizeConfigure An Indiviaual Bucket PolicyGive Arize permission to access individual bucketsConfigure Multiple Buckets Via Role Based PermissionsAssign Arize a role to access multiple buckets using external IDsConfigure An Individual Bucket PolicyConfigure Multiple Buckets Via Role Based PermissionsAdd File PathFill in the file path where you would like Arize to pull your model's inferences. Arize will automatically infer your bucket name and prefix. Example File Path In Arize UICreate the path to your bucket and folder to pull your model's inferences. In this example, you might have an AWS bucket and folder named s3://example-demo-bucket/click-thru-rate/production/v1/ that contains parquet files of your model inferences. Your bucket name is example-demo-bucket and your prefix is click-thru-rate/production/v1/.The file structure can take into consideration various model environments (training, production, etc) and locations of ground truth. In addition, S3 bucket import allows recursive operations. This means that it will include all nested subdirectories within the specified bucket prefix, regardless of the number or depth of these directories.File Directory ExampleThere are multiple ways to structure your file directory. If actuals and predictions can be sent together, simply store this data in a the same file and import this data together through a single file importer job. In the case of delayed actuals, we recommend you separate your predictions and actuals into separate folders and loading this data through two separate file importer jobs. Learn more here. s3://bucket1/click-thru-rate/production/prediction/\u251c\u2500\u2500 11-19-2022.parquet \u251c\u2500\u2500 11-20-2022.parquet\u251c\u2500\u2500 11-21-2022.parquet\u200bs3://bucket1/click-thru-rate/production/actuals/\u251c\u2500\u2500 12-1-2022.parquet # same prediction id column, model, and space as the corresponding prediction\u251c\u2500\u2500 12-2-2022.parquet\u2514\u2500\u2500 12-3-2022.parquetConfigure Ingestion KeyTag your bucket with the key arize-ingestion-key and the provided tag value (i.e. AWS Object Tags). In Arize UI: Copy arize-ingestion-key valueExample Bucket Tag In Arize UIIn AWS Console: Navigate to your S3 bucket -> Properties -> Edit Bucket PolicyNavigate to your bucket properties tabIn AWS Console: Set tag Key = arize-ingestion-key and Value as the value copied from Arize UI from the previous stepAdd arize-ingestion-key as a bucket tag Enable Bucket Policy PermissionsIn Arize UI: Copy the policy supplied by Arize in the file importer job setupCopy AWS Policy In Arize UIIn the AWS console: Navigate to your S3 bucket -> Permission -> Edit Bucket PolicyAdd/Edit bucket policyIn the AWS console: Paste the above AWS policy from Arize UI into the bucket policyAdd policy to your bucketConfigure Role Based PermissionsAsk Arize: To give Arize access to multiple buckets, ask arize to provide you with an External ID. Reach out to [email\u00a0protected] for assistance. Provide Arize: Provide Arize with the role ARN to access each AWS bucket you want to connect. In AWS Console: For each role, Arize will assume add the following statement to the role's Trust Policy { \"Effect\": \"Allow\", \"Principal\": { \"AWS\": \"arn:aws:iam::756106863523:root\" }, \"Action\": \"sts:AssumeRole\", \"Condition\": { \"StringEquals\": { \"sts:ExternalId\": \"<EXTERNAL ID PROVIDED BY ARIZE>\" } }}In AWS Console: Add the following statement to the role's Permissions Policies{ \"Effect\": \"Allow\", \"Action\": [ \"s3:GetBucketTagging\", \"s3:GetObject\", \"s3:ListBucket\" ], \"Resource\": [ \"arn:aws:s3:::<YOUR BUCKET NAME>\", \"arn:aws:s3:::<YOUR BUCKET NAME>/*\" ] }Configure Ingestion KeyTag your bucket with the key arize-ingestion-key and the provided tag value (i.e. AWS Object Tags). In Arize UI: Copy arize-ingestion-key valueIn AWS Console: Navigate to your S3 bucket -> Properties -> Edit Bucket PolicyIn AWS Console: Set tag Key = arize-ingestion-key and Value as the value copied from Arize UI from the previous stepDefine Your Model SchemaModel schema parameters are a way of organizing model inference data to ingest to Arize. When configuring your schema, be sure to match your data column headers with the model schema. You can either use a form or a simple JSON-based schema to specify the column mapping. Arize supports CSV, Parquet, Avro, and Apache Arrow. Refer here for a list of the expected data types by input type.  File Schema Form InputsForm Schema JSON InputsPropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.RequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timeprediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200bprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models rankColumn name for rank of each element on the its group or", "start_char_idx": 0, "end_char_idx": 7283, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "05bccf93-b57d-4f32-bbb2-2bd57f51b860": {"__data__": {"id_": "05bccf93-b57d-4f32-bbb2-2bd57f51b860", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf2a9af9-7270-47cd-aeea-3b53774d1e2c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "hash": "265256e17df1a42e4df4231e93ca257ddaf34dc309bbde4bdcfddba496c4330f"}, "2": {"node_id": "af4ad4f2-c1e9-4289-90af-0f1e994746e2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}, "hash": "03166e91fe52f769d06d66410acd3abc530416d79bb6abcc4e6059c542b802e8"}}, "hash": "d6f536b3a084ca431b02301e49f7d483e0109bd30e03aa12d5a13564c2080aa0", "text": "listRequired for ranking models relevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalValidate Your Model SchemaOnce you fill in your applicable predictions, actuals, and model inputs, click 'Validate Schema' to visualize your model schema in the Arize UI. Check that your column names and corresponding data match for a successful import job. Once finished, your import job will be created and will start polling your bucket for files. If your model receives delayed actuals, connect your predictions and actuals using the same prediction ID, which links your data together in the Arize platform. Arize regularly checks your data source for both predictions and actuals, and ingests them separately as they become available. Learn more here.Check Job StatusArize will attempt a dry run to validate your job for any access, schema, or record-level errors. If the dry run is successful, you can proceed to create the import job. From there, you will be taken to the 'Job Status' tab.All active jobs will regularly sync new data from your data source with Arize. You can view the job details by clicking on the job ID, which reveals more information about the job.Job status page showing job listingsTo pause, delete, or edit your file schema, click on 'Job Options'.Delete a job if it is no longer needed or if you made an error connecting to the wrong bucket. This will set your job status as 'deleted' in Arize. Pause a job if you have a set cadence to update your table. This way, you can 'start job' when you know there will be new data to reduce query costs. This will set your job status as 'inactive' in Arize. Edit a file schema if you have added, renamed, or missed a column in the original schema declaration.Troubleshoot Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. \u200bValidation Errors\u200bIf there is an error validating a file against the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Once you've identified the job failure point, fix the file errors and reupload the file to Arize with a new name. Applying Bucket Policy & Tag via Terraformresource \"aws_s3_bucket\" \"arize-example-bucket\" {  bucket = \"my-arize-example-bucket\"  tags = {    arize-ingestion-key = \"value_from_arize_ui\" }}\u200bresource \"aws_s3_bucket_policy\" \"grant_arize_read_only_access\" {  bucket = aws_s3_bucket.arize-example-bucket.id  policy = data.aws_iam_policy_document.grant_arize_read_only_access.json}\u200bdata \"aws_iam_policy_document\" \"grant_arize_read_only_access\" {  statement {    principals {      type        = \"AWS\"      identifiers = [\"arn:aws:iam::<REDACTED>:role/arize-importer\"] }\u200b    actions = [ \"s3:GetBucketTagging\", \"s3:GetObject\", \"s3:ListBucket\", ]\u200b    resources = [      aws_s3_bucket.arize-example-bucket.arn, \"${aws_s3_bucket.arize-example-bucket.arn}/*\", ] }}Sending Data Methods - PreviousGoogle Cloud Storage (GCS)NextPrivate Image Link Access Via AWS S3Last modified 1mo agoOn this pageSelect Amazon S3Enable Access To Individual or Multiple BucketsDefine Your Model SchemaValidate Your Model SchemaCheck Job StatusTroubleshoot Import JobApplying Bucket Policy & Tag via TerraformSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7284, "end_char_idx": 12299, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f1aeed01-3dc6-48f0-b335-5c81f7eb3b98": {"__data__": {"id_": "f1aeed01-3dc6-48f0-b335-5c81f7eb3b98", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "37d34887-1b48-486e-8cb6-acaf8734d4f1", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "hash": "ab1d9619259b5147b005a788cc4d661e65f5c3952fe9ad9a50ed21e214071c91"}, "3": {"node_id": "8d3dcd4d-5772-4048-b323-b801473e70c3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "hash": "2ef6c59250af77fd479af7a981e4e1cfa10b8411c7bd2fae62d61993b8275684"}}, "hash": "2df92266f91005b57a1fa83da602d0a28173088655d0d598ca208e37dd454046", "text": "Azure Blob Storage - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAzure Blob StorageSet up an import job to ingest data into Arize from AzureThe Azure Blob Storage connector is currently available to Enterprise plan customers. Please contact [email\u00a0protected] for access. Refer to step 3 for more details.Set up an import job to log inference files to Arize. Updates to files are checked every 10 seconds. Users generally find a sweet spot around a few hundred thousand to a million rows in each file, with the total file limit being 1GB.Step 1. Get The Storage Container Name & PrefixCreate a blob storage container and folder (optional) where you would like Arize to pull your model's inferences.For example you might set up a container named bucket1 and folder /click-thru-rate/production/v1/ that contains CSV files of your model inferences.In this example, your bucket name is bucket1 and your prefix is click-thru-rate/production/v1/There are multiple ways to structure model data. To easily ingest model inference data from storage, adopt a standardized directory structure across all models.Step 2. Get the Storage Account Name & Shared KeyFind the storage account name that your container is created under, and choose one access key to share with Arize. In Azure UI, from the Container page, navigate back to the storage account in the top left.To get a shared key, navigate to Access Keys in the storage account menu.Step 3. Contact Arize To Complete The Permissions SetupEmail [email\u00a0protected] to set up Azure permissions. Our team will contact you to securely share your container name and storage account name, and provide your access key. Once we confirm setup is complete, begin setting up import jobs.Step 4. Select Azure StorageNavigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'Azure Blob Storage' card to begin a new file import job. Fill in the file path where you would like Arize to pull your model's inferences. Arize will automatically infer your bucket name and prefix. Example File Path In Arize UIIn this example, you might have a bucket and folder named azure://example-demo-bucket/click-thru-rate/production/v1/ that contains parquet files of your model inferences. Your bucket name is example-demo-bucket and your prefix is click-thru-rate/production/v1/.The file structure can take into consideration various model environments (training, production, etc) and locations of ground truth. In addition, Azure blob store import allows recursive operations. This means that it will include all nested subdirectories within the specified bucket prefix, regardless of the number or depth of these directoriesFile Directory ExampleThere are multiple ways to structure your file directory. If actuals and predictions can be sent together, simply store this data in a the same file and import this data together through a single file importer job. In the case of delayed actuals, we recommend you separate your predictions and actuals into separate folders and loading this data through two separate file importer jobs. Learn more here. azure://bucket1/click-thru-rate/production/prediction/\u251c\u2500\u2500 11-19-2022.parquet \u251c\u2500\u2500 11-20-2022.parquet\u251c\u2500\u2500 11-21-2022.parquet\u200bazure://bucket1/click-thru-rate/production/actuals/\u251c\u2500\u2500 12-1-2022.parquet # same prediction id column, model, and space as the corresponding prediction\u251c\u2500\u2500 12-2-2022.parquet\u2514\u2500\u2500 12-3-2022.parquetStep 5. Add Proof Of Ownership To Your ContainerIn your container metadata, add an entry with the key as arize_ingestion_key and the provided tag value. In Arize UI: Copy the arize_ingestion_key value.In Azure UI: Navigate to your Container -> Settings -> Metadata.Click on Metadata and fill out the key value pair defined in the Arize UIStep 6a. Define Your Model SchemaModel schema parameters are a way of organizing model inference data to ingest to Arize. When configuring your schema, be sure to match your data column headers with the model schema. You can either use a form or a simple JSON-based schema to specify the column mapping.  Arize supports CSV, Parquet, Avro, and Apache Arrow. Refer here for a list of the expected data types by input type. PropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.RequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timeprediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200bprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models rankColumn name for rank of each element on the its group or listRequired for ranking models relevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalStep 6b. Validate Your Model SchemaOnce you fill in your applicable predictions, actuals, and model inputs, click 'Validate Schema' to visualize your model schema in the Arize UI. Check that your column names and", "start_char_idx": 0, "end_char_idx": 7889, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8d3dcd4d-5772-4048-b323-b801473e70c3": {"__data__": {"id_": "8d3dcd4d-5772-4048-b323-b801473e70c3", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "37d34887-1b48-486e-8cb6-acaf8734d4f1", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "hash": "ab1d9619259b5147b005a788cc4d661e65f5c3952fe9ad9a50ed21e214071c91"}, "2": {"node_id": "f1aeed01-3dc6-48f0-b335-5c81f7eb3b98", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}, "hash": "2df92266f91005b57a1fa83da602d0a28173088655d0d598ca208e37dd454046"}}, "hash": "2ef6c59250af77fd479af7a981e4e1cfa10b8411c7bd2fae62d61993b8275684", "text": "corresponding data match for a successful import job. Once finished, your import job will be created and will start polling your bucket for files.If your model receives delayed actuals, connect your predictions and actuals using the same prediction ID, which links your data together in the Arize platform. Arize regularly checks your data source for both predictions and actuals, and ingests them separately as they become available. Learn more here.Step 7. Check Job StatusArize will attempt a dry run to validate your job for any access, schema, or record-level errors. If the dry run is successful, you can proceed to create the import job. From there, you will be taken to the 'Job Status' tab.All active jobs will regularly sync new data from your data source with Arize. You can view the job details by clicking on the job ID, which reveals more information about the job.Job Status tab showing job listingsTo pause, delete, or edit your file schema, click on 'Job Options'.Delete a job if it is no longer needed or if you made an error connecting to the wrong bucket. This will set your job status as 'deleted' in Arize. Pause a job if you have a set cadence to update your table. This way, you can 'start job' when you know there will be new data to reduce query costs. This will set your job status as 'inactive' in Arize. Edit a file schema if you have added, renamed, or missed a column in the original schema declaration.Step 8. Troubleshoot Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. Validation ErrorsIf there is an error validating a file against the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Once you've identified the job failure point, fix the file errors and reupload the file to Arize with a new name. PreviousPrivate Image Link Access Via AWS S3Next - Sending Data MethodsGoogle BigQueryLast modified 1mo agoOn this pageStep 1. Get The Storage Container Name & PrefixStep 2. Get the Storage Account Name & Shared KeyStep 3. Contact Arize To Complete The Permissions SetupStep 4. Select Azure StorageStep 5. Add Proof Of Ownership To Your ContainerStep 6a. Define Your Model SchemaStep 6b. Validate Your Model SchemaStep 7. Check Job StatusStep 8. Troubleshoot Import JobSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7890, "end_char_idx": 10782, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a175d1ba-4ab0-4694-9a07-c62342846fa1": {"__data__": {"id_": "a175d1ba-4ab0-4694-9a07-c62342846fa1", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b5b1a345-1092-4bb4-94c4-a1a92e091e76", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "hash": "e8b1073ed575183aa4adae7149434eacacc4755458b89e1433461bc129f78a65"}, "3": {"node_id": "9c4e69b3-413c-417a-a155-2dd3c0dcd41b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "hash": "19fc396fb49f52991e45227c7794f6ae46be2bd0a639ce693bc63d65bb02d9bf"}}, "hash": "f13124d4baa0c5b635022d6b086fa1839632fcf253cad12e19d5717f65ff3c74", "text": "Databricks - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDatabricksLearn how to setup an import job using DatabricksStep 1 - Generate a TokenIf necessary, generate a PAT (Personal Access Token), which will be used to authenticate in the following steps when you generate a token for your service principal.Navigate to your Workspace and click \"User Settings\"Click \"Generate new token\"Take note of your PATWith Unity CatalogWithout Unity Catalog1.Navigate to your Workspace and click \"Admin Settings\"2.In the \"Service Principals\" tab, click \"Add Service Principal\"\u200b1.Click on \"User Management\" on accounts.cloud.databricks.com2.Create a Service Principal3.Take note of the Application ID4.Run the following curl command to create a service principal in your workspace where ${DATABRICKS_HOST} is the workspace URL, ${DATABRICKS_TOKEN} is the PAT you just created, and $APPLICATION_ID is the Application ID of the service principal you just createdcurl -X POST \\${DATABRICKS_HOST}/api/2.0/preview/scim/v2/ServicePrincipals \\--header \"Content-type: application/json\" \\--header \"Authorization: Bearer ${DATABRICKS_TOKEN}\" \\--data \"{ \\\"displayName\\\": \\\"displayName\\\", \\\"externalId\\\": \\\"externalId\\\", \\\"applicationId\\\": \\\"${APPLICATION_ID}\\\", \\\"id\\\": \\\"id\\\", \\\"active\\\": true}\"\u200bClick on the service principal and enable \u201cDatabricks SQL access\u201d and \u201cWorkspace access\u201d and click \u201cUpdate\u201dNavigate to \"Admin Settings\" > \"Workspace Settings\". Search for Personal Access TokensClick Permission Settings and grant \"Can Use\" to the service account you just created.With your Token (PAT) and Application ID, run the following CURL command. Don't forget to fill in the environment variables with your specific information (${DATABRICKS_HOST} should be the URL of your workspace)curl -X POST \\${DATABRICKS_HOST}/api/2.0/token-management/on-behalf-of/tokens \\--header \"Content-type: application/json\" \\--header \"Authorization: Bearer ${DATABRICKS_TOKEN}\" \\--data \"{\\\"application_id\\\": \\\"${APPLICATION_ID}\\\" }\"Save the token_value from the response. This is the Token you will use to complete the remaining setup in Arize later.Step 2 - Grant Access To Your TableGo to the Data Explorer (on the left drawer) and click on the catalog with the table/view you want to grant access.Click \u201cPermissions\u201d and grant \u201cUSE CATALOG\u201d and \u201cUSE SCHEMA\u201d. Click Grant.Go to the view/table and click \u201cPermissions\u201d and grant \u201cSELECT\u201d to the view/tableGo to \"SQL Warehouses\" > [YOUR_WAREHOUSE_NAME] and click on \"Permissions\". Grant Can Use permissions to your service principal.Step 3 - Start the Data Upload WizardNavigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'Databricks' card or navigate to the Data Warehouse tab to start a new table import job to begin a new table import job. Storage Selection: DatabricksSelect Databricks from Table OptionsInput Hostname, Endpoint, Port, and Token (from Step 1)You can find Hostname, Endpoint, and Port in your WorkspaceSimilarly for Table IDIf you have issues granting permissions please reach out to [email\u00a0protected]Step 4 - Configure Your Model And Define Your Table\u2019s SchemaMatch your model schema to your model type and define your model schema through the form input or a json schema.Set up model configurationsMap your table using a formMap your table using a JSON schemaPropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.RequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timechange_timestamp*Timestamp of when a row was added (see example for details)Required *(only applicable for table upload)prediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200bprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models\u200brankColumn name for rank of each element on the its group or listRequired for ranking models\u200brelevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalOnce finished, Arize will begin querying your table and ingesting your records as model inferences.Step 5 - Add Model Data To The Table Or ViewArize will run queries to ingest records from your table based on your configured refresh interval.Step 6 - Check your Table Import JobArize will attempt a dry run to validate your job for any access, schema or record-level errors. If the dry run is successful, you may then create the import job. After creating a job following a successful dry run, you will be taken to the 'Job Status' tab where you can see the status of your import jobs.You can view the job details and import progress by clicking on", "start_char_idx": 0, "end_char_idx": 7601, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9c4e69b3-413c-417a-a155-2dd3c0dcd41b": {"__data__": {"id_": "9c4e69b3-413c-417a-a155-2dd3c0dcd41b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b5b1a345-1092-4bb4-94c4-a1a92e091e76", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "hash": "e8b1073ed575183aa4adae7149434eacacc4755458b89e1433461bc129f78a65"}, "2": {"node_id": "a175d1ba-4ab0-4694-9a07-c62342846fa1", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}, "hash": "f13124d4baa0c5b635022d6b086fa1839632fcf253cad12e19d5717f65ff3c74"}}, "hash": "19fc396fb49f52991e45227c7794f6ae46be2bd0a639ce693bc63d65bb02d9bf", "text": "the job ID, which uncovers more information about the job.Step 7 - Troubleshooting An Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. Validation ErrorsIf there is an error validating a file or table against the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Once you've identified the job failure point, append the edited row to the end of your table with an updated change_timestamp value. PreviousGoogle BigQuery FAQNext - Sending Data MethodsSnowflakeLast modified 4d agoOn this pageStep 1 - Generate a TokenStep 2 - Grant Access To Your TableStep 3 - Start the Data Upload WizardStep 4 - Configure Your Model And Define Your Table\u2019s SchemaStep 5 - Add Model Data To The Table Or ViewStep 6 - Check your Table Import JobStep 7 - Troubleshooting An Import JobSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7602, "end_char_idx": 9054, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "619f7580-dc9e-459d-bab0-97ce2617bd3d": {"__data__": {"id_": "619f7580-dc9e-459d-bab0-97ce2617bd3d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0692058a-430b-4fd5-9e6a-0d92fc0d4b9c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "hash": "69b6f6d3a75cadf32cedccd1c7607fff795eb4b79c3a5f222b4b9e1232ce142c"}, "3": {"node_id": "1f9e9eb7-d7fb-455b-a516-216d1cbcb656", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "hash": "34643c26b3e574154abc207a6c5201617b4311cfe41cd090e2a8eb6521e0db40"}}, "hash": "d9c87fd3c552ad47bdd9d2bc37c2d1749ee03863609827568d6ed6f705c29a01", "text": "Google Cloud Storage (GCS) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGoogle Cloud Storage (GCS)Set up an import job to ingest data into Arize from GCSIf you prefer to use Terraform, jump to Applying Bucket Policy & Tag via Terraform Set up an import job to log inference files to Arize. Updates to files are checked every 10 seconds. Users generally find a sweet spot around a few hundred thousand to a million rows in each file with the total file limit being 1GB.Step 1. Select Google StorageNavigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'GCS' card to begin a new file import job. Step 1: Pick GCS Step 2.  Specify File PathGet File Path In GCS: Within your project, navigate to the folder you wish to ingest and click on a file to easily copy your file path. Copy File Path From GCSIn Arize UI:Paste the file path where you would like Arize to pull your model's inferences. Arize will automatically infer your bucket name and prefix (based on the folder). Note: The file path must start with gs://Example File Path In Arize UIIn this simple example, your GCS path is gs://docs-example-bucket/production/ that contains parquet files of your model inferences. The file structure can take into consideration various model environments (training, production, etc) and locations of ground truth. In addition, GCS bucket import allows recursive operations. This means that it will include all nested subdirectories within the specified bucket prefix, regardless of the number or depth of these directories.Example 1: Predictions & Actuals Stored in Separate Folders (different prefixes)This example contains model predictions and actuals in separate files. This helps in cases of delayed actuals. Learn more here. gs://bucket1/click-thru-rate/production/\u251c\u2500\u2500 prediction-folder/\u2502   \u251c\u2500\u2500 12-1-2022.parquet #this file can contain multiple versions\u2502   \u251c\u2500\u2500 12-2-2022.parquet\u2502   \u251c\u2500\u2500 12-3-2022.parquet\u251c\u2500\u2500 actuals-folder/\u2502   \u251c\u2500\u2500 12-1-2022.parquet\u2502   \u251c\u2500\u2500 12-2-2022.parquet\u2502   \u2514\u2500\u2500 12-3-2022.parquetExample 2: Production & Training Stored in Separate FoldersThis example separates model environments (production and training). gs://bucket1/click-thru-rate/v1/\u251c\u2500\u2500 production-folder/\u2502   \u251c\u2500\u2500 12-1-2022.parquet \u2502   \u251c\u2500\u2500 12-2-2022.parquet\u2502   \u251c\u2500\u2500 12-3-2022.parquet\u251c\u2500\u2500 training-folder/\u2502   \u251c\u2500\u2500 12-1-2022.parquet\u2502   \u251c\u2500\u2500 12-2-2022.parquet\u2502   \u2514\u2500\u2500 12-3-2022.parquetStep 3. Add GCS Project ID The GCS Project ID is a unique identifier for a project. See GCS Docs for steps on how to retrieve this ID.  Example Project ID In Arize UIStep 4. Add Proof of Ownership To Your GCS BucketTag your GCS bucket with the key arize-ingestion-key and the provided tag value. For more details, see docs on Using Bucket Labels.1) In Arize UI: Copy arize-ingestion-key valueCopy Arize Ingestion Key From Arize UI2) In Google Cloud console: Navigate to Cloud StorageHere, you will see a list of your buckets. Find the bucket matching the bucket name set in your job (step 2), select the button for more options, and update the label of the bucket to include the arize-ingestion-key.Key: arize-ingestion-keyValue: arize-ingestion-key value from the Arize UIStep 5. Grant Arize Access PrivilegesCreate a custom role and copy the command from the Custom IAM Role field in Arize UI. Copy Custom IAM Role From Arize UIPaste and run the above gcloud commands in Google Cloud Shell. Be sure to set --project to your project id.Start the Google Cloud ShellCreate the IAM RoleGrant Arize access to the custom roleCopy the command from the Apply IAM Permission Field in the Arize UI.Copy IAM Permission From Arize UI Paste and run the above gsutil command in the Google Cloud Shell. Be sure to update your project id in the service account path.Apply the IAM PermissionsStep 6a. Define Your Model SchemaModel schema parameters are a way of organizing model inference data to ingest to Arize. When configuring your schema, be sure to match your data column headers with the model schema. Either use a form or a simple JSON-based schema to specify the column mapping.  Arize supports CSV, Parquet, Avro, and Apache Arrow. Refer here for a list of the expected data types by input type. Set up model configurationsMap your file using form inputsMap your file using a JSON schemaPropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.RequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timeprediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreOptional rankColumn name for rank of each element on the its group or listRequired for ranking models prediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models relevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the", "start_char_idx": 0, "end_char_idx": 7353, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1f9e9eb7-d7fb-455b-a516-216d1cbcb656": {"__data__": {"id_": "1f9e9eb7-d7fb-455b-a516-216d1cbcb656", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0692058a-430b-4fd5-9e6a-0d92fc0d4b9c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "hash": "69b6f6d3a75cadf32cedccd1c7607fff795eb4b79c3a5f222b4b9e1232ce142c"}, "2": {"node_id": "619f7580-dc9e-459d-bab0-97ce2617bd3d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}, "hash": "d9c87fd3c552ad47bdd9d2bc37c2d1749ee03863609827568d6ed6f705c29a01"}}, "hash": "34643c26b3e574154abc207a6c5201617b4311cfe41cd090e2a8eb6521e0db40", "text": "same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptional6b. Validate Your Model SchemaOnce you fill in your applicable predictions, actuals, and model inputs, click 'Validate Schema' to visualize your model schema in the Arize UI. Check that your column names and corresponding data match for a successful import job. File Preview in UIOnce finished, your import job will be created and will start polling your bucket for files. If your model receives delayed actuals, connect your predictions and actuals using the same prediction ID, which links your data together in the Arize platform. Arize regularly checks your data source for both predictions and actuals, and ingests them separately as they become available. Learn more here.Step 7. Check Job StatusArize will attempt a dry run to validate your job for any access, schema, or record-level errors. If the dry run is successful, you can proceed to create the import job. From there, you will be taken to the 'Job Status' tab.All active jobs will regularly sync new data from your data source with Arize. You can view the job details by clicking on the job ID, which reveals more information about the job.Job Status tab showing job listingsTo pause, delete, or edit your file schema, click on 'Job Options'.Delete a job if it is no longer needed or if you made an error connecting to the wrong bucket. This will set your job status as 'deleted' in Arize. Pause a job if you have a set cadence to update your table. This way, you can 'start job' when you know there will be new data to reduce query costs. This will set your job status as 'inactive' in Arize. Edit a file schema if you have added, renamed, or missed a column in the original schema declaration.Step 8. Troubleshoot Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. Validation ErrorsIf there is an error validating a file the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Once you've identified the job failure point, fix the file errors and reupload the file to Arize with a new name. Applying Bucket Policy & Tag via Terraformresource \"google_storage_bucket\" \"arize-example-bucket\" { // (optional) uniform_bucket_level_access = true  name           = \"arize-example-bucket\"  project        = google_project.development.project_id  labels         = { \"arize-ingestion-key\" = \"value_from_arize_ui\" }}\u200bresource \"google_project_iam_custom_role\" \"arize-example-bucket\" {  description = \"permission to view storage bucket, and view and list objects\"  permissions = [ \"storage.buckets.get\", \"storage.objects.get\", \"storage.objects.list\" ]  project = google_project.development.project_id  role_id = \"FileImporterViewer\"  title   = \"File Importer Viewer\"  stage   = \"ALPHA\"}\u200bresource \"google_storage_bucket_iam_binding\" \"arize-example-bucket-iam-binding\" {  bucket = google_storage_bucket.arize-example-bucket.name  role = \"projects/<PROJECT_ID>/roles/FileImporterViewer\"  members = [ \"serviceAccount:[email\u00a0protected]\", ]}\u200bPreviousUI Drag & Drop FAQNext - Sending Data MethodsAWS S3Last modified 13d agoOn this pageStep 1. Select Google StorageStep 2.  Specify File PathStep 3. Add GCS Project ID Step 4. Add Proof of Ownership To Your GCS BucketStep 5. Grant Arize Access PrivilegesStep 6a. Define Your Model Schema6b. Validate Your Model SchemaStep 7. Check Job StatusStep 8. Troubleshoot Import JobApplying Bucket Policy & Tag via TerraformSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7354, "end_char_idx": 11746, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f29f1a2e-21bd-4b0f-b57d-59e4a33fac88": {"__data__": {"id_": "f29f1a2e-21bd-4b0f-b57d-59e4a33fac88", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "05959813-46de-47de-b480-227edfbc1403", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "hash": "f391774066da4dc745ae49b4dd2f5175dd9fef4e6e59a5b1aa5d0ed70fbd305e"}, "3": {"node_id": "19bb19e9-cbf2-43a7-9b71-ddf760646a39", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "hash": "091afc5426112077567a37a98bf9344bd702dffad99c41a9fedd731c1d8fb592"}}, "hash": "9570f202b797ef5366535fe8ffbdd3778bbd33693dc83bbd77ad66bc08e38914", "text": "Google BigQuery - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryGoogle BigQuery FAQDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGoogle BigQueryLearn how to setup an import job using Google BigQueryStep 1 - Start the Data Upload WizardNavigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'Google BQ' card or navigate to the Data Warehouse tab to start a new table import job to begin a new table import job. Storage Selection: Google BQStep 2 - Input the Project ID, Dataset, and Table / ViewLocate the Project ID, Dataset, and Table or View name of the table/view you would like to sync from Google BigQuery.The GBQ Project ID is a unique identifier for a project. See here for steps on how to retrieve this ID.  The dataset and table name correspond to the path where your table is locatedConsole view to find Project ID, Dataset name and Table/View nameAdd your Table ID Arize. Arize will automatically parse your Dataset, Table Name, and GCP Project ID.Example TableIDStep 3 - Grant Access To Your Dataset, Table, or ViewTag your dataset/table/view with the arize-ingestion-key and the provided label value using the steps below. For more details, see docs on Adding labels to resources for BigQuery.In Arize UI: Copy arize-ingestion-key valueCopy Arize Ingestion KeyYou can grant access to a single table or view or all the tables/views in a dataset.Consider creating an authorized view if you don't want to grant access to the underlying tables, or granting access to each underlying table is too cumbersome.  Grant Access To A Table/ViewGrant Access To An Entire DatasetGrant Access To A Table/ViewFrom UIFrom CLI1.In Google Cloud console: Navigate to the BigQuery SQL Workspace\u200b\u200b2.Select the desired table or view, navigate to the Details tab and click \"Edit Details\". Under the Labels section, click \"Add Labels\". Add the following label:Key as \"arize-ingestion-key\"Value as the arize-ingestion-key value from the Arize UI\u200b\u200b3.Grant the roles/bigquery.jobUser role to our service account. Go to the IAM page and click \"Grant Access\"Add Arize service account as \"Principal\" with \"BigQuery Job User\" roleNavigate to your table/view from the Bigquery SQL Explorer page.Select \"Share\" and click on \"Permissions\"\u200b\u200bClick \"Add Principal\"\u200b\u200bAdd our service account: [email\u00a0protected] as a BigQuery Data Viewer, and click \"Save\"\u200b\u200bFor a view, you must grant access to all underlying tables, so you must repeat these step for all the underlying tables.For more details: see the official documentation for granting access here\u200b4.\u200bNavigate to Step 4 - Configure your model and define your table\u2019s schema\u200bYou can create a cloud shell instance from the UI to run the following commands1.Add the arize-ingestion-key key from the Arize UI as a label on the datasetbq update --set_label arize-ingestion-key:${KEY_FROM_UI} ${PROJECT_ID}:${DATASET}2.Grant the roles/bigquery.jobUser role to the Arize service account.gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:[email\u00a0protected] --role=roles/bigquery.jobUser3.To grant the roles/bigquery.dataViewer role to the Arize service account your table or viewTable: bq add-iam-policy-binding \\ --member='serviceAccount:[email\u00a0protected]' \\ --role='roles/bigquery.dataViewer' \\  ${PROJECT_ID}:${DATASET}.${TABLE}View: See the Google BigQuery guide to grant access to a view and navigate to the tab bq.4.\u200bNavigate to Step 4 - Configure your model and define your table\u2019s schema\u200bGrant Access To An Entire Dataset:From UIFrom CLI1.In Google Cloud console: Navigate to the BigQuery SQL Workspace\u200b\u200b2.Select the desired dataset, and click \"Edit Details\". Under the Labels section, click \"Add Labels\". Add the following label:Key as \"arize-ingestion-key\"Value as the arize-ingestion-key value copied from the Arize UI\u200b\u200b\u200b3.Grant the roles/bigquery.jobUser role to the Arize service account. Go to the IAM page and click \"Grant Access\"Navigate to your dataset from the Bigquery SQL Explorer page.Select \"Sharing\" and click on \"Permissions\"Click \"Add Principal\"\u200b\u200bAdd Arize service account: [email\u00a0protected] as a BigQuery Data Viewer, and click \"Save\"\u200b\u200bFor additional details: see the official documentation for granting access here\u200b4.\u200bNavigate to Step 4 - Configure your model and define your table\u2019s schema\u200bYou can create a cloud shell instance from the UI to run the following commands\u200b\u200b1.Add the arize-ingestion-key key from the Arize UI as a label on the datasetbq update --set_label arize-ingestion-key:${KEY_FROM_UI} ${PROJECT_ID}:${DATASET}2.Grant the roles/bigquery.jobUser role to the Arize service account.gcloud projects add-iam-policy-binding ${PROJECT_ID} --member=serviceAccount:[email\u00a0protected] --role=roles/bigquery.jobUser3.To grant the roles/bigquery.dataViewer role to the Arize service account on your dataset, see the BigQuery guide to grant access to a dataset and navigate to the tab bq.4.\u200bNavigate to Step 4 - Configure your model and define your table\u2019s schema\u200bStep 4 - Configure Your Model And Define Your Table\u2019s SchemaMatch your model schema to your model type and define your model schema through the form input or a json schema.Set up model configurationsMap your table using a formMap your table using a JSON schemaPropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.RequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timechange_timestamp*Timestamp of when a row was added (see example for details)Required *(only applicable for table upload)prediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or", "start_char_idx": 0, "end_char_idx": 7193, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "19bb19e9-cbf2-43a7-9b71-ddf760646a39": {"__data__": {"id_": "19bb19e9-cbf2-43a7-9b71-ddf760646a39", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "05959813-46de-47de-b480-227edfbc1403", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "hash": "f391774066da4dc745ae49b4dd2f5175dd9fef4e6e59a5b1aa5d0ed70fbd305e"}, "2": {"node_id": "f29f1a2e-21bd-4b0f-b57d-59e4a33fac88", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}, "hash": "9570f202b797ef5366535fe8ffbdd3778bbd33693dc83bbd77ad66bc08e38914"}}, "hash": "091afc5426112077567a37a98bf9344bd702dffad99c41a9fedd731c1d8fb592", "text": "ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200bprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models rankColumn name for rank of each element on the its group or listRequired for ranking models relevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalOnce finished, Arize will begin querying your table and ingesting your records as model inferences.Step 4b. Validate Model SchemaOnce you fill in your applicable predictions, actuals, and model inputs, click 'Validate Schema' to visualize your model schema in the Arize UI. Check that your column names and corresponding data match for a successful import job. Step 5 - Add Model Data To The Table Or ViewArize will run queries to ingest records from your table based on your configured refresh interval.Step 6 - Check your Table Import JobArize will attempt a dry run to validate your job for any access, schema, or record-level errors. If the dry run is successful, you can proceed to create the import job. From there, you will be taken to the 'Job Status' tab where you can see the status of your import jobs.Table of your import jobsAll active jobs will regularly sync new data from your data source with Arize. You can view the job details and import progress by clicking on the job ID, which reveals more information about the job.Audit trail of queries run on your tableStep 6.5 Pause or Delete An Import JobTo pause or edit your table schema, click on 'Job Options'.Delete a job if it is no longer needed or if you made an error connecting to the wrong bucket. This will set your job status as 'deleted' in Arize. Pause a job if you have a set cadence to update your table. This way, you can 'start job' when you know there will be new data to reduce query costs. This will set your job status as 'inactive' in Arize. Job Status tab showing job listingsStep 7 - Troubleshooting An Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. Validation ErrorsIf there is an error validating a file or table against the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Within the Job Details section, you can select More Details on a specific query to view the start time and end time that was used in that query. The query start time represents the max value of the change_timestamp based on the previous query, and the query end time is the current day/time that the query was run. The query start time will then be updated after each query to reflect the current max change_timestamp. This can help debug issues specifically related to the change_timestamp field. Once you've identified the job failure point, append the edited row to the end of your table with an updated change_timestamp value. Sending Data Methods - PreviousAzure Blob StorageNextGoogle BigQuery FAQLast modified 25d agoOn this pageStep 1 - Start the Data Upload WizardStep 2 - Input the Project ID, Dataset, and Table / ViewStep 3 - Grant Access To Your Dataset, Table, or ViewStep 4 - Configure Your Model And Define Your Table\u2019s SchemaStep 4b. Validate Model SchemaStep 5 - Add Model Data To The Table Or ViewStep 6 - Check your Table Import JobStep 6.5 Pause or Delete An Import JobStep 7 - Troubleshooting An Import JobSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7194, "end_char_idx": 12394, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "580c151d-75a7-4190-ad84-b7e448f711e5": {"__data__": {"id_": "580c151d-75a7-4190-ad84-b7e448f711e5", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/log-directly-via-sdk-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9268e9f4-0348-4664-acc5-4939a1ee056c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/log-directly-via-sdk-api"}, "hash": "ef7831cd1af1ce849c2526d9b47beea7c378b48a30a350c8c28e502c55d27d8f"}}, "hash": "7d966cf0421b18e3bf43c61ae235705ab158c6a8174f16902b9f5c7e90b5c536", "text": "Python Pandas SDK - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPython Pandas SDKLog model inference data directly to Arize using SDK/API methodsThis page shows how to send data to Arize using the Python Pandas SDK. Step 1: Set Up Python SDKInstall Arize SDKpip install arizeInitialize Arize client from arize.pandas.logger to call  Client.log() from arize.pandas.logger import Client, Schema\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)Step 2: Set Model Schema AttributesA model schema is broken into required and optional parameters. Optional model schema parameters vary based on model types. Learn more about model types here. Gain a comprehensive list of schema attributes and their definitions here. Example Rowprediction_idprediction_tsprediction_labelactual_labelstategendervectortextimage_link1fcd50f46891637538845No ClaimsNo Claimscafemale[1.27346, -0.2138, ...]\"This is an example text\"\"https://example_ur.jpg\"schema = Schema(    prediction_id_column_name=\"prediction_id\",     timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    actual_label_column_name=\"actual_label\",    feature_column_names=[\"state\"],    tag_column_names=[\"gender\"])Optional: Embeddings# Declare embedding feature columnsembedding_feature_column_names = { # Dictionary keys will be the name of the embedding feature in the app \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"vector\", # column containing embedding vector (required)        data_column_name=\"text\", # column containing raw text (optional NLP)        link_to_data_column_name=\"image_link\" # column containing image URL links (optional CV) )}\u200bschema = Schema(    embedding_feature_column_names=embedding_feature_column_names, ...)Optional: SHAP Values# Generate the Shap Values and save as a Dataframeexplainer = shap.TreeExplainer(tree_model)shap_values = explainer.shap_values(X_data)shap_dataframe = pd.DataFrame(        shap_values, columns=[f\"{fn}_shap\" for fn in data[\"state\"]])shap_cols = shap_dataframe.columns\u200bschema = Schema(    shap_values_column_names=dict(zip(\"state\", shap_cols)), ...)Optional: Delayed Actuals If your model receives delayed actuals, log your delayed production data using the same prediction ID, which links your files together in the Arize platform. This can be delivered days or weeks after the prediction is received. #log predictionsschema = Schema(    prediction_id_column_name=\"prediction_id\",     prediction_label_column_name=\"prediction_label\", ...)# then log actuals schema = Schema(    prediction_id_column_name=\"prediction_id\", #needs to be the same as above    actual_label_column_name=\"actual_label\", ...)Step 3: Log Inferences Arize expects the DataFrame's index to be sorted and begin at 0. If you perform operations that might affect the index prior to logging data, reset the index as follows:example_dataframe = example_dataframe.reset_index(drop=True)response = arize_client.log(    model_id='sample-model-1',     model_version='v1', #Specify your model version to easily track changes across the Arize platform (i.e. a retrained model)     batch_id=None,    model_type=ModelTypes.BINARY_CLASSIFICATION,    metrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS]    environment=Environments.PRODUCTION,#pick from training, production,or validation data    dataframe=example_dataframe,    schema=schema)Optional: Metrics Validationmetrics_validation=[Metrics.CLASSIFICATION, Metrics.AUC_LOG_LOSS]There is an optional argument that specifies desired groups of metrics for validation. Combined with a model_type and based on the schema, Arize will validate that these expected metrics will be available in the platform, and will validate required schema columns. Call __repr__() on a Metrics enum to see its description:repr(Metrics.CLASSIFICATION)> CLASSIFICATION metrics include: Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityLearn more about metrics families here.Supported SDKs\u200bPython Pandas SDK (log a pandas dataframe)\u200bPython Single Record SDK (log a single-record) \u200bJava SDK\u200b\u200bR SDK\u200b\u200bRest API\u200bPreviousSending Data FAQNext - Sending Data MethodsUI Drag & DropLast modified 13d agoOn this pageStep 1: Set Up Python SDKStep 2: Set Model Schema AttributesStep 3: Log Inferences Supported SDKsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5984, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "426818ff-842f-48fd-86f2-be8a7c65de23": {"__data__": {"id_": "426818ff-842f-48fd-86f2-be8a7c65de23", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1f7d1fef-9184-4c27-aa28-f1eead203125", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "hash": "facf69694889b2df31dd0a18404e3dbaf914aebfcb2bc853daeb7cc3d580d734"}, "3": {"node_id": "506faca4-8611-47fc-96ec-c143e8116c10", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "hash": "4f7723b71f5c185f45d343c8cb2e03d2ca368349dd99122c117a70aef5c400fc"}}, "hash": "36e5ddfc0758b58455a484b68bbece444cf4482a0260b221124a5df7b2948b58", "text": "Snowflake - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSnowflakeLearn how to setup an import job using SnowflakeStep 1 - Start the Data Upload WizardNavigate to the 'Upload Data' page on the left navigation bar in the Arize platform. From there, select the 'Snowflake' card or navigate to the Data Warehouse tab to start a new table import job to begin a new table import job. Storage Selection: \u2744\ufe0f SnowflakeUpload Data Page in ArizeStep 2 - Warehouse Onetime Setup A warehouse is an on-demand, scalable compute cluster used for executing data processing tasks, in this case, connect a warehouse to run queries and sync data from tables relevant to your model.To gain access to your tables, first configure an initial setup to any new Snowflake Warehouse. If you've previously connected your warehouse, skip this step and proceed to specify the table configuration.\u200bIn Snowflake: Copy your Warehouse nameWarehouses in SnowflakeIn Arize: Paste 'Warehouse Name' in the applicable field, and copy the code snippetWarehouse Field in ArizeIn Snowflake: Create a Snowflake 'SQL worksheet'Worksheets Tab in SnowflakeIn Snowflake: Paste code snippet from Arize, select the applicable Warehouse, and click 'Run All'Example Worksheet to Run AllStep 3 - Specify Snowflake Table ConfigurationArize requires the following field inputs to enable access permissions. Field NameDescriptionAccount IDThe account identifier<organization_name>-<account_name> (ex. WOOGSCZ-ZV77179)DatabaseThe high-level container for storing and organizing your schemas \n(ex. COVID19_EPIDEMIOLOGICAL_DATA)SchemaThe logical container that holds the target table within a database (ex. PUBLIC)Table NameThe database object that stores structured data in rows and columns that Arize will sync from (ex. DEMOGRAPHICS)Field heirarchy in SnowflakeIn Snowflake: Create an 'Account ID' by combining your <organization name> with your <account name>, separated by a hyphen. Account information is located at the bottom left of any Snowflake page.In the example below, the account ID in Arize isWOOGSCZ-ZV77179.Account information located on the bottom left of any Snowflake pageIn Snowflake: Copy the Database, Schema, and Table Names from the 'Databases' tab.Snowflake databse informationIn Arize: Input fields to Arize in the 'Dataset Configuration' cardDataset configuration in ArizeStep 4 - Configure Table PermissionsTable permissions enable Arize to access, read, and sync your data.In Arize: Copy the code snippet in the \u201cPermissions Configuration\u201d cardCopy Permissions Configuration in ArizeIn Snowflake: Paste the 'Permissions Configuration' code snippet in a Snowflake SQL Worksheet and click 'Run All'. See docs on granting permissions to Arize's role for Snowflake.Snowflake SQL WorksheetStep 5 - Configure Your Model And Define Your Table\u2019s SchemaMatch your model schema to your model type and define your model schema through the form input or a json schema.Set up model configurationsMap your table using a formMap your table using a JSON schemaPropertyDescriptionRequiredprediction_IDThe unique identifier of a specific prediction. Limited to 128 characters.Requiredchange_timestamp*Timestamp indicating when a row was added to the table. Used to automatically sync new rows(see example for details)Required *(only applicable for table upload)prediction_labelColumn name for the prediction valueRequired based on model type\u200bprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200btimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timeprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models rankColumn name for rank of each element on the its group or listRequired for ranking models relevance_labelColumn name for ranking actual or ground truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresColumn name for features. Features must be sent in the same file as predictionsOptional. Arize automatically infers columns as features if they are not specified. Choose between: Inferred featuresFeature prefixing (label features in your table)Listing features (list feature column names in the Arize UI)tagsColumn name for tags. Tags must be sent in the same file as predictions and featuresOptional. Choose between: Tag prefixing (label tags in your table) Listing tags (list tag column names in the Arize UI)  shap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data within a column, or configure your version within the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalOnce finished, Arize will begin querying your table and ingesting your records as model inferences.Step 6 - Add Model Data To The TableArize will run queries to ingest records from your table based on your configured refresh interval.Step 7 - Check Table Import Job StatusArize will attempt a dry run to validate your job for any access, schema, or record-level errors. If the dry run is successful, you can proceed to create the import job. Successful import job summaryFrom there, you will be taken to the 'Job Status' tab. where you can see the status of your import jobs. All active jobs will regularly sync new data from your data source with Arize. You can view the job details by clicking on the job ID, which reveals more information about the job.Job Status tab showing job listingsTo pause or edit your table schema, click on 'Job Options'.Delete a job if it is no longer needed or if you made an error connecting to the wrong bucket. This will set your job status as 'deleted' in Arize. Pause a job if you have a set cadence to update your table. This way, you can 'start job' when you know there will be new data to reduce", "start_char_idx": 0, "end_char_idx": 8006, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "506faca4-8611-47fc-96ec-c143e8116c10": {"__data__": {"id_": "506faca4-8611-47fc-96ec-c143e8116c10", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1f7d1fef-9184-4c27-aa28-f1eead203125", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "hash": "facf69694889b2df31dd0a18404e3dbaf914aebfcb2bc853daeb7cc3d580d734"}, "2": {"node_id": "426818ff-842f-48fd-86f2-be8a7c65de23", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}, "hash": "36e5ddfc0758b58455a484b68bbece444cf4482a0260b221124a5df7b2948b58"}}, "hash": "4f7723b71f5c185f45d343c8cb2e03d2ca368349dd99122c117a70aef5c400fc", "text": "query costs. This will set your job status as 'inactive' in Arize. Step 8 - Troubleshooting An Import JobAn import job may run into a few problems. Use the dry run and job details UI to troubleshoot and quickly resolve data ingestion issues. Validation ErrorsIf there is an error validating a file or table against the model schema, Arize will surface an actionable error message. From there, click on the 'Fix Schema' button to adjust your model schema. Dry Run File/Table Passes But The Job Fails If your dry run is successful, but your job fails, click on the job ID to view the job details. This uncovers job details such as information about the file path or query id, the last import job, potential errors, and error locations. Once you've identified the job failure point, append the edited row to the end of your table with an updated change_timestamp value. Sending Data Methods - PreviousDatabricksNext - Model TypesLarge Language Models (LLM)Last modified 4d agoOn this pageStep 1 - Start the Data Upload WizardStep 2 - Warehouse Onetime Setup Step 3 - Specify Snowflake Table ConfigurationStep 4 - Configure Table PermissionsStep 5 - Configure Your Model And Define Your Table\u2019s SchemaStep 6 - Add Model Data To The TableStep 7 - Check Table Import Job StatusStep 8 - Troubleshooting An Import JobSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8007, "end_char_idx": 9540, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "46c33a9c-947a-4f2d-b5e6-40c66dbc1a78": {"__data__": {"id_": "46c33a9c-947a-4f2d-b5e6-40c66dbc1a78", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "22e775c4-5bfc-4534-9a98-5e70cc9220ed", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop"}, "hash": "406206058a3a9dd20c275fa8900f86d9c096459719334bc7d96d7e2135ce04d7"}}, "hash": "63243e74cf8bdf26e49e2561fb93d530c089e2525a04f092efbd7251a3369c86", "text": "UI Drag & Drop - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropUI Drag & Drop FAQGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookUI Drag & DropDrag & Drop a file through the Arize UISupported File TypesArize supports CSV, Parquet, and Avro. The required model schema parameters vary based on the specific model type selected. Learn more about model types here.embeddings_features are available for Parquet and Avro files.How To Upload A Local FileUploading a local file is as simple as dropping a file into the upload container and can be broken down into a few easy steps.Go to the 'Upload Data' page from the left-side navigation and click on Local FilesSelect \"Local Files\" from Upload Data PageYou can get started by choosing the model type and downloading a sample file. \u200bRegression Model Sample File Download\u200b\u200bScore Model Sample File Download\u200bUpload a file from your desktop by either:Dragging the file into the upload containerClicking 'Select File'Drag file or click \"Select File\"Fill out model schema fields using this schema referenceFill out model schemaValidate your file; errors will be displayed on this pageValidate file'Start Job' to create a file import job for your local file You\u2019ll be taken to the Job Status tab to see your local file uploadsSuccessful local file importGo to Job Status Tab to see your local file uploadsJob Status of All Local File importsLocal File Upload Model SchemaModel schema parameters are a way of organizing model inference data to ingest to Arize. When configuring your schema, be sure to match your file column headers with the model schema. Use a form or a simple JSON-based schema to specify the column mapping.  Example Rowprediction_idprediction_tsuser_idfeature/metropolitan_areaindustryprediction_scoreactual_scoreprediction_labelactual_labeltag/zone1fcd50f46891637538845822561PAengineering0.077736960No ClaimsNo Claimsus-east-1Example Schema{  \"prediction_id\": \"prediction_id\",  \"timestamp\": \"prediction_ts\",  \"features\": \"feature/\", #with explicit features (must pick explicit or implicit)   \"prediction_score\": \"prediction_score\",  \"prediction_label\": \"prediction_label\",  \"actual_score\": \"actual_score\",  \"actual_label\": \"actual_label\",  \"tags\": \"tag/\",  \"shap_values\": \"shap/\",  \"exclude\": [\"user_id\"]}Schema ParametersRefer here for a list of the expected data types by file type. PropertyDescriptionRequiredprediction_IDThe unique identifier of a specific predictionRequiredtimestampThe timestamp of the prediction in seconds or an RFC3339 timestampOptional, defaults to current timestamp at file ingestion timeprediction_labelColumn name for the prediction valueRequiredprediction_scoreColumn name for the predicted score Required based on model type\u200bactual_labelColumn name for the actual or ground truth valueOptional for production recordsactual_scoreColumn name for the ground truth scoreRequired based on model type\u200bprediction_group_idColumn name for ranking groups or lists in ranking modelsRequired for ranking models rankColumn name for rank of each element on the its group or listRequired for ranking models relevance_labelColumn name for ranking actual or gound truth valueRequired for ranking models relevance_scoreColumn name for ranking ground truth scoreRequired for ranking models featuresA string prefix to describe a column feature/. Features must be sent in the same file as predictionsArize automatically infers columns as features. Choose between feature prefixing OR inferred features.  tagsA string prefix to describe a column tag/. Tags must be sent in the same file as predictions and featuresOptionalshap_valuesA string prefix to describe a column shap/. SHAP must be sent in the same file as predictions or with a matching prediction_idOptionalversionA column to specify model version. version/ assigns a version to the corresponding data withina column, or configure your version witin the UIOptional, defaults to 'no_version' batch_idDistinguish different batches of data under the same model_id and model_version. Must be specified as a constant during job setup or in the schemaOptional for validation records onlyexcludeA list of columns to exclude if the features property is not included in the ingestion schema Optionalembedding_featuresA list of embedding columns, required vector column, optional raw data column, and optional link to data column. Learn more here\u200bOptionalWe currently support uploading one file at a time, and a maximum file size of 300 mb.To upload multiple files or larger files, use one of our data connectors.Sending Data Methods - PreviousPython Pandas SDKNextUI Drag & Drop FAQLast modified 12d agoOn this pageSupported File TypesHow To Upload A Local FileLocal File Upload Model SchemaSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6289, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "88a4aba9-e65a-4f0a-a745-b71d70129331": {"__data__": {"id_": "88a4aba9-e65a-4f0a-a745-b71d70129331", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/data-quality-troubleshooting"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8707c59d-9c11-4bdf-8e53-544c99186523", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/data-quality-troubleshooting"}, "hash": "3ac5d767663c5430baacf2f417dc2a2f0e8d5054cd5ef8d944ec37f416911324"}}, "hash": "a6a957358e2f16f23dece1a4abefbd4c232c74580995539f84abf98d1deb3991", "text": "Data Quality Troubleshooting - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookData Quality TroubleshootingTroubleshoot Data Quality IssuesML models rely on upstream data for training and making predictions. The data for these models is typically collected from multiple systems or vendors, or it may be owned by another team. This makes it challenging to ensure the data is always of high quality.Since poor-performing data results in poor-performing models, use data quality monitors to detect shifts in upstream data and alert underlying changes.How To Understand Data Quality MetricsData quality monitors typically inform various troubleshooting avenues, such as performance/drift tracing, and indicate problems along the model building and deployment pipeline.Common Root Causes Data quality metrics help inform various root cause issues. The most common causes of data quality issues in production are:  Vendor Data: Purchasing 3rd partyFeature Generation: Creating, transforming, extracting, selecting featuresData Pipelines: Data engineering and trainingLatency: Delayes in your data pipelineData Quality MetricCommon Root CauseCountAn increase in count indicates duplicate data and an issue with your data pipeline. A decrease in count typically indicates latency issues or a broken data pipelinePercent EmptyAn increase in the percent empty indicates either a data pipeline issue or a feature generation issue (i.e. you create a feature but it's null in production)CardinalityAn increase in missing values/new values indicates a need to change your feature generation process and typically indicates feature drift Statistical MetricsA change in statistical metrics indicates a change in the underlying data distribution To measure data consistency metrics, learn more here. PreviousData Distribution VisualizationNext - EmbeddingsGenerate EmbeddingsLast modified 1mo agoOn this pageTroubleshoot Data Quality IssuesHow To Understand Data Quality MetricsCommon Root Causes SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3606, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cd15e0f8-b286-4a6d-8546-23ba67a0bf6a": {"__data__": {"id_": "cd15e0f8-b286-4a6d-8546-23ba67a0bf6a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "3f6bae1f-ffec-4528-a7cc-dcbe19db39ab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing"}, "hash": "c1d5f767ede7c2d85b4364ae03c2acd6e49e914e73b8c25765964ca99fabf918"}}, "hash": "7105348310ec9afd377377f5002cee5182bb36aae9d20e249997ad8a5c730832", "text": "Drift Tracing - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Distribution VisualizationData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDrift TracingHow To Troubleshoot DriftOnce a drift monitor triggers alerting you that your model has drifted beyond your threshold value, troubleshoot the cause of your drift in the drift tab to begin troubleshooting. \u200bPrediction Drift \u200b\u200bFeature Drift \u200bChange Your Baseline\u200b\u200bDelayed Actuals\u200bPrediction DriftPrediction Drift refers to a change in the prediction distribution of your model. Drift is measured using a reference data set. You'll also see details of your baseline dataset that's used as a comparison. Begin troubleshooting by clicking on parts of your model that deviate from your threshold on the Prediction Drift curve. From there, uncover changes in your Distribution Comparison and Feature Drift in the cards below. Distribution Comparisons for values above and below the model baseline Feature DriftOnce you've identified problem areas in your model to investigate, narrow down on problematic areas to troubleshoot with the Feature Drift card under the Performance Drift Chart. Feature Drift refers to changes in your feature distribution. Since feature drift is very common in the real world, it can happen at any time while your model is in production, yet remain undetected. The Feature Drift card highlights the most impactful features degrading your model and uncovers granular drift information per feature. Click into each feature name to look at the feature drift over time chart and the feature's distribution comparison to easily identify missing values, problematic slices, and areas to improve.Pro Tip: Learn how to configure the visualization of a feature's distribution comparison here. Change Your BaselineYour baseline can help indicate why your model has drifted.  To detect drift over time, set your baseline using training data to identify how your model changes between your features, predictions, and actuals. To detect short-term drift, set your baseline using historical production data (i.e. 2 weeks).Production data against training data baseline: This drift indicates that the data used to build the model has shifted from the data now seen in production.Current production data against recent production data baseline:This drift indicates high variance in production data distributions, which could indicate model performance degradation, data quality issues, or noisy features.Delayed ActualsIt is common to receive delayed actuals (aka ground truth) for your production model. In this situation, use proxy metrics to evaluate model performance. The most common proxy metrics for model performance are:Feature DriftPrediction score/class distribution driftChange in prediction score/classMany model issues can be resolved by retraining your model with targeted training data uncovered in Arize troubleshooting workflows (such as identifying the culprit of drift)!Tracing - PreviousPerformance TracingNextData Distribution VisualizationLast modified 3mo agoOn this pageHow To Troubleshoot DriftPrediction DriftFeature DriftChange Your BaselineDelayed ActualsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4722, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d4c48173-1914-42a7-8345-bba575666846": {"__data__": {"id_": "d4c48173-1914-42a7-8345-bba575666846", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/performance-tracing"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e41f550f-90f2-414c-8604-1546b5ca187a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/performance-tracing"}, "hash": "c47a5812fd20bad06cba2b9817783a196c7fc2e8a644897c6235f02a1ddbbea6"}}, "hash": "aa2f96480ca5736c2fe68c1504306698aefd2698d6305c261ea204b0fbc43c2f", "text": "Performance Tracing - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPerformance TracingHow to Troubleshoot Performance MonitorsOnce a monitor triggers, alerting you that performance has dropped, troubleshoot your performance monitors in the Performance Tracing tab within your model. Performance tracing enables you to easily understand the features and slices that impact your model's performance the most and begin resolution.\u200bPerformance Over Time\u200b\u200bAdd A Comparison Dataset\u200b\u200bPerformance Breakdown (Slice View)\u200b\u200bData Validation and Exploration (Table View) \u200b\u200bCalibration Chart and Confusion Matrix (Output Segmentation View)\u200bPerformance Over TimeThe Performance Tracing tab immediately visualizes your performance metric over time layered on top of your model's prediction volume. This gives you a broad understanding of your model's overall performance to identify areas of improvement, compare different datasets, and examine problematic slices. The 'Performance Over Time' graph is highly configurable. Use this graph to visualize different dimensions such as: Environments: pick from production, validation, or training environmentsVersions: pick from any model version Time periods: zoom in or out on any time period for your dataset Performance metrics: choose from an array of performance metrics such as accuracy, AUC, MAE, MAPE, RMSE, sMAPE, WAPE, and more. Filters: layer additional filters across features, prediction values, actuals, and tags to see your model's performance on a more granular level. Add A Comparison DatasetSend data from different environments to compare model performance between training, validation, or a different time period within your production data. Comparing your production data helps you identify gaps in data quality or where drift occurs for simple troubleshooting.Navigate to the toolbar, click 'Add a Comparison' and pick from a different environment, version, or time period.Selecting Your ViewUsers have the choice of selecting between 3 troubleshooting views: Slice, Table, and Output Segmentation.\n\nSlice ViewPerformance BreakdownTo identify key areas to improve with your comparison dataset, break performance issues down using Performance Insights and our Performance Heat Map. Performance InsightsThe Performance Insights panel surfaces the worst-performing slices impacting your model to perform a counterfactual analysis. Use Performance Insights to exclude features or slices as a filter to identify how your model's performance changes. To do this, scroll down to the 'Performance Insights' card and click on a feature. Once you click into a feature, a histogram of your feature slices will populate on the left side with options to 'Add cohort as a filter', 'Exclude cohort as a filter', and 'View explainability'. A performance slice is a subset of model values formed from any model dimension, such as specific periods of time, set of features, etc. Learn more about slices here. Performance Heat MapThe performance heat map visualizes your feature's performance by slice view to visually indicate the worst-performing slices within each feature. Click on the carrot on the left side of your feature's name to uncover its histogram. Compare feature performance amongst different environments, versions, and filters to uncover areas of improvement. Look out for different colors and distributions between the two histograms to identify areas of missing or poor-performing data. Once you've identified an area of interest, click on the 'View Feature Details' link to uncover a detailed view of your feature distribution over time. Table ViewThe Table View enables users to see and interact with individual records in a simple table. Data Exploration and Validation: Get a better understanding of what your data looks like by exploring a record-level view. This is similar to a df.head within a notebook environment. Validate the data that was sent into the platform to make sure it was sent in the correct data format. Column Selector (coming soon):Explore any column in your data, including features and tags, using the column selector. Customize your table view by adding/removing columns, and re-ording columns.\u200b\u200bSlide Over (coming soon):Get a comprehensive view at the prediction level of all of the columns of your data for deeper analysis.Output Segmentation ViewConfusion MatrixA confusion matrix provides a summary of all prediction results of a classification problem. Each result is shown with its corresponding number of correct/incorrect predictions (True Positive, True Negative, False Positive, False Negative), count values and classification criteria. By providing a  summary of all possible results, the confusion matrix lets you know the ways your classification model could get confused when making the predictions. It helps identify errors and the type of errors made by the model and thus helps improve the accuracy of the classification model.Calibration ChartThis chart plots Average Actuals against Estimated Probability. The better calibrated the model, the closer the plotted points will be to the diagonal line.If the model points are below the line: your model has over-forecast in its prediction. For example, predicting a credit card charge has a high probability of fraud when it not fraudulent. If the model points are above the line: your model has an under-forecast in its prediction. For example, predicting a credit card charge has a low likelihood of being fraud when it's actually fraudulent. PreviousAirflow RetrainNext - TracingDrift TracingLast modified 10d agoOn this pageHow to Troubleshoot Performance MonitorsPerformance Over TimeAdd A Comparison DatasetSelecting Your ViewSlice ViewPerformance BreakdownTable ViewOutput Segmentation ViewSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 7371, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b77ab1fe-c816-4011-a1bc-c76e8e5676ea": {"__data__": {"id_": "b77ab1fe-c816-4011-a1bc-c76e8e5676ea", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "58f63029-0e23-4aec-acd3-f4da9263a8aa", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "hash": "802d03ab25e19c9fe3afbc49a6a3d7aa1f413ea50931b505dcbcfd2dc163391e"}, "3": {"node_id": "b91e0417-d273-4f27-8cd9-d2422a38a641", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "hash": "b3d6f3f38bfece3699bc6911e1c61a6a23a6f568794b3b9c2b4aa52e34e584be"}}, "hash": "695bd6c6e70fde5c0ce8b7827e949d141e62a737db26b0bb4727abf1772ad403", "text": "Custom Metric Examples - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCustom Metric ExamplesCommon example use casesExample Custom MetricsCustom metrics are an extremely powerful tool to evaluate many dimensions of your ML model. From analyzing the business impact of your model to calculating a moving average, you can leverage custom metrics in many ways. Use this page as a guide on how you can create custom metrics tailored to your ML needs. Business metricsThe following examples use the arize-demo-fraud-use-case model to calculate business KPIs and other useful statistics using custom metrics. Percent of Features With Value > XWe'll use this example to calculate the percentage of predictions with a fico score below 600. Assume that the lending model automatically rejects customers with scores below 600, so you want to track this metric to determine the health of inbound applications. We can do this by using a FILTER (WHERE ... ) clause, which allows us to apply the < 600 filter to only the numerator and not the denominator. SELECTCOUNT(*) FILTER (WHERE fico_score < 600) / COUNT(*) * 100FROM modelLearn more about FILTER (WHERE) clauses here.\u200bWeighted Average Performance MetricWeighted averages can be useful when different predictions are important to your business. To do this, we'll calculate recall but weigh the predictions by the loan amount. This way, a false negative on more expensive loans will have a higher impact on the score than a false negative on a cheaper loan. We can use a WHERE clause to filter for the actual fraud cases, and a FILTER (WHERE ... ) clause to filter the numerator where the model incorrectly predicted not_fraud . SELECT\u200bSUM(loan_amount) FILTER (WHERE categoricalPredictionLabel = 'fraud') / SUM(loan_amount) \u200bFROM modelWHERE categoricalActualLabel = 'fraud'Count DistinctYou can use APPROX_COUNT_DISTINCT to get the cardinality of a dimension. In this example, we can calculate the average total loan amount per merchant. SELECT \u200bSUM(loan_amount) / APPROX_COUNT_DISTINCT(merchant_ID)\u200bFROM modelLearn more about APPROX_COUNT_DISTINCT and other aggregation functions here.\u200bPerformance metricsUse natively supported performance metrics as a function that can take multiple arguments for enhanced performance monitoring flexibility. Additionally, create completely new metrics using conditionals and other logic shown below.View the documentation for our performance metrics here.\u200bPrecisionPRECISION ()When a model has multiple predictions that are sent as features or tags, the PRECISION function allows you to specify the exact columns used. In this example, a user may have a model with multiple predictions, each one sent in as a tag or feature. The PRECISION() function allows you to specify different columns to use for predictions or actuals, using the predicted and actual keyword arguments:SELECTPRECISION(    predicted=multi_output_prediction,     actual=multi_output_actual,     pos_class='custom_positive_class')FROM modelLearn more about PRECISION and related functions here.\u200bChoosing a different threshold for classification metricsBy combining classification metrics with case statements, users can use a different classification threshold than the currently ingested data. To do this, you can use the predicted argument of the metric function. This expects the prediction label, which you can conditionally set using a CASE statement. This works for all classification metrics with the predicted argument. SELECTPRECISION(    predicted=(CASE WHEN scorePredictionLabel > 0.25 THEN 'fraud' ELSE 'not_fraud' END),    pos_class='fraud')FROM modelF BetaF1 score is a special case of F beta, where precision and recall are equally weighted. In some use cases, you may prefer to weigh precision more than recall, or vice versa, based on business needs. The F_BETA function allows you to specify the beta parameter to adjust this weighting. In this example, we want to weigh precision twice as much as recall, with a beta score of 0.5. SELECT F_BETA(beta=0.5)FROM modelLearn more about F_BETA and related functions here.\u200bPinball Loss FunctionCustom metrics can be used to create performance metrics such as pinball loss. Pinball loss is useful for quantile forecasts. An example could be a weather prediction, such as an 80% chance of 20 degrees or colder weather. Let y be the actuals and z be the prediction. \u03b1 is the quantile, in this case, 0.8 (for 80% chance). The formula for pinball loss is as such.L(y, z) = (y - z) * \u03b1       if y >= z        = (z - y) * (1 - \u03b1) if z > yThis is what pinball loss would look like for a numeric model. SELECTAVG( CASE  WHEN numericActualLabel >= numericPredictionLabel  THEN (numericActualLabel - numericPredictionLabel) * 0.8 ELSE (numericPredictionLabel - numericActualLabel) * (1 - 0.8) END)FROM modelCustom metrics are not just limited to predictions and actuals. For example, if multiple predictions at multiple quantiles are sent in as tags, such as a tag prediction_temp_p80 for the 80th percentile temperature prediction, pinball loss could look like this: SELECTAVG( CASE  WHEN numericActualLabel >= prediction_temp_p80  THEN (numericActualLabel - prediction_temp_p80) * 0.8 ELSE (numericActualLabel - prediction_temp_p80) * (1 - 0.8) END)FROM modelLearn more about CASE statements and other conditional structures here.\u200bData Consistency Data consistency measures the discrepancies between two datasets (i.e. online versus offline features). To compare the same set of features, we recommend sending in one dataset as feature values and the other dataset as tag values.For support with creating data consistency metrics, reach out to [email\u00a0protected] or message us on Slack here. Match RatePercent of unmatched feature values for a given column. SELECT COUNT(*) FILTER(WHERE (online_feature !=", "start_char_idx": 0, "end_char_idx": 7251, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b91e0417-d273-4f27-8cd9-d2422a38a641": {"__data__": {"id_": "b91e0417-d273-4f27-8cd9-d2422a38a641", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "58f63029-0e23-4aec-acd3-f4da9263a8aa", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "hash": "802d03ab25e19c9fe3afbc49a6a3d7aa1f413ea50931b505dcbcfd2dc163391e"}, "2": {"node_id": "b77ab1fe-c816-4011-a1bc-c76e8e5676ea", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}, "hash": "695bd6c6e70fde5c0ce8b7827e949d141e62a737db26b0bb4727abf1772ad403"}}, "hash": "b3d6f3f38bfece3699bc6911e1c61a6a23a6f568794b3b9c2b4aa52e34e584be", "text": "offline_feature)) / COUNT(*) * 100FROM modelAverage Residual ErrorThe average difference between two datasets for a given column.SELECT AVG(ABS(offline_feature - online_feature))FROM modelPreviousAll FunctionsNext - API ReferenceGraphQL APILast modified 1mo agoOn this pageExample Custom MetricsBusiness metricsPercent of Features With Value > XWeighted Average Performance MetricCount DistinctPerformance metricsPrecisionChoosing a different threshold for classification metricsF BetaPinball Loss FunctionData Consistency Match RateAverage Residual ErrorSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7252, "end_char_idx": 8031, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "42921c89-35d4-4e60-b682-f3080a99e76d": {"__data__": {"id_": "42921c89-35d4-4e60-b682-f3080a99e76d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2e67adf9-c949-4658-95f9-ab35036e1e7f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax"}, "hash": "0d498c5f63bda8144bdc3813e8a75608205c4437f9d478f6864883dd226a63b6"}}, "hash": "9dbd959229f1f78897f344c8fe1e7c8bb3b2f381cda3f070c5a7c87ddd432ecd", "text": "Custom Metric Syntax - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxConditionals and FiltersAll OperatorsAll FunctionsCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCustom Metric SyntaxBreakdown of the Arize Query LanguageCustom Metric Syntax OverviewCustom metrics use an Arize SQL-like query language. SELECT< AGG_FUNC | METRIC_FUNC >(exprs) [FILTER (WHERE exprs)] [CASE WHEN ...END ][ <OPERATOR> { < AGG_FUNC | ARIZE_METRIC >(exprs) | constant }]  \u2026 FROM model[WHERE (exprs) ]SELECTEvery query starts with a SELECT statement.FROMThe FROM statement should beFROM model, where model refers to the model that the custom metric was created under.ConstantsA constant can be a number or string. Strings use single quotes like this: 'this is a string'. Numbers can be floats or integers.Expressionsdimensionconstant[ dimension | constant | (exprs) ] <OPERATOR> [ dimension | constant | (exprs) ]An expression is a statement composed of simple math or boolean operators. An expression does not have an aggregation function within it. Expressions can include nested expressions, for example, A * (B + C). Expressions return the same number of rows as those that go into it.DimensionsA dimension is any feature, tag, prediction, or actual of a model. A dimension can either be of type string or of type numeric.TypeInvocationDescriptionFeaturefeature_name or \"feature name\"Features can be referenced directly or use double quotes. \u200bNote: if there are spaces in your feature name, you must use double quotes.Tagtag_name or \"tag name\"Tags can be referenced directly or use double quotes.\u200bNote: if there are spaces in your tag name, you must use double quotes.PredictioncategoricalPredictionLabel  scorePredictionLabel numericPredictionLabelFor scored categorical models, there is categoricalPredictionLabel and scorePredictionLabel\n\nFor numeric models, there is only numericPredictionLabelActualcategoricalActualLabel  scoreActualLabel numericActualLabelFor scored categorical models, there is categoricalActualLabel and scoreActualLabel\nFor numeric models, there is only numericActualLabelCommentsComments can be added to your query in one of two ways:Single line comment (shortcut is CMD + /)-- This is a single line commentMulti-line comments/* This * is a  * multiline comment */API Reference - PreviousCustom Metrics Query LanguageNextConditionals and FiltersLast modified 8mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4000, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1453a19b-f181-4aea-9971-bb0c42f8990e": {"__data__": {"id_": "1453a19b-f181-4aea-9971-bb0c42f8990e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-api-ui-visualization"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "924a6a3d-85a9-47fd-a3f9-1d719c04ce2d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-api-ui-visualization"}, "hash": "96b354422c0bdd3d3d216c1fe39946ebe4a87f0a33bcab4b1990d66641198f57"}}, "hash": "2b39ad3a11dfff981ca55d7a635b228e93baf9d361d3fa47a79027183c2e93e3", "text": "Data API - UI Visualization - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData APIPython referenceDashboard and Widget APIData API - UI Visualization\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookData API - UI VisualizationThese define APIs to get data out of the system into another platforms User InterfaceThis feature is currently not generally available and is in development with select design partners. Get Widget DataThis API call gets the data for a widget. The widget setup functions define the dimension (feature, prediction or actual). This call returns formatted data to be used in a User Interface gethttps://api.arize.com/v1/reporting/get-widget-dataGet Widget Data\u200bcurl --request POST 'https://api.arize.com/v1/reporting/created-dashboard' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"end_time\":\"2021-08-25T03:23:28.132Z\",              //Required   \"start_time\":\"2021-08-25T03:23:28.017Z\",            //Required   \"widget_id\":\"widget-1\"                              //Required   \"y_scale\":\"linear\"                                  //Optional   \"x_scale\":\"day\"                                     //Optional}Get Dashboard EmbedThis function returns an embed code to generate the dashboard page visualization in a 3rd party service. Example Embed code:<iframe src=\"https://app.arize.com/graph/embed?token=<EMBED_TOKEN>&height=800&width=1024&legend=false\" width=\"800\" height=\"1024\" frameBorder=\"0\"></iframe>gethttps://api.arize.com/v1/reporting/get-dashboard-embedGet Dashboard Embed\u200bcurl --request POST 'https://api.arize.com/v1/reporting/created-dashboard' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"height\":800,                                       //Optional   \"width\":1024,                                       //Optional   \"dashboard_id\":\"dash-1\"                             //Required}Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousDashboard and Widget APINext - On-Premise DeploymentOverviewLast modified 7mo agoOn this pageGet Widget DatagetGet Widget DataGet Dashboard EmbedgetGet Dashboard EmbedSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3655, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7bf5cbfd-13fd-4bce-b117-91e335ded852": {"__data__": {"id_": "7bf5cbfd-13fd-4bce-b117-91e335ded852", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c6b05237-0399-4108-b9c0-20271f73a8c9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "hash": "f5a4dc636f84389c7f87b591b8e9683af54449daf4f5c20930e54e1fe6d5f11c"}, "3": {"node_id": "e7223684-a1d0-4a6e-846b-da6fe07be03b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "hash": "caf9b4710d46533e5f3c3bbf2f9bab62e7aa2fe26ddfacac4683946671d678e2"}}, "hash": "89aeaa98557138d48248dd3da95188d37e6e35c47ec1a672965cba2cb7d77a56", "text": "Dashboard and Widget API - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData APIPython referenceDashboard and Widget APIData API - UI Visualization\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDashboard and Widget APIArize AI for Model Monitoring, Troubleshooting, and ExplainabilityThis feature is currently not generally available and is in development with select design partners. This API enables you to create dashboards and widgets that can be visualized in 3rd party platforms.Create DashboardCreate a new dashboard in a space for viewing model data. Note: This query will only return custom created or cloned dashboards. This query will not return preset dashboards.posthttps://api.arize.com/v1/reporting/create-dashboardCreate Dashboard\u200bcurl --request POST 'https://api.arize.com/v1/reporting/created-dashboard' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"name\":\"dashboard_name\",                          //Required   \"space_id\":\"internal_space_name\",                 //Required}'This method creates a dashboard in an account. The dashboard can be used to create widgets for data visualization and data export.  Publish WidgetThis method publishes/adds an already created widget to an already created Dashboard  posthttps://api.arize.com/v1/reporting/publish-widgetPublish Widgetcurl --request POST 'https://api.arize.com/v1/reporting/created-dashboard' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"widget_ids\":[\"widget-id-1\"],                          //Required   \"dashboard_ids\":\"dashboard-id-1\"                     //Required}'This method takes an array of widget ID's (strings) and then connects the widget to the dashboard.Create Timeseries WidgetThis method creates a timeseries widget that can be performance based or based on data metrics.posthttps://api.arize.com/v1/reporting/create-timeseries-widgetCreate Timeseries Widget\u200bcurl --request POST 'https://api.arize.com/v1/reporting/created-timeseries-widget' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"metric_type\": \"EvaluationMetric\",                  //Required   \"dashboard_ids\":\"dashboard-id-1\"                     //Optional   \"grid_position\": [1,5,4,7],                          //Optional   \"title\" : \"Hello World\"                              //Optional}'This API is designed to allow teams to create a widget object in the platform and attach it to a Dashboard. The widgets can also be created outside of a dashboard and attached to a dashboard at a later point.Update Timeseries Widgetposthttps://arize.api.com/v1/reporting/update-timeseries-widgetPlots object:ParameterDescriptionTypeRequiredmodel_idThe ID of the model to plotstringRequiredmodel_version_idsThe version IDs of the model to plotstringOptionaldimension_metricThe name of the dimension to plot for data metrics, not used for evaluation metrics. Feature, prediction or actualstringOptionalevaluation_metricThe evaluation metric. Supported values: \"accuracy\", \"precision\", \"recall\", \"f1\", \"sensitivity\", \"specificity\", \"false_positive_rate\", \"false_negativerate\", \"AUC\", \"log_loss\", \"mae\", \"mape\", \"rmse\", \"mse\"stringOptionalfiltersFilters object to apply to widget* (ask Arize team for latest filter query examples) dict/objOptionalaggregationThe aggregation type for data metrics: \"average\", \"percent\", \"count\", \"unique\", \"std', \"min\", \"max\"stringRequired\u200bcurl --request POST 'https://api.arize.com/v1/reporting/update-timeseries-widget' \\--header 'Authorization: API_KEY' \\--data-raw '{   \"metric_type\": \"EvaluationMetric\",                  //Required   \"dashboard_ids\":\"dashboard-id-1\"                     //Optional   \"grid_position\": [1,5,4,7],                          //Optional   \"title\" : \"Hello World\"                              //Optional   \"plots\" : {         \"model_id\" : \"model-1\"                         //Required         \"model_version_ids\" : []                       //Optional         \"dimension_metric\" : null                      //Optional         \"evaluation_metric\" : \"accuracy\"               //Optional         \"filters\" : null                               //Optional         \"model_version_ids\" : [\"v1\"]                   //Optional         \"aggregation\" : null .                         //Optional   }}'The update time series API is designed to allow teams to set the data visualization calculations and options of widgets on dashboards. Questions? Email us at", "start_char_idx": 0, "end_char_idx": 5710, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e7223684-a1d0-4a6e-846b-da6fe07be03b": {"__data__": {"id_": "e7223684-a1d0-4a6e-846b-da6fe07be03b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c6b05237-0399-4108-b9c0-20271f73a8c9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "hash": "f5a4dc636f84389c7f87b591b8e9683af54449daf4f5c20930e54e1fe6d5f11c"}, "2": {"node_id": "7bf5cbfd-13fd-4bce-b117-91e335ded852", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}, "hash": "89aeaa98557138d48248dd3da95188d37e6e35c47ec1a672965cba2cb7d77a56"}}, "hash": "caf9b4710d46533e5f3c3bbf2f9bab62e7aa2fe26ddfacac4683946671d678e2", "text": "[email\u00a0protected] or Slack us in the #arize-support channelPreviousPython referenceNextData API - UI VisualizationLast modified 7mo agoOn this pageCreate DashboardpostCreate DashboardPublish WidgetpostPublish WidgetCreate Timeseries WidgetpostCreate Timeseries WidgetUpdate Timeseries WidgetpostSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 5711, "end_char_idx": 6230, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "10033e50-a69d-4517-bc9e-929425aaf98b": {"__data__": {"id_": "10033e50-a69d-4517-bc9e-929425aaf98b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "049b9932-b473-4cf1-a30a-392e71674d94", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "hash": "c158e55516d514df9a08c837733e953e41af08f2ccb5eea95891e3b3d3e04ac3"}, "3": {"node_id": "349b62d6-58a9-4454-bb28-aafb500ea2d8", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "hash": "5ccfe8e137223da35836547796ab9d4e35487e6a863bc2667e7fb5729d623125"}}, "hash": "179d1745e95fd02bceca88bbef046263406adf740109a13d9f7813b2b3de93fe", "text": "Python reference - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData APIPython referenceDashboard and Widget APIData API - UI Visualization\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPython referenceclass ArizeExportClient\u200b\u200bView Source on Github\u200bThe ArizeExportClient class encapsulates the required connection parameters for the Arize exporter. Note that the ArizeExportClient is available with the Arize SDK >= 7.0.3. You can install this with pip install arize >= 7.0.3The ArizeExportClient requires an Arize API key. You can get this one of two ways:1.Use the export functionality on our Embeddings, Performance Tracing, or Datasets tabs to generate a code snippet. Copying the code snippet will copy your API key as well. Take a look here for more details.2.Get the API key from the GraphQL explorer. Follow these instructions here.Once you have the API key - you can initialize the client. The client reads the key from one of two places. As an environment variableAs an constructor argumentBy default, the ArizeExportClient looks for the API key from an environment variable called ARIZE_API_KEY.import osfrom arize.exporter import ArizeExportClient\u200b# Make sure to do this before initializing the clientos.environ['ARIZE_API_KEY'] = <ARIZE_API_KEY>\u200bclient = ArizeExportClient()You can also initialize the ArizeExportClient with the key as one of the arguments:from arize.exporter import ArizeExportClient\u200bclient = ArizeExportClient(api_key=<ARIZE_API_KEY>)ReferenceArgumentTypeDescriptionapi_keyOptional[str]Arize provided personal API key associated with your user profile, located on the API Explorer page. API key is required to initiate a new client, it can be passed in explicitly, or set up as an environment variable or in profile file.hostOptional[str]URI endpoint host to send your export request to Arize AI. Defaults to https://flight.arize.comportOptional[int]URI endpoint port to send your export request to Arize AI. Defaults to 443.\u200b#export_model_to_df\u200b\u200bView Source on Github\u200bThis method is invoke on an instance of ArizeExportClient and is the primary method for exporting data from Arize to a Pandas DataFrame. To use this method, you first need to get your space id and your model id. Space id:The easiest way to get your space id is to get it from the URL when you visit the Arize platform. If your url is this: https://app.arize.com/organizations/.../spaces/U3BhY2U6NzU0Your space id is the series of numbers and letters right after /spaces/. In this case, my space id is U3BhY2U6NzU0Model id:Your model id is the same as the display name of your model. For example, for our demo fraud model, the model id is arize-demo-fraud-use-case.Code examples:Production dataProduction with ground truthTraining or validationfrom arize.exporter import ArizeExportClientfrom arize.utils.types import Environments\u200bclient = ArizeExportClient()\u200bdf = client.export_model_to_df(    space_id='U3BhY2U6NzU0',    model_id='arize-demo-fraud-use-case',    environment=Environments.PRODUCTION,    start_time=datetime.fromisoformat('2022-05-04T01:10:26.249+00:00'),    end_time=datetime.fromisoformat('2022-05-04T01:10:27.249+00:00'),)\u200bBy default, actuals are not included in the exporter. In order to include ground truth, include the include_actuals argument:from arize.exporter import ArizeExportClientfrom arize.utils.types import Environments\u200bclient = ArizeExportClient()\u200bdf = client.export_model_to_df(    space_id='U3BhY2U6NzU0',    model_id='arize-demo-fraud-use-case',    environment=Environments.PRODUCTION,    include_actuals=True,    start_time=datetime.fromisoformat('2022-05-04T01:10:26.249+00:00'),    end_time=datetime.fromisoformat('2022-05-04T01:10:27.249+00:00'),)Export of pre-production data is supported as well. To get pre-production data, set the environment to either Environments.TRAINING or Environments.VALIDATION. Optionally include the model_version and/or batch_id to further refine your export. from arize.exporter import ArizeExportClientfrom arize.utils.types import Environments\u200bclient = ArizeExportClient()\u200bdf = client.export_model_to_df(    space_id='U3BhY2U6NzU0',    model_id='arize-demo-fraud-use-case',    environment=Environments.TRAINING,    include_actuals=True,    start_time=datetime.fromisoformat('2022-05-04T01:10:26.249+00:00'),    end_time=datetime.fromisoformat('2022-05-04T01:10:27.249+00:00'),    model_version='v1',    batch_id='test',\u200b)Reference:ArgumentTypeDescriptionspace_idstrThe id for the space where to export models from, can be retrieved from the url of the Space Overview page in the Arize UI.model_idstrThe name of the model to export, can be found in the Model Overview tab in the Arize UI.environmentEnvironmentThe environment for the model to export (can be Production, Training, or Validation). Needs to be of the Environments enum in utils.types.start_timedatetimeThe start time for the data to export for the model, start time is inclusive. Time interval has hourly granularity. Must be a python datetime object.end_timedatetimeThe end time for the data to export for the model, end time is not inclusive. Time interval has hourly granularity. Must a python datetime object.include_actualsOptional[bool] An optional input to indicate whether to include actuals / ground truth in the data to export. include_actuals only applies to the Production environment and defaults to False.model_versionOptional[str]An optional input to indicate the version of the model to", "start_char_idx": 0, "end_char_idx": 6791, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "349b62d6-58a9-4454-bb28-aafb500ea2d8": {"__data__": {"id_": "349b62d6-58a9-4454-bb28-aafb500ea2d8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "049b9932-b473-4cf1-a30a-392e71674d94", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "hash": "c158e55516d514df9a08c837733e953e41af08f2ccb5eea95891e3b3d3e04ac3"}, "2": {"node_id": "10033e50-a69d-4517-bc9e-929425aaf98b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}, "hash": "179d1745e95fd02bceca88bbef046263406adf740109a13d9f7813b2b3de93fe"}}, "hash": "5ccfe8e137223da35836547796ab9d4e35487e6a863bc2667e7fb5729d623125", "text": "export. Model versions for all model environments can be found in the Datasets tab on the model page in the Arize UI.batch_idOptional[str]An optional input to indicate the batch name of the model to export. Batches only apply to the Validation environment, and can be found in the Datasets tab on the model page in the Arize UI.API Reference - PreviousData APINextDashboard and Widget APILast modified 1mo agoOn this pageclass ArizeExportClientReference#export_model_to_dfReference:SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6792, "end_char_idx": 7498, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3b87de7a-0e1d-4d5f-a840-813b70d29f14": {"__data__": {"id_": "3b87de7a-0e1d-4d5f-a840-813b70d29f14", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/client"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d830eb6a-d70b-4ff8-ae6a-4f7935c1c729", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/client"}, "hash": "044428f08880099faced1c87665f8082fd1752d0e050b4fbdff8ed0305721778"}}, "hash": "6cf92908084078a2cfc813adcae8113fc03262d3cba4fb3fcdf447ae9edeac0d", "text": "Client - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookClient\u200b\u200bView source on Github\u200bArize class to begin logging predictions and actuals.Import and initialize Arize Client from arize.apifrom arize.api import Clientclass Client(    api_key: str,    space_key: str,    uri: Optional[str] = \"https://api.arize.com/v1\",    max_workers: Optional[int] = 8,    max_queue_bound: Optional[int] = 5000)ArgumentData TypeDescriptionapi_keystr(Required) Arize-provided api key associated with your service/space. Click \"Show API Key\" in the \"Upload Data\" page to copy the key.space_keystr(Required) Arize-provided identifier for relating records to spaces. Click \"Show API Key\" in the \"Upload Data\" page to copy the key.\n*If using version < 4.0.0, replace space_key=SPACE_KEY with organization_key=SPACE_KEYuristr(Optional) URI endpoint required for on-prem customers. Defaults to \"https://api.arize.com/v1\"max_workersint(Optional) Number of max concurrent requests to Arize. Default value = 8max_queue_boundint(Optional) Number of maximum concurrent future objects queued for publishing to Arize. Default value = 5000Code Examplefrom arize.api import Clientfrom arize.utils.types import ModelTypes, Environments, Embedding\u200b\u200bAPI_KEY = 'ARIZE_API_KEY'SPACE_KEY = 'YOUR SPACE KEY'arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200bif SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\": raise ValueError(\"\u274c CHANGE SPACE AND API KEYS\")else: print(\"\u2705 Arize client setup done! Now you can start using Arize!\")PreviousSingle Record LoggingNextlogLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3330, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "06684fbd-38cf-4812-a9b3-f9aa3324893f": {"__data__": {"id_": "06684fbd-38cf-4812-a9b3-f9aa3324893f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/embedding"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f790a3e9-7d0f-4252-a3c9-8734364f96f3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/embedding"}, "hash": "a31c55fe689787d4cf0ffd57f383f2b2ae86af9b5b7c2679571095cc47e696b6"}}, "hash": "da36f19d82debac400c0477017bd88dfaab45fecc2d624b9c24d139c896dcad2", "text": "Embedding - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbedding\u200b\u200bView source on Github\u200bArize class to map up to 3 columns (vector, data, and link_to_data) to a single embedding feature.class Embedding(    vector: List[float]    data: Optional[Union[str, List[str]]]    link_to_data: Optional[str])ParametersData TypeDescription vectorList[float](Required) Vector of a given embedding feature. The contents of this column must be List[float] or nd.array[float]datastr or List[str](Optional) Used for Natural Language Processing model type. Data of a given embedding feature, typically the raw text associated with the embedding vector.link_to_datastr(Optional) Used for Computer Vision model type. Link to data of a given embedding feature, typically a link to the data file (image, audio, ...) associated with the embedding vector. Host data in a cloud storage provider (GCS, AWS, Azure), local server, or public URL. Navigate here to view private AWS S3 image links. \n\nExample: \"https://link-to-my-image.png\"\nNOTE: Currently only supports links to image files.Code Examplefrom arize.utils.types import ModelTypes, Environments, Embedding\u200b# Example NLP embedding featuresembedding_features = { \"nlp_embedding\": Embedding(            vector=pd.Series([4.0, 5.0, 6.0, 7.0]),            data=\"This is a test sentence\", ),}\u200b# Example CV embedding featuresembedding_features = { \"image_embedding\": Embedding(            vector=np.array([1.0, 2, 3]),            link_to_data=\"https://link-to-my-image.png\", ),}PreviousObject DetectionNextutils.types.ModelTypesLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3354, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "222133ca-97a8-45fe-afb0-094a17fd8000": {"__data__": {"id_": "222133ca-97a8-45fe-afb0-094a17fd8000", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "304c1bae-1027-48b0-8529-67fef42010e9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/log"}, "hash": "96364022c8d99926743077408372040767fc1e82a8edf1f2ba4ab498ba416281"}}, "hash": "044bd918b002f3cf4349f77dc41388d87fa991b785034a70f1850d89c93ecee0", "text": "log - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBooklog\u200b\u200bView source on Github\u200bArize method to log model data record-by-record.log(     model_id: str,    model_type: ModelTypes,    environment: Environments,    model_version: Optional[str] = None,    prediction_id: Optional[Union[str, int, float]] = None,    prediction_timestamp: Optional[int] = None,    prediction_label: Union[str, bool, int, float, Tuple[str, float]] = None,    actual_label: Union[str, bool, int, float, Tuple[str, float]] = None,    features: Optional[Dict[str, Union[str, bool, float, int]]] = None,    embedding_features: Optional[Dict[str, Embedding]] = None,    shap_values: Dict[str, float] = None,    tags: Optional[Dict[str, Union[str, bool, float, int]]] = None,    batch_id: Optional[str] = None,    prompt: Optional[Embedding] = None,    response: Optional[Embedding] = None  )ParamaterData TypeDescriptionmodel_idstr(Required) A unique name to identify your model in the Arize platformmodel_type\u200barize.utils.types.ModelTypes\u200b(Required*) Declared what model type this prediction/actual is for\n*(as of v.5.X.X)environment\u200barize.utils.types.Environments\u200b(Required*) The environment that this prediction/actual is for (Production, Training, Validation) \n*(as of v.5.X.X)model_versionstr(Optional) Used to group together a subset of predictions and actuals for a given model_id. Defaults to no_versionprediction_idstr(Optional) A unique string to identify a prediction event.Important: This value matches a prediction to an actual label or feature importance (SHAP) in the Arize platform. If prediction_id is not provided, Arize will, when possible, create a random prediction id on the server side.prediction_timestampint(Optional) int representing Unix epoch time in seconds, set overwrite the timestamp for prediction.If None, default to log prediction using the current timestamp.Important: Future and Historical predictions are supported up to 1 year from current wall clock time.prediction_labelOne of str, bool, int, float, Tuple[str,float](Optional) The predicted value for a given model input.\n\n*Ingest ranking predictions as a ranking object \u200bactual_labelOne of str, bool, int, float, Tuple[str,float](Optional) The actual or ground truth value for a given model input. Important: This actual will be matched to the prediction with the same prediction_id as the one in this call even if they were logged in separate log calls.\n\n*Ingest ranking actuals as a ranking object\u200bfeatures[dict<str, [str, bool, float, int]>)](Optional) Dictionary containing human readable and debuggable model features.Keys must be of typestr. Values must be one of str, bool, float, int.embedding_features[dict<str, Embedding>] (Optional) Dictionary containing human readable and debuggable model embedding features. Keys must be str. Values must be Embedding objectshap_values[dict<str, float>](Optional) Dictionary containing human readable and debuggable model features keys, along with SHAP feature importance values. Keys must bestr,  Values must befloat.tags[dict<str, [str, bool, float, long]>](Optional) Dictionary containing human readable and debuggable meta data that can be added on a prediction ID. This can be used to filter analysis by non-feature data. Keys must bestr. Values must be one of str, bool, float, long.batch_idstr(Optional) Only applicable to Validation datasets. Used to distinguish different batch of data under the same model_id and model_version. prompt\u200bEmbedding\u200b(Required for Generative_LLM) Embedding object containing the embedding vector (required) and raw text (optional, but recommended) for the input text on which your GENERATIVE_LLM model acts on.response\u200bEmbedding\u200b(Required for Generative_LLM) Embedding object containing the embedding vector (required) and raw text (optional, but recommended) for the text GENERATIVE_LLM model generates.Code Examplefuture = arize_client.log(    prediction_id=record[\"prediction_id\"],    features=record[\"features\"],    prediction_label=record[\"predicted_label\"],    actual_label=record[\"actual_label\"],    model_id=\"binary-classification-metrics-only-single-record-ingestion-tutorial\",    model_type=ModelTypes.BINARY_CLASSIFICATION,    model_version=\"1.0.0\",    environment=Environments.PRODUCTION)\u200bresult = future.result()PreviousClientNextRankingLast modified 1mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6093, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5e834ad7-b773-4411-af47-2b4bcda0e6da": {"__data__": {"id_": "5e834ad7-b773-4411-af47-2b4bcda0e6da", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/objectdetection"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "180da81f-aabd-4790-aaab-35e7add82b3f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/objectdetection"}, "hash": "0b2031ea1153776745c9d3abcccb7e0bc5b24384eadb186c488bdb26131353e1"}}, "hash": "14ab7a5ce2ae2697997d133942014ad630d414ce2365e3bd9a69831e9c88314d", "text": "Object Detection - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookObject Detection\u200b\u200bView source on Github\u200bObjectDetectionLabelArize class to define the prediction and actual arguments associated with the Object Detection model typeclass ObjectDetectionLabel(    bounding_boxes_coordinates: List[List[float]]    categories: List[str]    scores: Optional[List[float]] = None)ArgumentData TypeDefinitionsbounding_box_coordinatesList[List[float]](Required) Field defining the coordinates of the rectangular outline that locates an object within an image or video. \n\nPascal VOC format required. categoriesList[str](Required) Field containing the predefined classes or labels used by the model to classify the detected objects.scoresList[float](Optional*) Field containing the confidence scores that the model assigns to its predictions, indicating how certain the model is that the predicted class is contained within the bounding box.\n\n* This parameter is not applicable to actual (ground truth) labels and is only applicable when defining prediction_labelCode Examplefrom arize.utils.types import Environments, ModelTypes, Schema, ObjectDetectionLabel\u200bobject_detection_prediction = ObjectDetectionLabel(    bounding_boxes_coordinates: [[147.5, 98.0, 169.67, 276.69], [114.19, 108.4...]]    categories: ['chair', 'chair', 'bed', 'dining table', 'chair']    scores: [0.90, 0.97, 0.98, 0.96, 0.96, 0.92, ...])\u200bobject_detection_actual = ObjectDetectionLabel(    bounding_boxes_coordinates: [[437.51, 366.37, 529.0, 480.97], [0.0, 302.24...]]    categories: ['dining table', 'bed', 'chair', 'chair'])\u200bresponse = arize.log(    model_id=\"demo-object-detection-single-log\",    model_version=\"v1\",    environment=Environments.PRODUCTION,    model_type=ModelTypes.OBJECT_DETECTION,    prediction_id=\"123\",    prediction_label=object_detection_prediction,    actual_label=object_detection_actual)PreviousRankingNextEmbeddingLast modified 21d agoOn this pageObjectDetectionLabelCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3749, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8f46c265-5c52-4b2d-9c5e-0ff8c31f9987": {"__data__": {"id_": "8f46c265-5c52-4b2d-9c5e-0ff8c31f9987", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/ranking"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0c39c442-7084-4d4c-b256-5b1a14cbbda9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/ranking"}, "hash": "2f90334992b09d5db9e3942a0939a180b85c769d6f7e3724cfc567f492f22f81"}}, "hash": "d17baff77185eef976c614ddc2df35e606c619807e462c7bf4928d3bced7bcb9", "text": "Ranking - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRanking\u200b\u200bView source on Github\u200bRankingPredictionLabelArize class to define the prediction arguments associated with the ranking model typeclass RankingPredictionLabel(    group_id: str # required    rank: int # required    score: Optional[float]    label: Optional[str])ArgumentData TypeDefinitionsgroup_idstr(Required) Name for ranking groups or lists in ranking modelsrankint(Required) Name for rank of each element on the its group or list. The content of this column must be integer between 1-100.scorefloat(Optional) Numeric prediction scorelabelstr(Optional) Categorical prediction score RankingActualLabelArize class to define the ground truth arguments associated with the ranking model typeclass RankingActualLabel(    relevance_labels: Optional[List[str]]    relevance_score: Optional[float])ArgumentData TypeDescriptionrelevance_labelsList[str](Optional) Categorical ground truth scorerelevance_scorefloat(Optional) Numeric Ground truth scoreCode Examplefrom arize.utils.types import Environments, ModelTypes, Schema, RankingPredictionLabel, RankingActualLabel\u200bpred_label = RankingPredictionLabel(    group_id=\"A\",    rank=1,    score=1.0,    label=\"click\",)\u200bact_label = RankingActualLabel(    relevance_labels=[\"click\", \"save\"],    relevance_score=0.5,)\u200bresponse = arize.log(    model_id=\"demo-ranking-single-log\",    model_version=\"v1\",    environment=Environments.PRODUCTION,    model_type=ModelTypes.RANKING,    prediction_id=\"123\",    prediction_label=pred_label,    actual_label=act_label,    features=features,)PreviouslogNextObject DetectionLast modified 4mo agoOn this pageRankingPredictionLabelRankingActualLabelCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3476, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "eb23ec53-58fd-41c8-b88e-b1637841ffa7": {"__data__": {"id_": "eb23ec53-58fd-41c8-b88e-b1637841ffa7", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.environments"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d4c7b444-9e97-445a-a5da-ea6a5252076d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.environments"}, "hash": "2f57e58ca2fee77cd7773210389596eb59740513b7249cc10bb61b5f7e323fa3"}}, "hash": "185433976081fcc277ca569c4be0004e499ea6b99ca012443ba1470eafcfec0b", "text": "utils.types.Environments - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.Environments\u200b\u200bView source on Github\u200bArize enum to specify your model environment represented in the platform for further analysis and comparisonsEnvironmentSDK EnvironmentDescription TrainingEnvironments.TRAININGAn environment used to develop and train ML models (data prep, data processing, and model tuning)ValidationEnvironments.VALIDATIONAn environment used to evaluate and fine-tune ML models before deployment (testing performance separate from training data)ProductionEnvironments.PRODUCTIONAn environment to deploy ML models and serve predictionsCode Exampleresponse = arize_client.log(    model_id='sample-training-model',  ...    environment=Environments.TRAINING)\u200bresponse = arize_client.log(    model_id='sample-validation-model',  ...    environment=Environments.VALIDATION)\u200bresponse = arize_client.log(    model_id='sample-production-model',  ...    environment=Environments.PRODUCTION)Previousutils.types.MetricsNext - API ReferenceJava SDKLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2836, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f2af5035-6e7f-4660-aaba-46cecdd64c57": {"__data__": {"id_": "f2af5035-6e7f-4660-aaba-46cecdd64c57", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.metrics"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5a010431-0dd5-4236-9df8-532d123c7884", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.metrics"}, "hash": "f8f70c48e80e53db371cd89389bf17b86d52b2aaae96e1f2ed80599fff25bda3"}}, "hash": "72b76485eb62584f61fe24b6d73ea26a0d1fe93ea50eaff5e43c4c4ec9fb491e", "text": "utils.types.Metrics - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.Metrics\u200b\u200bView source on Github\u200bArize enum for metrics grouping when validating a schema column in log() call.Use CaseSDK MetricMetricRegressionMetrics.REGRESSIONMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorClassificationMetrics.CLASSIFICATIONAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityRankingMetrics.RANKINGNDCGAUC & LogLossMetrics.AUC_LOG_LOSSAUC, PR-AUC, Log LossRanking LabelMetrics.RANKING_LABELGroupAUC, MAP, MRRMethodrepr()To view applicable metrics, pass in your desired SDK Metric from above.repr(Metrics.[SDK Metric])Code Exampleresponse = arize_client.log(    model_id='sample-binary-classification-model',  ...    metrics_validation=[Metrics.CLASSIFICATION]\u200b)\u200bresponse = arize_client.log(    model_id='sample-regression-model',  ...    metrics_validation=[Metrics.REGRESSION])\u200bresponse = arize_client.log(    model_id='sample-ranking-model',  ...    metrics_validation=[Metrics.RANKING, Metrics.RANKING_LABEL])Previousutils.types.ModelTypesNextutils.types.EnvironmentsLast modified 4mo agoOn this pageMethodCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "83d3ff59-b33d-4a5b-b915-ed11b87c1b88": {"__data__": {"id_": "83d3ff59-b33d-4a5b-b915-ed11b87c1b88", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.modeltypes"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5aa11672-2e24-4cb2-9969-bfb2216dcf8f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.modeltypes"}, "hash": "c10d4115edcbc8e4fe9401b467a57d9770959bd54629cd8a2b19ff5a1f12e01b"}}, "hash": "a6cb8c24a7107b6ac94ebaa90070fdbd17cc177501242b856282eee189dc11cc", "text": "utils.types.ModelTypes - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingSingle Record LoggingClientlogRankingObject DetectionEmbeddingutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.ModelTypes\u200b\u200bView source on Github\u200bArize enum to specify your model type represented in the platform and validate applicable performance metrics. Model Typesfrom arize.utils.types import ModelTypesSpecify a model_type when logging a prediction for the first time for a new model.Methodlist_types()View SourceReturns a list of all model types. ModelTypes.list_types()Use CaseSDK ModelTypeDescription\u200bRegression\u200bModelTypes.REGRESSIONRegression models predict continuous values\u200bBinary Classification\u200bModelType.BINARY_CLASSIFICATIONBinary classification models predict only two categorical values, typically represented as 0 or 1\u200bMulti Class\u200bModelType.SCORE_CATEGORICALMulticlass models predict multiple categorical values\u200bRanking \u200bModelType.RANKINGRanking models predict the relative ordering of a set of items based on their features\u0000\u0000\u200bNatural Language Processing (NLP)\u200bModelType.SCORE_CATEGORICALNLP models are categorical models specifically designed to work with text data and perform various tasks (i.e. sentiment analysis and language translation)\u200bComputer Vision (CV)\u200bModelType.SCORE_CATEGORICALCV models are categorical models specifically designed to work with visual data and perform various tasks (i.e. object detection and image classification)Code Exampleresponse = arize_client.log(    model_id='sample-binary-classification-model',  ...    model_type=ModelTypes.BINARY_CLASSIFICATION)\u200bresponse = arize_client.log(    model_id='sample-regression-model',  ...    model_type=ModelTypes.REGRESSION)\u200bresponse = arize_client.log(    model_id='sample-ranking-model',  ...    model_type=ModelTypes.RANKING)\u200bPreviousEmbeddingNextutils.types.MetricsLast modified 4mo agoOn this pageModel TypesCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3564, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "82043aab-ba90-4fa8-9c34-9b2d47ad7d7b": {"__data__": {"id_": "82043aab-ba90-4fa8-9c34-9b2d47ad7d7b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/autoembeddings"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c71f1a99-d486-4ef1-9dec-3f5eb711c8c2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/autoembeddings"}, "hash": "62a81f1df120c76929ff684ccc780116c462ef59a2501c7356c6e84ca73d01c0"}}, "hash": "19689388fd151b7a8ffcd576de5be9122f574a96c36c10d5466984ce36192485", "text": "AutoEmbeddings - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAutoEmbeddingsInstall extra dependencies to generate embedding vectors\u200b\u200bView Source on Github\u200bInstall extra dependencies in the SDK:pip install arize[AutoEmbeddings]The EmbeddingGenerator ClassArize class to generate embeddings data.Import and initialize EmbeddingGenerator from arize.pandas.embeddings:from arize.pandas.embeddings import EmbeddingGeneratorMethodsfrom_use_case\u200bView Source\u200bPass in use_case and more options depending on the use case.ArgumentDescriptionuse_caseUseCases.NLP.SEQUENCE_CLASSIFICATION or UseCases.NLP.SUMMARIZATION orUseCases.CV.IMAGE_CLASSIFICATION model_nameRefer to Supported Models\u200blist_pretrained_models\u200bView Source\u200bReturns updated table listing of supported models.EmbeddingGenerator.list_pretrained_models()Code Examplefrom arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200b# example CVgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.CV.IMAGE_CLASSIFICATION,    model_name=\"google/vit-base-patch16-224-in21k\",    batch_size=100)df[\"image_vector\"] = generator.generate_embeddings(    local_image_path_col=df[\"local_path\"])\u200b# example NLPgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.NLP.SEQUENCE_CLASSIFICATION,    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512,    batch_size=100)df[\"text_vector\"] = generator.generate_embeddings(text_col=df[\"text\"])PreviousLLM_EvaluationNextutils.types.ModelTypesLast modified 24m agoOn this pageThe EmbeddingGenerator ClassCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3362, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "60646944-c492-4115-a5c9-3d5c3bb60783": {"__data__": {"id_": "60646944-c492-4115-a5c9-3d5c3bb60783", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/client"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "76da110a-95ac-4aa5-a855-5bb719f045f7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/client"}, "hash": "dff31ce7b53e6876b7c7d6e5ed4fba0e3ead3b76bb1f723041a7c76f680362a8"}}, "hash": "7ae12607a78a3dc5080108a1e3dfce7180615f224faf554858caa114774f1848", "text": "Client - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookClient\u200b\u200bView Source on Github\u200bArize class to begin logging predictions and actuals from a Pandas.DataFrame. Import and initialize Arize Client from arize.pandas.logger from arize.pandas.logger import Clientclass Client(    api_key: str #from Arize platform    space_key: str     uri: Optional[str] = \"https://api.arize.com/v1\")ArgumentData TypeDescriptionapi_keystr(Required) Arize-provided api key associated with your service/space. Click \"Show API Key\" in the \"Upload Data\" page in the Arize UI to copy the key.space_keystr(Required) Arize-provided identifier for relating records to spaces. Click \"Show API Key\" in the \"Upload Data\" page in the Arize UI to copy the key.uristr(Optional) URI endpoint required for on-prem customers. Defaults to \"https://api.arize.com/v1\"Code Examplefrom arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments, Schema, Metricsimport pandas as pd\u200bSPACE_KEY = \"SPACE_KEY\" # update value here with your Space KeyAPI_KEY = \"API_KEY\" # update value here with your API key\u200barize_client = Client(space_key=SPACE_KEY, api_key=API_KEY)\u200bif SPACE_KEY == \"SPACE_KEY\" or API_KEY == \"API_KEY\": raise ValueError(\"\u274c NEED TO CHANGE SPACE AND/OR API_KEY\")else: print( \"\u2705 Import and Setup Arize Client Done! Now we can start using Arize!\" )PreviousPandas Batch LoggingNextlogLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3232, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e3b783d1-c8b2-4254-a1a2-230b860b6879": {"__data__": {"id_": "e3b783d1-c8b2-4254-a1a2-230b860b6879", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/embeddingcolumnnames"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ce597fae-849d-4561-ac33-f6f27fd1bfa2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/embeddingcolumnnames"}, "hash": "a5baeab4f2de0b5f6cf9224497b968524ed9934b42514a4c037f2278fc3c89e3"}}, "hash": "4195d75db4302beadefed8ca17a1741c2f1230748a768e8a73c7bece0a9e2433", "text": "EmbeddingColumnNames - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookEmbeddingColumnNames\u200b\u200bView source on Github\u200bArize class to map up to 3 columns (vector, data, and link_to_data) to a single embedding feature.class EmbeddingColumnNames(    vector_column_name: str    data_column_name: Optional[str] = None    link_to_data_column_name: Optional[str] = None)ParametersData TypeExpected Type In ColumnDescription vector_column_namestrThe contents of this column must be List[float] or nd.array[float].(Required)Column name for the vector of a given embedding feature. data_column_namestrThe contents of this column must be str or List[str].(Optional)Used for Natural Language Processing model type - Column name for the data of a given embedding feature, typically the raw text associated with the embedding vector. link_to_data_column_namestrThe contents of this column must be str.(Optional) Used for Computer Vision model type -Column name for the link to data of a given embedding feature, typically a link to the data file (image, audio, ...) associated with the embedding vector. Host data in a cloud storage provider (GCS, AWS, Azure), local server, or public URL. Navigate here to view private AWS S3 image links. \n\nExample URL: \"https://link-to-my-image.png\"\nNOTE: Currently only supports links to image files.Code Example# Declare embedding feature columnsembedding_feature_column_names = { # Dictionary keys will be the name of the embedding feature in the app \"embedding_display_name\": EmbeddingColumnNames(        vector_column_name=\"vector\", # column containing embedding vector (required)        data_column_name=\"text\", # column containing raw text (optional NLP)        link_to_data_column_name=\"image_link\" # column containing image URL links (optional CV) )}PreviousSchemaNextObjectDetectionColumnNamesLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3664, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9517a28a-a65c-4ea7-b58c-0628a7104b4d": {"__data__": {"id_": "9517a28a-a65c-4ea7-b58c-0628a7104b4d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "748bc204-476b-4074-a648-3d659e07b165", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "hash": "6214c02c98baebab65031b8e1bcddfba2302acbe2764879081d3cb8992792afa"}, "3": {"node_id": "df2b68f7-bf75-43a1-8c32-a4f3a543c4b4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "hash": "7b038ad480a7702630825e1f8df692c0532652db36efa436b6a0903dea75b715"}}, "hash": "632b982ef3736241565982b0c7c312e52ee922aa28d4bb2995974d298cf8f5df", "text": "LLM_Evaluation - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookLLM_EvaluationInstall extra dependencies to compute LLM evaluation metrics\u200b\u200bView Source on GitHub\u200bInstall extra dependencies in the SDK:!pip install arize[LLM_Evaluation] Import metrics from arize.pandas.generative.llm_evaluationMetricsbleu\u200bView Source\u200bBLEU score is typically used to evaluate the quality of machine-translated text from one natural language to another. BLEU calculates scores for individual translated segments, typically sentences, by comparing them to a set of high-quality reference translations. These scores are then averaged over the entire corpus to obtain an estimate of the overall quality of the translation.ArgumentExpected TypeDescriptionresponse_colpd.Series[Required] Pandas Series containing translations (as strings) to scorereferences_colpd.Series[Required] Pandas Series containing a reference, or list of several references, per predictionmax_orderint[Optional] Maximum n-gram order to use when computing BLEU score. Defaults to 4smoothbool[Optional] Whether or not to apply Lin et al. 2004 smoothing. Defaults to FalseCode Examplebleu_scores = bleu(    response_col=df['summary'],     references_col=df['reference_summary'],    max_order=5, # optional field    smooth=True # optional field )sacre_bleu\u200bView Source\u200bA hassle-free computation of shareable, comparable, and reproducible BLEU scores. Inspired by Rico Sennrich\u2019s multi-bleu-detok.perl, it produces the official Workshop on Machine Translation (WMT) scores but works with plain text.ArgumentExpected TypeDescriptionresponse_colpd.Series[Required] Pandas Series containing translations (as strings) to scorereferences_colpd.Series[Required] Pandas Series containing a reference, or list of several references, per prediction\n\nNote: There must be the same number of references for each prediction (i.e. all sub-lists must be of the same length)smooth_methodstr[Optional] The smoothing method to use, defaults to 'exp'. Possible values are: \n- 'none': no smoothing \n- 'floor': increment zero counts \n- 'add-k': increment num/denom by k for n>1 \n- 'exp': exponential decaysmooth_valuefloat[Optional] The smoothing value. Defaults to None\nsmooth_method='floor',  smooth_value defaults to 0.1\nsmooth_method='add-k', smooth_value defaults to 1lowercasebool[Optional] If True, lowercases the input, enabling case-insensitivity. Defaults to Falseforcebool[Optional] If True, insists that your tokenized input is actually de-tokenized. Defaults to Falseuse_effective_orderbool[Optional] If True, stops including n-gram orders for which precision is 0. This should be True, if sentence-level BLEU will be computed. Defaults to FalseCode Examplesacre_bleu_scores = sacre_bleu(    response_col=df['summary'],     references_col=df['reference_summary'],    smooth_method='floor', # optional field    smooth_value=0.1, # defaulted to 0.1 since smooth_method is 'floor'    lowercase=True # optional field )google_bleu\u200bView Source\u200bBLEU score is typically used as a corpus measure, and it has some limitations when applied to single sentences. To overcome this issue in RL experiments, there exists a variation called the GLEU score. The GLEU score is the minimum of recall and precision.ArgumentExpected TypeDescriptionresponse_colpd.SeriesPandas Series containing translations (as strings) to scorereferences_colpd.SeriesPandas Series containing a reference, or list of several references, for each translationmin_lenintThe minimum order of n-gram this function should extract. Defaults to 1max_lenintThe maximum order of n-gram this function should extract. Defaults to 4Code Examplegoogle_bleu_scores = google_bleu(    response_col=df['summary'],     references_col=df['reference_summary'],     min_len=2, # optional field    max_len=5 # optional field )rouge\u200bView Source\u200bA software package and a set of metrics commonly used to evaluate machine translation and automatic summarization software in natural language processing. These metrics involve comparing a machine-produced summary or translation with a reference or set of references that have been human-produced.ArgumentExpected TypeDescriptionresponse_colpd.Series[Required] Pandas Series containing predictions (as strings) to scorereferences_colpd.Series[Required] Pandas Series containing a reference, or list of several references, per predictionrogue_typesList[str][Optional] A list of rouge types to calculate. Defaults to ['rougeL']. Valid rogue types: \n-rogue1: unigram (1-gram) based scoring\n-rogue2: bigram (2-gram) based scoring-rogueL: longest common subsequence based scoring\n-rogueLSum: splits text using '/n'use_stemmerbool[Optional] If True, uses Porter stemmer to strip word suffixes. Defaults to False.Code Examplerouge_scores = rouge(    response_col=df['summary'],     references_col=df['reference_summary'],     rouge_types=['rouge1', 'rouge2', 'rougeL', 'rougeLsum'] # optional field )meteorAn automatic metric typically used to evaluate machine translation, which is based on a generalized concept of unigram matching between the machine-produced translation and the reference human-produced translations.\u200bView Source\u200bArgumentExpected TypeDescriptionresponse_colpd.Series[Required] Pandas Series containing predictions (as strings) to scorereferences_colpd.Series[Required] Pandas Series containing a reference, or list of several references, per predictionalphafloat[Optional] Parameter for controlling relative weights of precision and recall. Default is", "start_char_idx": 0, "end_char_idx": 7084, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "df2b68f7-bf75-43a1-8c32-a4f3a543c4b4": {"__data__": {"id_": "df2b68f7-bf75-43a1-8c32-a4f3a543c4b4", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "748bc204-476b-4074-a648-3d659e07b165", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "hash": "6214c02c98baebab65031b8e1bcddfba2302acbe2764879081d3cb8992792afa"}, "2": {"node_id": "9517a28a-a65c-4ea7-b58c-0628a7104b4d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}, "hash": "632b982ef3736241565982b0c7c312e52ee922aa28d4bb2995974d298cf8f5df"}}, "hash": "7b038ad480a7702630825e1f8df692c0532652db36efa436b6a0903dea75b715", "text": "0.9betafloat[Optional] Parameter for controlling shape of penalty as a function of fragmentation. Default is 3gammafloat[Optional] The relative weight assigned to fragmentation penalty. Default is 0.5Code Examplemeteor_scores = meteor(    response_col=df['summary'],     references_col=df['reference_summary'],     alpha=0.8, # optional field    beta=4, # optional field    gamma=0.4 # optional field )PreviousObjectDetectionColumnNamesNextAutoEmbeddingsLast modified 3mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7085, "end_char_idx": 7784, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "08dca518-ddf1-4380-b62c-85df75f2e3ca": {"__data__": {"id_": "08dca518-ddf1-4380-b62c-85df75f2e3ca", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "260b7be8-0a99-4379-96ff-ab7906a492cd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/log"}, "hash": "a684c4aac38f18ab3f7a2dde0824b7990968e453366c1402bd7c4aec53f5bc71"}}, "hash": "ee80fa636c9f392ad4d38a8b48966ef0dcd4842741314e15184114e21233f72c", "text": "log - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBooklog\u200b\u200bView source on Github\u200bArize method to log inferences within a dataframe to Arize via a POST request.log(    dataframe: pd.DataFrame,    schema: Schema,    environment: Environments,    model_id: str,    model_type: ModelTypes,    metrics_validation: Optional[List[Metrics]] = None,    model_version: Optional[str] = None,    batch_id: Optional[str] = None,    sync: Optional[bool] = False,    validate: Optional[bool] = True,    path: Optional[str] = None,    surrogate_explainability: Optional[bool] = False,    timeout: Optional[float] = None,    verbose: Optional[bool] = False,)Client.log() returns a requests.models.Response object. You can check its http status code to ensure successful delivery of records.if response.status_code == 200: print(f\"\u2705 You have successfully logged production dataset to Arize\")else: print( f\"Logging failed with response code {response.status_code}, {response.text}\" )This API uses fast serialization to the file system from Python and followed up by a fast client to server upload. It does require storage in the file system for the file being uploaded. ParameterData TypeDescriptiondataframe[Pandas.DataFrame](Required) The dataframe containing your model datamodel_idstr(Required) A unique name to identify your model in the platformmodel_versionstr(Required*)A subset of predictions and actuals for a given model_id to compare and track changes\n\n*Required for logging predictions. Optional for logging actuals or shap valuesmodel_type\u200barize.utils.types.ModelTypes\u200b(Required) Declare your model type represented in the platform and validate applicable performance metricsenvironment\u200barize.utils.types.Environments\u200b(Required) The environment (Production, Training, Validation) for your dataframeschema\u200barize.pandas.logger.Schema\u200b(Required) A Schema instance that specifies the column names for corresponding data in the dataframebatch_idstr(Optional*) Used to distinguish different batch of data under the same model_id and model_version\n\n*Only applicable and required for validation environmentmetrics_validation\u200barize.utils.types.Metrics\u200b(Optional) A list of desired metric groups; defaults to None. When populated, and if validate=True, the presence of schema columns are validated against the desired metricsvalidatebool(Optional) When set to True, validation is run on the model schema and dataframe before sending data. Defaults to True (recommended). pathstr(Optional) Temporary directory/file to store the serialized data in binary before sending to Arizesyncbool(Optional) When sync is set to True, the log call will block, or wait, until the data has been successfully ingested by the platform and immediately return the status of the logsurrogate_explainabilitybool(Optional) Computes feature importance values using the surrogate explainability method. This requires that the arize module is installed with the [MimicExplainer] option. If feature importance values are already specified by the shap_values_column_names attribute in the Schema, this module will not runArize expects the DataFrame's index to be sorted and begin at 0. If you perform operations that might affect the index prior to logging data, reset the index as follows:dataframe = dataframe.reset_index(drop=True)Code Exampleresponse = arize_client.log(    dataframe=df,    schema=schema,    environment=Environments.Production,    model_id=\"example_model\",    model_type=ModelTypes.BINARY_CLASSIFICATION    metrics_validation=metrics_validation=[Metrics.CLASSIFICATION, Metrics.REGRESSION, Metrics.AUC_LOG_LOSS]    model_version=\"1.0\"    validate=True ) PreviousClientNextSchemaLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5499, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5a95db40-1469-40d1-a1c1-0c240154d3e6": {"__data__": {"id_": "5a95db40-1469-40d1-a1c1-0c240154d3e6", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/objectdetectioncolumnnames"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "6f46fec1-4041-4b68-a6b7-cce13699898e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/objectdetectioncolumnnames"}, "hash": "418598252de0919acc7812d6b4ff1847daed50224e167520478d5981d0336d86"}}, "hash": "5632ff319910e9240dfd7ed99481497245b82bd2111479d2b61b301092f8320a", "text": "ObjectDetectionColumnNames - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookObjectDetectionColumnNames\u200b View source on GitHub Arize class to map up to 3 columns (bounding_boxes_coordinates_column_name, categories_column_name, and scores_column_name) to a single object detection prediction or actual column.class ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name: str    categories_column_name: str    scores_column_name: Optional[str] = None)ParametersData TypeExpected Type In ColumnDescription bounding_boxes_coordinates_column_namestrThe contents of this column must be List[List[float]](Required) Column name containing the coordinates of the rectangular outline that locates an object within an image or video. \n\nPascal VOC format required. categories_column_namestrThe contents of this column must be List[str](Required) Column name containing the predefined classes or labels used by the model to classify the detected objects.scores_column_namestrThe contents of this column must be List[float](Optional*) Column name containing the confidence scores that the model assigns to its predictions, indicating how certain the model is that the predicted class is contained within the bounding box.\n\n* This parameter is not applicable to actual (ground truth) labels and is only applicable when defining object_detection_prediction_column_namesCode ExampleIndexprediction_bboxes\tactual_bboxesprediction_categoriesactual_categoriesprediction_scores0[[50.43, 109.49, 538.21...[[55.39, 107.72, 539.25, 362.9], [554.41, 194....[bus][bus, person, person][0.9997552]object_detection_prediction_column_names=ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name=\"prediction_bboxes\",    categories_column_name=\"prediction_categories\",    scores_column_name=\"prediction_scores\")object_detection_actual_column_names=ObjectDetectionColumnNames(    bounding_boxes_coordinates_column_name=\"actual_bboxes\",    categories_column_name=\"actual_categories\",)PreviousEmbeddingColumnNamesNextLLM_EvaluationLast modified 2mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3868, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5098be58-8027-4524-866d-80ec073d9d75": {"__data__": {"id_": "5098be58-8027-4524-866d-80ec073d9d75", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "735e890f-8307-41d3-a5de-fb99fbf335bc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "hash": "15b027c32685bd5eec9738a0b05729543d8f5d31c985e2a94a12383df8946f2b"}, "3": {"node_id": "6dc02ce8-a2b3-42f1-8ddd-82a4a1e0e39f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "hash": "68c14937b345ef2ae557ce4268137c7b1c648b4617c3e61071e6d14e81b0af33"}}, "hash": "8e1bc11b6fabd47775ff87666e8613732e2d90baa315b17f54d520c7edc98638", "text": "Schema - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSchema\u200b\u200bView Source on Github\u200bArize class to organize and map column names containing model data within your Pandas dataframe to Arize. Import and initialize Arize Schema from arize.utils.types from arize.utils.types import Schemaclass Schema(    prediction_id_column_name:Optional[str] = None    feature_column_names: Optional[List[str]] = None    tag_column_names: Optional[List[str]] = None    timestamp_column_name: Optional[str] = None    prediction_label_column_name: Optional[str] = None    prediction_score_column_name: Optional[str] = None    actual_label_column_name: Optional[str] = None    actual_score_column_name: Optional[str] = None    shap_values_column_names: Optional[Dict[str, str]] = None    actual_numeric_sequence_column_name: Optional[str] = None    embedding_feature_column_names: Optional[Dict[str, EmbeddingColumnNames]] = None    prediction_group_id_column_name: Optional[str] = None    rank_column_name: Optional[str] = None    attributions_column_name: Optional[str] = None    relevance_score_column_name: Optional[str] = None    relevance_labels_column_name: Optional[str] = None    object_detection_prediction_column_names: Optional[ObjectDetectionColumnNames] = None    object_detection_actual_column_names: Optional[ObjectDetectionColumnNames] = None    prompt_column_names: Optional[EmbeddingColumnNames] = None    response_column_names: Optional[EmbeddingColumnNames] = None)ParameterData TypeExpected Type In ColumnDescription prediction_id_column_namestrContents must be a string limited to 128 characters(Optional) A unique string to identify a prediction event. Required to match a prediction to delayed actuals or feature importances in Arize. If the column is not provided, Arize will generate a random prediction id.feature_column_namesList[str]The content of this column can be int, float, string(Optional) List of column names for featuresembedding_feature_column_names\u200b[Dict[str, EmbeddingColumnNames]]\u200bLearn more here\u200b(Optional) Dictionary mapping embedding display names to EmbeddingColumnNames objectstimestamp_column_namestrThe content of this column must be int Unix Timestamps in seconds(Optional) Column name for timestamps \n prediction_label_column_namestrThe content of this column must be convertible to string (Optional) Column name for categorical prediction valuesprediction_score_column_namestrThe content of this column must be int/float(Optional Column name for numeric prediction valuesactual_label_column_namestrThe content of this column must be convertible to string(Optional) Column name for categorical ground truth valuesactual_score_column_namestrThe content of this column must be int/float(Optional) Column name for numeric ground truthtag_column_namesList[str]The content of this column can be int, float, string. LImited to 1k values(Optional) List of column names for tagsshap_values_column_namesDict[str,str]The content of this column must be int/float(Optional) dict of k-v pairs where k is the feature_colname  and v is the corresponding shap_val_col_name. For example, your dataframe contains features columnsfeat1, feat2, feat3,...and corresponding shap value columns feat1_shap, feat2_shap, feat3_shap,... You want to set shap_values_column_names = {\"feat1\": \"feat1shap\", \"feat2\": \"feat2_shap:\", \"feat3\": \"feat3_shap\"}prediction_group_id_column_namestrThe content of this column must be string and is limited to 128 characters(Required*) Column name for ranking groups or lists in ranking models\n\n*for ranking models onlyrank_column_namestrThe content of this column must be integer between 1-100(Required*) Column name for rank of each element on the its group or list\n\n*for ranking models onlyrelevance_score_column_namestrThe content of this column must be int/float(Required*) Column name for ranking model type numeric ground truth values\n\n*for ranking models onlyrelevance_labels_column_namestrThe content of this column must be a string(Required*) Column name for ranking model type categorical ground truth values\n\n*for ranking models onlyobject_detection_prediction_column_names[ObjectDetectionColumnNames]Learn more here\u200bObjectDetectionColumnNames object containing information defining the predicted bounding boxes' coordinates, categories, and scores.object_detection_actual_column_names[ObjectDetectionColumnNames]Learn more here\u200bObjectDetectionColumnNames object containing information defining the actula bounding boxes' coordinates, categories, and scores.prompt_column_names[EmbeddingColumnNames]Learn more here\u200bEmbeddingColumnNames object containing the embedding vector data (required) and raw text (optional) for the input text your model acts onresponse_column_names[EmbeddingColumnNames]Learn more here\u200bEmbeddingColumnNames object containing the embedding vector data (required) and raw text (optional) for the text your model generatesCode Exampleprediction idfeature_1tag_1prediction_tsprediction_labelactual_labelembedding1fcd50f4689cafemale1637538845No ClaimsNo Claims[1.27346, -0.2138, ...]schema = Schema(    prediction_id_column_name=\"prediction id\",    feature_column_names=[\"feature_1\", \"feature_2\", \"feature_3\"],     tag_column_names=[\"tag_1\", \"tag_2\", \"tag_3\"],     timestamp_column_name=\"prediction_ts\",    prediction_label_column_name=\"prediction_label\",    prediction_score_column_name=\"prediction_score\",   ", "start_char_idx": 0, "end_char_idx": 6979, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6dc02ce8-a2b3-42f1-8ddd-82a4a1e0e39f": {"__data__": {"id_": "6dc02ce8-a2b3-42f1-8ddd-82a4a1e0e39f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "735e890f-8307-41d3-a5de-fb99fbf335bc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "hash": "15b027c32685bd5eec9738a0b05729543d8f5d31c985e2a94a12383df8946f2b"}, "2": {"node_id": "5098be58-8027-4524-866d-80ec073d9d75", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}, "hash": "8e1bc11b6fabd47775ff87666e8613732e2d90baa315b17f54d520c7edc98638"}}, "hash": "68c14937b345ef2ae557ce4268137c7b1c648b4617c3e61071e6d14e81b0af33", "text": "actual_label_column_name=\"actual_label\",    actual_score_column_name=\"actual_score\",    shap_values_column_names=shap_values_column_names=dict(zip(\"feature_1\", shap_cols)),    embedding_feature_column_names=embedding_feature_column_names,    prediction_group_id_column_name=\"group_example_name\",    rank_column_name=\"example_rank\",    relevance_score_column_name=\"relevance_score\",    relevance_labels_column_name=\"actual_relevancy\",) PreviouslogNextEmbeddingColumnNamesLast modified 2mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6980, "end_char_idx": 7695, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1ea64d01-8701-4195-987a-ca21df4d1c5e": {"__data__": {"id_": "1ea64d01-8701-4195-987a-ca21df4d1c5e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.environments"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "906ef3d6-09ca-484e-8753-ba6dc50fa9f9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.environments"}, "hash": "70eb3363c07c23a8860f0a376ecdde97a2f4e01c28497b7ddbe9f9fa7183465e"}}, "hash": "052631b54ab28bcba98ff01f46100848d807ed5f514e635769e0c5631b971972", "text": "utils.types.Environments - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.Environments\u200b\u200bView source on Github\u200bArize enum to specify your model environment represented in the platform for further analysis and comparisonsEnvironmentSDK EnvironmentDescription TrainingEnvironments.TRAININGAn environment used to develop and train ML models (data prep, data processing, and model tuning)ValidationEnvironments.VALIDATIONAn environment used to evaluate and fine-tune ML models before deployment (testing performance separate from training data)ProductionEnvironments.PRODUCTIONAn environment to deploy ML models and serve predictionsCode Exampleresponse = arize_client.log(    model_id='sample-training-model',  ...    environment=Environments.TRAINING)\u200bresponse = arize_client.log(    model_id='sample-validation-model',  ...    environment=Environments.VALIDATION)\u200bresponse = arize_client.log(    model_id='sample-production-model',  ...    environment=Environments.PRODUCTION)Previousutils.types.MetricsNextSingle Record LoggingLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2881, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c080e82e-3558-4876-a978-d7f4d5fcd7ab": {"__data__": {"id_": "c080e82e-3558-4876-a978-d7f4d5fcd7ab", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.metrics"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0aeb2d90-5dac-4c51-93b7-326540a233a3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.metrics"}, "hash": "148bee5b6b9aefd1a83ac8dc189d35da0d11b238681577685d6eb2847ed284f4"}}, "hash": "42a80433889170f6f3c888c21884a4ed9750608a967c7c09a8baf3ade155f280", "text": "utils.types.Metrics - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.Metrics\u200b\u200bView Source on Github\u200bArize enum for metrics grouping when validating a schema column in log() call.Use CaseSDK MetricMetricRegressionMetrics.REGRESSIONMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorClassificationMetrics.CLASSIFICATIONAccuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityRankingMetrics.RANKINGNDCGAUC & LogLossMetrics.AUC_LOG_LOSSAUC, PR-AUC, Log LossRanking LabelMetrics.RANKING_LABELGroupAUC, MAP, MRRMethodrepr()To view applicable metrics, pass in your desired SDK Metric from above.repr(Metrics.[SDK Metric])Code Exampleresponse = arize_client.log(    model_id='sample-binary-classification-model',  ...    metrics_validation=[Metrics.CLASSIFICATION]\u200b)\u200bresponse = arize_client.log(    model_id='sample-regression-model',  ...    metrics_validation=[Metrics.REGRESSION])\u200bresponse = arize_client.log(    model_id='sample-ranking-model',  ...    metrics_validation=[Metrics.RANKING, Metrics.RANKING_LABEL])Previousutils.types.ModelTypesNextutils.types.EnvironmentsLast modified 4mo agoOn this pageMethodCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2955, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "84699106-2432-4048-8750-4e2be63e48c6": {"__data__": {"id_": "84699106-2432-4048-8750-4e2be63e48c6", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.modeltypes"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9d2b621d-07ab-41ca-9518-a07141454a6e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.modeltypes"}, "hash": "605316f3ff8cfdeacca6a35a598f74f5988f5d9c434834e213fa362ea2a2114f"}}, "hash": "d2b6a2522bfe30ecde2f0b019c4b465102e0efaab0ad843556d06f37d2936886", "text": "utils.types.ModelTypes - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKPandas Batch LoggingClientlogSchemaEmbeddingColumnNamesObjectDetectionColumnNamesLLM_EvaluationAutoEmbeddingsutils.types.ModelTypesutils.types.Metricsutils.types.EnvironmentsSingle Record LoggingJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookutils.types.ModelTypes\u200b\u200bView source on Github\u200bArize enum to specify your model type represented in the platform and validate applicable performance metrics. Model Typesfrom arize.utils.types import ModelTypesSpecify a model_type when logging a prediction for the first time for a new model.Methodlist_types()View SourceReturns a list of all model types. ModelTypes.list_types()Use CaseSDK ModelTypeDescription\u200bRegression\u200bModelTypes.REGRESSIONRegression models predict continuous values\u200bBinary Classification\u200bModelType.BINARY_CLASSIFICATIONBinary classification models predict only two categorical values, typically represented as 0 or 1\u200bMulti Class\u200bModelType.SCORE_CATEGORICALMulticlass models predict multiple categorical values\u200bRanking \u200bModelType.RANKINGRanking models predict the relative ordering of a set of items based on their features\u0000\u0000\u200bNatural Language Processing (NLP)\u200bModelType.SCORE_CATEGORICALNLP models are categorical models specifically designed to work with text data and perform various tasks (i.e. sentiment analysis and language translation)\u200bComputer Vision (CV)\u200bModelType.SCORE_CATEGORICALCV models are categorical models specifically designed to work with visual data and perform various tasks (i.e. object detection and image classification)\u200bLarge Language Models (LLMs)\u200bModelTypes.GENERATIVE_LLMModels that use vast amounts of data to generate human-like language and perform a wide range of natural language processing tasks \u200bObject Detection\u200bModelTypes.OBJECT_DETECTIONObject detection models identify and locate objects within images or videos by assigning them specific bounding boxesCode Exampleresponse = arize_client.log(    model_id='sample-binary-classification-model',  ...    model_type=ModelTypes.BINARY_CLASSIFICATION)\u200bresponse = arize_client.log(    model_id='sample-regression-model',  ...    model_type=ModelTypes.REGRESSION)\u200bresponse = arize_client.log(    model_id='sample-ranking-model',  ...    model_type=ModelTypes.RANKING)\u200bPreviousAutoEmbeddingsNextutils.types.MetricsLast modified 2mo agoOn this pageModel TypesCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3965, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "97a54811-0f27-4ec4-922f-23516ffeb5a0": {"__data__": {"id_": "97a54811-0f27-4ec4-922f-23516ffeb5a0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/api-changelog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d0f57afd-b130-465c-a9fb-b22004f6b3ff", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/api-changelog"}, "hash": "90a50e4a853b675896956b9ffa99a1c9e7d8a4ebec172f6a793b703070a25dcb"}}, "hash": "1861594be8041686fafaf02ec7c47f07c4945051461703c110c80207b980411f", "text": "API Changelog - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAPI ChangelogUpdates to the Arize GraphQL APIWe improve the Arize platform continuously by releasing new features, squashing bugs, and delivering fresh documentation. This changelog is an account of what's happened with regards to the GraphQL API.November 17, 2022Breaking Change: the validationResult object returned from createFileImportJob when the dryRun parameter is set to true has been changed to return an error type which includes the error code, the error message, and the error row. Additionally, the errorFilePath field has been renamed to filePath.October 7, 2022Addition: added startTime and endTime to the files connection under an importJob to allow  pulling files from specific time ranges using an RFC 3339 graphql dateTime scalar. The API limits the query to 1 month and allows you to confirm the files that have been ingested into Arize.August 19, 2022Addition: we've released workflows for file importer. You can now create and delete file import jobs, as well as query for jobs and their associated files. Learn more about our new release here. August 2, 2022Addition: the ModelType now supports querying the model's schema (features, tags, predictions, and actuals) in paginated connections. For full details, check out the ModelSchema type definition.PreviousResource LimitationsNext - API ReferenceData APILast modified 8mo agoOn this pageNovember 17, 2022October 7, 2022August 19, 2022August 2, 2022SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3279, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "93ffcb8e-0e82-4e88-992a-2263e287b879": {"__data__": {"id_": "93ffcb8e-0e82-4e88-992a-2263e287b879", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/custom-metrics-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a04b55ec-0418-4970-8fc9-6421eaffcd7a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/custom-metrics-api"}, "hash": "b0bee273243edf97cce4cbdc390dec1b6328efbd2fab024a4a728dc5773280eb"}}, "hash": "1879f6ad967ad8a764b3271e35fc05b102b237fdc51a0e61e64a5c300d632c63", "text": "Custom Metrics API - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCustom Metrics APILearn how to query, create, and update custom metrics programmaticallyUse custom metrics to define a metric specific to your business use case or to your model. By using a programmatic API, you can automate the process of creating a custom metric, updating that metric, and creating monitors on that metric.Learn more about custom metrics here.For a brief overview of GraphQL itself, please consult our introduction.Creating a custom metricCreating a custom metric directly:mutation { createCustomMetric( input: {  name: \"prediction count\",  description: \"Returns the count of predictions over time\",  modelId: \"model_id\",  metric: \"SELECT COUNT(*) FROM model\"  }) { customMetric { id } }}A more repeatable way to do this is to use query parameters:# Query:mutation myCustomMetricMutation($input: CreateCustomMetricMutationInput!) { createCustomMetric(input: $input) { customMetric { id } }}\u200b# Params:{ \"input\": {  \"name\": \"prediction count\",  \"description\": \"Returns the count of predictions over time\",  \"modelId\": \"model_id\",  \"metric\": \"SELECT COUNT(*) FROM model\" }}Note that error messages work the same in GraphQL as in the UI. For example, if my metric was this: SELECT COUNT(income) FROM model, I would get this error message in both the UI and the API:{ \"errors\": [ { \"message\": \"The custom metric failed to save: column \\\"income\\\" does not exist on line 1, column 13\",      ...However, due to the ability to use auto complete and the model schema panel in the UI, we do encourage using the UI to create an initial custom metric before attempting to create one directly using the GraphQL API.Updating a custom metricIn order to update a custom metric, use the updateCustomMetricMutation. Follow an example here. mutation { updateCustomMetric(input: { customMetricId:\"custom_metric_id\", modelId:\"model_id\", name:\"new custom metric name\", description:\"new description\", customMetric:\"SELECT avg(annual_income) FROM model\" }) {  customMetric { id } }}Querying a custom metricYou can query for custom metrics associated with a model like this:{ node(id: \"model_id\") { ... on Model { customMetrics(first: 10) { edges { node { name metric description } } } } }}If you know the id of your custom metric - you can also query for it directly:{ node(id:\"custom_metric_id\"){ ... on CustomMetric { id name description metric } }}Creating a monitor for a custom metricUsers can monitor a custom metric using the performance monitor type. Follow an example here. To create a custom metric monitor - first get the custom metric id. This can come from the result of the createCustomMetricMutation above, or it can come from the URL of the custom metric:app.arize.com/organizations/:org_id/spaces/:space_id/models/:model_id/custom_metrics/:custom_metric_id/Then, use the createPerformanceMonitorMutation to create the monitor:mutation { createPerformanceMonitor(input:{ modelId: \"model_id\", customMetricId: \"custom_metric_id\", operator: greaterThan, name: \"custom metric monitor\" }){ monitor{ id uri } }}\u200bExamplesAPI Use CasesExample ColabsCreate Custom Metrics With GraphQL\u200bColab\u200bUpdate Custom Metrics With GraphQL\u200bColab\u200bTo learn more about performance monitors - refer to our monitors API documentation here.PreviousFile Importer APINextResource LimitationsLast modified 2mo agoOn this pageCreating a custom metricUpdating a custom metricQuerying a custom metricCreating a monitor for a custom metricExamplesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5282, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "57fa9bdc-031b-44b6-a172-110a17480d78": {"__data__": {"id_": "57fa9bdc-031b-44b6-a172-110a17480d78", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/example-use-cases"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d9474079-16d1-455f-9456-e1bc84430565", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/example-use-cases"}, "hash": "4f5aa2287269537d015fef166799652810ff5d5ab3fcf9d76c6708239aaddd49"}}, "hash": "07ac5dc00ef4b976249f25548df270c2a71acfc691f64077c96b9574a77d1ed8", "text": "Example Use Cases - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookExample Use CasesExamples of how to leverage the Arize API for your monitoring needsGraphQL Example Use CasesReady to get started? Navigate through our case-specific Colabs to help get you started using our GraphQL API for your monitors. Learn how to identify the relevant mutation for your monitors, export your monitors into a spreadsheet, edit the spreadsheet for your use case, and bulk modify your monitors using GraphQL. Learn more about different mutations and their functions here. Use CasesExample ColabsPatching Drift Monitors\u200bColab\u200bCreating Performance Monitors\u200bColab\u200bCreating Data Quality Monitors\u200bColab\u200bCreating Drift Monitors\u200bColab\u200bCreating a File Import Job\u200bColab\u200bQuerying for Failed Files of an Import Job\u200bColab\u200bA mutation is an operation that allows you to modify server-side data. Learn more about mutations here. \u200bPatching Drift Monitors\u200bThis use case example helps you understand the patch mutation for drift monitors. Since Arize has 3 types of monitors (Drift, Performance, and Data Quality), we use a different patch mutation for each kind of monitor.  Learn how to edit existing threshold values using the patchDriftMonitor mutation to bulk edit your drift monitors. \u200bCreating Performance Monitors \u200bThis use case example helps you understand the create mutation for performance monitors. This mutation allows you to update or create monitors in bulk. Since Arize utilizes 3 types of monitors (Drift, Performance, and Data Quality), we use a different create mutation for each kind of monitor. Learn how to use the createPerformanceMonitor mutation to bulk create performance monitors with explicit thresholds. \u200bCreating Data Quality Monitors\u200bThis use case example helps you understand the create mutation for performance monitors. This mutation allows you to update or create monitors in bulk. Since Arize utilizes 3 types of monitors (Drift, Performance, and Data Quality), we use a different create mutation for each kind of monitor. Learn how to use the createDataQualityMonitor mutation to bulk create performance monitors with explicit thresholds. \u200bCreating Drift Monitors This use case example helps you understand the create mutation for drift monitors. This mutation allows you to update or create monitors in bulk. Since Arize has 3 types of monitors (Drift, Performance, and Data Quality), we use a different create mutation for each kind of monitor.  Learn how to use the createDriftMonitor mutation to bulk create drift monitors. Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousGetting Started With Programmatic AccessNextMonitors APILast modified 8mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4529, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "08ccaf81-dee9-489f-98e4-403a20ede888": {"__data__": {"id_": "08ccaf81-dee9-489f-98e4-403a20ede888", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "23e673fa-2239-4ebd-92cf-35da1cb7ab9d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "hash": "72bce731a332ed95a6e76a9f6dbc3a8d42f11063e1d27d4843f58aafb7bd6c93"}, "3": {"node_id": "1063440c-3d07-4af3-9481-920af9aa0531", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "hash": "94c26bdada21dede4410334fc1a83927c16088ccda330cc4c39b50a6cadcfda0"}}, "hash": "398ec88aaf591f41003df3dee23887692b52266ebfd1d6ad4039d60811d65c1d", "text": "File Importer API - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookFile Importer APILearn how to create and delete import jobs and query for job and file details using our programmatic APIUse the file importer API for a direct path between your cloud storage and the Arize platform.While the Arize platform has an intuitive user interface for data ingestion workflows, the object store integration provides a direct way to easily set up jobs and automate job creation. For a brief overview of GraphQL itself, please consult our introduction.Creating Import JobsTo create an import job: you must complete the setup steps outlined for GCS here or AWS here to grant Arize access to your bucket.Import jobs belong to a Space -- which has a globally unique ID. To create an import job, you'll need to retrieve your space ID from the platform URL: /organizations/:organization_id/spaces/:space_id.Import Job Tips: Create a reusable mutation to create a file import job that will read files from your bucketValidate your file import job before you begin your file import job. Using two additional parameters  - dryRun and fileName - as inputs when creating the import job mutation.dryRun(boolean): If true, the import job will be attempted but no changes will be written. The validationResult field may be requested to check the validation status.fileName(string): The file name to perform a dry run on. If a file name is not selected, the dry run will be performed on the first file.Dry Run File Import JobCreate File Import Job Mutationmutation dryRunMyImportJob($input: CreateFileImportJobInput!) { createFileImportJob(input: $input) { validationResult { validationStatus filePath  error { code message row } } }}variables:{ \"input\": { \"spaceId\": \"space_id\", \"modelName\": \"My Test Model\", \"modelType\": \"categorical\", \"modelEnvironmentName\": \"production\", \"blobStore\": \"S3\", \"bucketName\": \"testing-folder\", \"prefix\": \"myfolder/mysubfolder/\", \"schema\": { \"predictionId\": \"prediction_id\", \"predictionLabel\": \"PREDICTION\", \"actualLabel\": \"ACTUAL\", \"shapValues\": \"shap/\", \"tags\": \"tag/\", \"timestamp\": \"prediction_ts\", \"predictionScore\": \"PREDICTION_SCORE\", \"actualScore\": \"ACTUAL_SCORE\" }, \"dryRun\": true }}Alternatively, you may pass in the inputs directly:mutation { createFileImportJob(input: { spaceId: \"space_id\", modelName: \"My Test Model\", modelType: categorical, modelEnvironmentName: production, blobStore: S3, bucketName: \"testing-folder\", prefix: \"myfolder/mysubfolder/\", schema: { predictionId: \"prediction_id\", predictionLabel: \"PREDICTION\", actualLabel: \"ACTUAL\", shapValues: \"shap/\", tags: \"tag/\", timestamp: \"prediction_ts\", predictionScore: \"PREDICTION_SCORE\", actualScore: \"ACTUAL_SCORE\" }, dryRun: true }) { validationResult { validationStatus filePath  error { code message row } } }}mutation createMyNewImportJob($input: CreateFileImportJobInput!) { createFileImportJob(input: $input) { fileImportJob { id } }}variables{ \"input\": { \"spaceId\": \"space_id\", \"modelName\": \"My Test Model\", \"modelType\": \"categorical\", \"modelEnvironmentName\": \"production\", \"blobStore\": \"S3\", \"bucketName\": \"testing-folder\", \"prefix\": \"myfolder/mysubfolder/\", \"schema\": { \"predictionId\": \"prediction_id\", \"predictionLabel\": \"PREDICTION\", \"actualLabel\": \"ACTUAL\", \"shapValues\": \"shap/\", \"tags\": \"tag/\", \"timestamp\": \"prediction_ts\", \"predictionScore\": \"PREDICTION_SCORE\", \"actualScore\": \"ACTUAL_SCORE\" } }}Alternatively, you may pass in the inputs directly:mutation { createFileImportJob(input: { spaceId: \"space_id\", modelName: \"My Test Model\", modelType: categorical, modelEnvironmentName: production, blobStore: S3, bucketName: \"testing-folder\", prefix: \"myfolder/mysubfolder/\", schema: { predictionId: \"prediction_id\", predictionLabel: \"PREDICTION\", actualLabel: \"ACTUAL\", shapValues: \"shap/\", tags: \"tag/\", timestamp: \"prediction_ts\", predictionScore: \"PREDICTION_SCORE\", actualScore: \"ACTUAL_SCORE\" } }) { fileImportJob { id } }}The variables provided are an example of one particular mapping. For more information on mapping your file, please consult the file schema documentation located on within each data connector page or here on the available fields for all queries and mutations. Google ColaboratoryCreate a File Import JobQuerying for Import Jobs and FilesYou can query for import jobs off of a Space node. query { node(id: \"space_id\") { ... on Space { importJobs(first: 50) { edges { node { id modelName totalFilesCount schema { predictionId predictionLabel } } } } } }}Query fields within an import job given specific criteria using the FileImportJobConnection  from a Space. If you have a large number of import jobs, you will have to use pagination to pull the complete list. This data can then be viewed or used in other queries.To view files that belong to an import job, query for files using an import job node since the files belong to an import job. For instance, to view failing files and their error message, use the FileImportJobFileConnection which returns files with a passed status or all files if no status is provided. You may additionally filter files based on a date range, providing an RFC3339 compliant date time shown below.query { node(id: \"import_job_id\") { ... on FileImportJob { files( first: 25 status: FAILED startTime: \"2023-01-02T01:00:00Z\" endTime: \"2023-02-01T01:00:00Z\" ) { edges { node { id filePath error { message } } }  } } }}Google ColaboratoryQuery for jobs and filesDeleting Import JobsDeleting import jobs using a mutation simply requires", "start_char_idx": 0, "end_char_idx": 7052, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1063440c-3d07-4af3-9481-920af9aa0531": {"__data__": {"id_": "1063440c-3d07-4af3-9481-920af9aa0531", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "23e673fa-2239-4ebd-92cf-35da1cb7ab9d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "hash": "72bce731a332ed95a6e76a9f6dbc3a8d42f11063e1d27d4843f58aafb7bd6c93"}, "2": {"node_id": "08ccaf81-dee9-489f-98e4-403a20ede888", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}, "hash": "398ec88aaf591f41003df3dee23887692b52266ebfd1d6ad4039d60811d65c1d"}}, "hash": "94c26bdada21dede4410334fc1a83927c16088ccda330cc4c39b50a6cadcfda0", "text": "you to know the ID of the import job you want to delete.mutation { deleteFileImportJob(input: {jobId: \"job_id\"}) { space { id } }}ExamplesAPI Use CasesExample ColabsCreating a File Import Job\u200bColab\u200bQuerying for Failed Files of an Import Job\u200bColab\u200bPreviousModels APINextCustom Metrics APILast modified 2mo agoOn this pageCreating Import JobsQuerying for Import Jobs and FilesDeleting Import JobsExamplesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7053, "end_char_idx": 7679, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6aae5dbd-b15c-421a-a4d3-743ae88a1d10": {"__data__": {"id_": "6aae5dbd-b15c-421a-a4d3-743ae88a1d10", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/getting-started-with-programmatic-access"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9dbcc6cb-5a60-4e6b-b3f1-5c6b5d8ad578", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/getting-started-with-programmatic-access"}, "hash": "8def14d66ed8bf15c08eb316a3ffa257ce3c2e99c6211ea21997823752065c44"}}, "hash": "725eabe57536e59913d1dc3e37dcd6f8c967e3dd4fce5bc004ad0871a38cba72", "text": "Getting Started With Programmatic Access - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGetting Started With Programmatic AccessLearn how to gain access to the GraphQL API explorerOverview Video Watch this overview video to learn how to gain developer access, navigate to the API Explorer, and start your first query & mutation. Granting Developer PermissionsThe GraphQL API is considered a 'Developer Access' feature. To enable developer permissions, navigate to your organization's settings page: From any page, click on your Organization name on the top left of the page. This will take you to a hover state where you can click on the 'View All Organizations' button. From there, click into the settings tab where you can manage 'Developer Access' for all members of your organization by toggling the 'Developer Access' switch on and off for each member.The Arize GraphQL API is available to enterprise-grade customers. To upgrade your account contact [email\u00a0protected]\u200bAccessing the API ExplorerThe API explorer is an interactive editor to make API queries. To access the API explorer from any page, enable Developer Access. Navigate to the '<>' button on the bottom left of your screen to easily enter the API explorer. Accessing the API Explorer Helpful Shortcuts: \u2318- Click - Open live documentation\u2318- Space - Open a list of all fields on an object\u2318 - Return - Run query \u2318 - Shift - P - Format queryAccess the API Key Use the API key to make API queries with other tools such as cURL, Postman, and client libraries for various programming languages. Click the 'Get Your API Key' button on the top right of the Explorer page to generate your API key. Access API KeyHaving trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousMutationsNextExample Use CasesLast modified 8mo agoOn this pageOverview Video Granting Developer PermissionsAccessing the API ExplorerAccess the API Key SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3744, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4d0d7642-858a-4352-aad6-78381bd0f963": {"__data__": {"id_": "4d0d7642-858a-4352-aad6-78381bd0f963", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b785648c-c907-432a-a3f1-d636d7f65172", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql"}, "hash": "4bebe2390b10cc377a3cf9dc1708cd7303050d8ab06b79b0d16d8e4f995ace53"}}, "hash": "404d4a59bc543b2ff0e92a18bc8550be89b0350f02bf3ea5b83eebe6f19acdb3", "text": "How To Use GraphQL - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLForming CallsUsing Global Node ID'sQuerying Nested DataMutationsGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookHow To Use GraphQLLearn useful terminology and concepts for using the Arize GraphQL API.GraphQL provides developers with the ability to build more powerful tools with precise and flexible queries. This represents an architectural and conceptual shift from the well-known REST API. Since GraphQL is relatively new, you'll likely encounter unfamiliar terminology in the GraphQL API. Use this page as a recourse to help you navigate the necessary terminology and concepts to implement the Arize GraphQL API. SchemaA schema defines a GraphQL API's type system and resides on the GraphQL API server. It describes the complete set of possible data (objects, fields, relationships, everything) that a client can access. Calls from the client are validated and executed against the schema. A client can find information about the schema via introspection. FieldA field is a unit of data you can retrieve from an object. As the official GraphQL docs notes that: \"The GraphQL query language is basically about selecting fields on objects.\"The official spec also details the following:All GraphQL operations must specify their selections down to fields which return scalar values to ensure an unambiguously shaped response.This means that if you try to return a field that is not a scalar, schema validation it will throw an error. There must be nested subfields added until all fields return scalars.ArgumentAn argument is a set of key-value pairs attached to a specific field. Some fields require an argument. Mutations require an input object as an argument.ImplementationA GraphQL schema may use the term implements to define how an object inherits from an interface.Here's a contrived example of a schema that defines interface X and object Y:\n\ninterface X {  some_field: String!  other_field: String!}\u200btype Y implements X {  some_field: String!  other_field: String!  new_field: String!}This means object Y requires the same fields/arguments/return types that interface X does, while adding new fields specific to object Y. (The ! means the field is required.)ConnectionConnections let you query related objects as part of the same call. With connections, you can use a single GraphQL call where you would have to use multiple calls to a REST API. It's helpful to picture a graph: dots connected by lines. The dots are nodes, the lines are edges. A connection defines a relationship between nodes.EdgeEdges represent connections between nodes. When you query a connection, you traverse its edges to get to its nodes. Every edges field has a node field and a cursor field. Cursors are used for pagination.NodeNode is a generic term for an object. You can look up a node directly, or you can access related nodes via a connection. If you specify a node that does not return a scalar, you must include subfields until all fields return scalars. Discovering the GraphQL APIGraphQL is introspective. This means you can query a GraphQL schema for details about itself.Query __schema to list all types defined in the schema and get details about each:query { __schema { types { name kind description fields { name } } }}Query __type to get details about any type:query { __type(name: \"Model\") { name kind description fields { name } }}We would love to hear from you! Please reach out to [email\u00a0protected] and join our community slack. Let's build great things together.API Reference - PreviousGraphQL APINextForming CallsLast modified 1yr agoOn this pageSchemaFieldArgumentImplementationConnectionEdgeNodeDiscovering the GraphQL APISupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5444, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "073267bd-96c6-4f03-b63a-1dcc7e059625": {"__data__": {"id_": "073267bd-96c6-4f03-b63a-1dcc7e059625", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/models-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e79940f0-1d98-49fd-852e-3daf6a9a319c", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/models-api"}, "hash": "cb8557470b6a76426fb61821728381c608c1b0f45a2bf4e5c917fa48bc656d0e"}}, "hash": "bba338d35e888740d8d2b93bf8fafe756863bbeaba5c76713eaa1905f2bb12a8", "text": "Models API - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookModels APILearn how to query models using our programmatic APIFor a brief overview of GraphQL itself, please consult our introduction.Querying for ModelsModels belong to a Space. Because of this, you can either query for models off of a Space node   or a Model node directly.The model or space id is in the url when you visit the corresponding page. The format looks like this: spaces/:space_id/models/:model_id.You can also query for a list of models given the space id. More details here.Query Model DirectlyQuery by Spacequery { node(id: \"model_id\") { ... on Model { name modelType uri } }}query { node(id: \"space_id\") { ... on Space { models(first: 50) { edges { node { id name } } } } }}The ModelsConnection off of Space provides a convenient way for you to pull models that match the given criteria. If you have a large number of models, you will have to use pagination to pull the complete list. This data can then be structured to your liking and be exported to the platform of your choosing. Model SchemaYou can query your model's schema through the Arize GraphQL API. The ModelSchema type contains important information about your models such as  features , tags, predictions and actuals which is useful when programmatically creating Monitors. For more examples see the Monitors API documentation. Querying a Model's schema can return the equivalent of thousands of REST requests, resulting in a high computation cost on our servers. Be mindful of your complexity score to ensure your call falls within our complexity cost limit. More details here.query { node(id: \"model_id\") { ... on Model { name modelSchema { features(first: 10) { edges { node { dimension { name } } } } } } }}\u200bDimension ConfigurationYou can query binning information relating to your model's features, actuals, predictions and tags . Query by Model SchemaCreate / Update a Dimension Configurationquery { node(id: \"model_id\") { ... on Model { name modelSchema { features(first: 10) { edges { node { dimensionConfig { id dimensionName dimensionCategory numBins binOption bins } } } } } } }}\u200b\u200bmutation CreateOrUpdateDimensionConfiguration( $input: UpdateDimensionConfigMutationInput!) { updateDimensionConfig(input: $input) { dimensionConfig { dimensionName binOption numBins bins id } }}variables{ \"input\": { \"modelId\": \"model_id\", \"dimensionName\": \"dimension_name\", \"dimensionCategory\": \"featureLabel\", \"binOption\": \"equalWidth\", \"numBins\": 4 }\u200bPreviousMonitors APINextFile Importer APILast modified 5mo agoOn this pageQuerying for ModelsModel SchemaDimension ConfigurationSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4408, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "68a50699-9944-4d40-acd7-fbc0aaf7123d": {"__data__": {"id_": "68a50699-9944-4d40-acd7-fbc0aaf7123d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "118db4c0-2d07-4a21-9282-6e9e0b9f7e89", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "hash": "351d94ee58b42b68dc1bd5601005e09c03d24f7535b71442512965c17879a675"}, "3": {"node_id": "278babb4-b596-4355-9cb7-3b66e61f72ab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "hash": "0fa261431f48d590f36fc56dfdf1e9a58d8fbff24a6e04c02999ad72d80c27b8"}}, "hash": "70ff91d54c6efb7c6dfba1262d52fc8feffea4e7e646dcba8ece301a7d70066f", "text": "Monitors API - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookMonitors APILearn how to query, patch, and create monitors using our programmatic APIMonitors keep track of the various facets of your models. They track key metrics over time and let you analyze incidents that may be causing your model to degrade. The Arize platform provides workflows to troubleshoot incidents whenever a monitor is triggered. However, it's also useful to export existing monitors programmatically and make configuration changes outside of the Arize platform. The Arize GraphQL API is designed to do just that - to allow you to build tooling that lets you manage monitors using your own custom workflows.For a brief overview of GraphQL itself, please consult our introduction.Querying for MonitorsMonitors belong to a Model and thus also belong to a Space. Because of this, you can either query for monitors off of a Model node or a Space node.The model or space id is in the url when you visit the corresponding page. The format looks like this: spaces/:space_id/models/:model_id.You can also query for a list of models given the space id. More details here.Query by ModelQuery by Spacequery { node(id: \"model_id\") { ... on Model { monitors(first: 50) { edges { node { id name monitorCategory } } } } }}query { node(id: \"space_id\") { ... on Space { monitors(first: 50) { edges { node { id name monitorCategory } } } } }}The MonitorsConnection off of Model and Space provide a convenient way for you to pull monitors that match the given criteria. If you have a large number of monitors, you will have to use pagination to pull the complete list. This data can then be structured to your liking and be exported to the platform of your choosing. For a full working example, consult one of our example use case Colabs.Updating / Patching MonitorsIf you are managing a large number of monitors with Arize, you may want to periodically update certain parts of the configuration of a group of monitors. The Arize API provides patch mutations (partial modification) for each type of monitor. Here are a few examples:\n\nPatch Drift MonitorPatch Performance Monitormutation updateDriftMonitorThreshold($monitorId: ID!, $threshold: Float!) { patchDriftMonitor( input: {  monitorId: $monitorId,  set: {  threshold: $threshold,  dynamicAutoThresholdEnabled: false  } } ) { monitor { id, name, threshold } }}variables{ \"monitorId\": \"monitor_id\", \"threshold\": 0.25}mutation updatePerfMonitorThreshold($monitorId: ID!, $threshold: Float!) { patchPerformanceMonitor( input: {  monitorId: $monitorId,  set: {  threshold: $threshold,  dynamicAutoThresholdEnabled: false  } } ) { monitor { id, name, threshold } }}variables{ \"monitorId\": \"monitor_id\" \"threshold\": 0.97}Each patch mutation takes a monitor's node_id an a set input that contains the properties of the monitor. Each mutation returns the monitor that has been modified - there is no need to re-query for the data! View an example Colab below.Google ColaboratoryPatching Drift MonitorsNotice that the mutations above make use of naming a query and using variables to make the mutations re-usable.  This is a very powerful abstraction and will help you construct maintainable queries and mutations. See GraphQL docs\u200bDeleting MonitorsDeleting monitors using a mutation simply requires you to know the ID of the monitor you want to delete.mutation { deleteMonitor(input: {monitorId: \"monitor_id\"}) { clientMutationId }}Muting MonitorsYou can mute a monitor by using the generic patchMonitor or a specific mutation like patchDriftMonitor, patchPerformanceMonitor, or patchDataQualityMonitor.Generic mutationSpecific mutationmutation { patchMonitor( input: { monitorId: \"monitor_id\" set: { notificationsEnabled: false } }) { clientMutationId }}mutation { patchMonitor( input: { monitorId: \"monitor_id\" set: { notificationsEnabled: false } }) { clientMutationId }}Creating MonitorsIn most cases, the Arize platform will provide you with the best experience for creating monitors as the UI gives you a live preview of your monitor as you fill out its configuration. Additionally, Arize's managed monitors, auto-thresholding capabilities, and model baselines can often provide great monitoring coverage for your models. \n\nHowever, there may be cases where you would like to create a known set of custom monitors that track a specific cohort (filtered dataset) of features or a set of monitors that track a specific tag. Programmatically creating monitors can provide you the flexibility you need so you can ensure sufficient monitoring coverage.\n\nLet's suppose you have a lending model and you would like to exhaustively monitor the performance of the model for all 50 states. You may want to create a re-usable mutation that looks something like mutation createPerformanceMonitorForState($state: String!){ createPerformanceMonitor( input: { modelId: \"model_id\",  operator: lessThan,  performanceMetric: accuracy,  dynamicAutoThreshold: { stdDevMultiplier: 1.2 } filters: [{ dimensionType: featureLabel, operator: equals name: \"stateName\" values: [$state] }], contacts: [{ notificationChannelType: email, emailAddress: \"[email\u00a0protected]\" }] } ) { monitor { id } }}Notice that we have used a variable to pass in a state to the createPerformanceMonitor mutation. We now can loop over all 50 states, invoke this mutation and get 100% coverage for all 50 states. The end result will be 50 monitors that will alert you when the performance dips below the specified threshold.ThresholdingTwo different variants of thresholds are supported: fixed thresholds and dynamic auto thresholds. Fixed thresholds are a great fit when you explicitly know when you would like the monitor to fire. However, if you would like the monitor to automatically calculate a threshold for you, you can supply an auto-threshold configuration. Note that by default, auto thresholds are enabled with a standard deviation multiplier of 2.Auto ThresholdManual ThresholddynamicAutoThreshold: { stdDevMultiplier: 2}threshold: 0.01This configuration will", "start_char_idx": 0, "end_char_idx": 7604, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "278babb4-b596-4355-9cb7-3b66e61f72ab": {"__data__": {"id_": "278babb4-b596-4355-9cb7-3b66e61f72ab", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "118db4c0-2d07-4a21-9282-6e9e0b9f7e89", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "hash": "351d94ee58b42b68dc1bd5601005e09c03d24f7535b71442512965c17879a675"}, "2": {"node_id": "68a50699-9944-4d40-acd7-fbc0aaf7123d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}, "hash": "70ff91d54c6efb7c6dfba1262d52fc8feffea4e7e646dcba8ece301a7d70066f"}}, "hash": "0fa261431f48d590f36fc56dfdf1e9a58d8fbff24a6e04c02999ad72d80c27b8", "text": "set your threshold to mean +/- (stdDevMultiplier * stdDev) of a historical sample. The +/- part of the threshold calculation is determined by the operator.Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. Monitor FiltersThe filters list lets you filter down the metric you are monitoring down to a cohort of inferences. It lets you filter down the data you are monitoring by features, tags, and actuals. Here are some examples:Features and TagsPredictionsActualsGraphQL Typefilters: [ { dimensionType: featureLabel, name: \"stateName\" operator: equals values: [\"california\"] },  { dimensionType: tagLabel, name: \"business_impact_score\" operator: greaterThan values: [\"2\"] }]filters: [ { dimensionType: predictionClass, operator: equals values: [\"fraud\"] },  { dimensionType: predictionScore, operator: lessThan values: [\"0.7\"] }]filters: [ { dimensionType: actualClass, operator: equals values: [\"fraud\"] },  { dimensionType: actualScore, operator: lessThan values: [\"0.7\"] }]\"\"\"Filters for a particular model's inference data\"\"\"input DimensionFilterInput { \"\"\"The part of the model to filter on.\"\"\" dimensionType: DimensionFilterType!\u200b \"\"\"The operator of the filter.\"\"\" operator: ComparisonOperator!\u200b \"\"\"Required when specifying a tag or a feature label filter.\"\"\" name: String\u200b \"\"\"The values to match on.\"\"\" values: [String!]!}Note that numeric filter values are passed in as strings but they must be parsable as numbers.Drift Monitor BaselinesDrift is monitored by comparing your model's current distribution to a baseline distribution. For more information on baselines and how to choose a baseline, refer to our documentation here. There are a few ways to set a baseline using our API:Model BaselineCustom Moving BaselineCustom Fixed BaselineA model baseline refers to the baseline used for all monitors in a model. Your model is preset with a baseline defined by a moving time range of your model's production data for 17 days. mutation { createDriftMonitor(input: { modelId: \"model_id\" dimensionCategory: predictionClass name: \"Drift Monitor using Moving Custom Baseline\" operator: greaterThan driftMetric: psi baseline: { useModelPrimaryBaseline: true, } }) { monitor { uri } }}\u200bCustom baselines can be set for individual monitors separate of the overall model baseline. In this case, the baseline utilizes a moving time window. mutation { createDriftMonitor(input: { modelId: \"model_id\" dimensionCategory: predictionClass name: \"Drift Monitor using Moving Custom Baseline\" operator: greaterThan driftMetric: psi baseline: { useModelPrimaryBaseline: false, movingWindowSeconds: 604800, // 1 week movingWindowDelaySeconds: 864000, // 10 days } }) { monitor { uri } }}Custom baselines can be set for individual monitors separate of the overall model baseline. In this case, the baseline utilizes a fixed time window. mutation { createDriftMonitor(input: { modelId: \"model_id\" dimensionCategory: predictionClass name: \"Drift Monitor using Fixed Custom Baseline\" operator: greaterThan driftMetric: psi baseline: { useModelPrimaryBaseline: false, fixedStartDate: \"2020-12-23T04:59:59.999Z\", fixedEndDate: \"2021-12-23T04:59:59.999Z\", } }) { monitor { uri } }}Google ColaboratoryCreating Performance MonitorsQuerying for IntegrationsIntegrations belong to a Model and thus also belong to a Space. Because of this, you can either query for monitors off of a Model node or a Space node.The model or space id is in the url when you visit the corresponding page. The format looks like this: spaces/:space_id/models/:model_id.You can also query for a list of models given the space id. More details here.Query by ModelQuery by Spacequery { node(id: \"model_id\") { ... on Model { monitors(first: 50) { edges { node { id name monitorCategory } } } } }}query { node(id: \"space_id\") { ... on Space { monitors(first: 50) { edges { node { id name monitorCategory } } } } }}\u200bMonitoring AlertsMonitors surface potential issues with performance and data, sending real-time alerts so you can take immediate action. Learn how to programmatically update email alerts and integrate with other altering systems. Setting Monitor Alerting ContactsYou can update either an email or paging service your monitor alerts by using the generic patchMonitor or a specific mutation such as: patchDriftMonitor, patchPerformanceMonitor, or patchDataQualityMonitor. To view and set up external integrations see below.Generic mutationmutation { patchMonitor( input: $input) { clientMutationId }}variables{ \"monitorId\": \":monitor_id\", \"set\": { \"contacts\": [ { \"emailAddress\": \"[email\u00a0protected]\", \"notificationChannelType\": \"email\" }, { \"integrationKeyId\": \":integration_id\", \"notificationChannelType\": \"integration\" } ] }}Alerting IntegrationsNatively integrate with an alerting service to identify and resolve issues faster. Learn more about our alerting integrations here. Querying Current IntegrationsIntegrations belong to an AccountOrganization, thus belonging to an Account. Because of this, you must query for integrations off of an AccountOrganization node.You can find the account organization in the url organizations/:account_organization_id/QueryCreatePatchDeleteTest Integrationquery GetIntegrationsForOrganization { node(id: \"account_organization_id\") { ... on AccountOrganization { integrations { id providerName name } } }}\u200bmutation CreateIntegrationKey($input: CreateIntegrationKeyInput!) { createIntegrationKey(input: $input) { integrationKey { providerName name id } }}variables{ \"input\": { \"providerName\": \"provider_name\", \"accountOrganizationId\": \"account_organization_id\", \"serviceName\": \"your_custom_service_name\", \"apiKey\": \"api_key_from_provider\" }}mutation PatchIntegrationKey($input: PatchIntegrationKeyInput!) { patchIntegrationKey(input: $input) { integrationKey { providerName name id } }}variables{ \"input\": { \"integrationKeyId\": \"integration_key_id\", \"set\": { \"serviceName\": \"new custom service name\", \"apiKey\": \"new_api_key_from_provider\" } }}mutation DeleteIntegrationKey { deleteIntegrationKey(input: {integrationKeyId: \"integration_key_to_delete\"}) { integrationKey { providerName name id } }}\u200bmutation { testIntegrationKey( input: { integrationKeyId: \"integration_key_id\" } ) { statusCode } }ExamplesAPI Use CasesExample ColabsPatching Drift Monitors\u200bColab\u200bCreating Performance Monitors\u200bColab\u200bCreating Data Quality Monitors\u200bColab\u200bCreating Drift Monitors\u200bColab\u200b\u200bPreviousExample Use CasesNextModels APILast modified 2mo agoOn this pageQuerying for MonitorsUpdating / Patching MonitorsDeleting MonitorsMuting MonitorsCreating MonitorsQuerying for IntegrationsMonitoring AlertsAlerting IntegrationsExamplesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7605, "end_char_idx": 14503, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0f4ad5a5-528f-489a-93aa-45f993aa8d95": {"__data__": {"id_": "0f4ad5a5-528f-489a-93aa-45f993aa8d95", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/resource-limitations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a7d4d2bd-e685-4663-b7dc-dda2622a9237", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/resource-limitations"}, "hash": "a0003c8e0123221b4d8650a7fcef2fddc336caf164eb8e5e61d1aa2c9fac4d1e"}}, "hash": "5d4a86f9f82ec48b55d2fa1a6cc75b312bc9c366f4910dbfd11c8e4a5d772a16", "text": "Resource Limitations - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookResource LimitationsThe Arize GraphQL API has limitations in place to protect against excessive or abusive calls to our servers.Pagination EnforcementCertain connections require a first or last argument to be passed in to avoid massive fan-out queries. For these types of queries, you will encounter an error indicating that you must set a page size that is under a certain number. For more details about pagination and GraphQL, please consult this guide.\u200bRate LimitThere are simple frequency limitations placed on the Arize GraphQL API to avoid abusive behavior. Queries are limited to 100 queries per minute and mutations are limited to 300 per minute. A good rule of thumb is to avoid more than 100 requests a minute and to avoid massive parallel jobs.Complexity LimitWith GraphQL, one query can replace multiple. A single complex GraphQL query could return data equivalent to thousands of REST requests. This means the query rate limit does not sufficiently represent the computational costs on our servers.  To accurately represent the server cost of a query, the GraphQL API calculates a call's complexity score based on the query itself. As long as your query falls under our complexity cost limit of 1000, you can execute this level of query. \u200bCheck the complexity limit and cost for a given query in the explorer by specifying the rateLimit node. Calculating ComplexityNote: The minimum cost of a call to the GraphQL API is 1, representing a single request.Each node equates to 1 complexity point. This includes the estimated nodes returned from connections.Each node field defaults to 1 complexity point. Below is an example query and complexity score calculation:query { node(id:\"U3BhN226MQ==\") { ... on Space{ name monitors(first: 50, monitorCategory:drift){ edges { node { name threshold status } } } } }}Calculation:1  Space node \n            +\n1 Space field (name) \n            +\n(50 Monitors X  5 Monitor Fields (name, threshold, status, edges, node )1+1+(50\u22175)=2521+1 + (50 * 5) = 2521+1+(50\u22175)=252Total Query Cost = 252Returning a call's complexity costWith the GraphQL API, you can check the complexity cost for a given query by querying fields on the rateLimit object:query { rateLimit { limit cost }}The limit field returns the maximum number of points the client is permitted to consume for a given callThe cost field returns the point cost for the current callHaving trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousCustom Metrics APINextAPI ChangelogLast modified 10mo agoOn this pagePagination EnforcementRate LimitComplexity LimitSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4491, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "fa43a101-31a6-43a0-96f3-01b37a0ed21a": {"__data__": {"id_": "fa43a101-31a6-43a0-96f3-01b37a0ed21a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "ae9d966f8a6986f5140e4a22097ba9f2b68ce3be4ed0a381bf1ca7dbcacbf17d"}, "3": {"node_id": "9b512b54-d163-481e-8a3b-1e28e16b0059", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "82b7d3defce577d082ba64d3bbe82e4e042650155097824db0a3cedccba68788"}}, "hash": "8878a806b4e02f69ec28814f7e958451d03e6c640d0bd54670a89c40c250789d", "text": "bulkLog - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookbulkLogCall arize.bulkLog to publish the features, predicted label, actual, and SHAP for a single data point to Arize for monitoring, analysis, and explainability in bulk.OverviewUse the initialized Arize client to call  arize.bulkLog() with collections of predicted labels, observed actuals, their feature inputs, their shap values, and corresponding prediction ids. Once records are sent to Arize's platform, you'll be able to visualize and analyze data holistically or within aggregated slices.arize.bulkLog() returns a Response. You can await on the Response to complete to ensure successful delivery of records.When logging a prediction for the first time for a new model, we classify the model in the Arize platform based on the data type of the prediction.For more information on model schema discovery, visit here:What Is A Model SchemaAPI<T> Response bulkLog(\n   final String modelId, \n   final String modelVersion,\n   final List<String> predictionIds,\n   final List<Map<String, ?>> features,\n   final List<Map<String, ?>> tags,\n   final List<Map<String, Embedding>> embeddingFeatures,\n   final List<T> predictionLabels,\n   final List<T> actualLabels,\n   final List<Map<String, Double>> shapValues\n   final List<Long> predictionTimestamps) throws IOException, IllegalArgumentException;Important: If multiple iterable arguments (i.e prediction, actual, and explainability) are passed in the same call, they must be (1) the same length, (2) map to the same predictionIds by entry.API ArgumentsParamaterData TypeDescription\u200bmodelIdStringThe unique identifier for your model.RequiredmodelVersionStringUsed to group together a subset of predictions and actuals for a given model_id.Required for logging predictions. Optional for logging actuals or shap values.  predictionIdsList<Strings>Unique identifiers for all your bulk predictions contained in a List<Strings>Important: The values are used to match predictions to actual labels or feature importances (SHAP) in the Arize platform.RequiredfeaturesList<Map<String, ?>>Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>List of Maps containing human readable and debuggable model features. Keys must be Strings and values one of: String, int, long, short, double, float, boolean, List<String>OptionalembeddingFeaturesMap<String, Embedding>Map containing human readable and debuggable model embedding features. Map keys must be String and values EmbeddingOptionaltagsMap<String, ?> Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>Map containing human readable and debuggable model features. Map keys must be String and values one of: String, int, long, short, double, float, boolean, List<String>OptionalpredictionLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe predicted labels for your given model inputs contained in a List<T>Important: If sent in as an argument, entries are matched respectively to the entries in prediction ids, feature values, and feature importances in the same index. Important: Must have the same number of elements as feature, actuals, and importances is all sent together.OptionalactualLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe actual observed labels for a given model input. Important: If passed together in a single  call with predictionLabels, both inputs must have the same shape. Important: If model is Score Categorical, Arize.ScoreCategorical object should be passed in with corresponding predictedLabel, probabilityScore.OptionalshapValuesList<Map<String, Double>>The SHAP value sets for a set of predictions. SHAP value sets are correspond to the prediction ids with the same index.OptionalpredictionTimestampsList<int>List of int representing Unix epoch time in seconds, set to overwrite the timestamp for prediction.If null, defaults to using the current timestamp.Important: Future and Historical predictions are supported up to 1 year from current wall clock time. OptionalSample Codeimport com.arize.ArizeClient;import com.arize.Response;import com.arize.types.Embedding;\u200b// You only need to instantiate the client oncefinal ArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\")); final List<Map<String, ?>> features = new ArrayList<Map<String, ?>>();features.add(new HashMap<String, Object>() {{ put(\"days\", 5); put(\"is_organic\", 1);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 3); put(\"is_organic\", 0);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 7); put(\"is_organic\", 0);}});\u200bfinal List<Map<String, Embedding>> embeddingFeatures = new ArrayList<Map<String, Embedding>>();embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.5), Arrays.asList(\"test\", \"token\", \"array\"), \"https://example.com/image.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"this\", \"is\"), \"https://example.com/image_3.jpg\"));}});embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(0.0, 0.6), Arrays.asList(\"another\", \"example\"), \"https://example.com/image_2.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(0.1, 1.0), Arrays.asList(\"an\", \"example\"), \"https://example.com/image_4.jpg\"));}});embeddingFeatures.add(new HashMap<String,", "start_char_idx": 0, "end_char_idx": 6973, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9b512b54-d163-481e-8a3b-1e28e16b0059": {"__data__": {"id_": "9b512b54-d163-481e-8a3b-1e28e16b0059", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "ae9d966f8a6986f5140e4a22097ba9f2b68ce3be4ed0a381bf1ca7dbcacbf17d"}, "2": {"node_id": "fa43a101-31a6-43a0-96f3-01b37a0ed21a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "8878a806b4e02f69ec28814f7e958451d03e6c640d0bd54670a89c40c250789d"}, "3": {"node_id": "5a4d6dbe-974e-439a-ac7a-afb5a1406543", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "d14e29e7840f85b95e3c85f811cb114de6265455aef996c6b507f06bb9bd5549"}}, "hash": "82b7d3defce577d082ba64d3bbe82e4e042650155097824db0a3cedccba68788", "text": "Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"third\"), \"https://example.com/image_3.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.4), Arrays.asList(\"token\", \"array\"), \"https://example.com/image_5.jpg\"));}});\u200bfinal List<Map<String, ?>> tags = new ArrayList<Map<String, ?>>();tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 5); put(\"my business metric\", 1);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 3); put(\"my business metric\", 0);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 7); put(\"my business metric\", 8);}});\u200bfinal List<Map<String, Double>> shapValues = new ArrayList<>();shapValues.add(new HashMap<String, Double>(){{ put(\"days\", 1.0); put(\"is_organic\", -1.5);}});shapValues.add(new HashMap<String, Double>(){{ put(\"days\", 1.0); put(\"is_organic\", -1.1);}});shapValues.add(new HashMap<String, Double>(){{ put(\"days\", 1.0); put(\"is_organic\", -1.1);}});\u200bfinal List<String> labels = new ArrayList<String>(Arrays.asList(\"pear\", \"banana\", \"apple\"));final List<String> predictionIds = new ArrayList<String>(Arrays.asList(UUID.randomUUID().toString(), UUID.randomUUID().toString(), UUID.randomUUID().toString()));\u200bfinal Response asyncResponse = arize.bulkLog(\"exampleModelId\", \"v1\", predictionIds, features, embeddingFeatures, tags, labels, null, shapValues,null);\u200b// This is a blocking call similar to future.get()asyncResponse.resolve();\u200b// Check that the API call was successfulswitch (asyncResponse.getResponseCode()) { case OK: // TODO: Success! System.out.println(\"Success!!!\"); break; case AUTHENTICATION_ERROR: // TODO: Check to make sure your Arize API KEY and Space key are correct break; case BAD_REQUEST: // TODO: Malformed request System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); case NOT_FOUND: // TODO: API endpoint not found, client is likely malconfigured, make sure you // are not overwriting Arize's endpoint URI break; case UNEXPECTED_FAILURE: // TODO: Unexpected failure, check for a reason on response body System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); break;}\u200bSystem.out.println(\"Response Code: \" + asyncResponse.getResponseCode());System.out.println(\"Response Body: \" + asyncResponse.getResponseBody());\u200b// Don't forget to shutdown the client with your application shutdown hook.arize.close();System.out.println(\"Done\");Sample Code - Sending Data for Ranking ModelsArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\"));\u200bfinal List<String> predictionIds =        new ArrayList<>(                Arrays.asList(                        UUID.randomUUID().toString(),                        UUID.randomUUID().toString(),                        UUID.randomUUID().toString(),                        UUID.randomUUID().toString(),                        UUID.randomUUID().toString(),                        UUID.randomUUID().toString()));\u200b\u200bfinal List<ArizeClient.Ranking> predictionLabels =        Arrays.asList(                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"XX\").setPredictionScore(9.8).setRank(1).build(),                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"XX\").setPredictionScore(9.5).setRank(2).build(),                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"XX\").setPredictionScore(9.0).setRank(3).build(),                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"YY\").setPredictionScore(9.7).setRank(1).build(),                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"YY\").setPredictionScore(9.2).setRank(2).build(),                new ArizeClient.Ranking.RankingBuilder().setPredictionGroupId(\"YY\").setPredictionScore(8.0).setRank(3).build()        );\u200bfinal List<ArizeClient.Ranking> actualLabels =        Arrays.asList(                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Arrays.asList(\"click\", \"purchase\")).build()).build(),                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Collections.singletonList(\"click\")).build()).build(),                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Collections.singletonList(\"no-event\")).build()).build(),                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Collections.singletonList(\"click\")).build()).build(),                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Collections.singletonList(\"no-event\")).build()).build(),                new ArizeClient.Ranking.RankingBuilder().setRelevanceScore(1).setRelevanceLabels(MultiValue.newBuilder().addAllValues(Arrays.asList(\"click\", \"purchase\")).build()).build()\u200b        );final List<Map<String, ?>> tags = new ArrayList<>();for (ArizeClient.Ranking predictionLabel : predictionLabels) {    tags.add(new HashMap<String, Object>() {        {            put(\"Rank\", predictionLabel.getRank());        }    });}\u200bfinal Response asyncResponse =        arize.bulkLog(", "start_char_idx": 6974, "end_char_idx": 12286, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5a4d6dbe-974e-439a-ac7a-afb5a1406543": {"__data__": {"id_": "5a4d6dbe-974e-439a-ac7a-afb5a1406543", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "ae9d966f8a6986f5140e4a22097ba9f2b68ce3be4ed0a381bf1ca7dbcacbf17d"}, "2": {"node_id": "9b512b54-d163-481e-8a3b-1e28e16b0059", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}, "hash": "82b7d3defce577d082ba64d3bbe82e4e042650155097824db0a3cedccba68788"}}, "hash": "d14e29e7840f85b95e3c85f811cb114de6265455aef996c6b507f06bb9bd5549", "text": "               \"exampleModelId\",                \"v1\",                predictionIds,                null,                null,                tags,                predictionLabels,                actualLabels,                null,                null); // This is a blocking call similar to future.get()asyncResponse.resolve();Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviouslogNextlogValidationRecordsLast modified 4mo agoOn this pageOverviewAPIAPI ArgumentsSample CodeSample Code - Sending Data for Ranking ModelsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 12287, "end_char_idx": 13067, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "06a637df-0553-4e55-8063-7a859c308a25": {"__data__": {"id_": "06a637df-0553-4e55-8063-7a859c308a25", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/constructor"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "70c500cb-9350-476a-b085-b5869f8a655b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/constructor"}, "hash": "8361dfba877092d046567b165c6edeb0de780e6a287656db4ae507f61c753c21"}}, "hash": "7139da13ee7fb5b95f0e2e987fb872036ded1c78b412d385da55a0fb598fa875", "text": "Constructor - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookConstructorCall `new Arize()` to initialize the Arize client prior to publishing prediction and actual recordsOverviewIf using version < 1.0.0, the space_key argument is calledorganization_keyInstantiating the client with Arize(API_KEY, SPACE_KEY) returns a client object you can use to log individual records arize.log(), records in bulk arize.logBulk() , validation records arize.logValidationRecords(), and training records arize.logTrainingRecords() to Arize. You need only instantiate the client once to initialize a session. Sessions are tied to a specific space, however, you can log records to any model ID and version in your space.Instantiation ArgumentsArgumentTypeDescriptionapi_keyStringArize-provided api key associated with your service/spacespace_keyStringArize-provided identifier for relating records to a spaceCode Exampleimport com.arize.ArizeClient;\u200bArizeClient arize = new ArizeClient(\"ARIZE_API_KEY\", \"SPACE_KEY\");Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelAPI Reference - PreviousJava SDKNextlogLast modified 1yr agoOn this pageOverviewInstantiation ArgumentsCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2881, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e3381666-8a88-43c2-974f-1553477edd03": {"__data__": {"id_": "e3381666-8a88-43c2-974f-1553477edd03", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e7638f3b-a378-455b-b84d-a42828b1f875", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "hash": "09656a4def3348c4d0ffb592aeb70c9ec7df7c8bf0297300b3fb79ebcf68a8b6"}, "3": {"node_id": "3c1fad62-c326-421b-9ccf-e9f348454393", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "hash": "a79bc71523d3cc97dadf45532b986927c5692f9431b83c44d2708453b69add2b"}}, "hash": "990de14e19860a1049a1f4a74e317d6bae3fba45ec010a8eb5dba01708263b4b", "text": "log - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBooklogCall arize.log to publish the features, predicted label, actual observed label, and SHAP for a single data point to Arize for monitoring, analysis, and explainability.Use the initialized Arize client to call  arize.log() with a predicted label, predicted actual, their feature inputs, their shap values, and a corresponding prediction id. Once records are sent to Arize's platform, you'll be able to visualize and analyze data holistically or within aggregated slices.arize.log() returns a  Response. You can await on the Response to complete to ensure successful delivery of records.When logging a prediction for the first time for a new model, we classify the model in the Arize platform based on the data type of the prediction.For more information on model schema discovery, visit here:What Is A Model SchemaAPI<T> Response log(   final String modelId,   final String modelVersion,    final String predictionId,   final Map<String, ?> features,   final Map<String, ?> tags,   final Map<String, Embedding> embeddingFeatures,   final T predictionLabel,   final T actualLabel,   final Map<String, Double> shapValues,   long predictionTimestamp) throws IllegalArgumentExceptionArgument, IOExceptionAPI ArgumentsArgumentType(s)DescriptionRequiredmodelIdStringCostumer provided unique identifier for a given model.YmodelVersionStringUsed to group together a subset of predictions and actuals for a given model_id. If null is passes, a prediction will only be associated with a model id with no version.YpredictionIdStringUnique string identifier for specific label. Must match a previously sent Prediction record.YfeaturesMap<String, ?>Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>Map containing human readable and debuggable model features. Map keys must be String and values one of: String, int, long, short, double, float, boolean, List<String>OptionalembeddingFeaturesMap<String, Embedding>Map containing human readable and debuggable model embedding features. Map keys must be String and values Embedding\u200btagsMap<String, ?> Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>Map containing human readable and debuggable model features. Map keys must be String and values one of: String, int, long, short, double, float, boolean, List<String>OptionalpredictionLabelString, boolean, int, long, short, float, doubleThe predicted label for a given model input (associated via predictionId).OptionalactualLabelString, boolean, int, long, short, float, doubleThe actual label for a given model input (associated via predictionId)OptionalshapValuesMap<String, Double>Map keys must be String and match the names of the features used in the prediction; values must be Double.OptionalpredictionTimestamplongIf long representing Unix epoch time in seconds, set overwrite the timestamp for prediction.If null, default to current timestamp.Important: Future and Historical predictions are supported up to 1 year from current wall clock time.OptionalSample Code (Categorical)import com.arize.ArizeClient;import com.arize.Response;import com.arize.types.Embedding;\u200bMap<String, String> features = new HashMap<>();features.put(\"key\", \"value\");\u200bMap<String, Embedding> embeddingFeatures = new HashMap<>();embeddingFeatures.put( \"embedding_feature_key\", new Embedding( Arrays.asList(1.0, 0.5), Arrays.asList(\"test\", \"token\", \"array\"), \"https://example.com/image.jpg\")); Map<String, String> tags = new HashMap<>();tags.put(\"tag_key\", \"tag_value\");\u200bArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\"));\u200bResponse asyncResponse = arize.log(\"exampleModelId\", \"v1\", UUID.randomUUID().toString(), features, embeddingFeatures, tags, \"pear\", null, null, 0);\u200b// This is a blocking call similar to future.get()asyncResponse.resolve();\u200b// Check that the API call was successfulswitch (asyncResponse.getResponseCode()) { case OK: // TODO: Success! System.out.println(\"Success!!!\"); break; case AUTHENTICATION_ERROR: // TODO: Check to make sure your Arize API KEY and Space key are correct break; case BAD_REQUEST: // TODO: Malformed request System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); case NOT_FOUND: // TODO: API endpoint not found, client is likely malconfigured, make sure you // are not overwriting Arize's endpoint URI break; case UNEXPECTED_FAILURE: // TODO: Unexpected failure, check for a reason on response body System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); break;}\u200b// Don't forget to shutdown the client with your application shutdown hook.arize.close();Sample Code - Score Categoricalimport com.arize.ArizeClient;import com.arize.Response;import com.arize.types.Embedding;\u200bMap<String, String> features = new HashMap<>();features.put(\"key\", \"value\");\u200bMap<String, Embedding> embeddingFeatures = new HashMap<>();embeddingFeatures.put( \"embedding_feature_key\", new Embedding( Arrays.asList(1.0, 0.5), Arrays.asList(\"test\", \"token\", \"array\"), \"https://example.com/image.jpg\")); Map<String, String> tags = new HashMap<>();tags.put(\"tag_key\", \"tag_value\");\u200bArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\"));\u200b// Score Categorical LabelArizeClient.ScoredCategorical scoreLabel = new ArizeClient.ScoredCategorical(\"Categorical Label\", 20.21);Response asyncResponse = client.log(\"modelId\", \"modelVersion\", \"predictionId\", features, embeddingFeatures, tags, scoreLabel, null, null, 0);\u200b// This is a blocking call similar to", "start_char_idx": 0, "end_char_idx": 7049, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3c1fad62-c326-421b-9ccf-e9f348454393": {"__data__": {"id_": "3c1fad62-c326-421b-9ccf-e9f348454393", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e7638f3b-a378-455b-b84d-a42828b1f875", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "hash": "09656a4def3348c4d0ffb592aeb70c9ec7df7c8bf0297300b3fb79ebcf68a8b6"}, "2": {"node_id": "e3381666-8a88-43c2-974f-1553477edd03", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}, "hash": "990de14e19860a1049a1f4a74e317d6bae3fba45ec010a8eb5dba01708263b4b"}}, "hash": "a79bc71523d3cc97dadf45532b986927c5692f9431b83c44d2708453b69add2b", "text": "future.get()asyncResponse.resolve();\u200b// Check that the API call was successfulswitch (asyncResponse.getResponseCode()) { case OK: // TODO: Success! System.out.println(\"Success!!!\"); break; case AUTHENTICATION_ERROR: // TODO: Check to make sure your Arize API KEY and Space key are correct break; case BAD_REQUEST: // TODO: Malformed request System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); case NOT_FOUND: // TODO: API endpoint not found, client is likely malconfigured, make sure you // are not overwriting Arize's endpoint URI break; case UNEXPECTED_FAILURE: // TODO: Unexpected failure, check for a reason on response body System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); break;}\u200b// Don't forget to shutdown the client with your application shutdown hook.arize.close();Sample Code - Sending in Numeric Sequences for Ranking ModelsThe following code snippet highlights the use of the ScoredCategorical constructor for including a numeric sequence in the actualScoreLabelimport com.arize.ArizeClient.ScoredCategorical;\u200bMap<String, String> features = new HashMap<>();features.put(\"key\", \"value\");\u200b// Score Categorical LabelScoredCategorical predictionScoreLabel = new ScoredCategorical(\"Categorical Label\", 20.21);ScoredCategorical actualScoreLabel = new ScoredCategorical(\"relevant\", 4.13, Arrays.asList(0.12, 0.23, 0.34))\u200bResponse response = client.log(\"modelId\", \"modelVersion\", \"predictionId\", features, predictionScoreLabel, actualScoreLabel, null, 0);\u200b// This is a blocking call similar to future.get()asyncResponse.resolve();Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousConstructorNextbulkLogLast modified 1yr agoOn this pageAPIAPI ArgumentsSample Code (Categorical)Sample Code - Score CategoricalSample Code - Sending in Numeric Sequences for Ranking ModelsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7050, "end_char_idx": 9134, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d73071d9-026f-46f2-abb4-aa65df3ca774": {"__data__": {"id_": "d73071d9-026f-46f2-abb4-aa65df3ca774", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0f548f54-6b44-41c2-b277-f1b82a519347", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "hash": "ee3c8892fc7b9878692fa6a229c8d891e3ebf1a8351c9fe528fd4720fc06a4c2"}, "3": {"node_id": "e6b458ed-bca6-4700-abd4-aa3dff0b96c5", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "hash": "4b7a2cda5924a34a646f5f6691261647eb40e7ee7ace64dffb754a8e16e89b5d"}}, "hash": "39747e699fa9415951562adf028336f38f2b2cdf5cd68162996528c9627cb58f", "text": "logTrainingRecords - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBooklogTrainingRecordsOverviewUse the initialized Arize client to call  arize.logTrainingRecords() with collections of predicted and actual labels, its feature inputs, and corresponding prediction ids. Once records are sent to Arize's platform, you'll be able to visualize and analyze data holistically or within aggregated slices and use this data to compare against your production and validation results.arize.logTrainingRecords() returns a Response. You can await on the Response to complete to ensure successful delivery of records.When logging a prediction for the first time for a new model, we classify the model in the Arize platform based on the data type of the prediction. For more information on model schema discovery, visit here:What Is A Model SchemaThese are training \"inferences\", the response of your model to training data or a sample of training data. It is not just the training data set. Inferences include the prediction output of the model and data inputs - they give the Arize platform the ability to compare the models response (evaluations) to data versus production.Different model versions will have different responses to the same training data and capturing inferences allows Arize to evaluate the response.API<T> Response logTrainingRecords( final String modelId,  final String modelVersion, final List<Map<String, ?>> features, final List<Map<String, ?>> tags, final List<Map<String, Embedding>> embeddingFeatures, final List<T> predictionLabels, final List<T> actualLabels, final List<Long> predictionTimestamps) throws IOException, IllegalArgumentException;API argumentsParamaterData TypeDescription\u200bmodelIdStringThe unique identifier for your model.RequiredmodelVersionStringUsed to group together a subset of predictions and actuals for a given model_id.RequiredfeaturesList<Map<String, ?>>Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>List of Maps containing human readable and debuggable model features. Keys must be Strings and values one of: String, int, long, short, double, float, boolean, List<String>OptionalembeddingFeaturesMap<String, Embedding>Map containing human readable and debuggable model embedding features. Map keys must be String and values EmbeddingOptionaltagsMap<String, ?> Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>Map containing human readable and debuggable model features. Map keys must be String and values one of: String, int, long, short, double, float, boolean, List<String>OptionalpredictionLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe predicted labels for your given model inputs contained in a List<T>Important: If sent in as an argument, entries are matched respectively to the entries in prediction ids, feature values, and feature importances in the same index. Important: Must have the same number of elements as feature, actuals, and importances is all sent together.RequiredactualLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe actual observed labels for a given model input. Important: If passed together in a single  call with predictionLabels, both inputs must have the same shape. Important: If model is Score Categorical, Arize.ScoreCategorical object should be passed in with corresponding predictedLabel, probabilityScore.RequiredSample Codeimport com.arize.ArizeClient;import com.arize.Response;\u200bfinal ArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\"));\u200bfinal List<Map<String, ?>> features = new ArrayList<Map<String, ?>>();features.add(new HashMap<String, Object>() {{ put(\"days\", 5); put(\"is_organic\", 1);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 3); put(\"is_organic\", 0);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 7); put(\"is_organic\", 0);}});\u200bfinal List<Map<String, Embedding>> embeddingFeatures = new ArrayList<Map<String, Embedding>>();embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.5), Arrays.asList(\"test\", \"token\", \"array\"), \"https://example.com/image.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"this\", \"is\"), \"https://example.com/image_3.jpg\"));}});embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(0.0, 0.6), Arrays.asList(\"another\", \"example\"), \"https://example.com/image_2.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(0.1, 1.0), Arrays.asList(\"an\", \"example\"), \"https://example.com/image_4.jpg\"));}});embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"third\"), \"https://example.com/image_3.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.4), Arrays.asList(\"token\", \"array\"), \"https://example.com/image_5.jpg\"));}});\u200bfinal List<Map<String, ?>> tags = new ArrayList<Map<String, ?>>();tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 5); put(\"my business metric\", 1);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 3); put(\"my business metric\", 0);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 7); put(\"my business metric\", 8);}});\u200bfinal List<String> predictionLabels = new", "start_char_idx": 0, "end_char_idx": 6930, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e6b458ed-bca6-4700-abd4-aa3dff0b96c5": {"__data__": {"id_": "e6b458ed-bca6-4700-abd4-aa3dff0b96c5", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "0f548f54-6b44-41c2-b277-f1b82a519347", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "hash": "ee3c8892fc7b9878692fa6a229c8d891e3ebf1a8351c9fe528fd4720fc06a4c2"}, "2": {"node_id": "d73071d9-026f-46f2-abb4-aa65df3ca774", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}, "hash": "39747e699fa9415951562adf028336f38f2b2cdf5cd68162996528c9627cb58f"}}, "hash": "4b7a2cda5924a34a646f5f6691261647eb40e7ee7ace64dffb754a8e16e89b5d", "text": "ArrayList<String>(Arrays.asList(\"pear\", \"banana\", \"apple\"));final List<String> actualLabels = new ArrayList<String>(Arrays.asList(\"pear\", \"strawberry\", \"apple\"));\u200bfinal Response asyncResponse = arize.logTrainingRecords(\"exampleModelId\", \"v1\", features, embeddingFeatures, tags, predictionLabels, actualLabels);\u200b// This is a blocking call similar to future.get()asyncResponse.resolve();\u200b// Check that the API call was successfulswitch (asyncResponse.getResponseCode()) { case OK: // TODO: Success! System.out.println(\"Success!!!\"); break; case AUTHENTICATION_ERROR: // TODO: Check to make sure your Arize API KEY and Space key are correct break; case BAD_REQUEST: // TODO: Malformed request System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); case NOT_FOUND: // TODO: API endpoint not found, client is likely malconfigured, make sure you // are not overwriting Arize's endpoint URI break; case UNEXPECTED_FAILURE: // TODO: Unexpected failure, check for a reason on response body System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); break;}\u200bSystem.out.println(\"Response Code: \" + asyncResponse.getResponseCode());System.out.println(\"Response Body: \" + asyncResponse.getResponseBody());\u200b// Don't forget to shutdown the client with your application shutdown hook.arize.close();System.out.println(\"Done\");Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviouslogValidationRecordsNext - API ReferenceR SDKLast modified 4mo agoOn this pageOverviewAPIAPI argumentsSample CodeSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6931, "end_char_idx": 8701, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e142128c-14e8-40f9-8df9-720a6e69ac55": {"__data__": {"id_": "e142128c-14e8-40f9-8df9-720a6e69ac55", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "70e9ad5e-7ec6-491f-bc72-5f93e943a341", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "hash": "07f22585d23729981d000b5ba7ed93ecc83b42268768dac7e0a7b0518806f2e9"}, "3": {"node_id": "0b43ed45-9991-4187-a4e6-db816a6a1dcd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "hash": "ad4626aa1f20ad95af7f7f32eccff5013a24b3a2fb5213c8da3609e3318c72c3"}}, "hash": "12105ef3b9f0c709ec2a87bfbf38fd13e16db840be04b26ecf36e160b81b91bf", "text": "logValidationRecords - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKConstructorlogbulkLoglogValidationRecordslogTrainingRecordsR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBooklogValidationRecordsOverviewUse the initialized Arize client to call  arize.logValidationrecords() with collections of predicted and actual labels, its feature inputs, and corresponding prediction ids for a specific named batch. Once records are sent to Arize's platform, you'll be able to visualize and analyze data holistically or within aggregated slices and use this data to compare against your production and training results or use it as baseline data for monitoring your model.arize.logValidationRecords() returns a Response. You can await on the Response to complete to ensure successful delivery of records.When logging a prediction for the first time for a new model, we classify the model in the Arize platform based on the data type of the prediction.For more information on model schema discovery, visit here:What Is A Model SchemaAPI<T> Response logValidationRecords( final String modelId,  final String modelVersion, final String batchId, final List<Map<String, ?>> features, final List<Map<String, ?>> tags, final List<Map<String, Embedding>> embeddingFeatures, final List<T> predictionLabels, final List<T> actualLabels, final List<Long> predictionTimestamps) throws IOException, IllegalArgumentException; API argumentsParamaterData TypeDescription\u200bmodelIdStringThe unique identifier for your model.RequiredmodelVersionStringUsed to group together a subset of predictions and actuals for a given model_id.RequiredbatchIdStringUsed to group together a subset of records for a given model_id and model_version.RequiredfeaturesList<Map<String, ?>>Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>List of Maps containing human readable and debuggable model features. Keys must be Strings and values one of: String, int, long, short, double, float, boolean, List<String>OptionalembeddingFeaturesMap<String, Embedding>Map containing human readable and debuggable model embedding features. Map keys must be String and values EmbeddingOptionaltagsMap<String, ?> Where value can be oneOf: String, int, long, short, double, float, boolean, List<String>Map containing human readable and debuggable model features. Map keys must be String and values one of: String, int, long, short, double, float, boolean, List<String>OptionalpredictionLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe predicted labels for your given model inputs contained in a List<T>Important: If sent in as an argument, entries are matched respectively to the entries in prediction ids, feature values, and feature importances in the same index. Important: Must have the same number of elements as feature, actuals, and importances is all sent together.RequiredactualLabelsList<T> where T is oneof String, boolean, int, long, short, float, double, ScoreCategoricalThe actual observed labels for a given model input. Important: If passed together in a single  call with predictionLabels, both inputs must have the same shape. Important: If model is Score Categorical, Arize.ScoreCategorical object should be passed in with corresponding predictedLabel, probabilityScore.RequiredSample Codeimport com.arize.ArizeClient;import com.arize.Response;\u200bfinal ArizeClient arize = new ArizeClient(System.getenv(\"ARIZE_API_KEY\"), System.getenv(\"ARIZE_SPACE_KEY\"));\u200bfinal List<Map<String, ?>> features = new ArrayList<Map<String, ?>>();features.add(new HashMap<String, Object>() {{ put(\"days\", 5); put(\"is_organic\", 1);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 3); put(\"is_organic\", 0);}});features.add(new HashMap<String, Object>() {{ put(\"days\", 7); put(\"is_organic\", 0);}});\u200bfinal List<Map<String, Embedding>> embeddingFeatures = new ArrayList<Map<String, Embedding>>();embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.5), Arrays.asList(\"test\", \"token\", \"array\"), \"https://example.com/image.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"this\", \"is\"), \"https://example.com/image_3.jpg\"));}});embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(0.0, 0.6), Arrays.asList(\"another\", \"example\"), \"https://example.com/image_2.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(0.1, 1.0), Arrays.asList(\"an\", \"example\"), \"https://example.com/image_4.jpg\"));}});embeddingFeatures.add(new HashMap<String, Embedding>() {{ put(\"embedding_feature_1\", new Embedding(Arrays.asList(1.0, 0.8), Arrays.asList(\"third\"), \"https://example.com/image_3.jpg\")); put(\"embedding_feature_2\", new Embedding(Arrays.asList(1.0, 0.4), Arrays.asList(\"token\", \"array\"), \"https://example.com/image_5.jpg\"));}});\u200bfinal List<Map<String, ?>> tags = new ArrayList<Map<String, ?>>();tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 5); put(\"my business metric\", 1);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 3); put(\"my business metric\", 0);}});tags.add(new HashMap<String, Object>() {{ put(\"metadata\", 7); put(\"my business metric\", 8);}});\u200bfinal List<String> predictionLabels = new ArrayList<String>(Arrays.asList(\"pear\", \"banana\", \"apple\"));final List<String> actualLabels = new ArrayList<String>(Arrays.asList(\"pear\",", "start_char_idx": 0, "end_char_idx": 6808, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "0b43ed45-9991-4187-a4e6-db816a6a1dcd": {"__data__": {"id_": "0b43ed45-9991-4187-a4e6-db816a6a1dcd", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "70e9ad5e-7ec6-491f-bc72-5f93e943a341", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "hash": "07f22585d23729981d000b5ba7ed93ecc83b42268768dac7e0a7b0518806f2e9"}, "2": {"node_id": "e142128c-14e8-40f9-8df9-720a6e69ac55", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}, "hash": "12105ef3b9f0c709ec2a87bfbf38fd13e16db840be04b26ecf36e160b81b91bf"}}, "hash": "ad4626aa1f20ad95af7f7f32eccff5013a24b3a2fb5213c8da3609e3318c72c3", "text": "\"strawberry\", \"apple\"));\u200bfinal Response asyncResponse = arize.logTrainingRecords(\"exampleModelId\", \"v1\", \"offline-batch\", features, embeddingFeatures, tags, predictionLabels, actualLabels);\u200b// This is a blocking call similar to future.get()asyncResponse.resolve();\u200b// Check that the API call was successfulswitch (asyncResponse.getResponseCode()) { case OK: // TODO: Success! System.out.println(\"Success!!!\"); break; case AUTHENTICATION_ERROR: // TODO: Check to make sure your Arize API KEY and Space key are correct break; case BAD_REQUEST: // TODO: Malformed request System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); case NOT_FOUND: // TODO: API endpoint not found, client is likely malconfigured, make sure you // are not overwriting Arize's endpoint URI break; case UNEXPECTED_FAILURE: // TODO: Unexpected failure, check for a reason on response body System.out.println(\"Failure Reason: \" + asyncResponse.getResponseBody()); break;}\u200bSystem.out.println(\"Response Code: \" + asyncResponse.getResponseCode());System.out.println(\"Response Body: \" + asyncResponse.getResponseBody());\u200b// Don't forget to shutdown the client with your application shutdown hook.arize.close();System.out.println(\"Done\");Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousbulkLogNextlogTrainingRecordsLast modified 4mo agoOn this pageOverviewAPIAPI argumentsSample CodeSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6809, "end_char_idx": 8442, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dbd9a112-6758-4875-b19b-f6855a6edf24": {"__data__": {"id_": "dbd9a112-6758-4875-b19b-f6855a6edf24", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdlog"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d30adf46-894f-4541-a25c-c43400a511db", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdlog"}, "hash": "4e524b280ea5fe511d88f338125758dff994606a67a7a390424cd8f55f810803"}}, "hash": "31d3bdb9f373f63138cbd682b380bcdad38c21fb504f5b6b6c22378085fd9b44", "text": "Client$log() - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKClient$new()Client$log()Rest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookClient$log()Batch Logging - Designed for sending batches of data to ArizeOverviewThe Client$log() is designed for training, validation or production environment where batches of data are processed. These environments may be either a R Studio Notebook or a R server that is batch processing lots of backend data.Import and initialize Arize R client from the Arize Client$new() to call  Client$log() with a R data.frame() containing inference data. Initializing Client ExamplesORGANIZATION_KEY <- 'ORGANIZATION_KEY'API_KEY <- 'API_KEY'arize_client <- Client$new(    organization_key = ORGANIZATION_KEY,     api_key = API_KEY)\u200bParameters & Returns schema <- create_schema(  prediction_id_column_name = \"prediction_id\",  prediction_label_column_name = \"prediction_label\",  prediction_score_column_name = \"prediction_score\",  actual_label_column_name = \"actual_label\",  actual_score_column_name = \"actual_score\",  feature_column_names = features,  timestamp_column_name = \"prediction_ts\")\u200b\u200b# send training dataarize_client$log( .data_frame = df_train, .schema = schema .model_id = model_id, .model_version = model_version, .model_type = model_types$SCORE_CATEGORICAL, .environment = environments$TRAINING,)ParameterData TypeDescriptionRequired.data_framedata.framedata.frame to logRequired.schemaarize::create_schemathe schema (see ?arize::create_schema)Required.model_idcharactercharacter, id for the modelRequired.model_typeinteger1 for binary, 2 for numeric, 3 for categorical, 4 for score-categoricalRequired.environmentenvironment1 for production, 2 for validation, 3 for trainingRequired.model_versioncharactercharacter, the model versionOptional.batch_idcharactercharacter, the batch idOptional.synclogicallogical, whether to syncOptional.validatelogicallogical, whether to run validation checksOptional.pathcharactercharacter, path to use for serializationOptionalSchema AttributesAttributeData TypeDescription Requiredprediction_id_column_namecharacterColumn name for prediction_idRequiredfeature_column_namesList[character]List of column names for featuresOptionalprediction_label_column_namecharacterColumn name for prediction labelOptionalprediction_score_column_namecharacterColumn name for prediction scoresOptionalactual_label_column_namecharacterColumn name for actual labelOptionalactual_score_column_namestrColumn name for numeric sequences. Used for NDCG calculations in ranking modelsOptionaltimestamp_column_namecharacterColumn name for timestampsOptionalExamplesCheck out the Example Tutorial \u200bExample 1: Logging Features, Predictions, & Actualsmodel_id <- \"click_through_rate_categorical_vignette_R\" # This is the model name that will show up in Arizemodel_version <- \"v1.0\" # Version of model - can be any string\u200bschema <- create_schema(  prediction_id_column_name = \"id\",  feature_column_names = features,  prediction_label_column_name = \"predictions\",  prediction_score_column_name = \"CTR_predicted\",  actual_label_column_name = \"actuals\",  actual_score_column_name = \"CTR\",  timestamp_column_name = \"model_date\")\u200barize_client$log( .data_frame = df_train, .model_id = model_id, .model_version = model_version, .model_type = model_types$SCORE_CATEGORICAL, .environment = environments$TRAINING, .schema = schema)\u200bPreviousClient$new()Next - API ReferenceRest APILast modified 1yr agoOn this pageOverviewInitializing Client ExamplesParameters & Returns Schema AttributesExamplesExample 1: Logging Features, Predictions, & ActualsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5160, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "15697f82-90a9-4130-bffa-808babca9d07": {"__data__": {"id_": "15697f82-90a9-4130-bffa-808babca9d07", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdnew"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8597bae9-c2bd-41ce-ae26-8bd8d61ce816", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdnew"}, "hash": "c5a446fa19dbef1b1521cf0fd9abdcf862b2ebfe571ec2912c81b77e664999fd"}}, "hash": "e1f011171db19c4be8937f650bb6927da909c71e2bdc5852935d8de6de68c383", "text": "Client$new() - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKClient$new()Client$log()Rest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookClient$new()Call Client$new() to initialize the Arize client prior to publishing prediction and actual recordsOverviewInitializing the client with Client$new() returns a client object you can use to log predictions and actuals.You need only call Client$new() once to initialize a session. Sessions are tied to a specific space, however, you can log records for any model in your space.Keyword arguments:ArgumentInput TypeDescriptionRequiredDefault Valueapi_keycharacterthe Arize-AI api keyRequiredN/Aorganization_keycharacterthe Arize-AI organization keyRequiredN/AInitializing Client ExamplesORGANIZATION_KEY <- 'ORGANIZATION_KEY'API_KEY <- 'API_KEY'arize_client <- Client$new(    organization_key = ORGANIZATION_KEY,     api_key = API_KEY)Retrieving Space and API KeysQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelAPI Reference - PreviousR SDKNextClient$log()Last modified 1yr agoOn this pageOverviewKeyword arguments:Initializing Client ExamplesRetrieving Space and API KeysSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2726, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4bd2ac03-c738-4d36-b32c-52221946fbe6": {"__data__": {"id_": "4bd2ac03-c738-4d36-b32c-52221946fbe6", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1057fd60-2309-4564-89a6-1f037bc04e45", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates"}, "hash": "f7746dc2c88e8e6a17b7ebdc7c5b20d1ed6be081aacd956496c40a7369f991e4"}}, "hash": "a828693b8c5c5f4ff2cd2b97a29ed9a80230701199be7130dbd6c94c2b964ec0", "text": "Templates - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesModel PerformancePre-Production PerformanceFeature AnalysisWidgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookTemplatesSet up dashboards instantly using model performance, pre-production performance and feature analysis templates.OverviewTemplates are designed as starting points for dashboard and model analysis. Once a dashboard is created from a template, it can be edited and customized as desired.Template TypesClick on the templates to create new model performance, pre-production performance, and feature performance dashboards. Click on a template type below to learn more.  Model PerformancePre-Production PerformanceFeature AnalysisQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channeldashboards - PreviousCreate A DashboardNextModel PerformanceLast modified 1yr agoOn this pageOverviewTemplate TypesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2489, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "af9a2b1f-f909-4fc1-bb7e-41995316e217": {"__data__": {"id_": "af9a2b1f-f909-4fc1-bb7e-41995316e217", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c2ab1e7b-c9df-4669-8a20-b68245c034f4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets"}, "hash": "d29f89fcc44930ea45d0f1283189160931ad50e5c759adb887a10a9e9aef87cd"}}, "hash": "c57949cfb00225cff26ebe2efb7730a5a70cba1fc10ac78bb7deb6f49568aaab", "text": "Widgets - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesWidgetsDistribution WidgetsTimeseries WidgetsStatistic Widgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookWidgetsCustomize dashboards with widgetsOverviewWidgets provide an easy way to customize dashboards and perform ad hoc analysis. They can be used to build dashboards from scratch, or as a way to modify templated dashboards.Control exact size and placement of widgets on a dashboard to emphasize or deemphasize any chartAdd, remove, or edit widgets and widget parameters at any timeWidget Types:Learn more about how to use each widget type:Distribution WidgetsTimeseries WidgetsStatistic WidgetsQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousFeature AnalysisNextDistribution WidgetsLast modified 1yr agoOn this pageOverviewWidget Types:SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2432, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9ba1d5b8-21ad-415a-b528-9273c4078035": {"__data__": {"id_": "9ba1d5b8-21ad-415a-b528-9273c4078035", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9a859b43-375a-4027-9392-5eba5c9df418", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "hash": "8f44cded088dbeaa35b4089c787ed13e4c9bc5cdd479ab8f8ffb1792174a2711"}, "3": {"node_id": "a289db9f-3096-4ecc-ae37-ca91e2cbc2c8", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "hash": "3b40cd4fc61e1c3511f6437aa03a6b0e69683598d46f9bfb82dbfa329aabd22d"}}, "hash": "4d73565ddf8043150f40cbb50ffc9528d6bc9ccae56c6344da10e9e60fac498c", "text": "How to Generate Your Own Embedding - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsHow to Generate Your Own EmbeddingLet Arize Generate Your EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookHow to Generate Your Own EmbeddingEmbedding vectors are generally extracted from the activation values of one or many hidden layers of your model.Ways to obtain embedding vectorsIn general, there are many ways of obtaining embedding vectors, including:1.Word embeddings2.Autoencoder Embeddings3.Generative Adversarial Networks (GANs)4.Pre-trained EmbeddingsGiven the accessibility to pre-trained transformer models, we will focus on them. This involves using models, such as BERT or GPT-x, trained on a large dataset and made publicly available, then fine-tuning them on a specific task.Use Case ExamplesOnce established the choice of models to generate embeddings, the question is: how? The way you generate your embedding must be such that the resulting vector represents your input according to your use case.CV Image ClassificationNLP ClassificationNLP Named Entity RecognitionIf you are working on image classification, the model will take an image and classify it into a given set of categories. Each of our embedding vectors should be representative of the corresponding entire image input.First, we need to use a feature_extractor that will take an image and prepare it for the large pre-trained image model.inputs = feature_extractor( [x.convert(\"RGB\") for x in batch[\"image\"]],     return_tensors=\"pt\").to(device)Then, we pass the results from the feature_extractor to our model. In PyTorch, we use torch.no_grad() since we don't need to compute the gradients for backward propagation, we are not training the model in this example.with torch.no_grad():    outputs = model(**inputs)It is imperative that these outputs contain the activation values of the hidden layers of the model since you will be using them to construct your embeddings. In this scenario, we will use just the last hidden layer.last_hidden_state = outputs.last_hidden_state# last_hidden_state.shape = (batch_size, num_image_tokens, hidden_size)Finally, since we want the embedding vector to represent the entire image, we will average across the second dimension, representing the areas of the image.embeddings = torch.mean(last_hidden_state, 1).cpu().numpy()If you are working on NLP sequence classification (for example, sentiment classification), the model will take a piece of text and classify it into a given set of categories. Hence, your embedding vector must represent the entire piece of text.For this example, let us assume we are working with a model from the BERT family.First, we must use a tokenizer that will the text and prepare it for the pre-trained large language model (LLM).inputs = {        k: v.to(device)  for k,v in batch.items() if k in tokenizer.model_input_names}Then, we pass the results from the tokenizer to our model. In PyTorch, we use torch.no_grad() since we don't need to compute the gradients for backward propagation, we are not training the model in this example.with torch.no_grad():    outputs = model(**inputs)It is imperative that these outputs contain the activation values of the hidden layers of the model since you will be using them to construct your embeddings. In this scenario, we will use just the last hidden layer.last_hidden_state = outputs.last_hidden_state# last_hidden_state.shape = (batch_size, num_tokens, hidden_size)Finally, since we want the embedding vector to represent the entire piece of text for classification, we will use the vector associated with the classification token,[CLS], as our embedding vector. embeddings = last_hidden_state[:,0,:].cpu().numpy()If you are working on NLP Named Entity Recognition (NER), the model will take a piece of text and classify some words within it into a given set of entities. Hence, each of your embedding vectors must represent a classified word or token.For this example, let us assume we are working with a model from the BERT family.First, we must use a tokenizer that will the text and prepare it for the pre-trained large language model (LLM).inputs = {        k: v.to(device)  for k,v in batch.items() if k in tokenizer.model_input_names}Then, we pass the results from the tokenizer to our model. In PyTorch, we use torch.no_grad() since we don't need to compute the gradients for backward propagation, we are not training the model in this example.with torch.no_grad():    outputs = model(**inputs)It is imperative that these outputs contain the activation values of the hidden layers of the model since you will be using them to construct your embeddings. In this scenario, we will use just the last hidden layer.last_hidden_state = outputs.last_hidden_state.cpu().numpy()# last_hidden_state.shape = (batch_size, num_tokens, hidden_size)Further, since we want the embedding vector to represent any given token, we will use the vector associated with a specific token in the piece of text as our embedding vector. So, let token_index be the integer value that locates the token of interest in the list of tokens that result from passing the piece of text to the tokenizer. Let ex_index the integer value that locates a given example in the batch. Then,token_embedding = last_hidden_state[ex_index, token_index,:]Additional ResourcesCheck out our tutorials on how to generate embeddings for different use cases using large, pre-trained models. Use-CaseCodeNLP Multi-Class Sentiment Classification using Hugging Face\u200bColab Link\u200bNLP Multi-Class Sentiment Classification using OpenAI\u200bColab Link\u200bNLP Named Entity Recognition using Hugging Face\u200bColab Link\u200bCV Image Classification using Hugging Face\u200bColab Link\u200bEmbeddings - PreviousGenerate EmbeddingsNextLet Arize Generate Your EmbeddingsLast modified 6mo agoOn this pageUse Case ExamplesAdditional ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat", "start_char_idx": 0, "end_char_idx": 7313, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a289db9f-3096-4ecc-ae37-ca91e2cbc2c8": {"__data__": {"id_": "a289db9f-3096-4ecc-ae37-ca91e2cbc2c8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9a859b43-375a-4027-9392-5eba5c9df418", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "hash": "8f44cded088dbeaa35b4089c787ed13e4c9bc5cdd479ab8f8ffb1792174a2711"}, "2": {"node_id": "9ba1d5b8-21ad-415a-b528-9273c4078035", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}, "hash": "4d73565ddf8043150f40cbb50ffc9528d6bc9ccae56c6344da10e9e60fac498c"}}, "hash": "3b40cd4fc61e1c3511f6437aa03a6b0e69683598d46f9bfb82dbfa329aabd22d", "text": "Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7314, "end_char_idx": 7429, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "729e5c5c-bc82-4011-aff1-5d22b2c8b350": {"__data__": {"id_": "729e5c5c-bc82-4011-aff1-5d22b2c8b350", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a0ee1405-edc2-4433-8f63-e1953e1156d7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "hash": "e831470a55cb506bbf50cb75f3b95a2916ea11f3390649c18e046d52e659c828"}, "3": {"node_id": "95ce2bd7-3899-47a8-a624-3dfff646d115", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "hash": "690a63fa5b17c766345d57e49eeeded65cf01c09b7363035349a5f26f2a7c4bc"}}, "hash": "7c09ca4913303f590d8a4d37db6358b8e09cf2ac7427c806b60e99b033e7641f", "text": "Let Arize Generate Your Embeddings - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsHow to Generate Your Own EmbeddingLet Arize Generate Your EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookLet Arize Generate Your EmbeddingsOnly available in arize>=6.0.0What are Auto-Embeddings?Generating embeddings is likely another problem to solve, on top of ensuring your model is performing properly. With our Python SDK, you can offload that task to Arize and we will generate the embeddings for you. We use large, pre-trained models that will capture information from your inputs and encode it into embedding vectors. We extract the embeddings in the appropriate way depending on your use case, and we return it to you to include in your pandas DataFrame, which you then send to Arize.Auto-Embeddings works end-to-end, you don't have to worry about formatting your inputs for the correct model. By simply passing your input, an embedding will come out as a result. We take care of everything in between.How to enable Auto-Embeddings?If you want to use this functionality as part of our Python SDK, you need to install it with the extra dependencies using pip install arize[AutoEmbeddings].Supported modelsYou can use any model available in the Hugging Face Hub, public or private. If you are using a private model, you will need to authenticate with Hugging Face first. If you are using arize<7.3.0, you will have a more restricted list of supported models. You can access it by runningfrom arize.pandas.embeddings import EmbeddingGeneratorEmbeddingGenerator.list_pretrained_models()There are thousands of models available in the Hugging Face Hub. If you find one where our implementation of AutoEmbeddings breaks, please reach out to us at [email\u00a0protected] or in our community Slack!How do they work?Auto-Embeddings is designed to require minimal code from the user. We only require two steps:1.Create the generator: you simply instantiate the generator using EmbeddingGenerator.from_use_case() and passing information about your use case, the model to use, and more options depending on the use case; see examples below.2.Let Arize generate your embeddings: obtain your embeddings column by calling generator.generate_embedding() and passing the column containing your inputs; see examples below.Use Case ExamplesComputer VisionImage ClassificationObject Detectionfrom arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200bgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.CV.IMAGE_CLASSIFICATION,    model_name=\"google/vit-base-patch16-224-in21k\",    batch_size=100)df[\"image_vector\"] = generator.generate_embeddings(    local_image_path_col=df[\"local_path\"])from arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200bgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.CV.OBJECT_DETECTION,    model_name=\"facebook/detr-resnet-101\",    batch_size=100)df[\"image_vector\"] = generator.generate_embeddings(    local_image_path_col=df[\"local_path\"])Natural Language ProcessingSequence ClassificationLarge Language Models (LLMs)from arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200bgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.NLP.SEQUENCE_CLASSIFICATION,    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512,    batch_size=100)df[\"text_vector\"] = generator.generate_embeddings(text_col=df[\"text\"])from arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200bgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.NLP.SUMMARIZATION,    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512,    batch_size=100)df[\"document_vector\"] = generator.generate_embeddings(text_col=df[\"document\"])df[\"summary_vector\"] = generator.generate_embeddings(text_col=df[\"summary\"])Tabular DataArize can generate embeddings for your tabular data as well. This is a useful way to detect and debug multivariate drift. For more information, go to the docs here.from arize.pandas.embeddings import EmbeddingGenerator, UseCases\u200b# Instantiate the embeddding generatorgenerator = EmbeddingGenerator.from_use_case(    use_case=UseCases.STRUCTURED.TABULAR_EMBEDDINGS,    model_name=\"distilbert-base-uncased\",    tokenizer_max_length=512,    batch_size=100)\u200b# Select the columns from your dataframe to considerselected_cols = [...]\u200b# (Optional) Provide a mapping for more verbose column namescolumn_name_map = {...: ...}\u200b# Generate tabular embeddings and assign them to a new columndf[\"tabular_embedding_vector\"] = generator.generate_embeddings(    df,    selected_columns=selected_cols,    col_name_map=column_name_map # (OPTIONAL, can remove))Arize expects the DataFrame's index to be sorted and begin at 0. If you perform operations that might affect the index prior to generating embeddings, reset the index as follows:df = df.reset_index(drop=True)Additional ResourcesCheck out our tutorials on generating embeddings for different use cases using Arize. Use-CaseCodeNLP Sentiment Classification\u200bColab Link\u200bCV Image Classification\u200bColab Link\u200bLarge Language Models\u200bColab Link\u200bEmbeddings for Tabular Data\u200bColab Link\u200bPreviousHow to Generate Your Own EmbeddingNext - EmbeddingsEmbedding DriftLast modified 18m agoOn this pageWhat are Auto-Embeddings?How do they work?Use Case", "start_char_idx": 0, "end_char_idx": 6622, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "95ce2bd7-3899-47a8-a624-3dfff646d115": {"__data__": {"id_": "95ce2bd7-3899-47a8-a624-3dfff646d115", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a0ee1405-edc2-4433-8f63-e1953e1156d7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "hash": "e831470a55cb506bbf50cb75f3b95a2916ea11f3390649c18e046d52e659c828"}, "2": {"node_id": "729e5c5c-bc82-4011-aff1-5d22b2c8b350", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}, "hash": "7c09ca4913303f590d8a4d37db6358b8e09cf2ac7427c806b60e99b033e7641f"}}, "hash": "690a63fa5b17c766345d57e49eeeded65cf01c09b7363035349a5f26f2a7c4bc", "text": "ExamplesAdditional ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6623, "end_char_idx": 6875, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4b2034fb-7800-45ef-88e4-93c5c6fb6424": {"__data__": {"id_": "4b2034fb-7800-45ef-88e4-93c5c6fb6424", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/shap"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "58089885-f316-4164-bc99-bdde2116f371", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/shap"}, "hash": "5533bc3cd19727f2718dc45474fbbc2c709886dbbba2fc5127e924c0b2de84af"}}, "hash": "114d7c15600a2a48b78683a8a1eb0fe6cd0813eef0108d681c986c32a7850cfd", "text": "SHAP - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilitySHAPSurrogate ModelBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSHAPSHAP (Shapley Additive exPlanations) is a method used to break down individual predictions of a complex model\u200bVisit the Shapley Values Documentation here to learn more \u200bTree Shap TreeSHAP is a fast explainer used for analyzing decision tree models in the Shap python library. TreeSHAP is designed for tree-based machine learning models such as decision trees, random forests and gradient boosted trees. TreeSHAP is offered as a rapid, model-specific alternative to KernelSHAP; however, it can sometimes produce unintuitive feature attributions.\u200b\u200bNeural Network Explainer Deep explainer (deep SHAP) is an explainability technique that can be used for models with a neural network based architecture. This is the fastest neural network explainability approach and is based on running a SHAP-based version of the original deep lift algorithm. \n\u200b\u200bKernal ExplainerKernelSHAP is a slow, perturbation-based Shapley approach that theoretically works for all types of models but is rarely used by teams in the wild (at least in production). KernelSHAP tends to be way too slow to be used in practice extensively on anything but small data. It also tends to cause confusion among teams. When teams complain about SHAP being slow, usually it\u2019s because they tested KernelSHAP. \u200bCode Example# 1. Generate the Shap Values and save as Dataframeexplainer = shap.TreeExplainer(tree_model)shap_values = explainer.shap_values(X_data)shap_dataframe = pd.DataFrame(        shap_values, columns=[f\"{fn}_shap\" for fn in data[\"feature_names\"]] )\u200b# 2.Define the Schema. Link the feature column with its corresponding shap columnfeature_cols = [\"MERCHANT_TYPE\", \"ENTRY_MODE\", \"STATE\", \"MEAN_AMOUNT\", \"STD_AMOUNT\", \"TX_AMOUNT\"]shap_cols = shap_dataframe.columns\u200bschema = Schema(    prediction_id_column_name=\"prediction_id\", ...    feature_column_names= feature_cols,    shap_values_column_names=dict(zip(feature_cols, shap_cols)),)\u200b# Log the dataframe with the schema mapping response = arize_client.log(    model_id=\"sample-model-1\",    model_version= \"v1\",    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    dataframe=test_dataframe,    schema=schema,)Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelExplainability & Fairness - PreviousModel ExplainabilityNextSurrogate ModelLast modified 7mo agoOn this pageTree Shap Neural Network Explainer Kernal ExplainerCode ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4121, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3a554674-5523-4965-9e68-97292a1ccda3": {"__data__": {"id_": "3a554674-5523-4965-9e68-97292a1ccda3", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/surrogate-model"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "afae243d-1d48-4bce-be11-1730eadd5be4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/surrogate-model"}, "hash": "c5391de7730a0ff7d48dc75509294fa9e57e3521a436a413037ce28d6930ee92"}}, "hash": "93957cefe2cb1aa75bb618db0f9296f4adf8a38bce5e4a51be07e70c544ebee5", "text": "Surrogate Model - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilitySHAPSurrogate ModelBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSurrogate ModelExplainability approach designed to build a transparent model off of the predictions of an actual model.View this page for more information on surrogate model feature importance values. For an example of logging surrogate model feature importance values values, check out the Arize Surrogate Model Feature Importance tutorial.\u200b\u200bSurrogate explainability is based on the idea of training a surrogate model to mimic a blackbox model, where a surrogate model is an interpretable model trained to approximate the predictions of a black box model as closely as possible. SHAP values can then be generated from the surrogate model when the blackbox model is not available. The goal is to approximate the predictions of the black box model as closely as possible and generate feature importance values from the interpretable surrogate model.\u200bArize Python SDK (specifically the pandas logger) gives the user the option to pass a flag with their request to send data that would produce SHAP values using the surrogate explainability approach. When the flag is enabled, a tree-based surrogate model is trained using the dataset's features and predictions, and SHAP values are generated from the surrogate model before sending the combined dataset to the Arize platform. The pandas logger can compute surrogate models for regression and binary classification models. For binary classification, the prediction score should have values between 0 and 1. In this Colab we show how to use the surrogate_explainability flag without calculating library to generate feature importance values from a surrogate model using only the prediction outputs from a black box model. Both classification and regression examples are provided and feature importance values are sent to Arize using the Pandas logger. The library used to create a surrogate model is only supported for regression and classification models currently.Code Example!pip install -q 'arize[MimicExplainer]'\u200b# Define a Schema() object for Arize to pick up data from the correct columns for loggingschema = Schema(    prediction_id_column_name=\"prediction_id\", ...    feature_column_names= feature_cols,)\u200b# Log the dataframe with the schema mappingresponse = arize_client.log(    dataframe=test_dataframe,     schema=schema,    model_id=\"surrogate_model_example\",    model_version= \"v1\",    model_type=ModelTypes.SCORE_CATEGORICAL,    environment=Environments.PRODUCTION,    surrogate_explainability = True # assign surrogate_explainability to True)\u200bMake sure to install the dependencies for the Surrogate Explainer!\nQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousSHAPNext - Explainability & FairnessBias Tracing (Fairness)Last modified 2mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4453, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a01e7261-cf3f-4307-a306-afe4c115731c": {"__data__": {"id_": "a01e7261-cf3f-4307-a306-afe4c115731c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking/collaborative-filtering-recommendation-engine"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "8e69cb74-dd0d-4953-ae1e-87c2bb9cc3df", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking/collaborative-filtering-recommendation-engine"}, "hash": "2756260556e2ea2cc274945f2da6a0645e3a644175f841731f637226acbe8bcc"}}, "hash": "15cf4feef6dbfee45499b4a46fd988793537f107282a7753817fd760cc08d288", "text": "Collaborative Filtering - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingCollaborative FilteringNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCollaborative FilteringGoogle ColaboratoryOverviewThis example runs through setting up a collaborative filtering ranking model in the Arize platform. A collaborative filtering model is normally used in recommendation engines to produce ranked personalized recommendations. This example works through a ranking recommendation based on predicting the user's 5-star rating of an unseen movie. Learn more here. Collaborative FilteringThe above picture represents a typical collaborative filtering scenario. A matrix is built based on activity, in this case, people and products they rate. The prediction of similar objects is typically based on distance (similarity) metric that can be cosine or euclidean distance. Common Observability Data for Collaborative Filtering The common data tracked includes:Timestamp: The date/time of the prediction/recommendation event.Prediction ID: A unique ID for a single prediction within a ranked list.Group ID: The group ID, such as a user or category, that identifies an entire ranked list.Relevancy Score: A score capturing the actual relevance of a prediction.Relevancy Labels: The truth label such as \"purchase\" or \"click\".Rank: a numeric representation of the order of the prediction in the ranked list.Prediction score:  The predicted score used to rank the list of predicted recommendations.Common Performance Metrics The common metrics for Collaborative Filtering are:LogLoss (for click and not-click)MAE, MAPE, RMSE (for rating prediction) NDCG or Recall @ kModel Types - PreviousRankingNext - Model TypesNatural Language Processing (NLP)Last modified 4mo agoOn this pageOverviewCommon Observability Data for Collaborative Filtering Common Performance Metrics SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3425, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "b76a9f17-c0e0-4a93-81ec-3e68fc361ee0": {"__data__": {"id_": "b76a9f17-c0e0-4a93-81ec-3e68fc361ee0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/airflow-retrain"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "41ffb412-8d71-486c-83cd-31e0ae7ad0b7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/airflow-retrain"}, "hash": "d739cd1d2f3aa4e15b3867b84f67d52d5b7a11a201d41622557cb361e10e96c9"}}, "hash": "c2af76312ad8c1affe755563048c0104c75a7c2146d7584544676e832eb43fcc", "text": "Airflow Retrain - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAirflow RetrainAWS ExampleThe following example shows how to kick off an Airflow retrain of a model from AWS. This setup uses email based triggers based on feedback from security teams. The goal of this approach was to kick off retraining events without requiring direct network IP connectivity between Arize and the customers AWS account. Arize to AWS event flowThe flow of events on a model retrain:1.Email generated on monitoring firing2.SES receives the monitoring email 3.SES triggers lambda function 4.Lambda function contains all logic to kick off airflow retrain SES (Simple Email Service) IdentityThis section walks through setting up the SES service.Setup an SES Identity, this verifies the ownership of a domain or email address such that Amazon SES can receive emails sent to that address. Create IdentityOnce the identity is setup you can setup a rule to receive emails. Create Lambda Function for Airflow RetrainThis section walks through creating a lambda function that we will reference in the email reception call. This example uses a Python Lambda function.The code of the Lambda function will follow this example:Invoking DAGs with an AWS Lambda function - Amazon Managed Workflows for Apache AirflowAmazon Managed Workflows for Apache AirflowExample Kicking off Aiflow in Lambda# Airflow V2import boto3import http.clientimport base64import astmwaa_env_name = 'YOUR_ENVIRONMENT_NAME'dag_name = 'YOUR_DAG_NAME'mwaa_cli_command = 'dags trigger'\u200bclient = boto3.client('mwaa')\u200bdef lambda_handler(event, context): # get web token    mwaa_cli_token = client.create_cli_token(        Name=mwaa_env_name )     conn = http.client.HTTPSConnection(mwaa_cli_token['WebServerHostname'])    payload = \"dags trigger \" + dag_name    headers = { 'Authorization': 'Bearer ' + mwaa_cli_token['CliToken'], 'Content-Type': 'text/plain' }    conn.request(\"POST\", \"/aws_mwaa/cli\", payload, headers)    res = conn.getresponse()    data = res.read()    dict_str = data.decode(\"UTF-8\")    mydata = ast.literal_eval(dict_str) return base64.b64decode(mydata['stdout'])The above code shows an example of kicking off an Airflow job using a labmda function.SES (Simple Email Service) RuleLastly we are going to create a rule in our SES service that references the lambda function and calls it when the email is received. In the email receiving section create a rule set and then create a rule.Create RuleName the rule that will call the lambda function when the email is received.Choose an email address to use in the Arize platform in the recipient section of the rule, emails to this address will execute the rule. Lambda ReferenceThe AWS Lambda function reference should be chosen in the action section.On initial setup when you are debugging, it can be useful to setup a 2nd action with \"Deliver to S3 bucket\" so you can review received messages as well.Lambda-airflow-retrainIn the lambda function reference the function name we created in the previous section - lambda-airflow-retrain.Create the rule.Finally, the rule does need to be set as active to work, go back to email receiving at set rule as active.Use Lambda-Airflow Email Address in ArizeUse the email address created for the rule to send for key retrain alerts.\u200b\u200bPreviousPagerDutyNext - TracingPerformance TracingLast modified 1yr agoOn this pageSES (Simple Email Service) IdentityCreate Lambda Function for Airflow RetrainSES (Simple Email Service) RuleUse Lambda-Airflow Email Address in ArizeSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5197, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "87a0af5d-0901-420f-896f-8696097a3d39": {"__data__": {"id_": "87a0af5d-0901-420f-896f-8696097a3d39", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/amazon-eventbridge"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "783870bf-2ce0-4d9c-802f-caf7bc786409", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/amazon-eventbridge"}, "hash": "257d3ad9d5cf915c5bcb71c03abc6688dd4399df5a15eab6ba0efcf572880fca"}}, "hash": "d41c180fdd695f875680208918e73821e1a9b52a1f604ac8ece8aee7b568359d", "text": "Amazon EventBridge - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAmazon EventBridgeLeverage Arize's model monitoring to automatically trigger ML Training workflowsAmazon EventBridge integration requires the use of a service like PagerDuty to publish your model monitoring events to Amazon EventBridge. See the PagerDuty guide for detailsWhy integrate with Amazon EventBridge?Integrating with Amazon EventBridge allows teams to easily create event-driven workflows that connect native AWS services with Arize's monitoring capabilities. Want to re-train your model automatically when your model's predictions drift from your model's baseline? AWS EventBridge can help you translate Arize AI's monitoring events into powerful automated workflows.Connect Arize AI to your incident management platformAmazon EventBridge integration requires the use of an incident management platform like PagerDuty to act as an event source. For the full list of Amazon partnered event sources, check out the EventBridge documentation\u200bConnect Amazon EventBridge to your incident management platformOnce you have Arize monitors integrated into your incident management platform, you'll have to configure the incident management platform to publish events to EventBridge.In this example, we use PagerDuty as our incident management platform and integrate with EventBridge by following the steps outlined in their integration guide.Once the integration is completed, any Arize monitor that fires can be used as a trigger to kick-start a workflow in AWS.Leverage Arize's drift monitoring capabilities to automate ML training workflowsArize's model monitoring capabilities can be used to auto-trigger ML pipelines within AWS. In this example, we will walk you through how to use Arize Monitors in conjunction with EventBridge to trigger AirFlow jobs to retrain your model whenever a model suffers from drift.Step 1: Setup a monitor to use as an event triggerNavigate to your model's monitor tab, click on new monitor and select drift monitor  Fill out the custom drift monitor to match your re-training criteria (e.x.  you may want to re-train your model whenever your predictions drift from your model's baseline). Make sure to name the monitor appropriately (e.x. retrain_model ) and to use your Integration Email Address (ex. [email\u00a0protected]<company>.pagerduty.com - see the PagerDuty guide for details)Once the monitor is saved and active, you are ready to react to monitor events via EventBridge.Step 2: Create a Lambda function to handle monitor eventsIn order to react to Arize's monitoring events, we need to configure a Lambda function that will parse the incident details and trigger a custom workflow. Below is an example Lambda that can be used as a template when integrating with PagerDuty's incident event payload:\nimport json\u200bdef lambda_handler(event, context):\u200b # Parse the PD incident dictionary    event_detail = event['detail']    incident = event_detail['incident']    title = incident['title']  # Parse the title to determine if it is the retrain trigger monitor    should_retrain_model = 'retrain_model_trigger' in title and 'Triggered' in title  # Construct a payload to return from the handler that can be used # by downstream workflows (AirFlow etc.) return { 'statusCode': 200, 'body': {            retrain: should_retrain_model } }\u200bMake sure to name your lambda appropriately so that it's easy to identify. Once complete, save and deploy the lambda in the same AWS region that you have EventBridge configured.\n\nStep 3: Connect EventBridge with your lambda handlerWe now need to configure an EventBridge to utilize the lambda we created above. Navigate to EventBridge in the AWS console and configure a rule that will invoke the lambda whenever a matching event is fired. The event pattern and rule details may differ depending on your integration. (See PagerDuty docs for details.)\n\nOnce completed, you should have a rule similar to the configuration below:EventBridge rule configurationStep 4: Connect downstream workflows via your Lambda handlerYou are all set! You can now fully automate powerful ML workflows within AWS (AirFlow, SageMaker, etc.). Need further assistance? Please don't hesitate to reach out to us at [email\u00a0protected]\u200bMonitors - PreviousNotifications & IntegrationsNextOpsGenieLast modified 7mo agoOn this pageWhy integrate with Amazon EventBridge?Connect Arize AI to your incident management platformConnect Amazon EventBridge to your incident management platformLeverage Arize's drift monitoring capabilities to automate ML training workflowsStep 1: Setup a monitor to use as an event triggerStep 2: Create a Lambda function to handle monitor eventsStep 3: Connect EventBridge with your lambda handlerStep 4: Connect downstream workflows via your Lambda handlerSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6472, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "05405d0e-5b2e-49ed-a545-08acf9caf065": {"__data__": {"id_": "05405d0e-5b2e-49ed-a545-08acf9caf065", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/opsgenie"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "eb06e579-e72a-4f1e-b824-414b9b637dd5", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/opsgenie"}, "hash": "f4a8dc0a2d29a0d975f845b82427159ea13b80e58ad8d1604b8c3fbda269c84b"}}, "hash": "ad1a69bfbf972db3e7940258a309d99cc7e4aa9f3062b533248c0c6620977f5e", "text": "OpsGenie - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookOpsGenieUse our OpsGenie alerting integration for streamlined troubleshooting workflowsArize supports native integration with OpsGenie to keep your alerts in one system. Use our OpsGenie integration to send more comprehensive metadata to the OpsGenie platform and debug your models faster.Looking for some automation? You can now set up an OpsGenie integration & assign to monitors with our GraphQL API!Integration SetupAlerting integrations can be configured in two ways on the Arize platform: either in your Organization Settings or the 'Config' Tab. Integration Setup: Organization SettingsSince integrations are available at the organization level, you can set up an integration by clicking on your organization name on the top left corner of any page and clicking into the 'Integrations' tab at the top of the navigation bar. From there, pick on the integration you want to set up for your organization, in this case: OpsGenie. Setup via Organization SettingsIntegration Setup: 'Config' Tab You can also add an alerting integration via the 'Config' tab within a model. From there, scroll down to the 'Integration' card where you can begin your API integration setup. Setup via Config TabLearn how to programmatically edit alerting integrations using our GraphQL API here\u200bCreate an API Integration Once you've added OpsGenie to your integrations list on the Arize platform, add a new API integration on OpsGenie to obtain an API key. Arize currently supports OpsGenie Team Keys only, so each integration in Arize will be tied to a specific team in OpsGenie. Learn more about OpsGenie and how to create an API integration here. Send AlertsAfter you save your alerting service, designate model and monitor specific alerts via the 'Config' Tab or within individual monitors.You can add multiple integrations for more tailored alerting specific to teams, access, and monitors. Send Alerts: Model From any page, click on the 'Config' Tab on the right under the main navigation bar. Scroll down to the 'Alert Email' card and click on the drop-down menu to select which integration(s) to send your models triggered alerts to. Edit Alerts via the Config TabSend Alerts: Monitor Customize individual monitors to send alerts to a different or additional integration to keep an eye on a specific monitor. Edit Monitor Specific AlertsHaving trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousAmazon EventBridgeNextSlackLast modified 1yr agoOn this pageIntegration SetupCreate an API Integration Send AlertsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4307, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "7fe51cdf-8ff7-4ea0-944d-7e77095456c2": {"__data__": {"id_": "7fe51cdf-8ff7-4ea0-944d-7e77095456c2", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/pagerduty"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "56f31f00-b684-40e9-acb5-b5e30f01568d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/pagerduty"}, "hash": "af0183b7df37e50a0d51d75d85e3faee014388487dde31b5894ca781ca8c0181"}}, "hash": "644e109075a00a858e1315c34ebd4b59e5efa8f095ffeeb55a5a007698df51e5", "text": "PagerDuty - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPagerDutyUse our PagerDuty alerting integration to enhance model monitoringArize + PagerDuty Benefits Arize supports native integration with PagerDuty to streamline your monitoring workflows using PagerDuty services. Use our Pagerduty integration to keep your teams in the loop, send more comprehensive metadata through alerts, and debug your models faster by: Notifying on-call responders based on ML model monitors from ArizeCreating high and low urgency incidents based on the severity of the event from the Arize AI event payloadCatching and debugging ML model issues faster with more comprehensive metadataRequirements Users will require a non-read-only account in Arize in order to create and use the Pagerduty integration.Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. Integration SetupAlerting integrations can be configured in two ways on the Arize platform: either in your Organization Settings or the 'Config' Tab. Integration Setup: Organization SettingsSince integrations are available at the organization level, you can set up an integration by clicking on your organization name on the top left corner of any page and clicking into the 'Integrations' tab at the top of the navigation bar. From there, pick on the integration you want to set up for your organization, in this case: PagerDuty. Integration Setup: 'Config' Tab You can also add an alerting integration via the 'Config' tab within a model. From there, scroll down to the 'Integration' card where you can begin your API integration setup. Learn how to programmatically edit alerting integrations using our GraphQL API here\u200bCreate an API Integration on PagerDutyThere are two ways to collect the API key from PagerDuty. The Arize platform supports PagerDuty's Simple Install workflow to easily integrate both platforms without the need to go back and forth manually. If you opt-out of the simple install flow, you can manually collect your integration key to use on the Arize platform. Simple InstallationOn the integration pop-up window within the Arize platform, click Connect to Pagerduty. This will redirect you to Pagerduty, where you will be prompted to log into your account.From there, select the services that you want to integrate with and click Connect. You will be redirected back to Arize and see your selected service(s) available as integrations in the app.Manual Installation From the 'Services' tab in the PagerDuty platform, click on the service relevant to your model. Within your service, click on the 'Integrations' tab located in the navigation bar and click 'Add another integration'. From there, search for Arize AI and click 'Add' to access your API key. Once you've copied your key, navigate back to the Arize platform to enter your key and select your alert's severity. To create a new service, please read Configuring Services and Integrations and follow the steps outlined in the Create a New Service sectionLearn more about PagerDuty and how to create an API integration here. Send AlertsAfter you save your alerting service on the Arize platform, designate your model and monitor specific alerts via the 'Config' Tab or within individual monitors.You can add multiple integrations for more tailored alerting specific to teams, access, and monitors. Send Alerts: Model From any page, click on the 'Config' Tab on the right under the main navigation bar. Scroll down to the 'Alert Email' card and click on the drop-down menu to select which integration(s) to send your models triggered alerts to. Send Alerts: Monitor Customize individual monitors to send alerts to a different or additional integration to keep an eye on a specific monitor. How to Uninstall  Delete individual integrations from the PagerDuty config page by clicking the trash icon.PreviousManual SetupNextAirflow RetrainLast modified 11mo agoOn this pageArize + PagerDuty Benefits Requirements Integration SetupCreate an API Integration on PagerDutySend AlertsHow to Uninstall SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5762, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9c93bd3c-59a9-4836-83ab-672b20b6c8a8": {"__data__": {"id_": "9c93bd3c-59a9-4836-83ab-672b20b6c8a8", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf21135a-de9a-41a0-af12-0e33611ca000", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack"}, "hash": "ea9e2018e7c813fd74297be517d6fc595ea5ac49c7a383fabf468050eee4c3d6"}}, "hash": "aa34a743d620ecdb869cbf45dd484d128dbfec95a33a6042031362191092ef2e", "text": "Slack - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackManual SetupPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSlackUse our Slack alerting integration for streamlined troubleshooting workflowsArize supports a native integration with Slack to keep your alerts in one system. Use the integration to send more comprehensive metadata to Slack and troubleshoot your models faster.Looking for some automation? You can now update your Slack integrations & assign to monitors with our GraphQL API!Integration SetupAlerting integrations can be configured in two ways on the Arize platform: either in your Organization Settings or the 'Config' Tab. Integration Setup: Organization SettingsSince integrations are available at the organization level, set up an integration by clicking on your organization name on the top left corner of any page and clicking into the 'Integrations' tab at the top of the navigation bar. From there, pick on the integration you want to set up for your organization, in this case: Slack. Integration Setup: 'Config' Tab You can also add an alerting integration via the 'Config' tab within a model. From there, scroll down to the 'Integration' card, where you can begin your API integration setup. Learn how to programmatically edit alerting integrations using our GraphQL API here\u200bCreate an API Integration On the integration pop-up window within the Arize platform, click Connect to Slack. This will redirect you to Slack, where you will be prompted to select a specific slack channel.From there, select the channel that you want to integrate with and click Allow. This enables Slack's incoming-webhook permission scope so that our application has permission to post in your selected Slack channel. You will be redirected back to Arize and see your selected service(s) available as integrations in the app.Note: Arize currently supports Slack Channel Keys only, so each integration in Arize will be tied to a specific channel in Slack. \u200bTesting Slack Integrations From the integration pop-up window, select the channel name from the list. Click Test Integration to see what an Arize Alert would look like.Testing an IntegrationExample from within Slack channel \u200b\u200bSend AlertsAfter you save your alerting service:Designate model and monitor specific alerts via the 'Config' Tab or within individual monitors.You can add multiple integrations for more tailored alerting specific to teams, access, and monitors. Send Alerts: Model From any modelClick on the 'Config' Tab on the right under the main navigation barScroll down to the 'Alert Email' card and click on the drop-down menu to select which integration(s) to send your models triggered alerts toClick on the 'Config' Tab on the right under the main navigation barScroll down to the 'Alert Email' card and click on the drop-down menu to select which integration(s) to send your model's triggered alerts to. Edit Alerts via the Config TabSend Alerts: Monitor Customize individual monitors to send alerts to a different or additional integration to keep an eye on a specific monitor. Edit Monitor Specific AlertsHaving trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousOpsGenieNextManual SetupLast modified 6mo agoOn this pageIntegration SetupCreate an API Integration Testing Slack Integrations Send AlertsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4987, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5abc1ffe-683e-43c1-8257-79daba457189": {"__data__": {"id_": "5abc1ffe-683e-43c1-8257-79daba457189", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "48896621-9b83-4f8b-800f-fdc387260f99", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "hash": "60663328ce1cc2bba598b4926cb2c4585a8c458f64b8d3bafcd435a4a5e2fa96"}, "3": {"node_id": "ba7ae850-1512-4b82-a7cf-6dbc4f38f7fd", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "hash": "da25a3c5e40a6d73f1b4778729330a946573d8fdda0ff0562a553ef2127ede61"}}, "hash": "e7b4d2ad129166242034f641a09d5f3bf7c4f6662025cb9f3f3d21b9d38fd23f", "text": "Choosing Your Metrics - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsChoosing Your MetricsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookChoosing Your MetricsMonitor Performance, Drift, Data Quality, and Custom MetricsOverviewMonitors automatically detect drift, data quality issues, or anomalous performance degradations with highly configurable dimensions based on both common KPIs and custom metrics.TypePerformanceMetricsAUC, LogLoss, Mean Error, MAE, MAPE, SMAPE, WAPE, RMSE, MSE, RSquared, Accuracy, Precision, Recall, f_1, Sensitivity, Specificity, False Negative Rate, False Positive RateTypeDriftMetricsPSI, KL Divergence, JS Distance, KS StatisticTypeData QualityMetricsPercent Empty, Cardinality, New Values, Missing Values, Quantiles (P99.9, P95, P50, P99Learn how to set up your monitors here!\u200bPerformance Monitors\u200bModel performance metrics measure how well your model performs in production. Monitor model performance with daily or hourly checks using an evaluation metric. Your model type determines your performance metric. Performance Metrics Metrics are batched into Metric Groups that align with model types and their variants. Metric GroupMetricsClassification Accuracy, Recall, Precision, FPR, FNR, F1, Sensitivity, SpecificityRegressionMAPE, MAE, RMSE, MSE, R-Squared, Mean ErrorRanking[email\u00a0protected], [email\u00a0protected]Ranking Labels[email\u00a0protected], MRR AUC / LogLossAUC, PR-AUC, Log LossComputer Vision / Object DetectionAccuracy (MAP & IoU coming soon)Valid Model Type & Metric Group CombinationsModel TypeMetric Group CombinationRegressionRegressionBinary ClassificationClassification and/or Regression and/or AUC/LogLossRanking w/ labelRanking and/or Ranking LabelsRanking w/ score Ranking and/or AUC/LogLossMap performance metrics relevant to your model type within each model type page. MetricMetric Family\u200bAUC\u200bauc/logloss\u200bLogLoss\u200bauc/loglossMean Errorclassification \nregression\u200bMAE\u200bclassification \nregression\u200bMAPE\u200bregression\u200bSMAPE\u200bregression\u200bWAPE\u200bregression\u200bRMSE\u200bregression\u200bMSE\u200bregressionrSquaredregression\u200bAccuracy\u200bclassification\u200bPrecision\u200bclassification\u200bRecall\u200bclassification\u200bF_1\u200bclassification\u200bSensitivity\u200bclassification\u200bSpecificity classification\u200bFalse Negative Rate\u200bclassification\u200bFalse Positive Rate\u200bclassification\u200bNDCG\u200bclassification\nranking\u200bDrift Monitors\u200bDrift monitors measure distribution drift, which is the difference between two statistical distributions. Arize offers various distributional drift metrics to choose from when setting up a monitor. Each metric is tailored to a specific use case; refer to this guide to help choose the appropriate metric for various ML use cases.Drift MetricsMetricData TypeDescription\u200bPSI\u200binteger, floats, stringSample size has less of an effect on PSILess sensitive, but will have fewer False positives when compared to KS or EMD (use PSI if you expect fluctuations in your data and don\u2019t want too many false alarms)Binning Strategy can affect the calculation of PSIA true statistical \u2018distance\u2019, having the property of symmetry PSI(A -> B) == PSI(B->A)\u200bEuclidian Distance*Embedding VectorsEuclidean distance check determines if the group of production data\u2019s average centroid has moved away from the baseline group\n\nFor unstructured data types, learn more here\u200b\u200bKL Divergence\u200binteger, floats, stringLess sensitive than other metrics (such as KS statistic) and will have fewer False positives when compared to KSUse KL if you expect fluctuations in your dataSample size has less of an effect on KLBinning Strategy can affect resultsThe non-symmetric version of PSIKL(A -> B) != KL(B->A)\u200bJS Distance\u200binteger, floats, stringSimilar to KL except in two areas: JS is always finite and symmetricInterpretable from 0 --> 1 (PSI doesn't have this property as it's evaluated from 0 --> infinity)0 = identical distributions1 = completely different with no overlapMildly sensitive compared to PSI and KL, but not as sensitive as KS Binning strategy can affect results\u200bKS Statistic\u200binteger, floatsNon-parametric, so it doesn't make assumptions about the underlying dataIt doesn't require binning to calculate, so binning strategy doesn't affect this metricA smaller P-value means more confident drift detectionKS Statistic returns P-valueKS is the most sensitive metric among all the drift metricsLarger datasets make KS increasingly more sensitiveWill produce more false positives Detects very slight differences\u200bData Quality Monitors\u200bModel health depends on high-quality data that powers model features. Data quality monitors help identify key data quality issues such as cardinality shifts, data type mismatch, missing data, and more.Data Quality MetricsMetricData TypeDescriptionPercent Emptyinteger, floats, string\n(Embedding vectors coming soon)The percent of nulls in your model featuresCardinality (Count Distinct)stringThe cardinality of your categorical features\u200bCardinality - New Values\u200bstringCount of new unique values that appear in production but not in baseline\n\nNote: this monitor requires a baseline to compare against\u200bCardinality - Missing Values\u200bstringCount of new unique values that appear in baseline but not in production \n\nNote: this monitor requires a baseline to compare against\u200bQuantiles\u200binteger, floatsp99.9, p99, p95, p50Suminteger, floatsSum of your numeric data over the evaluation windowCountinteger, floats, stringTraffic count of predictions, features, etc. Can be used with filtersAverageinteger, floatsAverage of your numeric data over the evaluation window\u200bMonitor Your Custom Metrics\u200bCouldn't find your metric above? Arize supports the ability to monitor custom metrics using SQL. Here is an example of a custom metric for the percent of a loan that is outstanding: SELECTSUM(loan_amount - repayment_amount) / SUM(loan_amount)FROM modelWHERE state = 'CA'AND loan_amount > 1000Learn how to create custom metrics here. Custom Metrics Query LanguageMonitors - PreviousGet Started With MonitorsNext - MonitorsPerformance MonitorsLast modified 1mo agoOn this pageOverviewPerformance MonitorsDrift MonitorsData Quality", "start_char_idx": 0, "end_char_idx": 7379, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "ba7ae850-1512-4b82-a7cf-6dbc4f38f7fd": {"__data__": {"id_": "ba7ae850-1512-4b82-a7cf-6dbc4f38f7fd", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "48896621-9b83-4f8b-800f-fdc387260f99", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "hash": "60663328ce1cc2bba598b4926cb2c4585a8c458f64b8d3bafcd435a4a5e2fa96"}, "2": {"node_id": "5abc1ffe-683e-43c1-8257-79daba457189", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}, "hash": "e7b4d2ad129166242034f641a09d5f3bf7c4f6662025cb9f3f3d21b9d38fd23f"}}, "hash": "da25a3c5e40a6d73f1b4778729330a946573d8fdda0ff0562a553ef2127ede61", "text": "MonitorsMonitor Your Custom MetricsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 7380, "end_char_idx": 7639, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d90886d0-265a-43d2-86cb-83299a6f0aa6": {"__data__": {"id_": "d90886d0-265a-43d2-86cb-83299a6f0aa6", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf7e3674-a267-4685-8e56-9d4bb5888e92", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "hash": "0cf57051ac900ae9ba2f17741aea6c9a0f03b475310cf6b5073b88bb25e9ed91"}, "3": {"node_id": "50c39b7b-f1d3-4579-aa27-0c43ebf10444", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "hash": "58a293c4661b9d8499ebeb2de7f09a6a1a8af5e49b85d99088d687192088c12f"}}, "hash": "55c6b2691e0b147dbf5e24da1ab5326d472d73e6242d44b524a79691dd7a1947", "text": "Installation - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverviewRequirementsInstallation\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookInstallationInstallation Details for Arize On-Prem DeploymentOverviewThe installation requires a release's TAR file that will be supplied by the Arize team. The TAR file includes all the documentation, terraforms, and Helm charts to install the Arize platform.Example content:arize-distribution-<hash>.tar|-examples|-terraform|-docs |-install-arize-using-helm.md |...arize.sharize-operator-chart.tgzarize-cr-chart.tgzRead the install-arize-using-helm.md documentation for more detailed instructions on how to install on GCP, AWS, or Azure.1. Pre-Deployment The Arize team can help size the cluster based on customer requirements. Storage bucket entities need to be created for Arize A service account or IAM roles need to be created with access to the bucket storage and Kubernetes clusterIP address and VPC setup should be discussed with the Arize team. Our team can help pre-configure the files for network setup based on required deployment options.There are three options available for loading Arize container images:(default) Let the cluster pull images from the Arize Central Registry ch.hub.arize.comTransfer images from the Arize Central Registry to a private registryDownload the images to a local folder and then upload the images into a private registry2. DeploymentTo get started quickly, you can use the scripts provided with the distribution. Extract the TAR file provided by the Arize team:tar -zxvf arize-distribution-<hash>.tararize.sh is the main installation script. This uses kubectl and helm to install the Arize Operator onto your cluster. The Operator then deploys the application and initializes the database and various components. arize.sh command\u200bNAME     arize.sh \u2013 Arize AI's On-Prem Deployment Utility Script\u200bSYNOPSIS     ./arize.sh [OPTIONS] <OPERATION> <PARAMS>\u200bDESCRIPTION\u0000\u0000\u200b      Script for managing the Arize platform. The script will look for a 'values.yaml' file in the same      folder or a file name provided with the -f option. If not file is found the script will use default      values or values passed in as arguments in the form 'cloud=gcp,etc'.\u200bOPERATIONS\u200b      download-charts       Download the helm charts for the corresponding release install               Install the Arize Operator and CR charts from values.yaml\u200b      install-air-gapped    Install in a air-gapped environment when Operator can not contact Arize hub      pull-images           Pull images from the Arize central registry to the local docker      push-images           Push images from the local docker to the remote registry      save-images           Save images from docker to a local images folder      load-remote-images    Combines the Pull and Push steps      load-images           Load images from a local images folder into docker ...\u200bEXAMPLE COMMON INSTALL\u200b      ./arize.sh install\u200bEXAMPLE AIR-GAPPED\u200b      ./arize.sh load-remote-images      ./arize.sh install ...The arize.sh script calls helm which takes settings from a values.yaml file. This file includes parameters such as:1.cloud: gcp/aws/azure2.clusterName: The cluster name on kubeconfig of the deployment 3.gazetteBucket: The bucket name to hold gazette events4.druidBucket: The storage bucket to hold ui data5.postgresPassword: The postgres db admin password6.organizationName: The name of the organization owning the deployment7.clusterSizing: The size of the deployment (small, medium, large, etc)8.smtpPassword: The password for the SMTP service9.smtpUser: The user for the SMTP service10.smtpHost: The host endpoint for the SMTP service11.smtpSenderEmail: The smtp authenticated address emails should come from. e.g. From: [email\u00a0protected]12.gcpProject: (GCP only)The name of the project in GCP.13.gcpServiceAccountName: (GCP only)The name of the service account14.gcpServiceAccountJsonKey: (GCP only) A key from the service account15.azurePrincipalId: (Azure only) The id of the Azure principal16.region: (AWS only) Cluster region17.serverSideEncryption: (AWS only) Optional encryption settings (Example: KMS)18.sseKmsKeyId: (AWS only) Optional KMS encryption keyRunning the script deploys the Arize Operator which then executes a number of steps that include:Applying the secretsApplying the manifests Preparing the DatabaseStarting the consumer applications Finally starting the User Interface and SDK receiverOutput of the script will look as follows:    ----------------------------------------------------------------------------------------------                    Welcome to Arize AI's On-Prem Utility Script    ----------------------------------------------------------------------------------------------    Using:      ...\u200b    \u25b6 Running pre-checks...    \u25b6 Helm install Arize Operator...    ...    \u25b6 Helm install Arize CR...    ...    \u25b6 Waiting for Operator pod to be running...    \u25b6 Waiting for Operator to complete: Executing    \u25b6 Waiting for Operator to complete: Running    \u25b6 Waiting for postgres job to complete...    \u25b6 Waiting for pods to be running...    \u25b6 Waiting for pods to be running...    ----------------------------------------------------------------------------------------------                                Installation Completed    ----------------------------------------------------------------------------------------------    \u2705 Receivers available at http://localhost:50050    \u2705 Application available at http://localhost:4040    \u2705 Metrics available at http://localhost:3000    \u2705 Alerts available at", "start_char_idx": 0, "end_char_idx": 6918, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "50c39b7b-f1d3-4579-aa27-0c43ebf10444": {"__data__": {"id_": "50c39b7b-f1d3-4579-aa27-0c43ebf10444", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bf7e3674-a267-4685-8e56-9d4bb5888e92", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "hash": "0cf57051ac900ae9ba2f17741aea6c9a0f03b475310cf6b5073b88bb25e9ed91"}, "2": {"node_id": "d90886d0-265a-43d2-86cb-83299a6f0aa6", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}, "hash": "55c6b2691e0b147dbf5e24da1ab5326d472d73e6242d44b524a79691dd7a1947"}}, "hash": "58a293c4661b9d8499ebeb2de7f09a6a1a8af5e49b85d99088d687192088c12f", "text": "http://localhost:9090    \u2705 Druid available at http://localhost:8888    \u2705 Alert Manager available at http://localhost:9093After installation, endpoints for sending data from the SDK and for accessing the Platform UI are available for consumption by other applications running in the cluster.  These endpoints can be exposed to infrastructure outside of kubernetes through additional Ingress configuration.Initial login is based on the default login and password in the configuration setup.3. Post DeployAfter deployment, teams should confirm:Secrets have been appliedAll Arize Kubernetes services are green and upTest that the User Interface is live by accessing it at localhost:4040:The Arize team will typically work on completing the installation through help in setting up IP addresses, initial login accounts and testing the end to end system.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousRequirementsNext - AdminSSO & RBAC (Role Based Access Control)Last modified 4mo agoOn this pageOverview1. Pre-Deployment 2. Deployment3. Post DeploySupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 6919, "end_char_idx": 8228, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8951ba30-63b9-41aa-a093-40ecc5a1c8ea": {"__data__": {"id_": "8951ba30-63b9-41aa-a093-40ecc5a1c8ea", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/requirements"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e541b8bf-7da2-414d-8f74-d68ed88cd044", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/requirements"}, "hash": "9a90c4da3845f0e241d6c9b089cdf4b1942e3e403ee326db5a3c8dbcc0abb861"}}, "hash": "c4cd8079b7219bfc3ccf9d19457be5137f3f952656e78fb5e86080f4bf004841", "text": "Requirements - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverviewRequirementsInstallation\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRequirementsRequirements for Arize On-Prem InstallationCluster and Server RequirementsKubernetes v1.23+ (Important: Recommend containerd runtime)Namespaces for Arize DeploymentStorage - 2x storage buckets Credentials for Platform to Read/Write StorageIn the case of a Proof of Concept (POC) deployment our team recommends a minimum of 5 nodes, each with at least:8 CPU64Gi of RamSizing is based on your expected volume, access patterns, and expected shape of data, please reach out to our team to discuss the best cluster sizing for your needs.Cloud Storage OptionsThe distribution includes deployment manifests for running a blob storage implementation with one of the three major clouds:Google Cloud StorageAmazon S3Azure StorageExamples of Blob Storage Credentials:Amazon S3config[profile default]region=us-east-1...credentials[default]aws_access_key_id=ACCESS_KEYaws_secret_access_key=SECRET_KEY_123...aws role    annotations:      eks.amazonaws.com/role-arn: '<AWS_IAM_ROLE_FOR_SERVICE_ACCOUNT>'Google Cloudservice-account.json\u200b{ \"type\": \"service_account\", \"project_id\": \"<<PROJECT ID>>\", \"private_key_id\": \"<<PRIVATE KEY ID>>\", \"private_key\": \"<<PRIVATE KEY>>\", ...}AzureazurePrincipalId: <id>azurePrincipalPassword: <id>azureStorageAccountName: <id>azureStorageAccountKey: <id>PermissionsThe person running the installation is assumed to have administrator privileges on the cluster.kubectl and helm installed and configured for a user to create Workloads, ClusterRoles, and ClusterRoleBindingspermissions to create storage buckets, service accounts, and modify IAM rolesFirewall Configuration Ingress TCP port 443 for the applicationTCP port 443 for record receiversEgressNAT access to docker registry ch.hub.arize.com. Alternatively, you can mirror images on your private container images registry such as ECR, GCR, ACR, Artifactory, etc.SMTPEgress to an SMTP server with email send permissions is required for full platform functionality.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelOn-Premise Deployment - PreviousOverviewNextInstallationLast modified 4mo agoOn this pageCluster and Server RequirementsCloud Storage OptionsPermissionsFirewall Configuration SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3918, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "da1a7295-10db-450a-8a6d-69b4a1321f77": {"__data__": {"id_": "da1a7295-10db-450a-8a6d-69b4a1321f77", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/algorithmia"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dfbfb421-2fd4-44da-8a3f-a07455b47093", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/algorithmia"}, "hash": "4105e1677b7fa89c10fc1f7ed4c952543a05fc211192851fbeb64415003c122a"}}, "hash": "acd6f39abf2813b7ca5f1939ac3fd540b94998b8c06436636353efc9f180d7e6", "text": "Algorithmia - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAlgorithmiaIntegrating Arize with model management platform, Algorithmia.Algorithmia is an MLOps platform with APIs to serve, host and manages models. The Arize platform can easily integrate into Algorithmia to enable model observability, explainability, and monitoring.The following example shows how to upload a model into Algorithmia, add Arize tracking to the model, and send data to the Arize platform.Read the full blog post here. Algorithmia Integration NotebookArize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models. Algorithmia is a platform for model serving and help you manage machine learning at scale.In this notebook, we show that we can quickly create a model and download it to serve on Algorithmia, and integration with Arize platform can be done directly on Algorithmia, without needing any environment dependency aside from Algorithmia from user environment.Step 1-2: creates a basic model and downloads it as a .pkl file to be loaded on Algorithmia.Step 3-4: Developing and testing Algorithmia + Arize API locallyStep 5 (Outside Notebook): Develop and build for \"server-side\" on AlgorithmiaStep 6: Test from \"client-side\" that the model executes properlyGoogle ColaboratoryResources - PreviousML PlatformsNextAzure & DatabricksLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3224, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a9acc3a3-44aa-4993-b5d5-cf6073236488": {"__data__": {"id_": "a9acc3a3-44aa-4993-b5d5-cf6073236488", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/anyscale-ray-serve"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "69f6c3f1-2eb4-4268-a5ea-6ed6a4d18f30", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/anyscale-ray-serve"}, "hash": "dfc1896476b8da366165f6419c2dd5392be250319147135fff939223f43ba766"}}, "hash": "95b38952b89dfeb3b6e63cc2ef7733f1a4d2c72dba2ec7c2279d12a8ea98f4ea", "text": "Ray Serve (Anyscale) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRay Serve (Anyscale)Arize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models. Ray Serve is an framework agnostic and scalable model serving library built on Ray. For additional context, check out the blog post on our partnership with Ray.$pip install arize$pip install 'ray[serve]'Arize Integration in 3 StepsArize can be easily integrated with Ray Serve with at single entry point during ray.serve.deployment. Following 3 simple steps, (1) Import Arize Client and saving it as model instance attribute (2) Saving important model meta-data for argument passing (3) Log production data using arize.client during HTTP request call function, where models will make prediction during production.See below for a quick start example.Quick Start Examplefrom ray import serve\u200bimport numpy as npimport pandas as pdfrom sklearn import datasetsfrom sklearn.ensemble import RandomForestClassifierfrom sklearn.model_selection import train_test_split\u200bimport uuidimport requestsimport concurrent.futures as cffrom arize.api import Clientfrom arize.types import ModelTypes\u200bdata = datasets.load_breast_cancer()X, y = datasets.load_breast_cancer(return_X_y=True)X, y = X.astype(np.float32), y.astype(int)X, y = pd.DataFrame(X, columns=data['feature_names']), pd.Series(y)X_train, X_test, y_train, y_test = train_test_split(X, y, random_state=42)model = RandomForestClassifier().fit(X_train, y_train)\u200b# Integration starts here@serve.deployment(name='ArizeModel')class ArizeModel: \"\"\"    Rayserve and Arize Quick-start Integration Model    \"\"\" def __init__(self):        self.model = model # change to reading a pkl file, or otherwise # Step 1 Save Arize client        self.arize = Client(space_key='YOUR_SPACE_KEY',                             api_key='YOUR_API_KEY') # Step 2 Saving model metadata for passing in later        self.model_id = 'rayserve-model'        self.model_version = '1.0'        self.model_type = ModelTypes.BINARY\u200b async def __call__(self, starlette_request):        payload = await starlette_request.json() # Reloading data into correct json format        X_test = pd.read_json(payload)        y_pred = self.model.predict(X_test)\u200b # Step 3 Log production to Arize        ids_df = pd.DataFrame([str(uuid.uuid4()) for _ in range(len(X_test))])        log_responses = self.arize.bulk_log(            model_id=self.model_id,            prediction_ids=ids_df,            model_version=self.model_version,            prediction_labels=pd.Series(y_pred),            features=X_test,            model_type=self.model_type, )  # Record HTTP response of logging to arize        arize_success = True for response in cf.as_completed(log_responses):            status_code = response.result().status_code            arize_success = arize_success and status_code == 200\u200b # Return production inferences and arize logging results return {'result': y_test.to_numpy(), 'arize-sucessful': arize_success}If using version < 4.0.0, replace space_key=YOUR_SPACE_KEY with organization_key=YOUR_SPACE_KEYAfter we define our model as above, we can serve and monitor our model production on Arize by running the following code by deploying them with Ray Serve.If you are using Ray 1.0serve.start()\u200b# Model deploymentArizeModel.deploy()If you are using Ray 2.0# Model deploymentserve.run(ArizeModel.bind())Simulate the production setting and show results# Simulate production settinginput = X_test.to_json()response = requests.get( \"http://localhost:8000/ArizeModel\", json=input )# Display resultsprint(response.text)\u200bPreviousPySparkNextSageMakerLast modified 9mo agoOn this pageArize Integration in 3 StepsQuick Start ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5566, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e52397b9-fbcb-4823-82a1-a6ecedbb6c4c": {"__data__": {"id_": "e52397b9-fbcb-4823-82a1-a6ecedbb6c4c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/azure-and-databricks-python"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c2d39c09-4bd7-4fcd-9c0a-0fd7046489f7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/azure-and-databricks-python"}, "hash": "6add3ba5238ea6157015b984e8887453990cccb943a3b1ec22b3b795bedf4ade"}}, "hash": "e9046acb08368e8aa68bbdb736f2ac3b1da3fef73038c342734a55d62ea3e67e", "text": "Azure & Databricks - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAzure & DatabricksTutorial with Azure & DatabricksTutorial OverviewThis tutorial walks throughUsing Arize in a Databricks workflowDeploying the built model to a Azure WorkspaceGoogle ColaboratoryPreviousAlgorithmiaNextBentoMLLast modified 7mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2128, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "be602cc2-1634-4937-aa58-760ca4ca6223": {"__data__": {"id_": "be602cc2-1634-4937-aa58-760ca4ca6223", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/bentoml"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e02e0904-9276-42c1-b2ac-5e8b4b7d95c6", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/bentoml"}, "hash": "554d0faf882793222027f8b159f81d7d8f13eb7c623b04cce09c6901b73ec331"}}, "hash": "2982a5d90c4a135acc1f417d63e5d7ae7bb66f2f86585754c9deacfa5df75839", "text": "BentoML - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookBentoMLIntegrate Model Serving With ML ObservabilityBentoML and Arize AI have partnered to streamline the MLOps toolchain and help teams build, ship, and maintain business-critical models. Leverage Bento\u2019s ML service platform to easily turn ML models into production-worthy prediction services. Once your model is in production, use Arize\u2019s ML observability platform to attain the necessary visibility to keep your model in production.Step 1: Build an ML application with BentoMLStep 2: Serve ML Apps & Collect Monitoring DataStep 3: Export and Analyze Monitoring DataTutorial BlogSupercharge Production ML With BentoML and Arize AIArize AIPreviousAzure & DatabricksNextCML (DVC)Last modified 7mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2571, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d5a8b73a-1ab5-47a9-a1f0-7285e245c617": {"__data__": {"id_": "d5a8b73a-1ab5-47a9-a1f0-7285e245c617", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ci-cd-cml"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "219825ff-0e55-4cb5-86f5-56b946b8be05", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ci-cd-cml"}, "hash": "46ee35fc2814989df6720f3d4589dcba5b56ca5c966dca6142bb61f9eb00f265"}}, "hash": "890d6f2f4de5d7d82b20a2ab7430133137b0af1eb72084bebc720c6d7d22646e", "text": "CML (DVC) - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookCML (DVC)Example of Arize use in CI / CD WorkflowOverviewThis tutorial runs through how to use Arize in a Continuous Integration and Continuous Deployment workflow for models. This tutorial is based on Continuous Machine Learning Groups work: CML \u00b7 Continuous Machine LearningCML \u00b7 Continuous Machine LearningThis tutorial will show you how to:Integrate Arize into the CI/CD workflowRun Arize on Validation data every time a new model version is checked inCapture data in the platform to compare different validated modelsWorkflow OverviewThe CI/CD workflow for models with CML involves a training script and a linkage to Github actions.CI CD CML ExampleThe following describes the steps for training and validation runs:1.A model directory is setup on Github which contains both model file and train scripts for CML2.Train scripts are built to run a set of inferences across any newly built model3.GitHub actions are setup to run the train script on any model checkin 4.On Model Checkin the train script is run1.The train Script logs the validation inferences to Arize2.Checks within the Arize platform can be setup to run on every new validation batch of data. These checks can include comparing against previous model data or fixed levels analysis3.On check failure dashboards can be created for model analysis4.Future: The ability to quickly poll  through API the validation checks as part of Github actions for pass / failAn example Train script for CML with Arize is included here:The github/workflows directory defines the github actions that are run on model checkin. This is derived from the CML example.tutorials_python/train.py at main \u00b7 Arize-ai/tutorials_pythonGitHubThe Train scripts typically have 2 parts:1.Train and Score the latest model########################################### MODELLING #############################################\u200b# Fit a model on the train sectionregr = RandomForestRegressor(max_depth=2, random_state=seed)regr.fit(X_train, y_train)\u200b# Report training set scoretrain_score = regr.score(X_train, y_train) * 100# Report test set scoretest_score = regr.score(X_test, y_test) * 100y_pred = regr.predict(X_test)2. Log artifacts and data to CML# Write scores to a filewith open(\"metrics.txt\", 'w') as outfile:        outfile.write(\"Training variance explained: %2.1f%%\\n\" % train_score)        outfile.write(\"Test variance explained: %2.1f%%\\n\" % test_score)An additional 3rd section is added to send the feature data, inferences (predictions) and ground truth (actuals) to Arize####################################################### Arize AI Validation Sample #########################################################\u200bSPACE_KEY=\"SPACE_KEY\"API_KEY=\"API_KEY\"model_name = \"validation-wine-model-cicd\"\u200b\u200bdatetime_rightnow = datetime.datetime.today()model_version_id_now = 'train_validate_' + datetime_rightnow.strftime('%m_%d_%Y__%H_%M_%S')id_df = pd.DataFrame([str(id) + model_version_id_now for id in X_test.index])arize_client = Client(space_key=SPACE_KEY, api_key=API_KEY,uri='https://devr.arize.com/v1')tfuture = arize_client.log(model_id=model_name, model_version=model_version_id_now,                           features=X_test, prediction_ids=id_df,                           prediction_labels=pd.DataFrame(y_pred))tfuture = arize_client.log(model_id=model_name, model_version=model_version_id_now,                           prediction_ids=id_df, actual_labels=pd.DataFrame(y_test))If using version < 4.0.0, replace space_key=SPACE_KEY with organization_key=SPACE_KEYThe above workflow can be modified for any model CI CID flow where scoring is done from a set of validation inferences.PreviousBentoMLNextDeepnoteLast modified 11mo agoOn this pageOverviewWorkflow OverviewSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5586, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c6cc2e35-aa38-4d2b-b395-2bde200f6fed": {"__data__": {"id_": "c6cc2e35-aa38-4d2b-b395-2bde200f6fed", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/connecting-to-kafka"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "badcaae8-e7f2-4af1-b721-2e0701a3bcc3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/connecting-to-kafka"}, "hash": "b84f804133e8a7a352412dc939ac7138c402899d698138d68a9ca28c4e212cf1"}}, "hash": "9936fce676cfc0b8e3aa6b9d3f24fe0e37600b585c15012fc41bab858cc7a947", "text": "Kafka - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookKafkaThe Arize Pandas SDK can be utilized to consumes micro-batches of predictions to Arize to enable real time observability.OverviewRelevant Kafka messages consist of a model\u2019s input features, its relevant metadata (referred to as tags in the Arize platform), and the predictions.Visualization of Arize fitting into a Kafka PipelineExampleIn the example below, Arize consumes a microbatch of up to 100,000 events or up to 10 seconds. This is a configuration that can be adjusted based on your use case.Arize consumes these events, deserialize them, and batch them together prior to sending them over the wire into the Arize platform. This micro-batching amortizes any round-trip overhead. Note that the automatic partition offset commits are disabled and manually commit the offsets after data has been persisted at the Arize edge. This ensures no data loss in the case of service disruption in any step of the process. Kafka consumers can be set to consume all partitions on a topic, or for larger clusters can be set to consume specific partitions \u2013 allowing for parallelization of the consumer and further increasing throughput for truly large data processing, ensuring data is always ingested in real time and minimizing any potential latency.from kafka import KafkaConsumer, OffsetAndMetadataimport jsonimport pandas as pd\u200bfrom arize.pandas.logger import Client, Schemafrom arize.utils.types import ModelTypes, Environments\u200b# list the Broker\u2019s endpoints where the consumer will be listening to\u200bBROKER_LIST = [\"localhost: 9092\"]TOPIC = \"arize - inference - stream\"deser = lambda x: json.loads(x.decode(\"utf - 8\"))\u200b# disable enable_auto_commit to ensure data is fully persisted prior to moving on to the next transaction\u200bconsumer = KafkaConsumer(    bootstrap_servers=BROKER_LIST,    value_deserializer=deser,    group_id=\"Arize - Consumer\",    enable_auto_commit=False,)\u200bconsumer.subscribe([TOPIC])\u200b# instantiate the Arize Client with your Space Credentials\u200barize_client = Client(    space_key=\"ARIZE_SPACE_KEY\",    api_key=\"ARIZE_API_KEY\",)while True:    record = consumer.poll(        timeout_ms=10_000,        max_records=100_000, ) for k, v in record.items(): # Set the messages into a pandas dataframe for fast streaming into Arize        inferences = pd.DataFrame([row.value for row in v])        reserved_columns = [ \"prediction_label\", \"prediction_score\", \"prediction_id\", \"prediction_ts\", ]\u200b # Define the schema for your model        schema = Schema(            prediction_id_column_name=\"prediction_id\",            timestamp_column_name=\"prediction_ts\",            feature_column_names=inferences.drop(columns=reserved_columns).tolist(),            prediction_label_column_name=\"prediction_label\",            prediction_score_column_name=\"prediction_score\", )\u200b # Log inferences to Arize        res = arize_client.log(            dataframe=inferences,            model_id=\"model_id\",            model_version=\"model_version\",            model_type=ModelTypes.SCORE_CATEGORICAL,            environment=Environments.PRODUCTION,            schema=schema, )\u200b # Once data is successfully sent to Arize, then we commit the consumer offsets.        meta = consumer.partitions_for_topic(TOPIC)        options = {record.partition: OffsetAndMetadata(record.offset + 1, meta)}        consumer.commit(options)Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousDeepnoteNextFeastLast modified 4mo agoOn this pageOverviewExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5337, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "024f1e88-dd1f-4150-ad24-ca0549749352": {"__data__": {"id_": "024f1e88-dd1f-4150-ad24-ca0549749352", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/deepnote"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "a9c1cfc8-ef22-413b-8ae9-d71f45673b15", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/deepnote"}, "hash": "e55c7986fdffbe5e4b89758af1457690f3ef62b70f2b79947819113354cb9f8c"}}, "hash": "c83cbd3bc92d1ea918c515b2fcc2b0ce5cf914e6812cfa827f8a79594c8dc389", "text": "Deepnote - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDeepnoteIntegrating Arize with collaboration notebook tool, DeepnoteDeepnote is a new kind of Jupyter-compatible data science notebook with real-time collaboration and running in the cloud. The Arize platform can easily integrate with Deepnote to enable model observability, explainability, and monitoring while also allowing collaboration between team members.The following is a Deepnote notebook showing how to quickly set-up Arize as an Integration, as well as a demo example to log training, validation, and production for ML observability.Arize_Deepnote_IntegrationDeepnote\u200bPreviousCML (DVC)NextKafkaLast modified 2yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2498, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "4ff35440-99ea-4166-80a9-349a7965834f": {"__data__": {"id_": "4ff35440-99ea-4166-80a9-349a7965834f", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/feast"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "cd857c5a-1fd1-45e8-b942-193e6e75442e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/feast"}, "hash": "f99056de003cea5085856c06de344d721610c30b83fbe89f20e517be3fe91166"}}, "hash": "3bf9aa4420a79ec3554b82a8c7cd7727ddb50a4da2d3dc766daf6d82bd9b4ad0", "text": "Feast - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookFeastIntegrating Arize with open sourced lightweight feature store, Feast.\u200bArize and Feast are two platforms aimed at different, but connected, parts of the ML pipeline. Arize helps you visualize your model performance, understand drift & data quality issues, and share insights as your Evaluation Store. Feast (i.e, Feature Store) is an operational data system for managing and serving machine learning features to models in production.Integration with Feast is simple in four steps.Step 1: Log production by calling arize.log after materializing and store.get_online_features.Step 2: At training time, log validation under batch_id of offlineafter fetch historical feature store.get_offline_features. Step 3: Set-up match environment on Arize.Step 4: Troubleshoot and observe any data inconsistency issue with Arize.Tutorial NotebookWe have set up a very basic example using Feast with Arize.Google Colaboratory\u200bPreviousKafkaNextGoogle Cloud MLLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2837, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d7f18fc0-9953-4672-bb97-1f082607fa59": {"__data__": {"id_": "d7f18fc0-9953-4672-bb97-1f082607fa59", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/google-cloud-ml-python"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1103ebe6-8bea-4ea4-b86b-a681434598ce", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/google-cloud-ml-python"}, "hash": "f71c22be121bd8c119bb4af8f5f922520c51baea7ba6ef2358b8eaff005e317d"}}, "hash": "f514bcfa58a8585d01ebc53d2d37899602db8004808040ea65b256214b631718", "text": "Google Cloud ML - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGoogle Cloud MLOverviewPlease request these Notebooks from our support team\u200bPreviousFeastNextHugging FaceLast modified 3yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2005, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "5dc1321d-7d0d-4789-9fd8-b96162a25223": {"__data__": {"id_": "5dc1321d-7d0d-4789-9fd8-b96162a25223", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/hugging-face"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f2964e91-937c-4d33-80c2-06b338f61070", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/hugging-face"}, "hash": "3d94cf601abfeee8482545a32b3c8793951f91a1fd5cca9e716a4467995a3004"}}, "hash": "0fadbce8b363c9fc806fb36ed39572c8c2f48fc452cd54fbebff1d8abc7d765b", "text": "Hugging Face - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookHugging FaceArize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models. Hugging Face is a library offers both models on-demand in its Model Hub as well as APIs for you to fine-tune NLP models and serve them directly from Hugging Face. For additional context, check out the blog post on our partnership with Hugging Face. Inference API IntegrationHugging Face Inference API allows you to access public model and ones you have uploaded through Model Hug. Depending on the task, Arize can be directly integrated during production during the query function, or during your model's pipeline.Integration can be done in 4 simple steps: (1) Set up your Arize and Hugging Face API/SPACE Key, (2) Process output (and/or features) (3) Log to Arize (4) Reformat and return outputsFine-Tune a Sentiment Classification Model ExamplePlease follow this notebook tutorial where we walk you through working with the Hugging Face ecosystem to fine-tune a pre-trained language model for a sentiment classification task. In addition, we will be extracting text embedding vectors and send them to Arize, where we will leverage our embedding tools to learn about and troubleshoot our dataset.Fine-Tune a Named Entity Recognition Model ExamplePlease follow this notebook tutorial where we walk you through working with the Hugging Face ecosystem to fine-tune a pre-trained language model for a token classification task, i.e., Named Entity Recognition (NER). In addition, we will be extracting token embedding vectors and send them to Arize, where we will leverage our embedding tools to learn about and troubleshoot our dataset.Zero-shot Text Classification ExampleFor zero-shot text classification problem, we log to Arize underModelType.SCORE_CATEGORICAL since we want to record both class label and probability score.Depending the specific NLP task and model pipeline, your response will be formatted differently. You may need to update Step 2 (Processing Outputs) to match model output and Step 3 (Logging to Arize) to match the specific NLP task goals.import numpy as npimport requestsfrom arize.api import Clientfrom arize.types import ModelTypes\u200bimport jsonimport requestsimport uuid\u200b# Step 1: Set up Arize and Hugging Face API/SPACE Key and TokensARIZE_SPACE_KEY = 'YOUR_ARIZE_SPACE_KEY'ARIZE_API_KEY = 'YOUR_ARIZE_API_KEY'arize = Client(space_key=ARIZE_SPACE_KEY, api_key=ARIZE_API_KEY)\u200bAPI_URL = \"https://api-inference.huggingface.co/models/facebook/bart-large-mnli\"YOUR_HUGGINGFACE_API_KEY = 'YOUR_HUGGINGFACE_API_KEY'\u200bheaders = {\"Authorization\": \"Bearer {}\".format(YOUR_HUGGINGFACE_API_KEY}\u200bdef query(payload): # Step 1: Standard request to Hugging Face Inference API    data = json.dumps(payload)    response = requests.request(\"POST\", API_URL, headers=headers, data=data)    output = json.loads(response.content.decode(\"utf-8\"))  # Step 2: Process output (and/or features) for logging to Arize    idx = np.argmax(output['scores'])    prediction, score = output['labels'][idx], output['scores'][idx]  # optional, if you want to log model features to Arize    features = feature_pipeline(data)\u200b # Step 3: Log to Arize    arize_response = arize.log(        model_id='facebook/bart-large-mnli',        model_version='1.0',        model_type=ModelTypes.SCORE_CATEGORICAL,        prediction_id = str(uuid.uuid4()),        prediction_label=(prediction, score), )     arize_success = arize_response.result().status_code == 200 # Step 4: Return the formatted output return {'prediction': prediction,  'score': score, 'arize-success': arize_success}If using version < 4.0.0, replace space_key=ARIZE_SPACE_KEY with organization_key=ARIZE_SPACE_KEYOn the client side of production, results can be queries through directly calling the functiondata = query( { \"inputs\": \"\"\"        I recently bought a device from your company         but it is not working as advertised and         I would like to get reimbursed!        \"\"\", \"parameters\": {\"candidate_labels\": [\"refund\", \"legal\", \"faq\"]}, })>>> {'prediction': 'refund', 'score': 0.8680453300476074, 'arize-success': True}PreviousGoogle Cloud MLNextLangChain \ud83e\udd9c\ud83d\udd17Last modified 11mo agoOn this pageInference API IntegrationFine-Tune a Sentiment Classification Model ExampleFine-Tune a Named Entity Recognition Model ExampleZero-shot Text Classification ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6236, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "66749c87-ae52-4559-ac24-048e3ef40202": {"__data__": {"id_": "66749c87-ae52-4559-ac24-048e3ef40202", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/langchain"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4dd61e0c-2858-400a-b621-1b0f47655bf5", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/langchain"}, "hash": "36bcd8f5ea0e5771698fe3c7abb3f1b8a2ee62ce95c05106ead8eab0fc6de803"}}, "hash": "135282f7704ca9342e419b3f273a82ab073f2061d916af3d3c2afb86269697e2", "text": "LangChain \ud83e\udd9c\ud83d\udd17 - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookLangChain \ud83e\udd9c\ud83d\udd17A framework for developing applications powered by Large Language Models (LLMs).Google ColaboratoryOverviewLangChain is a cutting-edge framework that facilitates the development of powerful applications driven by large language models. It follows two key principles: agenticity and data awareness. LangChain provides a wide range of modules that enable language models to connect with diverse data sources and interact seamlessly with their surroundings.Use Arize and LangChain together to effectively monitor the performance of your LLM agents, identify areas that require improvement, and make prompt engineering decisions about your LLM applications. With Arize and LangChain together, data scientists and machine learning engineers can ensure that their LLM applications are running at peak efficiency, enabling them to deliver improved results and drive greater value for their organizations.Import LibrariesTo enable LangChain integration, first import both libraries. !pip3 install langchain !pip3 install arize !pip3 install 'arize[AutoEmbeddings]'Log Data To ArizePass in ArizeCallBackHandler within your LangChain application to log prompt response pairs to Arize. from langchain.callbacks import StdOutCallbackHandlerfrom langchain.callbacks.arize_callback import ArizeCallbackHandlerfrom langchain.callbacks.base import CallbackManagerfrom langchain.llms import OpenAI\u200b# Define callback handler for Arizearize_callback = ArizeCallbackHandler(model_id=\"llm-langchain-demo\",model_version=\"1.0\",SPACE_KEY=\"YOUR_SPACE_KEY\",API_KEY=\"YOUR_API_KEY\")manager = CallbackManager([StdOutCallbackHandler(), arize_callback])llm = OpenAI(temperature=0, callback_manager=manager, verbose=True)PreviousHugging FaceNextMLflowLast modified 3mo agoOn this pageOverviewImport LibrariesLog Data To ArizeSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3682, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "95578f21-3247-4384-b4ba-353d60e0e444": {"__data__": {"id_": "95578f21-3247-4384-b4ba-353d60e0e444", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/mlflow"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d5fd8253-ceeb-4262-8a4a-95e8bea1dea3", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/mlflow"}, "hash": "a369a11fabdb7bb396d0809fd80ac120c35d93e1c2dfe99d414a4ab23f84a3e0"}}, "hash": "1253af82fb4b3f7a07420162a72844b64b3ff5f21d7651deaec141fb6cd9f306", "text": "MLflow - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookMLflowIntegrating Arize with ML life cycle tooling, MLflow.\u200bMLflow is an open source platform to manage the ML lifecycle, including experimentation, reproducibility, deployment, model registry. By integrating Arize and MLflow, you will be able to train, manage, and register your models while  actively monitoring performance, data quality, and troubleshooting degradations across your models. Use our lightweight integrations at different stages of your ML lifecycle (training & serving) to continuously monitor and ensure performance tracked by MLflow is preserved in production.$pip install arize$pip install mlflowCheck out our Arize x MLflow Colab tutorial to get started!\u2714\ufe0f Steps for this Walkthrough1.Examples of setting up Arize and MLflow2.Experiment Managing with MLflow + Production Benchmarking with Arize3.Storing and Loading model with MLflow4.Integrating Serving End-point with Arize + MLflow5.Some key take-aways for the joint value add of using two platforms togetherPreviousLangChain \ud83e\udd9c\ud83d\udd17NextNeptuneLast modified 4mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2907, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d0163aa9-f03a-4f55-8694-ab178773eef7": {"__data__": {"id_": "d0163aa9-f03a-4f55-8694-ab178773eef7", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/neptune"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "dcde8e85-8f2c-4597-bacd-59982631eff2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/neptune"}, "hash": "36c46bc0e635585411bf8bad9fdead7b445ed1122b314e3266b541e3366b7f6a"}}, "hash": "908e3f8b962e474683f56940b3c968a5876f5448d19a39cd9519bdf4eb5db59f", "text": "Neptune - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookNeptuneIntegrating Arize with experiment tracking tool, NeptuneArize and Neptune are MLOps tools that aim to improve connected, but different parts of your ML pipeline and ML workflow. Arize helps you visualize your production model performance, understand drift & data quality issues. Neptune logs, stores, displays, and compares all your MLOps metadata for better experiment tracking.With Arize and Neptune, you will be able to train the best model, and pre-launch validate your model, and compare production performances of those models.Read the full blog here.  Tutorial NotebookWe have set up a very basic example using Neptune with Arize.\u2714\ufe0f Steps for this Walkthrough Notebook1.Initialize Neptune and set-up Arize client2.Logging training callbacks to Neptune3.Logging training and validation records to Arize4.Storing and versioning model weights with Neptune5.Logging and versioning model in production with ArizeGoogle Colaboratory\u200bPreviousMLflowNextPaperspaceLast modified 11mo agoOn this pageTutorial Notebook\u2714\ufe0f Steps for this Walkthrough NotebookSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2929, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3f0a1f20-36f5-43d6-bba6-2d9441bf65bd": {"__data__": {"id_": "3f0a1f20-36f5-43d6-bba6-2d9441bf65bd", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/paperspace"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ccfaabeb-d828-4d5e-ba30-7e73e73dfe39", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/paperspace"}, "hash": "9e58bb02c7e4496ddf75fa8f862ab62c435bf6fc5014bdc755c3201fb27be3bd"}}, "hash": "c3ceee89a0c950870b43751c2aa4727b5d21fad49bce0215da1babd4e8ec3be1", "text": "Paperspace - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPaperspaceRead the full blog here. PreviousNeptuneNextPySparkLast modified 1yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 1956, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "dd12e28f-6f50-430e-ae77-f987d8d9f024": {"__data__": {"id_": "dd12e28f-6f50-430e-ae77-f987d8d9f024", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/pyspark"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5d37d42b-b518-47c4-9c42-60fee2dc354a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/pyspark"}, "hash": "2dd4826b5494530ec1379a4657b89c8caf6ea2b747b48218ed60abc658a2e456"}}, "hash": "4d1440ec1113c2319de6f84a362ab0f581e7e52553fe355cad9e579b2da63fd2", "text": "PySpark - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPySparkLeveraging PySpark to send events to ArizeTo log PySpark DataFrames to Arize, please use the following Colab as an example: Colab Link\u200b\u200bPreviousPaperspaceNextRay Serve (Anyscale)Last modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2078, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "00ecca9f-4abe-4e2b-ab8e-eb2a7ee64524": {"__data__": {"id_": "00ecca9f-4abe-4e2b-ab8e-eb2a7ee64524", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "96c70afa-6c7c-4e3c-9f10-be0d77a327d4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python"}, "hash": "6cc885c135f16af0b7753810979d504f735981e7399f61be9034db5611defa80"}}, "hash": "0a277f37e0a202d8493a817333f9227acde895ac42b010686142e9e6b34c9621", "text": "SageMaker - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerBatchRealTimeNotebook Instance with Greater than 20GB of DataSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSageMakerOverviewThese tutorials are designed to work in any environment and showcase a number of model types. Copy the Tutorials and upload to a SageMaker Notebook Instance ServerSome tutorials include both a PYNB Notebook and a Lambda .py file. Upload both files to the Notebook server as the Notebook will help upload the Lambada function.Simply copy the tutorials into your own drive and add your API & SPACE KEY for executionArize Hello World Pynbfrom arize.api import Client#SPACE KEY - SUPPLIED BY ARIZEspace_key = 'SPACE_KEY'#API KEY - GENERATED IN ARIZE ACCOUNT OR SUPPLIEDapi_key = 'API_KEY'\u200bPreviousRay Serve (Anyscale)NextBatchLast modified 1yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2595, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "538259db-ffe5-40ce-9ff4-d44b4cf5aa0b": {"__data__": {"id_": "538259db-ffe5-40ce-9ff4-d44b4cf5aa0b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/spell"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9fb7e68c-4a10-43a0-a772-f0654ca74244", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/spell"}, "hash": "3d375323ddc5e9155a0d16d140c747cec9f4f8d5edf5c3cfcdbdc36606589589"}}, "hash": "9167485536113374423975dfccb0c8d0098df099989297cb796288d50998e658", "text": "Spell - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSpellIntegrating Arize with model serving and tooling platform, SpellArize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models. Spell is an end-to-end ML platform that provides infrastructure for company to deploy and train models.Read more about the platforms on our partnership announcement. Read more about the platforms on our partnership announcementYou can either work through on Colab, or follow the steps below for your own model!Terminal OnlyColab NotebookStep 1: Logging into spell via command line.$ spell loginStep 2: Train and create model with spell.$ spell run \\    --github-url https://github.com/spellml/examples \\    --machine-type cpu \\    --mount public/tutorial/churn_data/:/mnt/churn_prediction/ \\    --pip arize --pip lightgbm \\    -- python arize/train.pyStep 3: Add your Arize API_KEY and SPACE_KEY to serve_async.py and server_sync.py. You can find your Arize credential details here\u200bStep 4: Creating your model your model and serving it.$ spell model create churn-prediction 'runs/$RUN_ID'$ spell server serve \\    --node-group default \\    --min-pods 1 --max-pods 3 \\    --target-requests-per-second 100 \\    --pip lightgbm --pip arize \\    --env ARIZE_SPACE_KEY=$ARIZE_SPACE_KEY \\    --env ARIZE_API_KEY=$ARIZE_API_KEY \\    churn-prediction:v1 serve_sync.py  # or serve_async.pyStep 5: Test your working instance, send in some data, and see that your model is observable on Arize.$ curl -X POST -d '@test_payload.txt' \\    https://$REGION.$CLUSTER.spell.services/$SPACE/churn-prediction/predict\u200bSpell Integration Tutorial\u200bColab Link\u200b\u200bPreviousNotebook Instance with Greater than 20GB of DataNextUbiOpsLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3596, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a2fe763e-6ddb-4187-bfa9-94e30671beb0": {"__data__": {"id_": "a2fe763e-6ddb-4187-bfa9-94e30671beb0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ubiops"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1898ae68-5586-4446-8d4e-ca3f775e4849", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ubiops"}, "hash": "f62caa773f77624d404807c702e850a6bdede139bd3185eab3e4eaa895370994"}}, "hash": "2e6ace7c84a579603b9f7ae1e74fa5bc79ddd295e9ef6c63be3e0053108f59a4", "text": "UbiOps - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookUbiOpsIntegrating Arize with model deployment and serving platform, UbiOps.\u200bUbiOps is an MLOps platform with APIs to deploy and serve models. The Arize platform can easily integrate with UbiOps to enable model observability, explainability, and monitoring.The following example shows how to deploy a model on UbiOps, add Arize tracking to the model, and send data to the Arize platform.Read the full blog post here. UbiOps Integration NotebookGoogle Colaboratory\u200bPreviousSpellNextWeights & BiasesLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2388, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "cec313b2-c3cf-41d3-90cb-8bf85ca3f58e": {"__data__": {"id_": "cec313b2-c3cf-41d3-90cb-8bf85ca3f58e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/weights-and-biases"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "bb1adff4-9674-4241-8e04-ed85392592bc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/weights-and-biases"}, "hash": "460050c2775e655f7f85749c79c6e1773b7a1f91e759c48ce95dacf27401bdc9"}}, "hash": "14c58ac976fa7792f94fcd0c68cf70e7bc73689ca08ddf088c64eea482b2ae78", "text": "Weights & Biases - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookWeights & BiasesArize helps you visualize your model performance, understand drift & data quality issues, and share insights learned from your models. Weights and Biases helps you build better model by logging metrics and visualize your experiments before production.$pip install arize$pip install wandbWeights and Biases Integration NotebookBefore production, Arize offers training and validation logging for creating model performance baseline, while Weights and Biases help you manage model experiment details and track your best performing models. During production, Weights and Biases offers hosting and serving your model, while Arize helps you monitor, visualize, and understand the served model in production.Work through our demo notebook to see usage cases for Arize with Weights & Biases!Google Colaboratory\u200bPreviousUbiOpsNext - ResourcesCommon Industry Use CasesLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2777, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2684e6cb-1144-4735-b973-9f1a7046fcc4": {"__data__": {"id_": "2684e6cb-1144-4735-b973-9f1a7046fcc4", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/churn-forecasting"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5d5d50ce-315e-4813-996d-b1f9a7fa6bd4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/churn-forecasting"}, "hash": "0634d91aeeae02ba3b4b3ad0f84d861f0234e1ef81507d1afeb029c3118e35c8"}}, "hash": "c9855b9d9e56dc55836b4a918316b16524dd6a64ded5ee9c0f9f6a428f5790f4", "text": "Churn Forecasting - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookChurn ForecastingOverview of how to use Arize for churn modelsCheck out our Churn Forecasting Colab for an interactive demo.Overview In this walkthrough, we will use the Arize platform to monitor a Churn Forecasting model's performance.This use case will walk you through how to manage your model's performance for your churn forecasting models. This will outline how model monitoring and observability can aid common problems associated with churn forecasting models in production. Learn how to actively monitor your model performance, identify root cause issues, and gain further insights into model improvement. We will look at a few scenarios common to churn models when monitoring performance. You will learn to:1.Get training, validation, and production data into the Arize platform2.Setup a baseline3.Setup performance monitors for Accuracy, False Negative Rate, and False Positive Rate4.Create customized dashboards5.Discover the root cause of issues6.Identify business impact Set up a Baseline Within Arize, you can set a baseline for the model which compares your model's behavior in production to a training set, validation set, or an initial model launch period. This allows us to determine when/where our model's behavior has changed drastically. A baseline will help identify potential model issues, changing user behaviors, or even changes in our model's concepts.Setting up a baseline will surface changes in the distributions of: 1.Model predictions \u2014churn / not_churn 2.Model input data \u2014 feature values 3.Ground truth/Actual values \u2014 was this transaction actually churnChoosing a baseline This churn model has a training environment that we will set as the baseline.If you want to compare to a previous period in production like the initial rollout of the model or using a trailing window of production then you can select production as a baseline in Arize. MonitoringArize sets up monitors across all features, predictions, and actual values. Below are critical metrics to monitor for a churn model:Accuracy \u2014\u00a0of all my predictions, what percent did the model predict correctly? False Negative Rate \u2014\u00a0Missed Chance to Retain % (these are customers who eventually churn but were identified by the model as not_churn which means we didn't even try to save them).False Positive Rate \u2014 Wasted Retention Effort % (these are customers who did not that were classified as churn which means the account team spent money on discounts or other campaigns to save a customer who wasn't a threat to churn). Drift Detection Drift is a change in distribution over time. This is measured for model inputs, outputs, and actuals of a model. Drift can be used to indicate if a model has grown stale, if there are data quality issues, or if there are adversarial inputs in your model. Detecting drift in your models will help protect your models from performance degradation and allow you to understand better how to begin resolution.Type of DriftPossible Drift CorrelationPrediction DriftYour customers are extremely happy and there's less signals of potentially churning customers!Actual Drift (No Prediction Drift)An unexpected shift in the market occurred like a pandemic causing customers to cancel their gym memberships or travel credit cardsFeature DriftA new support model is deployed so there is a new input(s)Prediction Drift Impact can surface when drift has impacted your model. Drift (PSI) measures how much your distribution has drifted. Feature Importance helps you explain why even small Drift (PSI) can have significant Drift Impact Data Quality Checks It\u2019s important to immediately surface data quality issues to identify how your data quality maps to your model\u2019s performance. Utilize data quality monitoring to analyze hard failures in your data quality pipeline, such as missing data or cardinality shifts. Missing / Null values could be an indicator of issues from an upstream data source.Cardinality is checked to ensure there are no spikes / drops in feature values.Performance Analysis Model performance metrics measure how well your model performs in production by comparing the prediction to the ground truth or actual. Once a performance monitor is triggered, Arize allows you to quickly navigate to the Performance tab to start troubleshooting your model issues and gain an understanding of what caused the degradation. Compare production to training or other windows of production. Bring in another dataset to compare performance and see which model performs better. This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.Identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. Custom DashboardIn the case of churn model, a few key metrics to review are the False Positive, False Negative , and overall Accuracy rates.In only a few clicks, you can add widgets to provide a single glance view of your model's Accuracy, False Positive Rate, and False Negative Rate. To visualize these metrics over time you can also create a custom time series widget which overlays three plots to showcase the fluctuation of these metrics over time.Arize enables you to review your model's performance and take action on these insights by enabling an export to notebook option when you found an insight that you want to further investigate!ExplainabilityLog feature importances to the Arize platform to explain your model's predictions. By logging these values, you gain the ability to view the global feature importances of your predictions as well as the ability to perform global and cohort prediction-based analysis to compare feature importances for your model's features.PreviousFraudNextLendingLast modified 7mo agoOn this pageOverview Set up a Baseline Choosing a baseline MonitoringDrift Detection Data Quality Checks Performance Analysis Custom DashboardExplainabilitySupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 7891, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a2b93ec2-19ef-4b9e-badf-8614f5d45c00": {"__data__": {"id_": "a2b93ec2-19ef-4b9e-badf-8614f5d45c00", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/click-through-rate"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b1e0d094-602a-4616-a138-e1e652e65e69", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/click-through-rate"}, "hash": "4b986b637caf7dcee342fa75460488bdc112f63468b8a8943aa1b43e20938579"}}, "hash": "864e0f3c2cf86711ad8af7f8b22f15bd2bcfe1ea9d161f34df188605ff1cd748", "text": "Click-Through Rate - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookClick-Through RateOverview of how to use Arize for click-through rate modelsCheck out our Click-Through Rate Colab to send data in and follow along our Click-Through Rate workflow.OverviewIn this walkthrough, we will use the Arize platform to monitor Click-through Rate (CTR) model performance.This use case will walk you through how to manage your model's performance for an online advertising platform. While you have spent a great deal of your time collecting online data and training models for best performance, it's common that your models in production have no tools available to monitor the performance of your models, identify any issues or get insights into how to improve your models. In this walkthrough, we will look at a few scenarios common to an advertisement use-case and more specifically look at CTR predictions versus actuals for a given ad or ad group.You will learn to:1.Get training, validation, and production data into the Arize platform2.Setup a baseline and performance dashboards3.Create threshold alerts4.Monitor for Log-Loss5.Understand where the model is underperforming6.Discover the root cause of issuesSet up a Baseline Within Arize, you are able to set a baseline for the model which compares your model's behavior in production to a training set, validation set, or an initial model launch period. This allows us to determine when/where our model's behavior has changed drastically. Datasets: Training Version 1.0Default Metric: Accuracy, Trigger Alert When: Accuracy is below .7, Positive Class: clickTurn On Monitoring: Drift \u2705, Data Quality \u2705, Performance \u2705MonitoringArize sets up monitors across all features, predictions, and actual values. For click-through rate, it's important to monitor the model's Accuracy.Drift Detection Drift is a change in distribution over time, measured for model inputs, outputs, and actuals of a model. Measure drift to identify if your models have grown stale, you have data quality issues, or if there are adversarial inputs in your model. Detecting drift in your models will help protect your models from performance degradation and allow you to better understand how to begin resolution.Prediction Drift Impact can surface when drift has impacted your model. Drift (PSI) is a measurement of how much your distribution has drifted. Lastly, Feature Importance helps your explain why even small Drift (PSI) can have significant Drift Impact.Data Quality Checks It\u2019s important to immediately surface data quality issues to identify how your data quality maps to your model\u2019s performance. Utilize data quality monitoring to analyze hard failures in your data quality pipeline, such as missing data or cardinality shifts. Missing / Null values could be an indicator of issues from an upstream data source.Cardinality is checked to ensure there are no spikes / drops in feature values.Performance Analysis Model performance metrics measure how well your model performs in production. Once a performance monitor is triggered, navigate to the Performance tab to start troubleshooting your model issues and gain an understanding of what caused the degradation. Compare production to training or other windows of production. Bring in another dataset to compare performance and see which model performs better. This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.Identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. Root Cause Analysis WalkthroughWe can see that our type I error (false positive error) has significantly increased. Our model is predicting that many more clicks than in actuality. Our models is expecting a large amount of users to be clicking on a given ad, when in fact they are not. If we look into which cohorts are performing worst, we can peak in our dual histograms. From here we can see that there are large deviations in the device and domain features.It seems that our performance degradation is due to unseen populations in the device and domain category. Maybe this would be a indication that we should dig deeper into these cohorts and better understand how we want to handle these never before seen populations in the modelActionable InsightNow that we understand what is affecting our model we can now:Retrain the model in these brand new cohorts inside the device and domain features Handle the empty values in our data pipelines, affecting our data qualityCustom DashboardIn only a few clicks, you can add widgets to provide a single glance view of your model's import metrics and KPI. To visualize these metrics over time you can also create a custom time series widget which overlays three plots to showcase the fluctuation of these metrics over time.Below we'll set up a templatized dashboard and then adjust the template to match our use case. Now let's make a simple customization to our template. You can refine the Prediction Score vs Actual Score by Day graph by adding a similar plot with these filters:Pred Shopping: Use Aggregation Function : Average with Average of set to Prediction Score with filter (feature category = [shopping]). Also add a filter (feature domain != [new_site.com])ExplainabilityLog feature importances to the Arize platform to explain your model's predictions. By logging these values, you gain the ability to view the global feature importances of your predictions as well as the ability to perform global and cohort prediction-based analysis to compare feature importances for your model's features.ResourcesCheck out our Click-Through Rate Colab for an interactive demo and our best practices blog for industry context!Visit the Arize Blog and Resource Center for more resources on ML observability and model monitoring.Resources - PreviousCommon Industry Use CasesNextSearch RankingLast modified 7mo agoOn this pageOverviewSet up a Baseline MonitoringDrift Detection Data Quality Checks Performance Analysis Actionable InsightCustom DashboardExplainabilityResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 8008, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "32326f3f-1502-4a1f-adc8-5f125292842e": {"__data__": {"id_": "32326f3f-1502-4a1f-adc8-5f125292842e", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/customer-lifetime-value"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fe8a78e1-762c-406d-9846-9b166ddc3f72", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/customer-lifetime-value"}, "hash": "029eb7f1bac7e8680a3a38b95221b969be747e6442a0f8196804e000d8e83685"}}, "hash": "1144aa80f4c1cc05fac698d9ebe33f7c6e41fb1b1f40b7950de896c79b51cd21", "text": "Customer Lifetime Value - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookCustomer Lifetime ValueOverview of how to use Arize for customer lifetime value modelsCheck out our Customer Lifetime Value Colab to see how you can leverage ML Observability for your models! Set up a Baseline and Monitors In just a few clicks, Arize automatically configures monitors that are best suited to your data to proactively detect drift, data quality, and performance issues.1.Datasets:  Training Version 1.02.Default Metric: RMSE, Trigger Alert When: RMSE is above 803.Turn On Monitoring: Drift \u2705, Data Quality \u2705, Performance \u2705Exploring model and feature drift Visualize feature and model drift between various model environments and versions to identify LTV patterns and anomalous distribution behavior. Arize provides drift over time widgets overlaid with your metric of choice (in our case, RMSE) to clearly determine if drift is contributing to our performance degradation.With the insights provided on Arize, you can deep dive into root causes and quickly gain intuitions, allowing for ML teams to quickly iterate, experiment, and ship new models in production.Analyzing root cause for low performing cohorts Arize empowers automatic drill down on low performing slices (feature/value combinations) through the Feature Performance Heatmap.We could pay close attention to feature/value combinations that could be indicative of model exploitations. In the case of LTV as stated in the colab, we used filters on the Feature Performance Heatmap to narrow down Fiber Optic in Internet Service and Yes in Streaming TV across Cities.Model Performance Dashboard As we continue to check in and improve our model's performance, we want to be able to quickly and efficiently view all our important model metrics in a single pane. Use our Regression Model Performance Dashboard to set up a customizable dashboard for a single glance view of your model's important metrics.In the case of LTV, we look at the model's RMSE, MAPE, and MAE values.In only a few clicks we can visualize these metrics over time by creating a time series widget and overlaying three plots to showcase the fluctuation of the metrics over time.By visualizing the feature drift and model performance, and understanding the features responsible, ML Engineers can gain additional information when troubleshooting model performance issues. Possible action items that could improve the model\u2019s performance: Examining possible concept drifts relating to the features in question Retraining model to fit new distributions specific to this drift ResourcesCheck out our Customer Lifetime Value Colab to see how you can leverage ML Observability for your models! PreviousLendingNextDemand ForecastingLast modified 11mo agoOn this pageSet up a Baseline and MonitorsExploring model and feature drift Analyzing root cause for low performing cohortsModel Performance DashboardResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4680, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "393ca83b-83cf-4b5c-8885-68a455d311eb": {"__data__": {"id_": "393ca83b-83cf-4b5c-8885-68a455d311eb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/demand-forecasting"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "2772a7e1-8e38-43e5-a6b6-8bd709a1f2d4", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/demand-forecasting"}, "hash": "8b7cbdba5e609bf23f248527a6b0c4817ce33ec089c22ae7ccc2873157f8f28d"}}, "hash": "90645d382da13d86687da7a2d4ffb37b37eba95196107727f6da0925e1a4926b", "text": "Demand Forecasting - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookDemand ForecastingOverview of how to use Arize for demand forecasting modelsCheck out our Demand Forecasting Colab for an interactive demo and our best practices blog for additional industry context!MonitorsUsing the Arize Dashboard function, you can quickly set-up a Mean Error monitor that notifies you when model Mean Error dips below a specific number. You can do this for any evaluation metric on Arize (i.e MAE, MSE, MAPE).Monitoring Prediction Bias with Mean ErrorCustomizable Performance DashboardMean Error alone is not enough to tell the story. In a feature drift event where there is both over-prediction and under prediction, mean error could be cancelled out to be zero. This is why we will not only need monitors, but a side-by-side chart to allow us to compare the magnitude and direction of both Mean Absolute Error and Mean Error. We can configure times series cards with custom model metrics on the  Performance Dashboard, as shown below.Creating a custom times series widget for Mean Error + Mean Absolute ErrorWe can also create a Data Metric times series widget to visualize mean values of our predictions vs. actuals to gain further insight into any potential biases.Creating a Data Metric Times Series WidgetVisualizing Data Metric and Errors side-by-sideIn the Arize Dashboard shown below, it's clear that we see an over prediction event first, then an under prediction event later. We can clearly see the magnitude of these errors based on our custom configuration.Investigating Feature DriftArize can also be used to triage your ML model performance. The model performance troubleshooting tools are designed by ML engineers for engineers to help you understand and solve your model performance issues.Identifying features responsible for driftFeature drifted during period of under-predictionNot all feature drifts are inherently malignant and impact our model performances -- only some do. With the insights provided on Arize, you can deep dive into root causes and quickly gain intuitions, allowing for ML teams to quickly iterate, experiment, and ship new models in production.By visualizing the feature drift and understanding the features responsible, ML Engineers can gain additional information to work with when improving our models when troubleshooting model performance issues.Some possible conclusions and action items our engineers could make might be...1.Examining possible concept drifts relating to the features in question2.Retraining our model to fit new distributions specific to this driftResourcesCheck out our Demand Forecasting Colab for an interactive demo and our best practices blog for additional industry context!PreviousCustomer Lifetime ValueNextInsuranceLast modified 11mo agoOn this pageMonitorsCustomizable Performance DashboardVisualizing Data Metric and Errors side-by-sideInvestigating Feature DriftResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4696, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c2079423-78d7-48dd-88d1-fb2c0b4be0de": {"__data__": {"id_": "c2079423-78d7-48dd-88d1-fb2c0b4be0de", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d0d5761b-d1fd-4b2d-a30b-9e0e6a415da7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "hash": "31789dfdce152f44cccbde8fff6741a491ec23b4dbef8b8246817bac50701fa0"}, "3": {"node_id": "689fe355-521f-409f-885d-90ca24c44426", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "hash": "960474e82fde622ed3ae249a8d6f2b151ba6dfbff0a516dd8cd14147bd751292"}}, "hash": "fc097032c59f26b5c2c83055b9f1953325f015c2a30165da4414e610f2616849", "text": "Fraud - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookFraudOverview of how to use Arize for fraud modelsCheck out our Credit Card Fraud Colab for an interactive demo, our best practices blog for additional industry context, and our fraud webinar to see how you can leverage ML Observability for your fraud models. Overview In this walkthrough, we will use the Arize platform to monitor a Fraud Detection model's performance.This use case will walk you through how to manage your model's performance for your fraud detection models. While you may have found optimal model performance in the training environment after spending a great deal of time collecting data and training your model, it's common that your model will perform worse in the production environment. With a limited availability of tools to monitor your model performance, identify root cause issues, or gain insights into how to actively improve your model, troubleshooting your model performance issues can prove to be troubling.  In this walkthrough, we will look at a few scenarios common to a fraud model when monitoring for performance. You will learn to:1.Get training, validation, and production data into the Arize platform2.Setup performance monitors for False Negative Rate, False Positive Rate, and Accuracy 3.Create customized dashboards4.Discover the root cause of issues5.Identify business impactSet up a Baseline Set up a baseline for easy comparison of your model's behavior in production to a training set, validation set, or an initial model launch period. Specifically, we want to see when/where our model's behavior has changed drastically. Setting up a baseline will help identify potential model issues, changing user behaviors, or even changes in our model's concepts (what people consider fraud might change over time).Setting up a baseline will surface changes in the distributions of: 1.Model predictions \u2014fraud / non fraud 2.Model input data \u2014 feature values 3.Ground truth/Actual values \u2014 was this transaction actually fraudChoosing a baseline In the case of our credit card fraud model, we have a training environment that we want to compare production to. Therefore we are setting up the baseline by selecting pre-prod training.With fraud detection, often times your training set may contain an exaggerated amount of fraud for the purpose of training your model. However, in the real world, credit card fraud models see less than 1% fraud transactions. If this is true for your training environment, you may want to select an initial model launch period from production as your baseline (assuming that period of time looks as expected). Monitoring Arize sets up monitors across all features, predictions, and actual values. In fraud detection it's important to monitor your model's: 1.False Negative Rate \u2014\u00a0Chargeback % (fraud transactions that were identified by the model as non fraud leading to a chargeback/immediate financial loss for the company).2.False Positive Rate \u2014 Upset Customer % (non fraud transactions that were classified as fraud leading to an awkward moment at the register and an upset customer). 3.Accuracy \u2014\u00a0of all my predictions, what percent did the model predict correctly? We need to be careful with this metric as it can be potentially misleading, especially if there is a small amount of fraud transactions. If a model has 1% fraud, misclassifying all transactions can still result in 99% accuracy.Drift Detection Drift is a change in distribution over time, measured for model inputs, outputs, and actuals of a model. Measure drift to identify if your models have grown stale, you have data quality issues, or if there are adversarial inputs in your model. Detecting drift in your models will help protect your models from performance degradation and allow you to better understand how to begin resolution.Type of DriftPossible Drift CorrelationPrediction DriftInflux of fraud predictions could mean that your model is under attack. You are classifying a lot more fraud than what you expect to see in production, but (so far) your model is doing a good job at catching this. Let's hope it stays that way. Actual Drift (No Prediction Drift)Influx of fraud actuals without changes to the distribution of your predictions means that fraudsters have found an exploit in your model and that they're getting away with it! Troubleshoot and fix your model ASAP to avoid any more costly chargebacks. Feature DriftInflux of new and/or existing feature values could be an indicator of seasonal changes (tax or holiday season) or, in the worst case, be correlated with a fraud exploitation. Use drift over time, stacked on top of your metric over time graph, to validate whether there is any correlation. Prediction Drift Impact can surface when drift has impacted your model. Drift (PSI) is a measurement of how much your distribution has drifted. Lastly, Feature Importance helps your explain why even small Drift (PSI) can have significant Drift Impact.Data Quality Checks It\u2019s important to immediately surface data quality issues to identify how your data quality maps to your model\u2019s performance. Utilize data quality monitoring to analyze hard failures in your data quality pipeline, such as missing data or cardinality shifts. Missing / Null values could be an indicator of issues from an upstream data source.Cardinality is checked to ensure there are no spikes / drops in feature values.Performance Analysis Model performance metrics measure how well your model performs in production. Once a performance monitor is triggered, navigate to the Performance tab to start troubleshooting your model issues and gain an understanding of what caused the degradation. Compare production to training or other windows of production. Bring in another dataset to compare performance and see which model performs better. This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.Identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. Custom DashboardIn the case of credit card fraud, the most important metrics to worry about are your False Positive, False Negative, and overall Accuracy rates. Note, Recall is the inverse of False Negative Rate if your positive class is Fraud. In only a few clicks you can add widgets to provide a single glance view of your model's Accuracy, False Positive Rate, and False Negative Rate. To visualize these metrics over time you can also create a custom timeseries widget which overlays", "start_char_idx": 0, "end_char_idx": 8240, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "689fe355-521f-409f-885d-90ca24c44426": {"__data__": {"id_": "689fe355-521f-409f-885d-90ca24c44426", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d0d5761b-d1fd-4b2d-a30b-9e0e6a415da7", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "hash": "31789dfdce152f44cccbde8fff6741a491ec23b4dbef8b8246817bac50701fa0"}, "2": {"node_id": "c2079423-78d7-48dd-88d1-fb2c0b4be0de", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}, "hash": "fc097032c59f26b5c2c83055b9f1953325f015c2a30165da4414e610f2616849"}}, "hash": "960474e82fde622ed3ae249a8d6f2b151ba6dfbff0a516dd8cd14147bd751292", "text": "three plots to showcase the fluctuation of these metrics over time.imageExplainability Log feature importances to the Arize platform to explain your model's predictions. By logging these values, you gain the ability to view the global feature importances of your predictions as well as the ability to perform global and cohort prediction-based analysis to compare feature importances for your model's features.ResourcesCheck out our Credit Card Fraud Colab for an interactive demo, our best practices blog for additional industry context, and our fraud webinar to see how you can leverage ML Observability for your fraud models. PreviousSearch RankingNextChurn ForecastingLast modified 7mo agoOn this pageOverview Set up a Baseline Choosing a baseline Monitoring Drift Detection Data Quality Checks Performance Analysis Custom DashboardExplainability ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8241, "end_char_idx": 9325, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "3e62db98-efe5-4ea1-a28c-1dc375f62337": {"__data__": {"id_": "3e62db98-efe5-4ea1-a28c-1dc375f62337", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/insurance"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "43912db0-6d9b-4768-8d1b-2c2bdc1a64cf", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/insurance"}, "hash": "02ef666dd52dddd23bc540529cb5bf5e5a41bb377196ee06f3cd9a9284d53bcf"}}, "hash": "58639181593c6174faed918b123a974fed69f76ca85764649d1b5f889a3e25ec", "text": "Insurance - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookInsuranceOverview of how to use Arize for insurance modelsCheck out our Insurance Colab and our Lending & Insurance Webinar to see how you can leverage ML Observability for your insurance models. Set up a Baseline and MonitorsIn just a few clicks, Arize automatically configures monitors that are best suited to your data to proactively detect drift, data quality, and performance issues.1.Datasets:  Training Version 1.02.Default Metric: Mean Error, Trigger Alert When: Mean Error is below -0.013.Turn On Monitoring: Drift \u2705, Data Quality \u2705, Performance \u2705Exploring Model and Feature DriftVisualize feature and model drift between various model environments and versions to identify loan defaulting patterns and anomalous distribution behavior. Arize provides drift over time widgets overlaid with your metric of choice (in our case, Mean Error) to clearly determine if drift is contributing to our performance degradation.Data drift causing model degradationWith the insights provided on Arize, you can deep dive into root causes and quickly gain intuitions, allowing for ML teams to quickly iterate, experiment, and ship new models in production.ResourcesCheck out our Insurance Colab and our Lending & Insurance Webinar to see how you can leverage ML Observability for your insurance models. PreviousDemand ForecastingNextTimeseries ForecastingLast modified 11mo agoOn this pageSet up a Baseline and MonitorsExploring Model and Feature DriftResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3271, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "c938f1b0-9822-40e0-a1cc-8ee9372dc395": {"__data__": {"id_": "c938f1b0-9822-40e0-a1cc-8ee9372dc395", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ca3494d5-a0c1-41ff-b7ae-dae66a92a60a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "hash": "c57d1148d7d3ff01be6cf28a58bf17252752f8dd2da0a7615a818dd264ac974c"}, "3": {"node_id": "a613825a-0230-4b5d-8b8b-366c2c582b5a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "hash": "c9292b3d1d4e88ee73006cfb9f7e1d18f334ecefeb2e547942af080ee24fe70d"}}, "hash": "ceb4917758c2729859a2ac80f2471090ca6d3b2c45355f7d5a79291e2544accc", "text": "Lending - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookLendingOverview of how to use Arize for insurance modelsCheck out our Lending Colab and our Lending & Insurance Webinar to see how you can leverage ML Observability for your lending models! Overview In this walkthrough, we will use the Arize platform to monitor a Lending Prediction model's performance.    This use case will walk you through how to manage your model's performance for your lending models. While you have spent a great deal of your time collecting online data and training models for it's best performance in the training environment, it's common that your models in production have a limited number of tools available to monitor your model performance, identify root cause issues, or gain insights into how to actively improve your model. In this walkthrough, we will look at a few scenarios common to lending models when monitoring for performance. You will learn to:1.Get training, validation, and production data into the Arize platform2.Create a baseline3.Setup performance monitors for False Negative Rate, False Positive Rate, Mean Error, and Accuracy 4.Set up customized dashboards5.Discover the root cause of issues6.Identify business impactSet up a Baseline Set up a baseline for easy comparison of your model's behavior in production to a training set, validation set, or an initial model launch period. Specifically, we want to see when/where our model's behavior has changed drastically. Setting up a baseline will help identify potential model issues, changing user behaviors, or even changes in our model's concepts (what people consider fraud might change over time).Setting up a baseline will surface changes in the distributions of: 1.Model predictions \u2014approve / deny 2.Model input data \u2014 feature values 3.Ground truth/Actual values \u2014 was this loan prediction actually deniedChoosing a baseline In the case of our lending model, we have a training environment that we want to compare production to. Therefore we are setting up the baseline by selecting pre-prod training.With lending decisions, often times your training set may contain an exaggerated amount of defaults for the purpose of training your model. However, in the real world, loans are much more likely to be paid off than to be defaulted on. If this is the case for your training environment, you may want to select an initial model launch period from production as your baseline (assuming that period of time looks as expected). Datasets:  Training Version 1.0Default Metric: Accuracy, Trigger Alert When: Accuracy is below 0.6, Positive Class: denyTurn On Monitoring: Drift \u2705, Data Quality \u2705, Performance \u2705MonitoringArize sets up monitors across all features, predictions, and actual values. In lending it's important to monitor your model's: 1.False Negative Rate \u2014\u00a0Chargeback % (denied loans that were identified by the model as approved leading to a chargeback/immediate financial loss for the company).2.False Positive Rate \u2014 Upset Customer % (approved loans that were classified as denied leading to an awkward moment at the register and an upset customer). 3.Accuracy \u2014\u00a0of all my predictions, what percent did the model predict correctly? We need to be careful with this metric as it can be potentially misleading, especially if there is a small amount of defaults. If a dataset has 5% of it labeled deny, misclassifying all transactions can still result in 95% model accuracy.In just a few clicks, Arize automatically configures monitors that are best suited to your data to proactively detect drift, data quality, and performance issues.Drift Detection Drift is a change in distribution over time, measured for model inputs, outputs, and actuals of a model. Measure drift to identify if your models have grown stale, you have data quality issues, or if there are adversarial inputs in your model. Detecting drift in your models will help protect your models from performance degradation and allow you to better understand how to begin resolution.Prediction Drift Impact can surface when drift has impacted your model. Drift (PSI) is a measurement of how much your distribution has drifted. Lastly, Feature Importance helps your explain why even small Drift (PSI) can have significant Drift Impact.Exploring model and feature drift Visualize feature and model drift between various model environments and versions to identify loan defaulting patterns and anomalous distribution behavior. Arize provides drift over time widgets overlaid with your metric of choice (in our case, Accuracy) to clearly determine if drift is contributing to our performance degradation.Here we see two important features (num_credit_lines and purpose) drifting, which likely means data drift is causing performance degradation. In addition to the baseline and current distributions diverging from each other, we also see the input credit_card in the feature purpose that are only seen in the production data and not the baseline dataset. In this case, where the baseline is your training dataset, you should retrain your model with the new data. With the insights provided on Arize, you can deep dive into root causes and quickly gain intuitions, allowing for ML teams to quickly iterate, experiment, and ship new models in production.Data Quality Checks It\u2019s important to immediately surface data quality issues to identify how your data quality maps to your model\u2019s performance. Utilize data quality monitoring to analyze hard failures in your data quality pipeline, such as missing data or cardinality shifts. Missing / Null values could be an indicator of issues from an upstream data source.Cardinality and Quantiles are checked to ensure there are no spikes / drops in feature values.Performance Analysis Model performance metrics measure how well your model performs in production. Once a performance monitor is triggered, navigate to the Performance tab to start troubleshooting your model issues and gain an understanding of w\nhat caused the degradation. Compare production to training or other windows of production. Bring in another dataset to compare performance and see which model performs better. This can help answer questions such as \"Were we seeing this problem in training?\" or \"Does my new / previous model version perform better?\". It can also be helpful to compare to other windows of production.Identify low performing segments. By looking at performance breakdown by feature, you can dig even deeper to see which segment within each feature of the model is underperforming. Custom DashboardIn the case of lending, the most important metrics to worry about are your False Positive, False Negative, and", "start_char_idx": 0, "end_char_idx": 8203, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a613825a-0230-4b5d-8b8b-366c2c582b5a": {"__data__": {"id_": "a613825a-0230-4b5d-8b8b-366c2c582b5a", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "ca3494d5-a0c1-41ff-b7ae-dae66a92a60a", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "hash": "c57d1148d7d3ff01be6cf28a58bf17252752f8dd2da0a7615a818dd264ac974c"}, "2": {"node_id": "c938f1b0-9822-40e0-a1cc-8ee9372dc395", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}, "hash": "ceb4917758c2729859a2ac80f2471090ca6d3b2c45355f7d5a79291e2544accc"}}, "hash": "c9292b3d1d4e88ee73006cfb9f7e1d18f334ecefeb2e547942af080ee24fe70d", "text": "overall Accuracy rates. Note, Recall is the inverse of False Negative Rate if your positive class is Defaulted. In only a few clicks you can add widgets to provide a single glance view of your model's Accuracy, False Positive Rate, and False Negative Rate. To visualize these metrics over time you can also create a custom timeseries widget which overlays three plots to showcase the fluctuation of these metrics over time.imageExplainability Log feature importances to the Arize platform to explain your model's predictions. By logging these values, you gain the ability to view the global feature importances of your predictions as well as the ability to perform global and cohort prediction-based analysis to compare feature importances for your model's features.ResourcesCheck out our Lending Colab and our Lending & Insurance Webinar to see how you can leverage ML Observability for your lending models!\u200bPreviousChurn ForecastingNextCustomer Lifetime ValueLast modified 7mo agoOn this pageOverview Set up a Baseline Choosing a baseline MonitoringDrift Detection Exploring model and feature drift Data Quality Checks Performance Analysis Custom DashboardExplainability ResourcesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 8204, "end_char_idx": 9610, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "f8310802-5d0c-46f6-a971-117dbef645e9": {"__data__": {"id_": "f8310802-5d0c-46f6-a971-117dbef645e9", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/search-ranking"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "32f4439a-5512-41ec-a1ea-be3a98120421", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/search-ranking"}, "hash": "bd68b7a44cb3e63a36faa5cec243da391045538271eec93bf97236bb69a07a7c"}}, "hash": "e2619b6f4bc930fb906aaaf9438ebc160a632fa9a1e1c771cdcbd2a496b55bb2", "text": "Search Ranking - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookSearch RankingUse the Arize platform to troubleshoot a search ranking model's performanceCheck out our How to Monitor Ranking Model's blog and follow along with our various Colab examples here. Ranking Overview\u200bRanking models are used by search engines to display query results ranked in the order of the highest relevance. These predictions seek to maximize user actions that are then used to evaluate model performance. The complexity within a ranking model makes failures challenging to pinpoint as a model\u2019s dimensions expand per recommendation. Notable challenges within ranking models include upstream data quality issues, poor-performing segments, the cold start problem, and more.  Ranking Use Case: Hotel Booking RankThis use case will use ML observability to improve a hotel booking ranking model with low model performance. A poor-performing search ranking model means the model is not surfacing the most relevant items in a list first.You will investigate model performance using NDCG at different @k values to improve this model and accurately predict relevant recommendations in the right order.  You will learn to:1.Evaluate NDCG for different k values2.Compare datasets to investigate where the model is underperforming3.Use the feature performance heatmap to identify the root cause of our model issuesGain a detailed view of how to log your ranking model schema here. Performance Metric: NDCGThis use case utilizes a rank-aware evaluation metric, which is used to accurately weigh rank order and relevant recommendations within a list. Normalized discounted cumulative gain (NDCG) is a rank-aware evaluation metric that measures a model's ability to rank query results in the order of the highest relevance (graded relevance).NDCG is the quotient of DCG and IDCG @ kOnce you ingest ranking data, the Arize platform computes your rank-aware evaluation metric. What is @ k?The k value determines the metric computation up to position k in a sorted list.For example, if k = 10, then NDCG evaluates the 10th item within the sorted list, whereas k = 20 evaluates the 20th item within a sorted list. How to Troubleshoot Ranking Models Use the 'arize-demo-hotel-ranking' model, available in all free accounts, to follow along. Step 1: Configure A Positive Class Configure our performance metric in the 'Config' tab. Default Metric: NDCGDefault @K value: 10Positive Class: RelevantStep 2: Evaluate Different @k Values NDCG is low for k = 10, which indicates this model inaccurately predicts most recommendations users interact with first. To investigate further, we'll increase our k value to 20. This helps us zoom out to have a more complete understanding of our ranking performance. When we increase our k value to 20, our model performance increases. Thus, this model performs better lower in the list, which is not favorable for our use case. Step 3: Add a Comparison DatasetTo investigate further, we'll add a comparison dataset using high-performing training data. Adding a comparison dataset during a period of high performance can help easily identify problem areas and enable you to better understand your performance breakdown. When we add our training dataset, we can confirm a significantly higher NDCG value than production. From here, scroll down to the 'Performance Breakdown' chart to analyze how our feature distributions differ between the two datasets. When comparing two histograms, look for the following:different colors (the more red = worse performing)missing valuesStep 4: Use Performance Breakdown As we scroll through our performance breakdown, we notice a significant gap in training data compared to production in the feature search_activity . From there, click on the card to uncover a more detailed view of search_activity. This view uncovers missing training data for skiing, sledding, snowboarding, and ice skating. To confirm our data quality issues, click on the 'View Feature Details' link on the top right, which will navigate us to a page where we visualize our distribution comparison, cardinality, and % empty over time.Step 5: Generate InsightsThe above analysis indicates users have been searching for winter activities while our model is optimized for summer/fall activities and has not been trained on new winter data. To improve our model performance and surface relevant recommendations in the right order, we need to retrain our model to account for a surge in winter destination/activity searches!PreviousClick-Through RateNextFraudLast modified 6mo agoOn this pageRanking OverviewRanking Use Case: Hotel Booking RankPerformance Metric: NDCGHow to Troubleshoot Ranking Models SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6458, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e84b70e6-e64c-4fa6-a6bf-4c2a1ea69c9b": {"__data__": {"id_": "e84b70e6-e64c-4fa6-a6bf-4c2a1ea69c9b", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/timeseries-forecasting"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "83958b99-e400-4d3c-9238-5aa02082f746", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/timeseries-forecasting"}, "hash": "c77ec2acc467f21cd3c31fb2662fb12507ae0d6c62ac0cf0f87fff9b3269fd87"}}, "hash": "c9411eca8a5ca84e7cbd44b0cafd0337b51e8afef27614de4afb735237873836", "text": "Timeseries Forecasting - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use CasesClick-Through RateSearch RankingFraudChurn ForecastingLendingCustomer Lifetime ValueDemand ForecastingInsuranceTimeseries Forecastingarize.comProduct Release NotesPhoenix OSSPowered By GitBookTimeseries ForecastingTimeseries PredictionOverviewThis example runs through how to setup a time series forecasting model in the Arize platform. In the timeseries forecasting use cases a model is run on specific run-date predicting data for a forecasting date in the future. This example will be predicting supply of a product from today, for each day, 10 days in the future. This setup can be modified for predicting:End of quarter sales run every day until end of the quarterPredicting a single day in the future 100 days out - run every dayPredicting sales of a product every day looking out over the next 30 daysExample of Timeseries ForecastingThe example above shows a supply model that makes 10 predictions for each day looking forward from the model run-date. The lag captures how many days ahead of the model run-date the specific prediction is for, where lag 0 is the actual day of the run.\u200bCommon Observability Data for Timeseries ModelThe common data that is tracked for timeseries models includes:Forecast Date: The date and time of the predicted event or observation.Run Date: The date on which your model ran and generated a prediction.Lag: The number of days between the run date and the forecast date.For example, if you run a model on Monday to predict the temperature on Friday, the run date would be Monday's date, the forecast date would be a timestamp for a time on Friday and the lag would be four days.Setting up TimeSeries DataThe above picture shows how the data is mapped into the Arize platform. The timestamp is the forecast date, the run-date & lag is sent in as a tag and the actual prediction is sent in as the prediction label.Common Performance Metrics The common metrics for timeseries forecasting are:MAERMSEMSEMAPEFilter options: Run-date, LagIn the Arize Dashboard shown below, it's clear that we see an over prediction event first, then an under prediction event later. We can clearly see the magnitude of these errors based on our custom configuration.Timeseries MAPEThe above MAE shows predictions vs actuals for various forecast dates. In many scenarios teams want filtered by Lag < 10 looking at MAE for predictions only 10 days out.  ExampleThe Colab example below shows how a timeseries model is setup in the Arize platform. Google ColaboratoryThis Colab example shows how to configure a timeseries with multiple quantile forecasts in Arize, and how to configure Pinball Loss as a Custom Metric. Google ColaboratoryPreviousInsuranceLast modified 7mo agoOn this pageOverviewCommon Observability Data for Timeseries ModelCommon Performance Metrics ExampleSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4429, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1f5578de-3e69-488f-a449-d1771d2fb3bb": {"__data__": {"id_": "1f5578de-3e69-488f-a449-d1771d2fb3bb", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "0b4223bd43dda5105d3f4e21e29623059e4537677cd4c690d9f71ab86411ec22"}, "3": {"node_id": "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "7921bf105f502b39b354f6945921d473946d8e82d359c935c646d3022f7ed1f8"}}, "hash": "7535d404b91b766be38ee807ec5d0811d427d82243f2c4ba5a8c36d9dd43a241", "text": "Sending Data FAQ - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data UploadSending Data FAQ\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookSending Data FAQDelayed ActualsWhat happens when you have two different models with the same set of prediction IDs?When sending delayed actuals, specify the model_id in your schema to match your actuals to the correct model. Does the Arize Platform look at specific model versions?Delayed actuals are mapped back to predictions via a model_id and prediction_id, regardless of version. This means that if you have the same prediction_id in multiple model versions, the actual will be joined to each row with the matching prediction_id.What happens after I send in actual data? If you send actuals to Arize to log delayed actuals (when preexisting predictions already exist in Arize), Arize will join the delayed actuals with the correlating prediction IDs in the platform at 5 AM UTC daily.However, if you have never logged predictions for your model, you must upload prediction values corresponding to your actuals (using the same prediction ID) to view your model in Arize. What if I have actuals after the 14-day join window?The Arize engineering support team can extend your connection windows. Reach out to [email\u00a0protected] for help with this.The configurations are applied at the space level. All models in the space will receive the same join window configuration. What happens in the case of partial actuals and null rows, and how does that impact my performance metric? Arize only calculates performance metrics on predictions that have actuals. Null rows are ignored when calculating performance metrics. If actuals have not been received yet (delayed actuals), refer to our default actual support information on how Arize handles nulls for your use case.Timestamps Q&AWhat does the data ingestion date mean?The data ingestion date is the timestamp for when the data was received by Arize. The data ingestion tab in the Arize UI shows the real-time data ingestion stats daily. Why should I use a prediction timestamp?The prediction timestamp represents when your model's prediction was made (time of inference). This timestamp is a column of data sent to Arize with the model inference data. Arize time series charts are based on the prediction timestamp. How should I format my prediction timestamp?Your timestamp can be in seconds or an RFC3339 timestamp. If you do not specify a timestamp, your timestamp will default to the time of file ingestion. Can I extend the prediction timestamp window?Arize supports sending in historical data with prediction timestamps up to 2 years before the current timestamp. The data sent to Arize will be retained and visible in Arize for up to 2 years. Reach out to [email\u00a0protected] to extend this window.Data Connector Q&AWhat is the row limit for a single upload? The current cap is 10 million rows; we recommend splitting the data into multiple files for larger uploads.What is the advised file size to optimize upload performance?While our system has the capacity to accommodate files up to 1GB, we find that files around the 50MB mark usually provide the best balance between volume of data and system performance. This size typically represents less than a million rows of data.How do I resolve timestamp issues?If the prediction timestamp column isn't correctly set, import jobs may result in parsing errors and fail. To make sure this doesn't happen, ensure that:the timestamp format is in seconds (not something more granular) or RFC3339the timestamp is within a year of today's date (either past or future)How do I resolve file schema issues?Ensure Training and Validation records must include both prediction and actual columns. Otherwise, it will result in a data validation error. How do I resolve data type issues?If the data type expected is numeric, but comes in as a stringEnsure there are no string values in numeric columnsIf None or Null values are used to represent empty numerics, represent them instead as NaNLearn more about data types here.Which data connector is right for me? Arize connectors are classified into two key categories: Data Warehouses/Lakes and Object Stores that fulfill distinctive data management and analytical needs.Data Warehouse/Lakes(Snowflake, GBQ, Databricks): Used for real-time analysis of high-volume datasets. They are the prime choice for quick, continual, and comprehensive data exploration.Object Store(GCS, AWS S3, Azure): Designed for reliable and cost-effective storage of substantial data quantities, these connectors are ideal for backup and archival purposes. They are the go-to option when long-term data preservation and accessibility are important.File Types Q&ACan I upload embeddings or ranking data in a CSV file?If your embeddings or ranking data are part of a CSV file, convert the data to Parquet before uploading your data to Arize. To convert your file: import pandas as pdimport math\u200b\"\"\"parse_vector is a helper function that converts a string representation of an embeddings vector to a list. Modify the separator and delimiters per the user's vector representation\u200bExample of a string vector representation: '[float1, float2, float3]'\"\"\"def parse_vector(v, sep=',', delim='[]'):  if not isinstance(v, str) and math.isnan(v): return v if isinstance(v, str) and v.lower() == \"nan\": return float('nan')     v_list = v.strip(delim).replace('\\n','').split(sep) return [float(k.strip(\" \")) for k in v_list]\u200bdf = pd.read_csv(\"<file name>.csv\")\u200bdf[<vector column>] = df.apply(lambda x: parse_vector(x[<vector column>]), axis=1)\u200bdf.to_parquet(\"<file name>.parquet\")\u200bWhat should a CSV file look like? The contents within a can file vary based on model type - with the exception of required fields (ie prediction_id). Predictions OnlyWhen configuring a model schema, what are the expected input types based on my data format? CSVParquetAvroApache ArrowBigQueryInput Data FieldData Typeprediction_idstring prediction_label/actual_labelstring / int / floatprediction_score/actual_scoreint / floattimestampint / float(number of seconds since unix epoch)string RFC3339 format (e.g", "start_char_idx": 0, "end_char_idx": 7476, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d": {"__data__": {"id_": "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "0b4223bd43dda5105d3f4e21e29623059e4537677cd4c690d9f71ab86411ec22"}, "2": {"node_id": "1f5578de-3e69-488f-a449-d1771d2fb3bb", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "7535d404b91b766be38ee807ec5d0811d427d82243f2c4ba5a8c36d9dd43a241"}, "3": {"node_id": "1c9a9194-920e-4a59-9b16-55e785aee575", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "5a67020d5fbefbb453a3c7848fe3cbfab86229ad3bcaadc4a6301ff7cbf861f4"}}, "hash": "7921bf105f502b39b354f6945921d473946d8e82d359c935c646d3022f7ed1f8", "text": "2022-04-16T16:15:00Z) featuresstringintfloattagsstringshap_valuesint floatInput Data FieldParquet Data Typeprediction_idstringint8 , int16, int32, int64 prediction_label/actual_labelstring booleanint8, int16, int32, int64float32, float64prediction_score/actual_scoreint8, int16, int32, int64 float32, float64timestampint64, float64 (number of seconds since unix epoch)string RFC3339 format (e.g 2022-04-16T16:15:00Z)timestamp date32, date64 features/tagsstring boolean (converted to string)int8, int16, int32, int64float32, float64decimal128 (round to 5 decimal places)date32, date64, timestamp (converted to integer)shap_valuesint32, int64 float32, float64embedding_feature:vectorlist of {int8|int16|int32|int64|float32|float64}embedding_feature:raw_datastringlist of stringsembedding_feature:link_to_datastringranking:prediction_group_idstring int8 , int16, int32, int64 ranking:rankint8, int16, int32, int64ranking:categoryarray of stringsranking:relevance_scoreint8, int16, int32, int64float32, float32Use the Avro schema embedded in the header of the Avro Object Container File(OCF) to decode and match to those specified in Arize file importer schema for data ingestion. The field name in the OCF file muststart with [A-Za-z_]subsequently contain only [A-Za-z0-9_]Input Data FieldAvro Data Typeprediction_idlong, int, stringprediction_label/actual_labelstring boolean, int, long, float, double, enum (will be converted to string)prediction_score/actual_scoreint, long, float, doubletimestamplong, double (number of seconds since unix epoch)string RFC3339 format (e.g 2022-04-16T16:15:00Z)timestamp logical typedate logical typefeatures/tagsstring enum , boolean (will be converted to string)int, longfloat, doubleshap_valuesint , long, float, doubleembedding_feature:vectorarray of {int|long|float|double}embedding_feature:raw_datastringarray of stringsembedding_feature:link_to_datastringranking:prediction_group_idlong, int, stringranking:rankint, longranking:categoryarray of stringsranking:relevance_scoreint , long, float, doubleThis example shows what an Arrow file columns and schema file would look like.The \"*\" can be used to add features to a file without changing the schemaColumn Name in FileArize Schemamy-prediction-tsprediction_timestampmy-prediction-id-customerprediction_idmy-prediction-scoreprediction_scoremy-prediction-labelprediction_labelmy-feature.addr_statefeaturesmy-feature.revenuefeaturesmy-environmentenvironmentmy-actual-labelactual_labelNote the name \"my-feature\" has multiple feature values.ModelSchema:   prediction_timestamp: \"my-prediction_ts\"   prediction_id: \"my-prediction-id-customer\"   prediction_score: \"my-prediction-score\"   prediction_label: \"my-prediction-label\"   features: \"feature.*\" # describes the path to the \"features\" object above, containing \"addr_state\" and \"revenue\"See here for definition of BigQuery types.Input Data FieldGBQ Data Typeprediction_idINT64, STRINGchange_timestampTIMESTAMPprediction_label/actual_labelSTRING BOOL, INT64, NUMERIC, FLOAT64prediction_score/actual_scoreINT64, NUMERIC, FLOAT64timestampINT64, FLOAT64 (number of seconds since unix epoch)STRING RFC3339 format (e.g 2022-04-16T16:15:00Z)TIMESTAMPfeatures/tagsSTRING BOOL (will be converted to string)INT64FLOAT64, NUMERICshap_valuesINT64 , FLOAT64, NUMERICembedding_feature:vectorARRAY of {INT64, FLOAT64, NUMERIC}embedding_feature:raw_dataSTRINGARRAY of STRINGembedding_feature:link_to_dataSTRINGranking:prediction_group_idINT64, STRINGranking:rankINT64ranking:categoryARRAY of STRINGranking:relevance_scoreINT64, FLOAT64, NUMERICInstalling the arize[MimicExplainer]I get \"no matches found\" errorI get this error when I try pip install arize[MimicExplainer]:no matches found: arize[MimicExplainer]Some shells (zsh) may interpret the brackets in a special way. In order to get around this, you may need to escape the brackets with a backslack: !! pip install arize\\[MimicExplainer\\]. I get a verbose error when trying to install arize[MimicExplainer]I get this error when pip is installing LightGBM (a dependency of the MimicExplainer): INFO:LightGBM:Starting to compile with CMake....FileNotFoundError: [Errno 2] No such file or directory: 'cmake'orsubprocess.CalledProcessError: Command '['make', '_lightgbm', ...]' returned non-zero exit status 2.\"This is because pip is attempting to compile lib_lightgbm - the C library for LightGBM. The compile process needs cmake as well as Open MP. To install this on a MacOS, try this first:brew install cmake libompData Sources Q&AWhat do example rows look like in a file? Example Row(with explicit feature and tag column prefixes) prediction_idprediction_tsuser_idtags/zonefeature/metropolitan_areaindustryprediction_scoreactual_scoreprediction_labelactual_label1fcd50f4689163753884582256us-east-11PAengineering0.077736960No ClaimsNo Claims(without explicit feature column prefixes for implicit ingestion) prediction_idprediction_tsuser_idtags/zonemetropolitan_areaindustryprediction_scoreactual_scoreprediction_labelactual_label1fcd50f4689163753884582256us-east-11PAengineering0.077736960No ClaimsNo Claims Example Schema{  \"prediction_id\": \"prediction_id\",  \"timestamp\": \"prediction_ts\",  \"features\": \"feature/\", # omit this row and feature/ column label prefix for implicit ingestion (must pick explicit or implicit)   \"prediction_score\": \"prediction_score\",  \"prediction_label\": \"prediction_label\",  \"actual_score\": \"actual_score\",  \"actual_label\": \"actual_label\",  \"tags\": \"tag/\", # requires explicit column declaration  \"shap_values\": \"shap/\", # requires explicit column declaration  \"exclude\": [\"user_id\"]}Python SDK Q&ADid Arize receive my prediction/actual record?When you log prediction data into Arize using the Python SDK, there are two ways to check the status depending on which mode is chosen.Batch: The pandas logger named arize.pandas returns a response so you can check the status with response.status_codeReal-time: The logger named arize.log returns a future .  See example:import concurrent.futures as cf\u200bdef arize_responses_helper(responses): \"\"\"    responses: a list of responses from Arize    returns: None    \"\"\" for response in cf.as_completed(responses):        res = response.result() if res.status_code != 200: raise ValueError(f'failed with code {res.status_code}, {res.text}')\u200b# Logging to Arize, returns a list of", "start_char_idx": 7477, "end_char_idx": 13804, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "1c9a9194-920e-4a59-9b16-55e785aee575": {"__data__": {"id_": "1c9a9194-920e-4a59-9b16-55e785aee575", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "0b4223bd43dda5105d3f4e21e29623059e4537677cd4c690d9f71ab86411ec22"}, "2": {"node_id": "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}, "hash": "7921bf105f502b39b354f6945921d473946d8e82d359c935c646d3022f7ed1f8"}}, "hash": "5a67020d5fbefbb453a3c7848fe3cbfab86229ad3bcaadc4a6301ff7cbf861f4", "text": "responsesresponses = arize.log(...) # your log call# Check responses!          arize_responses_helper(responses)After receiving a 200 response code, head over to your model's Data Ingestion Tab to confirm that Arize has received your data.The model's inferences are indexed by the received timestamp, NOT the timestamp of the inferences.What happens if I upload the same data with the same prediction ID twice? Does Arize treat that as one prediction/observation or as two?They are treated as separate observations. This would mean that 2 predictions sent with the same prediction ID would count as 2 predictions in the platform. If there was an actual sent for both predictions, it would show up as 2 separate predictions with both having a corresponding matching actual.What are the Supported Data Types for the Python SDK? We currently support the following data types for the corresponding columns.Column TypeSupported Data TypesFeaturesint, float, str, boolPrediction IDint, strPrediction Timestampsint, float, date, datetimePrediction Scoreint, floatActual Scoreint, floatSHAP valuesint, floatSupported data types for Prediction and Actual labels and scores depend on the model types.Column TypeScore CategoricalNumericPrediction Labelstrint, floatActual Labelstrint, floatPrediction Scoreint, floatNAActual Scoreint, floatNAActual Numeric SequenceList[int, float]NANull Values Q&AHow does Arize handle missing predictions or actual columns? Arize requires at least one prediction, actual, or feature importance column, but if all are missing, Arize will reject the dataset. How does Arize handle null values in a prediction or actual column? Arize generally accepts null values within prediction and actual columns. In order to successfully ingest null values while still constructing valid records in Arize, each row much contain least one non-null prediction, actual, or feature importance value. Learn more about valid combinations per model type within each model type page here. For example, in the case of a regression model, it's common for actuals (ground truth) to miss values. In this case, the actuals column will include null values and non-null values. For the rows where an actual is null, a prediction value or feature importance value is required to construct a valid record. What if my features or tags have None/NaN/Inf values?They are accepted and treated as empty.What if I have null values in my Prediction ID column?If you include a prediction_id column with null values within the column, Arize will reject the column.Sending Data Guides - PreviousFAQ & Troubleshoot Data UploadNext - Sending Data MethodsPython Pandas SDKLast modified 1mo agoOn this pageDelayed ActualsTimestamps Q&AData Connector Q&AFile Types Q&AInstalling the arize[MimicExplainer]Data Sources Q&APython SDK Q&ANull Values Q&ASupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 13805, "end_char_idx": 16856, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "bb9eb2b3-3ae6-446d-89bc-81588bc1db4c": {"__data__": {"id_": "bb9eb2b3-3ae6-446d-89bc-81588bc1db4c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example/aws-s3-example"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c7c44560-8e23-4c1c-8e67-3cc833495b08", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example/aws-s3-example"}, "hash": "51fe370f6dfb8a572025d6477b235cdc44f13ff9d23d1f04be2ff1b722806904"}}, "hash": "3d02808dd05256048d86897b9eaa841e65e196dac99f0e8bf64c11de1fa37469", "text": "Private Image Link Access Via AWS S3 - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Private Image Link Access Via AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPrivate Image Link Access Via AWS S3Enable AWS bucket access permissions to view private images in ArizeStep 1. Ingest Embeddings Using Links To Your Private S3 BucketAdd private S3 image URLs or URIs in the link_to_data_column_name (Python Pandas) or link_to_data (Python Single Record or any Data Connector in the UI). Once you upload to Arize, navigate to the 'Embeddings' tab to enable bucket access in S3. Click 'View Bucket Policy' to uncover bucket access information.Click View Bucket Policy To Get StartedNote: Link to data currently only supports links to image files. Learn more about ingesting image data on the Computer Vision model type page.Image ClassificationStep 2. AWS Bucket Access Permissions Tag your bucket with the key arize-integration-key, the provided tag value, and AWS Policy. AWS Bucket Access PolicyAdd Proof Of Ownership: Bucket TagIn Arize: Copy the  arize-integration-key valueArize Integration Key & ValueIn AWS Console: Navigate to your S3 bucket -> Properties -> Edit Bucket Tags\u200bNavigate To Your Bucket TagsIn AWS Console: Set tag Key = arize-integration-key and Value as the value copied from the Arize UI Add Arize Key Name & Value In S3Enable Bucket Access: AWS Policy In Arize UI: Copy the AWS policy from the Arize UIAWS Policy to Copy and Paste to AWS S3In the AWS console: Navigate to your S3 bucket -> Permission -> Edit Bucket PolicyAdd/Edit bucket policyIn the AWS console: Paste AWS policy from Arize UI and edit the bucket name in the resource fieldAdd Access Policy To AWS From ArizeStep 3. Reload Page!Reload the Arize UI to load your image data! Sending Data Methods - PreviousAWS S3Next - Sending Data MethodsAzure Blob StorageLast modified 4mo agoOn this pageStep 1. Ingest Embeddings Using Links To Your Private S3 BucketStep 2. AWS Bucket Access Permissions Add Proof Of Ownership: Bucket TagEnable Bucket Access: AWS Policy Step 3. Reload Page!SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3650, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a704e9e5-2222-4a91-9a9f-31f51369071c": {"__data__": {"id_": "a704e9e5-2222-4a91-9a9f-31f51369071c", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery/google-bigquery-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "1c3bc399-3304-4b80-812b-dbde1d93cdee", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery/google-bigquery-faq"}, "hash": "33bccf4769b70cdb5845f32e9d38adbd5c3024b51f8ba50ffe98803366647547"}}, "hash": "62c63463af261551272ef0575dc2554dd8b653e024cd09f7de3052cb251ec7fa", "text": "Google BigQuery FAQ - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryGoogle BigQuery FAQDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookGoogle BigQuery FAQHere you will find a list of common questions regarding data warehouse jobsWhat types of BigQuery tables are supported? Arize can ingest data from BigQuery views or native tables. Use cloud storage to ingest external tables. How do I use change_timestamp?The change_timestamp field is used for Arize to track which new rows need to be imported as we constantly sync new data. This column type may be the following types: TIMESTAMP, DATE, or DATETIME. Unless your table is small, it is important for performance and cost to ensure this column is also partitioned, so we don't need to re-scan data. For best performance, values in the change_timestamp field should also be unique.prediction_idchange_timestamppredicted_labelfeature_a12023-01-27 17:57:59.932798 UTCSpam1322023-02-15 12:01:00.134899 UTCNot Spam1532023-02-15 12:15:00.134899 UTCSpam3When adding new data, Arize will only ingest data \u201cnewer\u201d (based on change_timestamp column) than what's currently ingested.Can I update or delete rows? Deleted or updated data in your data warehouse will not be reflected by Arize. Only new records added to your data warehouse table will be ingested. How do I update/fix a row that failed to ingest? If your query failed due to an issue with a specific row or set of rows, fix the error and append the data to your table again using an updated change_timestamp. How do I debug my failed BigQuery table query? Any queries that fail to run for a given table import job will be displayed within the job's details. Sample Query Failure in Job DetailsThe QueryID that is displayed corresponds to a BigQuery job id. The BigQuery job id can be used to retrieve the execution of a given query and lookup the specific query to rerun. There are two ways to look up additional information about a BigQuery job. 1.BigQuery CLIbq show -j --format=prettyjson <project id>:<region>.<job id>The results of this command will display the query that ran for the given job, query parameters that were applied, error statuses, and information about its execution cost. 2.BigQuery UIJob statuses can be retrieved for a given BigQuery project. After searching for and selecting the given job, BigQuery will provide information about the query that was run and when it was run. However, it does not fill in the values of any query parameters that are used in the query. This information is provided by the Job Details page in Arize, and can be used to recreate the query. Sending Data Methods - PreviousGoogle BigQueryNext - Sending Data MethodsDatabricksLast modified 1mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4281, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "efdf8449-9a28-4fc2-ac7e-b1bcb1c57993": {"__data__": {"id_": "efdf8449-9a28-4fc2-ac7e-b1bcb1c57993", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop/ui-drag-and-drop-faq"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9d42c874-e19e-4a0d-a3ec-02ee523d51a9", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop/ui-drag-and-drop-faq"}, "hash": "a5e7c122e090375c254c968f05fef8ad560e4372f70e8fdd2e108a432397fd41"}}, "hash": "cb9044363d16af542411d338821a7b9883a4afa7707d552c0642283387d2e411", "text": "UI Drag & Drop FAQ - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropUI Drag & Drop FAQGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookUI Drag & Drop FAQFrequently Asked Questions About UI Drag & Drop in ArizeValidating your UploadBefore uploading your file, the job will be validated to test for any schema or file errors. The validation:scans a subset of records within the file and determines whether that subset can be successfully importedif the subset of records cannot be imported, the resulting error will be surfaced and the dry run can be repeatedDebugging After a job for your file has been started, details about the model, file name, the rows processed and any potential errors and the locations of those errors will be presented in the details pane.Sending Data Methods - PreviousUI Drag & DropNext - Sending Data MethodsGoogle Cloud Storage (GCS)Last modified 12d agoOn this pageValidating your UploadDebugging SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2503, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "e8b2fc05-f427-42ab-bc58-cb602c0f7446": {"__data__": {"id_": "e8b2fc05-f427-42ab-bc58-cb602c0f7446", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing/data-distribution-visualization"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "724fddd8-f6a3-4e9e-9339-817e1b071b79", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing/data-distribution-visualization"}, "hash": "d3a8894ff9082d1bd9326c1915e91dccdb08e15c1d07e148838fce6d951cbd6e"}}, "hash": "2f61bec8a70ddf032c0aec1a2f68842cfe0fd64adcaa969d742e60ff5aa1218a", "text": "Data Distribution Visualization - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Distribution VisualizationData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookData Distribution VisualizationConfigure the visualization of your data for distribution comparisons when troubleshooting drift.Distribution comparisons are useful for both visualizing data, as well as calculating drift metrics such as PSI. For categorical values, Arize simply calculates the percentage of data that falls under each unique value, and display the data in descending order of data volume. For numeric features, it often makes sense to group the values into bins, in order to show a useful summary of the data. However, there is no one-size-fits-all strategy for numeric binning that will work for a wide variety of data shapes. We will cover the best option for each use case below.Example of categorical binsChanging binning for numeric featuresWe offer 4 types of binning for numeric features:\u200bMedian centered bins\u200b\u200bDiscrete bins\u200b\u200bEqual width bins\u200b\u200bCustom bins\u200bYou can try out different visualizations in the feature details page. When you change your binning option, you will be able to update binning for that feature across the platform.This will affect:1.PSI calculations2.Drift monitors - both visualization and PSI calculations3.Performance tracing breakdown for that feature4.Model overview page (PSI value)Quick guide:If you have approximately normally distributed data, use median centered bins (the default).If you have a feature that encodes a boolean or an ID, use discrete bins. If you have a feature that\u2019s represented by only a small range of integers, such as number of actions in a day, try discrete bins. If you want to view your feature with exactly equal width bins, use the equal width bins option.If you already know your binning strategy or have business logic with hard cutoff points, use custom bins. Binning Options for Data Visualization:Median centered binning (default)For numeric onlyThis is our default binning method - it works well for normally distributed data but is good for highly skewed data as well. This method creates up to 10 bins, with the following constraints:1.The center of the bins (the division between bins 5 and 6) is at the median. 2.The 8 center bins have equal width. The width of each bin is \u2153 of the standard deviation of the data. These are the purple squares below. 3.The edge bins have variable width and end at the min/max of the dataset in order to account for long tails. These are the red rectangles below. 4.Bins on the edge with zero data will be removed - possibly producing less than 10 bins.Normal, bell-shaped curve, showing % of cases in 8 portions of the curveThis works very well for most normally distributed data, even if there is a long tail. Take the annual income feature in our model below. Income is normally distributed within a range, with a long tail on the right for high earners. In Arize, this feature is binned like this:The majority of the data is centered around median income of 43k, while about 30% of the data falls into the left and right edge bins. Discrete binsFor numeric or categorical featuresDiscrete bins allows users to see each value independently in the distribution chart. Note that for categorical features, this is the only binning option. For numeric features, this works particularly well for these use cases:Booleans or IDsSometimes, a boolean value or an ID may be expressed as an integer. Since the numeric value of these features is not actually relevant, using median centered bins above would not produce the right results. For example, this is what a boolean value looks like with median centered bins.Boolean value with median centered binsBy choosing discrete bins, you can easily see the distribution of the only two values for this feature, 0 and 1:Boolean value with discrete bins shows the only 2 valuesIn this example, we have an ID for a type of procedure, encoded as an integer. Median centered bins combine multiple values because they are numerically close, even though as an ID they may have no relationship. ID with median centered bins combines numerically close valuesBy choosing discrete bins, users can see the frequency of each ID independently.IDs with discrete binnong show each ID independentlySmall integer valuesFor small integer ranges, such as a count, discrete bins offer a more detailed view of the data than median centered bins. For example, this is a count of the orders in a day. With a small number of unique values, discrete bins offer a more granular view of the data.Median centered bins groups values togetherDiscrete bins provide a more granular viewEqual width binsFor numeric features onlyThis option creates equal width bins. The bin width is simply (max - min) / num_bins, where num_bins is specified by the user. This option is useful for fixed numeric ranges, for example, FICO scores.With median centered bins, the shape of the data is somewhat hidden by wide edge binsWith equal width bins, users can more clearly see the shape of the dataCustom binsFor numeric features onlyCustom bins offer ultimate control over the visualization of numeric data. This is helpful when you already know how to visualize your data, either from prior analysis, or from a business perspective where certain cutoffs already exist. Using the same FICO score example, creditors may have certain cutoffs for FICO scores. Say, a FICO score below 500 results in an automatic application rejection. For scores above 500, every 20 points results in a better interest rate than the previous bucket. Aligning the binning strategy with business logic ensures the drift visualization is relevant. Tracing - PreviousDrift TracingNext - TracingData Quality TroubleshootingLast modified 5mo agoOn this pageChanging binning for numeric featuresQuick guide:Binning Options for Data Visualization:Median centered binning (default)Discrete binsEqual width binsCustom binsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 7549, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "052d0636-00bd-47b0-9242-724c2c9a1aa5": {"__data__": {"id_": "052d0636-00bd-47b0-9242-724c2c9a1aa5", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-functions"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f138b696-0282-4c52-9636-2d44afa3e6c2", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-functions"}, "hash": "3945e2a1802a99af4f06255956eef8b7b21176abf4ef1f5827631592c9a733f6"}}, "hash": "218d886cdff5e2e94fb8dfcd585415bdfe9c0bb59213ce39bfee933a9d77a6e2", "text": "All Functions - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxConditionals and FiltersAll OperatorsAll FunctionsCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAll FunctionsAggregate and metric function syntaxFunctions OverviewThis page provides a reference of all available functions by aggregation functions and metric functions. Click the linked model type for documentation on a particular model.1.\u200bAggregation functions\u200b2.\u200bMetric functions\u200bAggregation functionsEvery User Defined Metric must have one or more aggregation functions or metrics.FunctionDescriptionTypeCOUNT(*)Counts the number of rowsn/aAPPROX_COUNT_DISTINCT(exprs)Counts the unique values of exprsStringSUM(exprs)Sums the value of the expression across rowsNumericAVG(exprs)Averages the value of the expression across rowsNumericAPPROX_QUANTILE(exprs,<decimal>)Approximate quantile of expres. Second argument must be a numeric literal between 0 and 1 inclusiveNumericMIN(exprs)Minimum of the value of the expression across rowsNumericMAX(exprs)Maximum of the value of the expression across rowsNumericMetric functionsMetric functions leverage existing metrics in Arize for use in your custom metric. They also allow you to customize the way existing metrics are calculated. Metric functions can take both positional arguments and keyword arguments. When using both, positional arguments must come before keyword arguments. Keyword arguments can be specified in any order.For classification metrics, the model's configured positive class is the default value, we will refer to this as defaultPositiveClass in this doc.Note that these functions need actual (a.k.a. ground truth) data to produce results.True PositiveTP(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes the true positive rate, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used.False PositiveFP(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes the false positive rate, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used.True NegativeTN(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes the true negative rate, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used.False NegativeFN(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes the false negative rate, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used.PrecisionPRECISION(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes precision, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used.RecallRECALL(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes recall, using the positive class. If pos_class= is omitted, then the positive class configured for the model is used. F1F1(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalCompute the F1 score, also known as balanced F-score or F-measure. If pos_class= is omitted, then the positive class configured for the model is used. F_BETAF_BETA(actual=categoricalActualLabel, predicted=categoricalPredictionLabel, pos_class=defaultPositiveClass, beta=1)Model Type: Score CategoricalComputes F-score with optional beta= parameter for re-weighting precision and recall. Beta is defaulted to 1, which produces the same result as the F-1 score. When beta=0, F-score equals precision, when beta goes to infinity, F-score equals recall. Commonly used values for beta= are 2, which weighs recall higher than precision, and 0.5, which weighs recall lower than precision. If pos_class= is omitted, then the positive class configured for the model is used. LOG_LOSSLOG_LOSS(actual=categoricalActualLabel, predicted=scorePredictionLabel, pos_class=defaultPositiveClass)Model Type: Score CategoricalComputes log loss of the model. Note that actual= is a string column while predicted= is a numeric column.ACCURACYACCURACY(actual=categoricalActualLabel, predicted=categoricalPredictionLabel)Model Type: Score CategoricalComputes accuracy of the model.MAEMAE(actual=scoreActualLabel, predicted=scorePredictionLabel)Model Type: Numeric, Score CategoricalComputes mean absolute error.MAPEMAPE(actual=scoreActualLabel, predicted=scorePredictionLabel)Model Type: Numeric, Score CategoricalComputes mean absolute percentage error.MSEMSE(actual=scoreActualLabel, predicted=scorePredictionLabel)Model Type: Numeric, Score CategoricalComputes mean squared error.RMSERMSE(actual=scoreActualLabel, predicted=scorePredictionLabel)Model Type: Numeric, Score CategoricalComputes root mean square error.PreviousAll OperatorsNextCustom Metric ExamplesLast modified 6mo agoOn this pageFunctions OverviewAggregation functionsMetric functionsTrue PositiveFalse PositiveTrue NegativeFalse NegativePrecisionRecallF1F_BETALOG_LOSSACCURACYMAEMAPEMSERMSESupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 7061, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2e827067-64b1-45dd-b8bb-cf78c4467126": {"__data__": {"id_": "2e827067-64b1-45dd-b8bb-cf78c4467126", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-operators"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "f4ccd784-7f52-4f27-b207-d84e1c6cac23", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-operators"}, "hash": "3f6a696c390bd6aff5396ae6ca98d157351bbd08f1c92123b3f8c9a5239e8ee8"}}, "hash": "a131d3571bd63c90ad77d96a0206d1faaceeb2d90e91b9b4775a0eef60b10f82", "text": "All Operators - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxConditionals and FiltersAll OperatorsAll FunctionsCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookAll OperatorsScalar operatorsOperators OverviewOperators in the Arize Query Language typically operate on one or two values and return a result based on the values. Different operators can apply to different dimensions and constant types.Types of Operators1.\u200bNumeric Operators\u200b2.\u200bComparison Operators\u200bNumeric OperatorsArithmetic operators only operate on numeric dimensions.OperatorDescriptionA + BPlusA - BMinusA * BMultiplyA / BDivide (integer division is cast to FLOAT)ABS(A)Absolute valueCEILRound to nearest intFLOORRound down to nearest intCOSCosineSINSineTANTangentTANHHyperbolic tangentLNNatural log (base e)LOGNatural log (base e)LOG10Log base 10SQRTSquare rootCBRTCube root GREATESTReturns the greatest value of the arguments. Returns null if any argument is null.LEASTReturns the least value of the arguments. Returns null if any argument is null.Comparison OperatorsThese general operators can apply to strings and numerics alike.OperatorDescriptionA = BEqual toA <> BNot equalA != BNot equalA > BGreater thanA <= B Greater than or equal toA < BLess thanA <= BLess than or equal toPreviousConditionals and FiltersNextAll FunctionsLast modified 8mo agoOn this pageOperators OverviewNumeric OperatorsComparison OperatorsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3011, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d3ec6e6a-80fe-4951-bf09-6c4c985d3a78": {"__data__": {"id_": "d3ec6e6a-80fe-4951-bf09-6c4c985d3a78", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/conditionals-and-filters"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "834b94d3-33f1-4321-a602-6c5e523cad92", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/conditionals-and-filters"}, "hash": "8e8b33b9093b1bbb16137e2ebba560043c04558efe173073f9088b96842edebb"}}, "hash": "2d89ee194ff6a065874408c2a7d190aa7f0f6491d078a1cd4f81c679129939d3", "text": "Conditionals and Filters - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageCustom Metric SyntaxConditionals and FiltersAll OperatorsAll FunctionsCustom Metric ExamplesGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookConditionals and FiltersAdditional flexibility when composing a queryConditionals and Filters OverviewConditions are used to define what logic is to be executed based on the status of some condition being satisfied. Filters are expressions used to specify a subset of the data items.CASECase statement. Expressions are evaluated in order, and the first to evaluate to true is returned.ELSE returns a default value if no statement evaluates to true. If there is no ELSE condition and no case evaluates to true, then NULL is returned.OperatorCASEWHEN exprs THEN result1[ WHEN exprs THEN result2 ]\u2026[ ELSE default ]ENDExampleCASEWHEN state = 'CA' THEN 1WHEN score > 500 THEN 1ELSE 0ENDCASE expression\u201cSimple\u201d case statement. This is similar to the above, except on checks equality between a common expression and values. OperatorCASE expressionWHEN value THEN result[WHEN ...][ELSE result]ENDExampleCASE stateWHEN 'CA' THEN 1WHEN 'TX' THEN 1ELSE 0ENDWHERE clauseWhere clause. Takes a list of filter expressions.NOTE: we do not currently support subqueries in WHERE clauses. OperatorWHERE filter_exprs [ AND | OR filter_exprs ]ExampleWHERE state = 'CA'FILTERFilter with a where clause. The where clause only applies to the aggregation preceding the FILTER keyword. Otherwise, the WHERE clause is identical to any other WHERE clause.Operatoraggregate_function( * ) [ FILTER ( WHERE filter_exprs ) ]ExampleCOUNT(*) FILTER ( WHERE   state = 'CA' OR state = 'TX')PreviousCustom Metric SyntaxNextAll OperatorsLast modified 8mo agoOn this pageConditionals and Filters OverviewCASECASE expressionWHERE clauseFILTERSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3395, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a2ed4e24-0db3-40e5-853a-33f62e5af7a2": {"__data__": {"id_": "a2ed4e24-0db3-40e5-853a-33f62e5af7a2", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/forming-calls"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b68a0820-be12-4895-9093-4a8031a1b219", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/forming-calls"}, "hash": "05c969cecbf634bb8558cc85beba573c2adab81a6dae604ca0131049bcd0df05"}}, "hash": "e3347ca6925b2b6f63b357e86286e29c09f02076cb500afb83ffee04439d2653", "text": "Forming Calls - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLForming CallsUsing Global Node ID'sQuerying Nested DataMutationsGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookForming CallsLearn how to authenticate with the GraphQL API in order to create and run queries and mutations.AuthenticationOnce your account is provisioned, an account admin can grant individuals developer access via your account settings page. Users with developer permissions will then have the ability to issue an API key for themselves and gain access to our API Explorer. \n\nThe API key that is granted to a user issues queries and mutations under that user's roles and permissions.\u200bThe Arize GraphQL API is available to enterprise-grade customers. To upgrade your account contact [email\u00a0protected]\u200bThe GraphQL endpointWhile a typical REST endpoint has multiple endpoints, the GraphQL API has a single endpoint: https://app.arize.com/graphqlCommunicating with GraphQLBecause GraphQL operations consist of complex, nested structures, we recommend using the Explorer to make GraphQL calls. You can also use cURL or any other HTTP-speaking library.In REST, HTTP determine the operation performed. In GraphQL, you'll provide a JSON-encoded body whether you're performing a query or a mutation, so the HTTP verb is POST.To query GraphQL using cURL, make a POST request with a JSON payload. The payload must contain a string called query:curl -H \"x-api-key: graphql_api_key\" \\ -H 'Content-Type: application/json' \\ -X POST \\ -d '{ \"query\": \"query { viewer { user { name } }}\" }' \\  https://app.arize.com/graphqlNote: The string value \"query\" must escape newline characters or the schema will not parse it correctly. For the POST body, use outer double quotes and escaped inner double quotes.As you can see, GraphQL is simply an HTTP POST and does not require any particular library. However, we highly recommend you use a client library as it can vastly improve your developer experience.\n\nIn our tutorials we will make use of the following clients in our script examples:Python: gql\u200bJavaScript: graphql-request\u200bAbout query and mutation operationsThe two types of allowed operations in Arize's GraphQL API are queries and mutations. Comparing GraphQL to REST, queries operate like GET requests, while mutations operate like POST/PATCH/DELETE. The mutation name determines which modification is executed.For information about rate limiting, please consult our resource limitations guide.Queries and mutations share similar forms, with some important differences.About queriesGraphQL queries return only the data you specify. To form a query, you must specify fields within fields (also known as nested subfields) until you return only scalars.Queries are structured like this:query { Objects or scalars to return}Here is a simple example of how to pull your informationQueryResponsequery { viewer { user { name email } } account { name }}{ \"data\": { \"viewer\": { \"user\": { \"name\": \"Arize Support\", \"email\": \"[email\u00a0protected]\" } }, \"account\": { \"name\": \"Arize AI\" } }}Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousHow To Use GraphQLNextUsing Global Node ID'sLast modified 7mo agoOn this pageAuthenticationThe GraphQL endpointCommunicating with GraphQLAbout query and mutation operationsAbout queriesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5098, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "116d8ee5-a3b5-4ca8-826a-efafde854497": {"__data__": {"id_": "116d8ee5-a3b5-4ca8-826a-efafde854497", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/mutations"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "81b47198-7d21-47c7-af35-50ac5f5a7b98", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/mutations"}, "hash": "78d290ed3a4fd6ee23a11015786bf9e2485c95a1b5f362d36f1bbf45f2807ae8"}}, "hash": "3d78e14d7e498fa818e4363cfd5f27527110d7f6ed1787052010e4bc45322c3d", "text": "Mutations - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLForming CallsUsing Global Node ID'sQuerying Nested DataMutationsGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookMutationsThis tutorial will show you how to mutate (create/update/delete) objects in our APIGraphQL provides the concept of mutations, which allow users to update data on the server. Note that unlike REST, there are no distinctions between a create, update, or delete mutation. Rather GraphQL relies on the mutation name and documentation to understand what a particular mutation does. In this example, we will loosely build off of the previous example of querying for monitors, by updating a monitor. We highly recommend that you type out these examples (with your own ID's) in the API explorer directly. The explorer helps with autocompletion and will help you understand the context of your queries. In addition, the Documentation Explorer on the right side will be your guide to the exact fields for each object.First - query for a monitorHere I'm using a monitor that is triggered from the previous example. You can find a monitor by following the example or by using the UI and grabbing the monitor id from the URL. (.../monitors/:monitor_id). RequestResponsequery { node(id: \"monitor_id\"){ ... on Monitor { name monitorCategory threshold currentMetricValue operator status } }}{ \"data\": { \"node\": { \"name\": \"Model Drift for delinq_2yrs\", \"monitorCategory\": \"drift\", \"threshold\": 0.000164044030786001, \"currentMetricValue\": \"0.00049\", \"operator\": \"greaterThan\", \"status\": \"triggered\" } }}Patch mutationLet's say we want to update the threshold to be higher than the current value, which will clear the monitor. Because our 3 types of monitors (Drift, Performance, and Data Quality) are all different, we have different mutations for each. This is a drift monitor, so we want the patchDriftMonitor mutation:RequestResponsemutation( $monitorId: ID!, $threshold: Float!,) { patchDriftMonitor( input:{ monitorId: $monitorId set:{ threshold: $threshold autoThresholdEnabled: false } } ) { monitor { threshold } }}Query arguments:{ \"monitorId\": \"monitor_id\", \"threshold\": 0.0005}{ \"data\": { \"patchDriftMonitor\": { \"monitor\": { \"threshold\": 0.0005 } } }}Here we split the query into two parts, a templatized mutation, and its arguments.  Templates are useful for reusing queries or mutations and is a much cleaner and more type-safe than string interpolation.The template:mutation( $monitorId: ID!, $threshold: Float!)First, we establish the template for reusing this mutation. This template only takes the arguments monitorId, and threshold. Each field needs a type, and ! denotes that the field is required. Even though monitorId looks like a string, it is a special type in GraphQL which allows further validations.The actual mutation patchDriftMonitor( input:{ monitorId: $monitorId set:{ threshold: $threshold autoThresholdEnabled: false } } )Then we call the actual mutation, using () . From looking at the Documentation Explorer, we can tell the shape of the input, which can be nested. Here, we only set a few of the possible fields for this input.  monitorId: $monitorId and threshold: $threshold use the input variables defined above, while autoThresholdEnabled: false is hardcoded. Return the updated value{ monitor { threshold }}GraphQL allows you to specify a response query at the end of a mutation. This conveniently allows you to verify your mutation in the same call.What's next?While we only showed how to make a single change to a monitor, mutations allow you to update or create monitors in bulk.For much more detailed and advanced examples for your use case, please consult our various Colabs. Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousQuerying Nested DataNextGetting Started With Programmatic AccessLast modified 6mo agoOn this pageFirst - query for a monitorPatch mutationWhat's next?SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5708, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "af3a7040-07d5-4210-8b4e-6f87f67502a0": {"__data__": {"id_": "af3a7040-07d5-4210-8b4e-6f87f67502a0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/querying-nested-data"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "5f1e57b2-517a-4dce-9845-a6b822082f3d", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/querying-nested-data"}, "hash": "9b2d8680ddad3602b553044c4c8c08795b6ae9318412c3d9f203701095df9566"}}, "hash": "20e3bf686b6e8f3b641a3b0498e1c1a67a9b76a50ea1abce85adfd1004c0080e", "text": "Querying Nested Data - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLForming CallsUsing Global Node ID'sQuerying Nested DataMutationsGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookQuerying Nested DataThis tutorial will show you how to query for nested data and collectionsNow that you know how to form basic queries using the node concept from the previous page, we will show you how to query nested collections of data. This is a very powerful concept that will allow you to quickly traverse the data objects in Arize without stopping to gather id's at every step.This example will show you how to find all of the triggered monitors and their models within your space. The benefit of GraphQL is that the skills you learn in this tutorial will apply to all other object relationships. We highly recommend that you type out these examples (with your own IDs) in the API explorer directly. The explorer helps with autocompletion and will help you contextualize your queries. In the explorer, navigate to the Documentation Explorer on the right to find the exact fields for each object.Querying collections1. Start with the spaceGrab your node id for you space from the browser (e.x. /spaces/:space_id), as described in the previous section\u200bRequestResponsequery { node(id: \"space_id\") { ... on Space { name } }}{ \"data\": { \"node\": { \"name\": \"test_space\" } }, \"extensions\": { \"tracing\": { \"startTime\": \"2022-06-14T21:39:53.186Z\", \"endTime\": \"2022-06-14T21:39:53.192Z\", \"duration\": 6 } }}2. Get the model connection in your space:Now, let's get the models for your space. There is a models property on space. This returns an edge, which is a container for the actual model (which is considered a node). There is a lot to unpack here, but first we'll show the example:RequestResponsequery { node(id: \"space_id\"){ ... on Space { models(first: 2) { totalCount edges { cursor node { name }  } } } }}{ \"data\": { \"node\": { \"models\": { \"totalCount\": 5, \"edges\": [ { \"cursor\": \"YXJyYXljb25uZWN0aW9uOjA=\", \"node\": { \"externalModelId\": \"arize-demo-churn-prediction-use-case\" } }, { \"cursor\": \"YXJyYXljb25uZWN0aW9uOjE=\", \"node\": { \"externalModelId\": \"arize-demo-click-through-rate-use-case\" } } ] } } }}tabHere are the components:models(first: 2){ totalCount }: models returns a connection. A connection can be thought of as a \"container\" for a collection of results as well as metadata. In this example, we requested the totalCount of the collection. Connections also can take arguments. Here we only request the first 2 models. There are also custom arguments or filters in addition to standard pagination-related arguments, for example: models(search: \"arize-demo\"). edges { cursor }: Connections return edges. Edges are like a container for each element in the collection, and also contain metadata. In this case, we returned the cursor field on the edge, which can be used for pagination like this models(first:2, after: \"YXJyYXljb25uZWN0aW9uOjE=\"). node { name }: Finally, we get to the actual model and its fields. Note that most objects in our system implement the node interface (as described on the previous page). This particular node is of the type Model and has the field name which is the modelId that was used to ingest the model. 3. Get only triggered monitorsFinally, we can go one level deeper and get the monitors on each model. Additionally, we'll use the arguments to filter only for triggered models. Note: you can also query for monitors on a space. We are just using space -> models to as an example of a deeply nested query. This is also helpful if you wanted to search for specific models in a space before getting their monitors. RequestResponsequery { node(id: \"space_id\"){ ... on Space { models(first: 1) { edges { node { name monitors(first: 1, currentStatus: triggered) { edges { node { name threshold currentMetricValue operator } } } }  } } } }}{ \"data\": { \"node\": { \"models\": { \"edges\": [ { \"node\": { \"externalModelId\": \"arize-demo-churn-prediction-use-case\", \"monitors\": { \"edges\": [ { \"node\": { \"name\": \"Model Drift for delinq_2yrs\", \"threshold\": 0.000164044030786001, \"currentMetricValue\": \"0.00043\", \"operator\": \"greaterThan\" } } ] } } } ] } } }\u200bHere we use the argument monitors(currentStatus: triggered) (note triggered is not a string, it is an enum and should not be in quotes) to denote that we only want to view triggered monitors. Now we can view the operator, the current value of the metric and the threshold, and the current threshold. What's next?After you get more comfortable querying for collections and using the Documentation Explorer, you'll be querying the rest of your data in no time. In the next section, we'll show you how to update your data through mutations. Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousUsing Global Node ID'sNextMutationsLast modified 6mo agoOn this pageQuerying collections1. Start with the space2. Get the model connection in your space:3. Get only triggered monitorsWhat's next?SupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 6776, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "d15c4be1-401e-40dc-b8d0-ed683287ea1d": {"__data__": {"id_": "d15c4be1-401e-40dc-b8d0-ed683287ea1d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/using-global-node-ids"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "89485e37-b4d9-4eea-b53f-a2ff20a405fc", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/using-global-node-ids"}, "hash": "7a6ae679ac7b44455ffebb4ecd47c341599a8934e16fa484560b4bfcd8efcab5"}}, "hash": "204f59a16f5e3d3bbde2720753c6d4909a17420818dd9ff42ba730f709d9fbb9", "text": "Using Global Node ID's - Arize Docs\n\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIHow To Use GraphQLForming CallsUsing Global Node ID'sQuerying Nested DataMutationsGetting Started With Programmatic AccessExample Use CasesMonitors APIModels APIFile Importer APICustom Metrics APIResource LimitationsAPI ChangelogData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookUsing Global Node ID'sYou can get global node IDs of objects via app.arize.com and use them in GraphQL operations.In Arize's GraphQL API, all nodes (entities) have a globally unique ID. This is a very powerful tool to quickly query and mutate parts of your account.Putting global node IDs to useYou can follow three steps to use global node IDs effectively:1.Navigate to a node you would like to query in the app (e.x. /spaces/:space_node_id)2.Find the object's type in GraphQL.3.Use the ID and type to do a direct node lookup in GraphQL.Let's walk through an example.1. Navigate to a modelYou will notice your URL will contain a model node id like /models/MDQ6VXNlcjU4MzIzMQ== (Note you can always query for your models but this can sometimes be the easiest way to get started). The value after  models/ is the model's globally unique node ID.2. Finding the object type in GraphQLIn this example, the node_id value is MDQ6VXNlcjU4MzIzMQ==. You can use this value to query the same object in GraphQL.You'll need to know the object's type first, though (even though we already sort of know it's a Model). You can check the type with a simple GraphQL query:query { node(id: \"MDQ6VXNlcjU4MzIzMQ==\") { __typename }}This type of query \u2014 that is, finding the node by ID \u2014 is known as a \"direct node lookup.\"When you run this query, you'll see that the __typename is Model3. Do a direct node lookup in GraphQLOnce you've confirmed the type, you can use an inline fragment to access the object by its ID and return additional data. In this example, we define the fields on Model that we'd like to query:query { node(id: \"MDQ6VXNlcjU4MzIzMQ==\") { ... on Model { modelType } }}This type of query is the standard approach for looking up an object by its global node ID.You can now execute interesting queries about this node (a.k.a. Model) and make use of this ID in mutations (e.x. creating a performance monitor).Having trouble? Reach out to us via email [email\u00a0protected] or Slack us in the #arize-support channel for more support. PreviousForming CallsNextQuerying Nested DataLast modified 1yr agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4018, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9a054106-1025-400c-8ee2-dd8b0e070ed0": {"__data__": {"id_": "9a054106-1025-400c-8ee2-dd8b0e070ed0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/feature-analysis"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9f28e5b6-ab72-4945-9081-4f0d61654dbf", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/feature-analysis"}, "hash": "f50b2b34e947071c08a6fbf3879ca49a99a8a95c761b1d1b7350f5cc6e1e6f2a"}}, "hash": "173bd9c75452db2951c9d43697a33549c80ef529e4f9ef9b84cde70388fb320b", "text": "Feature Analysis - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesModel PerformancePre-Production PerformanceFeature AnalysisWidgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookFeature AnalysisOverviewThese templates help you analyze the features a model uses as inputs for predictions. Feature-oriented dashboards enable quicker detection of issues, and are especially useful for deep troubleshooting to root cause problems. They can also be helpful aides in uncovering model retraining or improvement opportunities.Feature Analysis TemplatesTop FeaturesFeature AnalysisFeature Slice PerformanceFeature HeatmapThis template allows you to look at any model features over any time period and environment (Training, Production and Validation).Surfaces top features contributing to a modelDistribution view of each featureAbility to look at conditional analysis through slices/filtersThe feature analysis template is for feature analysis over time. The template lines up features based on the distribution and shows a day by day view.Distribution view of featureDay over day view of feature valueAbility to slice or filter based on input valuesThis template is designed to analyze the facets or slices of a single feature. Designed for analysis of a single featureIt creates a set of bins or slices based on the distributionIt then shows performance of those bins based on an Evaluation Metricthe performance is shown over time for each sliceNumeric feature bins are created automatically Categorical features, you do pick the values of your slicesThe feature performance heat map breaks each feature into slices and color-coordinates them based on performance. Overlay performance information on featuresShow both volume and performance overlaid on slices of features Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousPre-Production PerformanceNextWidgetsLast modified 6mo agoOn this pageOverviewFeature Analysis TemplatesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3550, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6d627ff6-2388-4ba9-bf57-bdb3a8d83f80": {"__data__": {"id_": "6d627ff6-2388-4ba9-bf57-bdb3a8d83f80", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/model-performance"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "c6b75f90-4a5d-4f30-a35e-50e4d624414b", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/model-performance"}, "hash": "5c765d057cb03caf073ca3b931a356b40231e9ca9636b99dea247d57e692fde6"}}, "hash": "3f154aa6fba53f16b1ef679900431fbe9bf37c8ececfa166fa2713f15eaccf7b", "text": "Model Performance - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesModel PerformancePre-Production PerformanceFeature AnalysisWidgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookModel PerformanceOverviewModel performance templates help you track the health of models. Create performance dashboards in the 'Model Performance' tab based on regression and scored models, or for enhanced model comparisons. Performance DashboardThe Performance Dashboard provides you with aggregate statistics for accuracy, recall, and other customizable evaluation and data metrics. Dashboards facilitate performance troubleshooting by providing support for customizable widgets and chainable filters to drill down to specific cohorts and see respective model statistics. You can slice and filter Dashboards by any model, model version, feature, and/or actual value.Once you have an idea of your overall model performance across various slices, it's time to start diving into which features could be causing this performance degradation. Feature Performance Heatmap Arize provides Feature Analysis Templates which automatically surface model performance issues across all features and various feature/value combinations. Visual indicators facilitate drill-down analysis of the most problematic slices affecting your overall model performance. Create a Feature Performance Heatmap in just a few clicks using the Arize template library. The Feature Performance Heatmap provides you with model performance information across all features at various feature/value combinations \u2014also known as a slice. Feature Performance Heatmaps also support conditional filters (like Dashboards). Additionally, they rank order the worst-performing slices to automatically surface potential root causes of your performance degradation. Model Performance TemplatesThe following templates are available for performance analysis. Regression ModelScored ModelRanking ModelModel A vs BProduction vs TrainingThis template allows you to track performance of predictions against actuals for regression models. View aggregate accuracy metricsAnalyze accuracy of slices of predictionsTrack fluctuations throughout a time periodThis template allows you to track performance of scored models. View aggregate statistics for accuracy, recall, specificity, Type I and II error rates, etc. for a single classAnalyze slices of performancePerformance feature analysisThis template allows you to track rank-aware performance metrics for ranking modelsView model performance based on individual featuresAnalyze model performance based on rank groupsTrack fluctuations throughout a time periodThis template is often used to compare two live models in production. It will show a model's performance against another specified model.Metrics to compare two models Canary vs Live model comparisonModel performance metrics over timeThis template is designed to compare production performance to training performance. It allows for commonly used approaches to analysis, and generally will show the distribution difference between production and training.Performance comparison between production and trainingAbility to slice on facets and compare slices/facets between production and trainingAbility to select features to compare between production and training datasetsQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousTemplatesNextPre-Production PerformanceLast modified 4mo agoOn this pageOverviewPerformance DashboardFeature Performance Heatmap Model Performance TemplatesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 5138, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "feebe11b-e06c-468b-b55e-6e0aff62c240": {"__data__": {"id_": "feebe11b-e06c-468b-b55e-6e0aff62c240", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/pre-production-performance"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "e7bcf91d-cbe0-47cd-bf92-2f5c3ea53d2f", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/pre-production-performance"}, "hash": "3fce8ab171ee5330467d7ab832acdfd41c41e85bcea8a4e1643d12801a6f422e"}}, "hash": "5064c7605c65235ae0ec8a0c1c8948aaaa0e807e358ff52a2e134c688c5f1152", "text": "Pre-Production Performance - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesModel PerformancePre-Production PerformanceFeature AnalysisWidgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookPre-Production PerformanceOverviewExplore your model\u2019s training data and validation data with pre-production performance templates. The model templates are based on model types you send into the platform, similar to the Model Performance templates.Pre-Production Performance TemplatesThe following templates are available for performance analysis. Training DataValidation DataThis template allows you to track your model's performance during training. See how accuracy or metrics compare to productionSame information as model performance dashboard, but on training dataThis template allows you to track your model's performance during training. See how accuracy or metrics compare to productionSame information as model performance dashboard, but on training dataQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousModel PerformanceNextFeature AnalysisLast modified 6mo agoOn this pageOverviewPre-Production Performance TemplatesSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2745, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "8f8d151c-5ab2-440e-bbc2-4a08a5568112": {"__data__": {"id_": "8f8d151c-5ab2-440e-bbc2-4a08a5568112", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/distribution-widgets"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "074f3a7d-35b4-4b22-b667-2eb1b12e7b8e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/distribution-widgets"}, "hash": "a37a9e14945f5c988e4e4867eeee29aa2c1df06d7116beaca21b2c0c89a03430"}}, "hash": "e4f11d5a996008f8176bbe1febe67abe10cbe3e791a7d3b2ebec0da116ac604a", "text": "Distribution Widgets - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesWidgetsDistribution WidgetsTimeseries WidgetsStatistic Widgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookDistribution WidgetsHow to use a distribution widget on a dashboardOverviewDistribution Widgets are one type of widget you can create on the dashboard. The distribution widget can analyze:FeaturesPredictions ActualsUse Cases Analyze distribution of any feature, prediction, actual for any time periodAllow you to compare distributions from Training, Validation and Production time periods  Distribution Widget - example feature called \"Grade\"Widget ConfigurationThe selection panel inside the widget configuration supports:Model NameModel Versions - All or SpecificModel Environment:ProductionValidationTrainingDistribution over (what data to visualize)FeaturePredictionActualsSlices / FiltersCohort ability to slice on any metricWidget OptionsWidget Display OptionsAt the top of the distribution widget there are display options that allow you to select a normalization view of the distribution or also configure the binning behavior. Select normalize to view as normalized (each graph is separately normalized).Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousWidgetsNextTimeseries WidgetsLast modified 1yr agoOn this pageOverviewUse Cases Widget ConfigurationWidget Display OptionsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2992, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "6a121da9-0719-4354-8497-e8f64d45b035": {"__data__": {"id_": "6a121da9-0719-4354-8497-e8f64d45b035", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/statistic-widgets"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "d64278c3-267f-4fad-b29e-1b288c379d81", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/statistic-widgets"}, "hash": "ff48873096fd04e4b42ac7957ea2b15048175606d5acf14137403a136a4ab7f8"}}, "hash": "935aec83f9c450c64a4faa23b1b47169aa00c8c82005375ecc16e73ba3f2b9e9", "text": "Statistic Widgets - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesWidgetsDistribution WidgetsTimeseries WidgetsStatistic Widgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookStatistic WidgetsHow to use a statistic widget on a dashboardOverviewThe statistic widget represents an aggregate value for a time period. The value shown represents what you would get if you summed up all the timeseries data points.Use CasesFor analyzing aggregate statistics, such as accuracy, over a time period. The chart type selection determines the type of metrics selectable in the setup:Model Data MetricsCount, Average, or Percent / Percent ErrorEvaluation MetricsAccuracy, Precision, Recall, F1, Sensitivity, Specificity, False Positive Rate, False Negative Rate, MAE, MSE, RMSE, or MAPEData Metric vs Evaluation MetricData MetricsThe same options available on the time series are available for the statistics widget:Statistic widget total for time period (left) vs Timeseries (right)The predictions count below shows the configuration and aggregation options for a statistic widget:Configuration for Statistic WidgetEvaluation MetricsThe same evaluation metrics available in the timeseries plots are available in statistic widgets. Here's an example showing a statistic widget on the left representing the accuracy for the entire time period.Statistic Widget Total for time period (right) vs Timeseries By Day (left)The statistic widget will have different configuration options based on the selection of an evaluation metric.Statistic Widget ConfgiurationEnvironmentsWhen you select Validation or Training the data displayed is based on the date of the batch not the production date range selector. This allows teams to compare a batch of data from training to any time of production.Environment selectionIn the picture above the fixed date the data was sent is shown below the environment selection.Questions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousTimeseries WidgetsNext - Explainability & FairnessModel ExplainabilityLast modified 1yr agoOn this pageOverviewUse CasesData MetricsEvaluation MetricsEnvironmentsSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "62dc2bdb-1b83-4cbb-ab93-78832de8258d": {"__data__": {"id_": "62dc2bdb-1b83-4cbb-ab93-78832de8258d", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/timeseries-widgets"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "9a824a66-adab-4712-8427-a8aa6d1f5eab", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/timeseries-widgets"}, "hash": "f8d89da1dde069cc698909ccedd47642db6857dc58c177a769fff0abba458cb4"}}, "hash": "149607d4a8e3172d27fc5973ec405ae6d464bfc6a34ebabf82f64f2efca21ad1", "text": "Timeseries Widgets - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A DashboardTemplatesWidgetsDistribution WidgetsTimeseries WidgetsStatistic Widgets\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookTimeseries WidgetsHow to use a timeseries widget on a dashboardOverviewThe time series widget supports graphing both model evaluation metrics and data metrics over time. Timeseries widgets display both hourly and daily data. Use CasesClassification Evaluation Metrics Daily or HourlyAccuracy, Recall, F1, Precision, False Positive Rate, etc...Numeric Model Evaluation Metrics Daily or HourlyRMSE, MAE, MAPE, etc...Model Data Metrics Daily/HourlyFeature values Categorical: Count of a specific featureNumeric: Average, P95, P5Count/Total (%)Prediction ValuesPrecent Error: Predictions based on Percent Error ThresholdCategorical: Count of a specific featureNumeric: Average, P95, P5Count/Total (%)Data MetricsThis type of chart tracks model data over a period of time, looking at the count of predictions versus actuals. Any timeseries widget supports adding additional plots and the facet/slice filtering.For Example: Let's add to the plot above an additional line chart showing count of predictions when the feature fico_score is > 500Time Series Model DataIn order to add a plot to a widget click the edit button on the drop down from the widget:Edit WidgetOnce in edit mode, the plots are in the form and if you scroll down you will find an add plot button:The image below shows a new plot being added that is the count of predictions where feature fico_score is greater than 500:New PlotHere's the prediction count of the model conditioned on fico_score: Prediction Count: Conditioned on a Feature \"fico_score\" > 500Evaluation MetricsEvaluation metrics are available for every model depending on the type. The platform supports evaluation metrics based on the type of model.Below is an example of an accuracy metric over a specific time period:Accuracy Above Widget ConfigrationEvaluation Metrics: Accuracy, RMSE, MSE, MAPECohort analysis of Evaluation metrics slicing on any facetAny environmentProduction: Performance in productionTraining/Validation: Plot point per training/validation runUser Defined Functions (UDFs) - Coming soonEvaluation Selection for ClassificationConfiguration support for this widget type includes:Setting the model versionModel Environment: Production, Training or Validation Evaluation MetricSlice/Facet FeaturesExample Configuration for Evaluation MetricQuestions? Email us at [email\u00a0protected] or Slack us in the #arize-support channelPreviousDistribution WidgetsNextStatistic WidgetsLast modified 1yr agoOn this pageOverviewUse CasesData MetricsEvaluation Metrics Widget ConfigrationSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4285, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "2bc1fbbe-c413-4da2-ab00-236dce85e0ba": {"__data__": {"id_": "2bc1fbbe-c413-4da2-ab00-236dce85e0ba", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack/onprem"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "26fefcaa-0799-4f67-bd1d-a5c924c65a06", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack/onprem"}, "hash": "d7df4eb4ad2354f8612af47512ec8dc527a91b1eae50ee222384d4df5e2db765"}}, "hash": "c00f14cd2ea9d90091584d9a98a8fec8d3efc15f201f5af6277c91e287a3a43d", "text": "Manual Setup - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & IntegrationsAmazon EventBridgeOpsGenieSlackManual SetupPagerDutyAirflow Retrain\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookManual SetupArize AI integration via Slack emailsSet up your model's monitors to automatically notify your Slack channel when a monitor has been triggered. Arize AI integrates with Slack via Slack's email feature. Integrating Arize AI monitor notifications with Slack centralizes your team's discussion around monitor notifications for more efficient discovery, coordination and resolution of model issues that your monitors have surfaced.For manual setup instructions, continue below. To learn how to use Arize's native integration with Slack, see the instructions here. Instructions Visit Slack's Help Center here for more details and additional options for setting up a Slack email.1. In your Slack workspace, navigate to the channel to which you would like monitor notifications sent.2. Open the channel's Settings.3. Under the Integrations tab, select the \"Send emails to this channel\" option.4. Follow the prompt to retrieve a Slack email address for your channel.5. Enter the Slack email address into the \"Alerts\" section of your monitor's config. You can also set this email on your model's config page as the default email for your model's managed monitors.Once you've completed these steps, a message will appear in your Slack channel whenever your monitor's status changes.PreviousSlackNextPagerDutyLast modified 7mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 3086, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "67dbc6df-e3f2-4fa2-8514-0ebe41f10fc0": {"__data__": {"id_": "67dbc6df-e3f2-4fa2-8514-0ebe41f10fc0", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/batch"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "4784cd69-9bde-40e1-b4f2-0286a955ab4e", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/batch"}, "hash": "f9358251a46a9c421e2447af50e9954e1245eafc61a43b162842f2581d482468"}}, "hash": "1a3013d0a905c2f920bb5fb2633796218563470f21016e09f323b2acd86d7942", "text": "Batch - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerBatchRealTimeNotebook Instance with Greater than 20GB of DataSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookBatchThis tutorial implements the following AWS architecture for handling a SageMaker Batch Transformer.The transformer generates an event that kicks off a Lambda function. The transformer generates the model inputs and predictions used by the lambda function.A separate process is assumed to process actuals as they are received in the system.The below file is a Jupyter notebook file that should be uploaded the the Sagemaker Notebook Instance. Google ColaboratoryThe Notebook file builds a lambda package in a Gzip to upload to AWS. The below file is the Lambda python function, this should be uploaded to a SageMaker Notebook Instance along with the above notebook.tutorials_python/lambda_function.py at main \u00b7 Arize-ai/tutorials_pythonGitHub\u200b\u200bPreviousSageMakerNextRealTimeLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2729, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "a4274c0c-9ddb-4529-9625-2f507d8a1205": {"__data__": {"id_": "a4274c0c-9ddb-4529-9625-2f507d8a1205", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/notebook-instance-with-greater-than-20gb-of-data"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "fed4ba86-42f4-4c34-bfe6-8c436fd66ef1", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/notebook-instance-with-greater-than-20gb-of-data"}, "hash": "8c5cc80be46f9854ea3fd80afb39fa8d25210d849980a345111036d44a37ec97"}}, "hash": "7931dc04ae8c6add27f55306735012a16ed6e26f06f649bde2d63e2632d15609", "text": "Notebook Instance with Greater than 20GB of Data - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerBatchRealTimeNotebook Instance with Greater than 20GB of DataSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookNotebook Instance with Greater than 20GB of DataUsing Arize with a Notebook Instance with more than 20G of dataThis section covers modifications to the SDK API call for sending over 20GB+ of data on a SageMaker Notebook instanceIn order to speed the transfer of data the Arize SDK pandas call makes use of 2 features on Notebook instances. 1.The Arize SDK serializes a pandas dataframe from Python to the file system using a fast serialization library that leverages C++. 2.The file is uploaded to the server from the file system using methods that maximize throughput.The choice to serialize to the file system was done after extensive testing showed this was the fastest open method to serialize a pandas dataframe. This method was compared extensively to serializing and uploading from Python directly.The above diagram shows how the SDK uses the SageMaker instance local file system to store a file prior to sending. The SDK will quickly serialize a file to the local file system and then upload that file to the Arize platform. In the case of files smaller than 20Gig this method is transparent to the user of the SDK.Files Larger than 20GBThe /tmp directory used by default by the Arize SDK is limited to 20GB and is not related to the instance size of the file system. In order to support larger files:1.Set the path variable of the python SDK pandas to point to the local file system2.Insure the instance is setup with enough local file storage to store your data response = arize_client.log(    path=\"/home/ec2-user/SageMaker/tmpinferences123.bin\"    ...The above example shows how to set the path variable in the SDK to point to the local file system.#checking file system spaceimport osstatvfs = os.statvfs('/tmp')print(\"GB of free space \" + str(statvfs.f_frsize * statvfs.f_bavail   / 1e9))As you might want to check the available storage in \"/tmp\" or \"/home/ec2-user/SageMaker\" you can use the code.Starting an Instance with greater than 5GBThe default instance is setup with 5GB in order to set a higher value click the advance section and put in a larger value for file system storage.Volume SettingThe attached volume section determines how much space is available in the ~/SageMaker volume. The volume size does not change the \"/tmp\" directory size which is the default used by the SDK. The path variable must still be used to point to the local volume.PreviousRealTimeNextSpellLast modified 1yr agoOn this pageFiles Larger than 20GBStarting an Instance with greater than 5GBSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 4465, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}, "9abba4d8-8dea-41ab-9a2e-54b5ee4212ef": {"__data__": {"id_": "9abba4d8-8dea-41ab-9a2e-54b5ee4212ef", "embedding": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/realtime"}, "excluded_embed_metadata_keys": [], "excluded_llm_metadata_keys": [], "relationships": {"1": {"node_id": "b5a51a65-d950-41cc-b9f2-b9a3a2543e26", "node_type": null, "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/realtime"}, "hash": "46a5e8cb6b47c78499faf6e60731c88543e0e34e2f90fa7bc814f419fe14cb2c"}}, "hash": "ea7010d21be3e817e3cad25ac69ffd055dd577b92b3f3a8b71a57bf6a7532f1c", "text": "RealTime - Arize Docs\n\n\n\n\n\n\n\n\n\n\nCommunity SlackSearch\u2303KLinksArize AIWhat is ML Observability?What is LLM Observability?QuickstartAll Tutorials/Notebooks\ud83e\ude84Sending Data GuidesWhat Is A Model SchemaHow To Send Delayed ActualsFAQ & Troubleshoot Data Upload\ud83d\udd0cSending Data MethodsPython Pandas SDKUI Drag & DropGoogle Cloud Storage (GCS)AWS S3Azure Blob StorageGoogle BigQueryDatabricksSnowflake\ud83d\udd22Model TypesLarge Language Models (LLM)Binary ClassificationMulti-Class ClassificationRegressionTimeseries ForecastingRankingNatural Language Processing (NLP)Image ClassificationObject Detection\ud83d\udd14MonitorsGet Started With MonitorsPerformance MonitorsDrift MonitorsData Quality MonitorsNotifications & Integrations\ud83d\udd0eTracingPerformance TracingDrift TracingData Quality Troubleshooting\ud83d\udd8cEmbeddingsGenerate EmbeddingsEmbedding DriftEmbedding & Cluster AnalyzerEmbeddings for Tabular Data (Multivariate Drift)Embeddings FAQ\ud83e\udd99LLM (Large Language Models)LLM EvaluationsTroubleshoot Retrieval with Vector StoresOpen AI Cluster Summarization\ud83d\udca1Active Learning and Fine TuningExport Data to Notebook\ud83c\udfa8dashboardsCreate A Dashboard\ud83e\uddd9\u2642Explainability & FairnessModel ExplainabilityBias Tracing (Fairness)\ud83e\udde9API ReferencePython SDKJava SDKR SDKRest APICustom Metrics Query LanguageGraphQL APIData API\ud83c\udfe1On-Premise DeploymentOverview\ud83d\udd11AdminSSO & RBAC (Role Based Access Control)\ud83d\udcdaResourcesProduct FAQGlossaryML PlatformsAlgorithmiaAzure & DatabricksBentoMLCML (DVC)DeepnoteKafkaFeastGoogle Cloud MLHugging FaceLangChain \ud83e\udd9c\ud83d\udd17MLflowNeptunePaperspacePySparkRay Serve (Anyscale)SageMakerBatchRealTimeNotebook Instance with Greater than 20GB of DataSpellUbiOpsWeights & BiasesCommon Industry Use Casesarize.comProduct Release NotesPhoenix OSSPowered By GitBookRealTimeOverviewThe following notebook and lambda function implement the following architecture. The SageMaker inference pipeline is deployed as a SageMaker endpoint. A Lambda function is generated that is tied to an external endpoint. When a realtime HTTP call is made the lambda function process the call, calls the SageMaker endpoint and returns the data.A separate process is assumed to process actuals as they are received in the system.\u200cThe below file is a Jupyter notebook file that should be uploaded the the Sagemaker Notebook Instance.Google ColaboratoryThe Lambda function Python is below:tutorials_python/lambda_function.py at main \u00b7 Arize-ai/tutorials_pythonGitHubBoth the Jupyter Notebook and the Python file should be uploaded to a Notebook Instance.\u200bPreviousBatchNextNotebook Instance with Greater than 20GB of DataLast modified 11mo agoSupportResourcesGet Started Chat Us On SlackBlogSignup For Free[email\u00a0protected]CourseBook A DemoSupportChat Us On Slack[email\u00a0protected]ResourcesBlogCourseGet Started Signup For FreeBook A DemoCopyright \u00a9 2023 Arize AI, Inc", "start_char_idx": 0, "end_char_idx": 2786, "text_template": "{metadata_str}\n\n{content}", "metadata_template": "{key}: {value}", "metadata_seperator": "\n"}, "__type__": "1"}}, "docstore/ref_doc_info": {"82f54fd0-4345-4257-b87a-e8171e872c18": {"node_ids": ["16537838-427b-47f6-b13c-9b9369bfa58c"], "metadata": {"URL": "https://docs.arize.com/arize/"}}, "3d360d67-7dd2-4612-aba2-675723a6e48e": {"node_ids": ["01ef153a-e560-4b71-a464-39e9b343843d"], "metadata": {"URL": "https://docs.arize.com/arize/examples"}}, "98af1be0-3d4c-49eb-a413-f30e8680dd9b": {"node_ids": ["7ae33b07-61b4-43e7-bc70-15e0582330cb", "265905fd-1d66-4b59-a686-3a8cad2818ba"], "metadata": {"URL": "https://docs.arize.com/arize/quickstart"}}, "8d84b686-a210-47bf-b536-ec508234da98": {"node_ids": ["7e2469e5-2c7f-4d10-8c9d-5362b2567373"], "metadata": {"URL": "https://docs.arize.com/arize/what-is-llm-observability"}}, "5c23863b-67de-4bd9-89dd-e8c18578c41a": {"node_ids": ["9dc8bc2b-c8d0-4d9f-8c44-add385a0a9dc"], "metadata": {"URL": "https://docs.arize.com/arize/what-is-ml-observability"}}, "71f363f4-b3b0-4460-addc-41487e65ad6f": {"node_ids": ["b5c3549b-fda1-4621-8306-672e4588c767"], "metadata": {"URL": "https://docs.arize.com/arize/active-learning-and-fine-tuning/export-data-to-notebook"}}, "86e579ca-b483-40af-8171-1294e02480f4": {"node_ids": ["247c7d24-f82c-47e4-97fb-c7744424e847"], "metadata": {"URL": "https://docs.arize.com/arize/admin/1.-setting-up-your-account"}}, "eff4c1f1-6201-45e5-8636-6227b8232e63": {"node_ids": ["c55e5ace-c87b-4d96-a750-b3ee3d539dec"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics"}}, "3a76cf24-098f-4dcd-b7a0-274532106c03": {"node_ids": ["cdded5de-231c-428b-94be-fbd288802449"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference"}}, "0c20e5d0-ee35-499b-a786-9fd2a19b56b3": {"node_ids": ["9895aa09-ee4e-4f00-bd2b-8f6a8546d668", "9626e825-0139-4faf-85f1-49bf41ebc6b0"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log"}}, "77ad6520-d54e-4fcb-b3c7-f1013fac33ba": {"node_ids": ["7445d565-1130-444b-900b-088601916ed9"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas"}}, "fb71ff94-13dd-4d4a-b987-1adb6f991e76": {"node_ids": ["70fe58b2-cc22-4b22-b879-6096c39a4de1"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api"}}, "1b9cac92-fee0-4d19-8dbb-2e52ccdf7389": {"node_ids": ["e6e0149f-3d72-4cc8-bf4e-95b01c65c98a"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk"}}, "36dc69a0-c0e1-4f3f-b321-7ec72b93edd3": {"node_ids": ["4d698582-91a2-405d-a0c6-56e04ac5c27c"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk"}}, "53f4e49e-24fb-49ff-a938-e2dee493548b": {"node_ids": ["4eeb734c-9289-4434-8524-fa7eb97b4c0f", "89122fbf-9cbf-44c7-8ae0-52b1f0123d96", "855bff49-bbd1-4c04-881f-a3e0b60cc0d8"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/rest-api"}}, "c90e974b-5a83-477f-8f98-8f25edaca229": {"node_ids": ["a3729128-ddbe-4853-a579-c22f14a80a61"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards"}}, "7b4639f8-7766-4ee0-aa4f-0ce22a947005": {"node_ids": ["06be9478-5ebb-45aa-b718-fb778db962b8"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data"}}, "1fd5a0ad-5fd4-418d-99ba-1926a61187ab": {"node_ids": ["d5bc9414-232e-4e2e-afb8-0d425453d245", "f74e2cbd-87c0-4073-b110-d72e4c56cf4d"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-and-cluster-analyzer"}}, "eeb925f8-fa80-41ae-bf1b-f2a0ec1c93e7": {"node_ids": ["1e29a976-7e19-44be-9bbe-67ebb85099e1"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embedding-drift"}}, "0696252c-9e64-4ef9-9b60-99c42cbaebf2": {"node_ids": ["f2ec490d-f288-44e5-b4f5-13d924f9b747"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-faq"}}, "99580bf8-b48b-40b7-8fc1-b0c96da65aa0": {"node_ids": ["b26a5040-6cf0-4d67-a9c0-fafc4d5b016e"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/embeddings-for-tabular-data-multivariate-drift"}}, "167257c2-2997-4bf1-83d7-302d1f1bd863": {"node_ids": ["5f2be5fa-22e9-4765-93c5-da142387689f"], "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/11.-bias-tracing-fairness"}}, "cbe5f483-f119-42e5-ac40-fad812cce4b6": {"node_ids": ["9004e605-a439-49f0-9d39-8e599f050890"], "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability"}}, "3561f72d-ce9b-48a9-b812-15cca731c1ce": {"node_ids": ["33b31146-0848-405f-813c-040328c82436"], "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/catching-hallucinations"}}, "ae09c232-a55e-46d1-aad4-bab40a8a4d9b": {"node_ids": ["b8e0d1c1-5f3f-436b-9805-2e683ee021cb"], "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/open-ai-cluster-summarization"}}, "2b73a05e-d4e5-4f5f-bc68-117b5b5602e6": {"node_ids": ["beef5aa9-1cac-4fed-82e5-da5d6802916a", "198511ca-f268-41ea-add3-4adea38e02d3"], "metadata": {"URL": "https://docs.arize.com/arize/llm-large-language-models/troubleshoot-retrieval-with-vector-stores"}}, "550e9121-8508-4271-84fe-3a9d2600ec97": {"node_ids": ["cf297e09-02dd-4eb6-8cc3-936c00a04a25", "ab96b404-fd90-4d9d-b5f6-59e477f555e8", "9b7a162e-e493-4dde-b04c-3b413752ba13"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/binary-classification"}}, "b7e72b75-e1cc-474b-9b89-7c3b8b383c76": {"node_ids": ["e1276b66-2ff3-4c48-995d-706670ea733b", "d8fcb14f-709e-4907-88ef-32cadbeea2a7"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/computer-vision-cv"}}, "8a8129ed-98b1-4192-88ed-62a44704b630": {"node_ids": ["1091a6e9-52c6-4420-beb3-852ab28b58d7", "b87ee96d-2344-4211-9144-53cb4d16ee45"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/large-language-models-llm"}}, "b39574db-5e18-4917-8641-5ac1cdbd767a": {"node_ids": ["ba8b0bfd-f43f-48cf-9ee3-bf03a0355bc4", "24851f7b-8d9e-4777-a679-1387840a511c"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/multiclass-classification"}}, "47377e5f-9894-429c-a4a1-dbc0d0dd406b": {"node_ids": ["93b509dd-c543-49e1-ba3d-4f63437a8457", "f2bcef10-15a7-49d7-8c60-ef8d33c95c53"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/natural-language-processing-nlp"}}, "ac472271-e567-4a83-a75a-9d01c41090df": {"node_ids": ["16677c61-fdb5-4197-924b-be5f956e5a2b"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/object-detection"}}, "414b333b-aa29-4e5b-b413-386f76d75009": {"node_ids": ["d50b4666-97f6-4277-9db1-6bea12e17e6a", "173378f1-c1a7-419d-a969-bb83da7e026a", "29f053dc-3e4b-4871-8e91-ba18e5c36cea"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking"}}, "b2b7670a-e539-4d40-850f-6f81029442dd": {"node_ids": ["65555ce6-8473-4fa6-9138-3ec6a81fc09f"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/regression"}}, "7ffed025-161a-4fb2-8640-980f9c8e8ed3": {"node_ids": ["7fda9c3d-8ad9-4946-89cd-01817e8a9782"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/timeseries-forecasting"}}, "73805f0a-6b4d-4957-9e4b-b3b1eda85abc": {"node_ids": ["4c20d69c-cf97-4b7d-a4b2-b1b16e78f617", "f5e46357-54de-4f59-a019-298e8a30a1d7"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/data-quality-monitors"}}, "d2a4cdde-a1dc-4a72-972e-43783c8b2efd": {"node_ids": ["84fb1872-054a-4e5f-8788-e33c05c61bed", "84c0925b-728a-47e4-86e1-50cf15a9bf70", "80c65da4-a51f-4e75-91cf-50fa6218752b"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/drift-monitors"}}, "ccf44bc5-eaf7-4cec-89c9-4946b4632f31": {"node_ids": ["d5eeb7a0-87ae-4b66-b9d6-5c79ba5c600b"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations"}}, "55fb72cd-945a-4318-b50e-11f2cd4e8919": {"node_ids": ["9cd23081-026e-4a39-bcd9-32335c843a28", "c08e61a2-8902-4287-b8fe-00fef6186bff"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/performance-monitors"}}, "1ac34e7d-2c35-4af3-8e30-0721cfa9e90f": {"node_ids": ["350524d7-b9f8-4b81-a7f9-4b096129edeb"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup"}}, "d3eda5a5-be0f-4567-8beb-90d5658a9b20": {"node_ids": ["accb5b15-dea6-4ba5-a525-ce566fc503eb"], "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise"}}, "c1353923-f196-45a9-915b-166c5aa69c7f": {"node_ids": ["876113dd-2d70-488c-b423-af4381373abc", "28a9b5b1-2b92-411e-867a-7eff22fc9b9a", "26cf1656-80fc-472e-8e5f-7b9e63e0732e", "6360467d-c0db-467e-9330-bb180218927e", "365e645a-9e22-40be-bea2-777c83512dbf"], "metadata": {"URL": "https://docs.arize.com/arize/resources/glossary"}}, "aaeff0aa-dfe9-4c80-bb28-181a7a19c0d7": {"node_ids": ["d79fa99e-1110-42ca-abce-007ada47b9f6"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations"}}, "ddc600fe-68f9-41ff-949a-a76af047f85e": {"node_ids": ["ef0ed8ee-4bc3-4c84-bc0d-86f2ee5c5a58", "01e6c4a8-f0fc-4cda-b522-b18af056a8bc"], "metadata": {"URL": "https://docs.arize.com/arize/resources/product"}}, "2a1ecd6b-5648-4099-8050-0aa12cbaa5f1": {"node_ids": ["b5185e4b-ea1e-409f-a90c-0619c1acea3d"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases"}}, "028ccb9c-9fa7-4f00-a8d8-0fe2c27533ab": {"node_ids": ["641efc54-02c7-4112-b45d-b76d83807040"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload"}}, "c960851a-f693-4d7d-bfe5-384094fae798": {"node_ids": ["cb5e46ac-708e-4b5e-a9d4-87a1a24aa859", "b9e7625f-b071-4b68-983a-0e89bf14ddea"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/how-to-send-delayed-actuals"}}, "fc309922-289e-4671-8182-59c0e23c8adb": {"node_ids": ["e785356a-8805-4591-8a94-5b259257130b", "0e88a5c4-ca0f-4b9e-ad78-b6ca6917f996"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/model-schema-reference"}}, "bf2a9af9-7270-47cd-aeea-3b53774d1e2c": {"node_ids": ["af4ad4f2-c1e9-4289-90af-0f1e994746e2", "05bccf93-b57d-4f32-bbb2-2bd57f51b860"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example"}}, "37d34887-1b48-486e-8cb6-acaf8734d4f1": {"node_ids": ["f1aeed01-3dc6-48f0-b335-5c81f7eb3b98", "8d3dcd4d-5772-4048-b323-b801473e70c3"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/azure-example"}}, "b5b1a345-1092-4bb4-94c4-a1a92e091e76": {"node_ids": ["a175d1ba-4ab0-4694-9a07-c62342846fa1", "9c4e69b3-413c-417a-a155-2dd3c0dcd41b"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/databricks"}}, "0692058a-430b-4fd5-9e6a-0d92fc0d4b9c": {"node_ids": ["619f7580-dc9e-459d-bab0-97ce2617bd3d", "1f9e9eb7-d7fb-455b-a516-216d1cbcb656"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/gcs-example"}}, "05959813-46de-47de-b480-227edfbc1403": {"node_ids": ["f29f1a2e-21bd-4b0f-b57d-59e4a33fac88", "19bb19e9-cbf2-43a7-9b71-ddf760646a39"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery"}}, "9268e9f4-0348-4664-acc5-4939a1ee056c": {"node_ids": ["580c151d-75a7-4190-ad84-b7e448f711e5"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/log-directly-via-sdk-api"}}, "1f7d1fef-9184-4c27-aa28-f1eead203125": {"node_ids": ["426818ff-842f-48fd-86f2-be8a7c65de23", "506faca4-8611-47fc-96ec-c143e8116c10"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/snowflake"}}, "22e775c4-5bfc-4534-9a98-5e70cc9220ed": {"node_ids": ["46c33a9c-947a-4f2d-b5e6-40c66dbc1a78"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop"}}, "8707c59d-9c11-4bdf-8e53-544c99186523": {"node_ids": ["88a4aba9-e65a-4f0a-a745-b71d70129331"], "metadata": {"URL": "https://docs.arize.com/arize/tracing/data-quality-troubleshooting"}}, "3f6bae1f-ffec-4528-a7cc-dcbe19db39ab": {"node_ids": ["cd15e0f8-b286-4a6d-8546-23ba67a0bf6a"], "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing"}}, "e41f550f-90f2-414c-8604-1546b5ca187a": {"node_ids": ["d4c48173-1914-42a7-8345-bba575666846"], "metadata": {"URL": "https://docs.arize.com/arize/tracing/performance-tracing"}}, "58f63029-0e23-4aec-acd3-f4da9263a8aa": {"node_ids": ["b77ab1fe-c816-4011-a1bc-c76e8e5676ea", "b91e0417-d273-4f27-8cd9-d2422a38a641"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-examples"}}, "2e67adf9-c949-4658-95f9-ab35036e1e7f": {"node_ids": ["42921c89-35d4-4e60-b682-f3080a99e76d"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax"}}, "924a6a3d-85a9-47fd-a3f9-1d719c04ce2d": {"node_ids": ["1453a19b-f181-4aea-9971-bb0c42f8990e"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-api-ui-visualization"}}, "c6b05237-0399-4108-b9c0-20271f73a8c9": {"node_ids": ["7bf5cbfd-13fd-4bce-b117-91e335ded852", "e7223684-a1d0-4a6e-846b-da6fe07be03b"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/data-reporting-api"}}, "049b9932-b473-4cf1-a30a-392e71674d94": {"node_ids": ["10033e50-a69d-4517-bc9e-929425aaf98b", "349b62d6-58a9-4454-bb28-aafb500ea2d8"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/api-reference/python-reference"}}, "d830eb6a-d70b-4ff8-ae6a-4f7935c1c729": {"node_ids": ["3b87de7a-0e1d-4d5f-a840-813b70d29f14"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/client"}}, "f790a3e9-7d0f-4252-a3c9-8734364f96f3": {"node_ids": ["06684fbd-38cf-4812-a9b3-f9aa3324893f"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/embedding"}}, "304c1bae-1027-48b0-8529-67fef42010e9": {"node_ids": ["222133ca-97a8-45fe-afb0-094a17fd8000"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/log"}}, "180da81f-aabd-4790-aaab-35e7add82b3f": {"node_ids": ["5e834ad7-b773-4411-af47-2b4bcda0e6da"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/objectdetection"}}, "0c39c442-7084-4d4c-b256-5b1a14cbbda9": {"node_ids": ["8f46c265-5c52-4b2d-9c5e-0ff8c31f9987"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/ranking"}}, "d4c7b444-9e97-445a-a5da-ea6a5252076d": {"node_ids": ["eb23ec53-58fd-41c8-b88e-b1637841ffa7"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.environments"}}, "5a010431-0dd5-4236-9df8-532d123c7884": {"node_ids": ["f2af5035-6e7f-4660-aaba-46cecdd64c57"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.metrics"}}, "5aa11672-2e24-4cb2-9969-bfb2216dcf8f": {"node_ids": ["83d3ff59-b33d-4a5b-b915-ed11b87c1b88"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.log/utils.types.modeltypes"}}, "c71f1a99-d486-4ef1-9dec-3f5eb711c8c2": {"node_ids": ["82043aab-ba90-4fa8-9c34-9b2d47ad7d7b"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/autoembeddings"}}, "76da110a-95ac-4aa5-a855-5bb719f045f7": {"node_ids": ["60646944-c492-4115-a5c9-3d5c3bb60783"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/client"}}, "ce597fae-849d-4561-ac33-f6f27fd1bfa2": {"node_ids": ["e3b783d1-c8b2-4254-a1a2-230b860b6879"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/embeddingcolumnnames"}}, "748bc204-476b-4074-a648-3d659e07b165": {"node_ids": ["9517a28a-a65c-4ea7-b58c-0628a7104b4d", "df2b68f7-bf75-43a1-8c32-a4f3a543c4b4"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/llm_evaluation"}}, "260b7be8-0a99-4379-96ff-ab7906a492cd": {"node_ids": ["08dca518-ddf1-4380-b62c-85df75f2e3ca"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/log"}}, "6f46fec1-4041-4b68-a6b7-cce13699898e": {"node_ids": ["5a95db40-1469-40d1-a1c1-0c240154d3e6"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/objectdetectioncolumnnames"}}, "735e890f-8307-41d3-a5de-fb99fbf335bc": {"node_ids": ["5098be58-8027-4524-866d-80ec073d9d75", "6dc02ce8-a2b3-42f1-8ddd-82a4a1e0e39f"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/schema"}}, "906ef3d6-09ca-484e-8753-ba6dc50fa9f9": {"node_ids": ["1ea64d01-8701-4195-987a-ca21df4d1c5e"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.environments"}}, "0aeb2d90-5dac-4c51-93b7-326540a233a3": {"node_ids": ["c080e82e-3558-4876-a978-d7f4d5fcd7ab"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.metrics"}}, "9d2b621d-07ab-41ca-9518-a07141454a6e": {"node_ids": ["84699106-2432-4048-8750-4e2be63e48c6"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/arize.pandas/utils.types.modeltypes"}}, "d0f57afd-b130-465c-a9fb-b22004f6b3ff": {"node_ids": ["97a54811-0f27-4ec4-922f-23516ffeb5a0"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/api-changelog"}}, "a04b55ec-0418-4970-8fc9-6421eaffcd7a": {"node_ids": ["93ffcb8e-0e82-4e88-992a-2263e287b879"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/custom-metrics-api"}}, "d9474079-16d1-455f-9456-e1bc84430565": {"node_ids": ["57fa9bdc-031b-44b6-a172-110a17480d78"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/example-use-cases"}}, "23e673fa-2239-4ebd-92cf-35da1cb7ab9d": {"node_ids": ["08ccaf81-dee9-489f-98e4-403a20ede888", "1063440c-3d07-4af3-9481-920af9aa0531"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/file-importer-api"}}, "9dbcc6cb-5a60-4e6b-b3f1-5c6b5d8ad578": {"node_ids": ["6aae5dbd-b15c-421a-a4d3-743ae88a1d10"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/getting-started-with-programmatic-access"}}, "b785648c-c907-432a-a3f1-d636d7f65172": {"node_ids": ["4d0d7642-858a-4352-aad6-78381bd0f963"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql"}}, "e79940f0-1d98-49fd-852e-3daf6a9a319c": {"node_ids": ["073267bd-96c6-4f03-b63a-1dcc7e059625"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/models-api"}}, "118db4c0-2d07-4a21-9282-6e9e0b9f7e89": {"node_ids": ["68a50699-9944-4d40-acd7-fbc0aaf7123d", "278babb4-b596-4355-9cb7-3b66e61f72ab"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/monitors-api"}}, "a7d4d2bd-e685-4663-b7dc-dda2622a9237": {"node_ids": ["0f4ad5a5-528f-489a-93aa-45f993aa8d95"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/resource-limitations"}}, "d685c8c5-2f03-4742-98fd-5b523b15ecc4": {"node_ids": ["fa43a101-31a6-43a0-96f3-01b37a0ed21a", "9b512b54-d163-481e-8a3b-1e28e16b0059", "5a4d6dbe-974e-439a-ac7a-afb5a1406543"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/bulklog"}}, "70c500cb-9350-476a-b085-b5869f8a655b": {"node_ids": ["06a637df-0553-4e55-8063-7a859c308a25"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/constructor"}}, "e7638f3b-a378-455b-b84d-a42828b1f875": {"node_ids": ["e3381666-8a88-43c2-974f-1553477edd03", "3c1fad62-c326-421b-9ccf-e9f348454393"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/log"}}, "0f548f54-6b44-41c2-b277-f1b82a519347": {"node_ids": ["d73071d9-026f-46f2-abb4-aa65df3ca774", "e6b458ed-bca6-4700-abd4-aa3dff0b96c5"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logtrainingrecords"}}, "70e9ad5e-7ec6-491f-bc72-5f93e943a341": {"node_ids": ["e142128c-14e8-40f9-8df9-720a6e69ac55", "0b43ed45-9991-4187-a4e6-db816a6a1dcd"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/java-sdk/logvalidationrecords"}}, "d30adf46-894f-4541-a25c-c43400a511db": {"node_ids": ["dbd9a112-6758-4875-b19b-f6855a6edf24"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdlog"}}, "8597bae9-c2bd-41ce-ae26-8bd8d61ce816": {"node_ids": ["15697f82-90a9-4130-bffa-808babca9d07"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/r-sdk/clientusdnew"}}, "1057fd60-2309-4564-89a6-1f037bc04e45": {"node_ids": ["4bd2ac03-c738-4d36-b32c-52221946fbe6"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates"}}, "c2ab1e7b-c9df-4669-8a20-b68245c034f4": {"node_ids": ["af9a2b1f-f909-4fc1-bb7e-41995316e217"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets"}}, "9a859b43-375a-4027-9392-5eba5c9df418": {"node_ids": ["9ba1d5b8-21ad-415a-b528-9273c4078035", "a289db9f-3096-4ecc-ae37-ca91e2cbc2c8"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/how-to-generate-your-own-embedding"}}, "a0ee1405-edc2-4433-8f63-e1953e1156d7": {"node_ids": ["729e5c5c-bc82-4011-aff1-5d22b2c8b350", "95ce2bd7-3899-47a8-a624-3dfff646d115"], "metadata": {"URL": "https://docs.arize.com/arize/embeddings/7.-troubleshoot-embedding-data/let-arize-generate-your-embeddings"}}, "58089885-f316-4164-bc99-bdde2116f371": {"node_ids": ["4b2034fb-7800-45ef-88e4-93c5c6fb6424"], "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/shap"}}, "afae243d-1d48-4bce-be11-1730eadd5be4": {"node_ids": ["3a554674-5523-4965-9e68-97292a1ccda3"], "metadata": {"URL": "https://docs.arize.com/arize/explainability-and-fairness/explainability/surrogate-model"}}, "8e69cb74-dd0d-4953-ae1e-87c2bb9cc3df": {"node_ids": ["a01e7261-cf3f-4307-a306-afe4c115731c"], "metadata": {"URL": "https://docs.arize.com/arize/model-types/ranking/collaborative-filtering-recommendation-engine"}}, "41ffb412-8d71-486c-83cd-31e0ae7ad0b7": {"node_ids": ["b76a9f17-c0e0-4a93-81ec-3e68fc361ee0"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/airflow-retrain"}}, "783870bf-2ce0-4d9c-802f-caf7bc786409": {"node_ids": ["87a0af5d-0901-420f-896f-8696097a3d39"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/amazon-eventbridge"}}, "eb06e579-e72a-4f1e-b824-414b9b637dd5": {"node_ids": ["05405d0e-5b2e-49ed-a545-08acf9caf065"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/opsgenie"}}, "56f31f00-b684-40e9-acb5-b5e30f01568d": {"node_ids": ["7fe51cdf-8ff7-4ea0-944d-7e77095456c2"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/pagerduty"}}, "bf21135a-de9a-41a0-af12-0e33611ca000": {"node_ids": ["9c93bd3c-59a9-4836-83ab-672b20b6c8a8"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack"}}, "48896621-9b83-4f8b-800f-fdc387260f99": {"node_ids": ["5abc1ffe-683e-43c1-8257-79daba457189", "ba7ae850-1512-4b82-a7cf-6dbc4f38f7fd"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/setup/choosing-your-metrics"}}, "bf7e3674-a267-4685-8e56-9d4bb5888e92": {"node_ids": ["d90886d0-265a-43d2-86cb-83299a6f0aa6", "50c39b7b-f1d3-4579-aa27-0c43ebf10444"], "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/installation"}}, "e541b8bf-7da2-414d-8f74-d68ed88cd044": {"node_ids": ["8951ba30-63b9-41aa-a093-40ecc5a1c8ea"], "metadata": {"URL": "https://docs.arize.com/arize/on-premise-deployment/on-premise/requirements"}}, "dfbfb421-2fd4-44da-8a3f-a07455b47093": {"node_ids": ["da1a7295-10db-450a-8a6d-69b4a1321f77"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/algorithmia"}}, "69f6c3f1-2eb4-4268-a5ea-6ed6a4d18f30": {"node_ids": ["a9acc3a3-44aa-4993-b5d5-cf6073236488"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/anyscale-ray-serve"}}, "c2d39c09-4bd7-4fcd-9c0a-0fd7046489f7": {"node_ids": ["e52397b9-fbcb-4823-82a1-a6ecedbb6c4c"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/azure-and-databricks-python"}}, "e02e0904-9276-42c1-b2ac-5e8b4b7d95c6": {"node_ids": ["be602cc2-1634-4937-aa58-760ca4ca6223"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/bentoml"}}, "219825ff-0e55-4cb5-86f5-56b946b8be05": {"node_ids": ["d5a8b73a-1ab5-47a9-a1f0-7285e245c617"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ci-cd-cml"}}, "badcaae8-e7f2-4af1-b721-2e0701a3bcc3": {"node_ids": ["c6cc2e35-aa38-4d2b-b395-2bde200f6fed"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/connecting-to-kafka"}}, "a9c1cfc8-ef22-413b-8ae9-d71f45673b15": {"node_ids": ["024f1e88-dd1f-4150-ad24-ca0549749352"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/deepnote"}}, "cd857c5a-1fd1-45e8-b942-193e6e75442e": {"node_ids": ["4ff35440-99ea-4166-80a9-349a7965834f"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/feast"}}, "1103ebe6-8bea-4ea4-b86b-a681434598ce": {"node_ids": ["d7f18fc0-9953-4672-bb97-1f082607fa59"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/google-cloud-ml-python"}}, "f2964e91-937c-4d33-80c2-06b338f61070": {"node_ids": ["5dc1321d-7d0d-4789-9fd8-b96162a25223"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/hugging-face"}}, "4dd61e0c-2858-400a-b621-1b0f47655bf5": {"node_ids": ["66749c87-ae52-4559-ac24-048e3ef40202"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/langchain"}}, "d5fd8253-ceeb-4262-8a4a-95e8bea1dea3": {"node_ids": ["95578f21-3247-4384-b4ba-353d60e0e444"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/mlflow"}}, "dcde8e85-8f2c-4597-bacd-59982631eff2": {"node_ids": ["d0163aa9-f03a-4f55-8694-ab178773eef7"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/neptune"}}, "ccfaabeb-d828-4d5e-ba30-7e73e73dfe39": {"node_ids": ["3f0a1f20-36f5-43d6-bba6-2d9441bf65bd"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/paperspace"}}, "5d37d42b-b518-47c4-9c42-60fee2dc354a": {"node_ids": ["dd12e28f-6f50-430e-ae77-f987d8d9f024"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/pyspark"}}, "96c70afa-6c7c-4e3c-9f10-be0d77a327d4": {"node_ids": ["00ecca9f-4abe-4e2b-ab8e-eb2a7ee64524"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python"}}, "9fb7e68c-4a10-43a0-a772-f0654ca74244": {"node_ids": ["538259db-ffe5-40ce-9ff4-d44b4cf5aa0b"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/spell"}}, "1898ae68-5586-4446-8d4e-ca3f775e4849": {"node_ids": ["a2fe763e-6ddb-4187-bfa9-94e30671beb0"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/ubiops"}}, "bb1adff4-9674-4241-8e04-ed85392592bc": {"node_ids": ["cec313b2-c3cf-41d3-90cb-8bf85ca3f58e"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/weights-and-biases"}}, "5d5d50ce-315e-4813-996d-b1f9a7fa6bd4": {"node_ids": ["2684e6cb-1144-4735-b973-9f1a7046fcc4"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/churn-forecasting"}}, "b1e0d094-602a-4616-a138-e1e652e65e69": {"node_ids": ["a2b93ec2-19ef-4b9e-badf-8614f5d45c00"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/click-through-rate"}}, "fe8a78e1-762c-406d-9846-9b166ddc3f72": {"node_ids": ["32326f3f-1502-4a1f-adc8-5f125292842e"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/customer-lifetime-value"}}, "2772a7e1-8e38-43e5-a6b6-8bd709a1f2d4": {"node_ids": ["393ca83b-83cf-4b5c-8885-68a455d311eb"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/demand-forecasting"}}, "d0d5761b-d1fd-4b2d-a30b-9e0e6a415da7": {"node_ids": ["c2079423-78d7-48dd-88d1-fb2c0b4be0de", "689fe355-521f-409f-885d-90ca24c44426"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/fraud"}}, "43912db0-6d9b-4768-8d1b-2c2bdc1a64cf": {"node_ids": ["3e62db98-efe5-4ea1-a28c-1dc375f62337"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/insurance"}}, "ca3494d5-a0c1-41ff-b7ae-dae66a92a60a": {"node_ids": ["c938f1b0-9822-40e0-a1cc-8ee9372dc395", "a613825a-0230-4b5d-8b8b-366c2c582b5a"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/lending"}}, "32f4439a-5512-41ec-a1ea-be3a98120421": {"node_ids": ["f8310802-5d0c-46f6-a971-117dbef645e9"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/search-ranking"}}, "83958b99-e400-4d3c-9238-5aa02082f746": {"node_ids": ["e84b70e6-e64c-4fa6-a6bf-4c2a1ea69c9b"], "metadata": {"URL": "https://docs.arize.com/arize/resources/use-cases/timeseries-forecasting"}}, "87f14a1a-8cde-4470-8583-22665fc8ed0b": {"node_ids": ["1f5578de-3e69-488f-a449-d1771d2fb3bb", "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d", "1c9a9194-920e-4a59-9b16-55e785aee575"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-guides/faq-and-troubleshoot-data-upload/sending-data-faq"}}, "c7c44560-8e23-4c1c-8e67-3cc833495b08": {"node_ids": ["bb9eb2b3-3ae6-446d-89bc-81588bc1db4c"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/aws-s3-example/aws-s3-example"}}, "1c3bc399-3304-4b80-812b-dbde1d93cdee": {"node_ids": ["a704e9e5-2222-4a91-9a9f-31f51369071c"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/google-bigquery/google-bigquery-faq"}}, "9d42c874-e19e-4a0d-a3ec-02ee523d51a9": {"node_ids": ["efdf8449-9a28-4fc2-ac7e-b1bcb1c57993"], "metadata": {"URL": "https://docs.arize.com/arize/sending-data-methods/ui-drag-and-drop/ui-drag-and-drop-faq"}}, "724fddd8-f6a3-4e9e-9339-817e1b071b79": {"node_ids": ["e8b2fc05-f427-42ab-bc58-cb602c0f7446"], "metadata": {"URL": "https://docs.arize.com/arize/tracing/drift-tracing/data-distribution-visualization"}}, "f138b696-0282-4c52-9636-2d44afa3e6c2": {"node_ids": ["052d0636-00bd-47b0-9242-724c2c9a1aa5"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-functions"}}, "f4ccd784-7f52-4f27-b207-d84e1c6cac23": {"node_ids": ["2e827067-64b1-45dd-b8bb-cf78c4467126"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/all-operators"}}, "834b94d3-33f1-4321-a602-6c5e523cad92": {"node_ids": ["d3ec6e6a-80fe-4951-bf09-6c4c985d3a78"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/12.-custom-metrics/custom-metric-syntax/conditionals-and-filters"}}, "b68a0820-be12-4895-9093-4a8031a1b219": {"node_ids": ["a2ed4e24-0db3-40e5-853a-33f62e5af7a2"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/forming-calls"}}, "81b47198-7d21-47c7-af35-50ac5f5a7b98": {"node_ids": ["116d8ee5-a3b5-4ca8-826a-efafde854497"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/mutations"}}, "5f1e57b2-517a-4dce-9845-a6b822082f3d": {"node_ids": ["af3a7040-07d5-4210-8b4e-6f87f67502a0"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/querying-nested-data"}}, "89485e37-b4d9-4eea-b53f-a2ff20a405fc": {"node_ids": ["d15c4be1-401e-40dc-b8d0-ed683287ea1d"], "metadata": {"URL": "https://docs.arize.com/arize/api-reference/graphql-api/how-to-use-graphql/using-global-node-ids"}}, "9f28e5b6-ab72-4945-9081-4f0d61654dbf": {"node_ids": ["9a054106-1025-400c-8ee2-dd8b0e070ed0"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/feature-analysis"}}, "c6b75f90-4a5d-4f30-a35e-50e4d624414b": {"node_ids": ["6d627ff6-2388-4ba9-bf57-bdb3a8d83f80"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/model-performance"}}, "e7bcf91d-cbe0-47cd-bf92-2f5c3ea53d2f": {"node_ids": ["feebe11b-e06c-468b-b55e-6e0aff62c240"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/templates/pre-production-performance"}}, "074f3a7d-35b4-4b22-b667-2eb1b12e7b8e": {"node_ids": ["8f8d151c-5ab2-440e-bbc2-4a08a5568112"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/distribution-widgets"}}, "d64278c3-267f-4fad-b29e-1b288c379d81": {"node_ids": ["6a121da9-0719-4354-8497-e8f64d45b035"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/statistic-widgets"}}, "9a824a66-adab-4712-8427-a8aa6d1f5eab": {"node_ids": ["62dc2bdb-1b83-4cbb-ab93-78832de8258d"], "metadata": {"URL": "https://docs.arize.com/arize/dashboards/dashboards/widgets/timeseries-widgets"}}, "26fefcaa-0799-4f67-bd1d-a5c924c65a06": {"node_ids": ["2bc1fbbe-c413-4da2-ab00-236dce85e0ba"], "metadata": {"URL": "https://docs.arize.com/arize/monitors/notifications-and-integrations/slack/onprem"}}, "4784cd69-9bde-40e1-b4f2-0286a955ab4e": {"node_ids": ["67dbc6df-e3f2-4fa2-8514-0ebe41f10fc0"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/batch"}}, "fed4ba86-42f4-4c34-bfe6-8c436fd66ef1": {"node_ids": ["a4274c0c-9ddb-4529-9625-2f507d8a1205"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/notebook-instance-with-greater-than-20gb-of-data"}}, "b5a51a65-d950-41cc-b9f2-b9a3a2543e26": {"node_ids": ["9abba4d8-8dea-41ab-9a2e-54b5ee4212ef"], "metadata": {"URL": "https://docs.arize.com/arize/resources/integrations/sagemaker-python/realtime"}}}, "docstore/metadata": {"16537838-427b-47f6-b13c-9b9369bfa58c": {"doc_hash": "172ade911e9a3f5c6de016416f7dce1f43534c2b9fca23aa66e2e62c16c047e0", "ref_doc_id": "82f54fd0-4345-4257-b87a-e8171e872c18"}, "01ef153a-e560-4b71-a464-39e9b343843d": {"doc_hash": "bb74296c19ffc71965573ff17f01fd0d62fb28b90d1da22726db792d112c450d", "ref_doc_id": "3d360d67-7dd2-4612-aba2-675723a6e48e"}, "7ae33b07-61b4-43e7-bc70-15e0582330cb": {"doc_hash": "fbbc136e20d97f2ca89462d489b636b3b049d46a47a5204523d281bb4b7bd278", "ref_doc_id": "98af1be0-3d4c-49eb-a413-f30e8680dd9b"}, "265905fd-1d66-4b59-a686-3a8cad2818ba": {"doc_hash": "8df63de31bdeb4a09010788c42f107b969b6ad72cf9926d257479b24aca9faa9", "ref_doc_id": "98af1be0-3d4c-49eb-a413-f30e8680dd9b"}, "7e2469e5-2c7f-4d10-8c9d-5362b2567373": {"doc_hash": "f94de6ef0546ed44ea4ea5fec4184ac3cd4d3a810ff1b45544e37f8be0db0cbb", "ref_doc_id": "8d84b686-a210-47bf-b536-ec508234da98"}, "9dc8bc2b-c8d0-4d9f-8c44-add385a0a9dc": {"doc_hash": "c322d7ef89e454f553e5815605aa383fada7731769e9b36bf6a020fc2b298ab9", "ref_doc_id": "5c23863b-67de-4bd9-89dd-e8c18578c41a"}, "b5c3549b-fda1-4621-8306-672e4588c767": {"doc_hash": "09522e8c04966c8fa23b0f0a9cedb198c1ca0b25059b30ea0ef6f8c4a3961704", "ref_doc_id": "71f363f4-b3b0-4460-addc-41487e65ad6f"}, "247c7d24-f82c-47e4-97fb-c7744424e847": {"doc_hash": "5c6ba60282e2640e822c522c4ecb6bfb0fe56c33b04b63f203f6b2ce273dd1c6", "ref_doc_id": "86e579ca-b483-40af-8171-1294e02480f4"}, "c55e5ace-c87b-4d96-a750-b3ee3d539dec": {"doc_hash": "98d40a02be9a174d4b472b0c1d1361b56ccd19eb7ae88e139bf2cfae64b80188", "ref_doc_id": "eff4c1f1-6201-45e5-8636-6227b8232e63"}, "cdded5de-231c-428b-94be-fbd288802449": {"doc_hash": "06c68d3eccfe120a509dae5c088ac1876005bf2ccb1a2ba471a1dfa536a429e7", "ref_doc_id": "3a76cf24-098f-4dcd-b7a0-274532106c03"}, "9895aa09-ee4e-4f00-bd2b-8f6a8546d668": {"doc_hash": "027c61ef8d1b0238e261651c491bb17815f61c8174c8fb9db1a8f8245c3a8ccf", "ref_doc_id": "0c20e5d0-ee35-499b-a786-9fd2a19b56b3"}, "9626e825-0139-4faf-85f1-49bf41ebc6b0": {"doc_hash": "df8dcb92da0d4e0ff4e0c53e93e23812012d7136a48ecbff2e86af5d80192cb9", "ref_doc_id": "0c20e5d0-ee35-499b-a786-9fd2a19b56b3"}, "7445d565-1130-444b-900b-088601916ed9": {"doc_hash": "b988591d1203814d4431fca22822c6ff4556f029dfbaa5c373b780c6df905e65", "ref_doc_id": "77ad6520-d54e-4fcb-b3c7-f1013fac33ba"}, "70fe58b2-cc22-4b22-b879-6096c39a4de1": {"doc_hash": "d01d108bfcda5edf69a15607457c28f6e9fcad1942e87914d8144ee66a9f36a2", "ref_doc_id": "fb71ff94-13dd-4d4a-b987-1adb6f991e76"}, "e6e0149f-3d72-4cc8-bf4e-95b01c65c98a": {"doc_hash": "7a78733388a6132855ca50622f13836dd45dc1320e622d8eb2a3c56729cc6a82", "ref_doc_id": "1b9cac92-fee0-4d19-8dbb-2e52ccdf7389"}, "4d698582-91a2-405d-a0c6-56e04ac5c27c": {"doc_hash": "8182354bd2b48f2a5d767e33a162c81578902a0c66f01c28e35ef0a5d836738d", "ref_doc_id": "36dc69a0-c0e1-4f3f-b321-7ec72b93edd3"}, "4eeb734c-9289-4434-8524-fa7eb97b4c0f": {"doc_hash": "af68175d65cd6a3032dc558b42e023718a3c0c37e76c9b9021cd718d06525a6f", "ref_doc_id": "53f4e49e-24fb-49ff-a938-e2dee493548b"}, "89122fbf-9cbf-44c7-8ae0-52b1f0123d96": {"doc_hash": "69e3e22ca11cfa1ae172e22fe2d91ad09a2564d51eda5c0474db3cbe2d4e9b9a", "ref_doc_id": "53f4e49e-24fb-49ff-a938-e2dee493548b"}, "855bff49-bbd1-4c04-881f-a3e0b60cc0d8": {"doc_hash": "89f2849900e1d26cdbdfbebce48d33cdf736068cb5700dadfbcc093530cd3fc0", "ref_doc_id": "53f4e49e-24fb-49ff-a938-e2dee493548b"}, "a3729128-ddbe-4853-a579-c22f14a80a61": {"doc_hash": "c73a0c9fdbdbfac0434170d897e29accc9d5d4afcda22a134646c65c2a5feaca", "ref_doc_id": "c90e974b-5a83-477f-8f98-8f25edaca229"}, "06be9478-5ebb-45aa-b718-fb778db962b8": {"doc_hash": "3d69851027472c8bee569175b94d152ba321cba10d83bdbcac9ee17efd3d23c7", "ref_doc_id": "7b4639f8-7766-4ee0-aa4f-0ce22a947005"}, "d5bc9414-232e-4e2e-afb8-0d425453d245": {"doc_hash": "fea41e9ca7019a32bebadb90bec7bbdbe14efc2af863417393c0ca75fc5e5e87", "ref_doc_id": "1fd5a0ad-5fd4-418d-99ba-1926a61187ab"}, "f74e2cbd-87c0-4073-b110-d72e4c56cf4d": {"doc_hash": "1c144545b58b04941b18149470536c8d6c3e126489b08bc3b0d3dd4a45fb6d54", "ref_doc_id": "1fd5a0ad-5fd4-418d-99ba-1926a61187ab"}, "1e29a976-7e19-44be-9bbe-67ebb85099e1": {"doc_hash": "25b434f7f7f674f2d0e6a73de031e6b0e9b9390a185a9af0207326c8ec21da46", "ref_doc_id": "eeb925f8-fa80-41ae-bf1b-f2a0ec1c93e7"}, "f2ec490d-f288-44e5-b4f5-13d924f9b747": {"doc_hash": "e61a878c0ca3c922fcb8155a44007bcd4510aafbc30e30c83bed26e8f4dffe7b", "ref_doc_id": "0696252c-9e64-4ef9-9b60-99c42cbaebf2"}, "b26a5040-6cf0-4d67-a9c0-fafc4d5b016e": {"doc_hash": "53c0c0dd173b4f93fa630264decb6af1ef335a83b0a74da4353fa9cff0791489", "ref_doc_id": "99580bf8-b48b-40b7-8fc1-b0c96da65aa0"}, "5f2be5fa-22e9-4765-93c5-da142387689f": {"doc_hash": "fce4a452d08c8329494ac7f76091d15c6b235a2e0d1d617ddbfa01c7f57953e8", "ref_doc_id": "167257c2-2997-4bf1-83d7-302d1f1bd863"}, "9004e605-a439-49f0-9d39-8e599f050890": {"doc_hash": "be7d3780f959b454f72f55dc2490211e2c465266fd0326ac1a3fcc0ccc1ddce3", "ref_doc_id": "cbe5f483-f119-42e5-ac40-fad812cce4b6"}, "33b31146-0848-405f-813c-040328c82436": {"doc_hash": "56dcbc5700eaa32c4bf301341d76ce3d0475df7ab23f99d3279abd74837597ea", "ref_doc_id": "3561f72d-ce9b-48a9-b812-15cca731c1ce"}, "b8e0d1c1-5f3f-436b-9805-2e683ee021cb": {"doc_hash": "17b51f2355a146ce0f74cfa4f4da57a1f8563fc65dac7bb8357a718631efdb5d", "ref_doc_id": "ae09c232-a55e-46d1-aad4-bab40a8a4d9b"}, "beef5aa9-1cac-4fed-82e5-da5d6802916a": {"doc_hash": "749f8ab41b5abd7346a6b8e4448b351fbb87d729a0ee704fb78238004bcc77ae", "ref_doc_id": "2b73a05e-d4e5-4f5f-bc68-117b5b5602e6"}, "198511ca-f268-41ea-add3-4adea38e02d3": {"doc_hash": "4d22a7152526a4b14a84e437b7928b89737b7f4b65dae442b357813e0f0f9511", "ref_doc_id": "2b73a05e-d4e5-4f5f-bc68-117b5b5602e6"}, "cf297e09-02dd-4eb6-8cc3-936c00a04a25": {"doc_hash": "8094b6f6111a3b6ccb3e7bbc85e28cca90a3221c64f57a4b495f91054dffe806", "ref_doc_id": "550e9121-8508-4271-84fe-3a9d2600ec97"}, "ab96b404-fd90-4d9d-b5f6-59e477f555e8": {"doc_hash": "1162e729fdddaf3236d734d84ea1d8c08a12771c18fab9ac2e23d8c8dffccd34", "ref_doc_id": "550e9121-8508-4271-84fe-3a9d2600ec97"}, "9b7a162e-e493-4dde-b04c-3b413752ba13": {"doc_hash": "4fe66fd2efc99a25b7800c08c0064c1abe8ef15fb4a2e28114d7b7241db2235c", "ref_doc_id": "550e9121-8508-4271-84fe-3a9d2600ec97"}, "e1276b66-2ff3-4c48-995d-706670ea733b": {"doc_hash": "f047356a2bdaa6d410cd44a468fdb9e8fe4912a61868bc61e84192092d3ef64b", "ref_doc_id": "b7e72b75-e1cc-474b-9b89-7c3b8b383c76"}, "d8fcb14f-709e-4907-88ef-32cadbeea2a7": {"doc_hash": "4ce525add7816e1f5597eec5a10c6be7d0d3f80a19a7bf62cf5c6834311025ad", "ref_doc_id": "b7e72b75-e1cc-474b-9b89-7c3b8b383c76"}, "1091a6e9-52c6-4420-beb3-852ab28b58d7": {"doc_hash": "a8811f44caeed0769d586802cd9c9b29a0b21e36fa99a3d614534c10557a2b9d", "ref_doc_id": "8a8129ed-98b1-4192-88ed-62a44704b630"}, "b87ee96d-2344-4211-9144-53cb4d16ee45": {"doc_hash": "d0130964dfba6770fc65287b9f84af429138d407eebdd128e8defd9c3400258f", "ref_doc_id": "8a8129ed-98b1-4192-88ed-62a44704b630"}, "ba8b0bfd-f43f-48cf-9ee3-bf03a0355bc4": {"doc_hash": "1ba1a5454844576144a3f84c4dc0f2ae841772cee9075c2ea5081bf19dc61075", "ref_doc_id": "b39574db-5e18-4917-8641-5ac1cdbd767a"}, "24851f7b-8d9e-4777-a679-1387840a511c": {"doc_hash": "c20a8bc9b2a7b498a8025de58e7ba3a76d976ebd8b996aa3a40993e9c4c8a66e", "ref_doc_id": "b39574db-5e18-4917-8641-5ac1cdbd767a"}, "93b509dd-c543-49e1-ba3d-4f63437a8457": {"doc_hash": "c77f01448f98c0b35ed1a143d07f801d2e281fcaddaf9b3b3419d8a8e94199bc", "ref_doc_id": "47377e5f-9894-429c-a4a1-dbc0d0dd406b"}, "f2bcef10-15a7-49d7-8c60-ef8d33c95c53": {"doc_hash": "e9c6ff9a4fff2fe7e476439e7d13dfe286403b59299d753c880f9da32600621a", "ref_doc_id": "47377e5f-9894-429c-a4a1-dbc0d0dd406b"}, "16677c61-fdb5-4197-924b-be5f956e5a2b": {"doc_hash": "0514e71d1e8cda444b15c08787608a44f2e1bed7c7eec2951956ad70af2bc618", "ref_doc_id": "ac472271-e567-4a83-a75a-9d01c41090df"}, "d50b4666-97f6-4277-9db1-6bea12e17e6a": {"doc_hash": "de7b04b42aa776e43fe4dde37b5b04139e60d3b2827cf87b567eef21ffab10b2", "ref_doc_id": "414b333b-aa29-4e5b-b413-386f76d75009"}, "173378f1-c1a7-419d-a969-bb83da7e026a": {"doc_hash": "613b93e7d1ef3f4e8abdac1783df008a2a1f0767f174fd468ec39ea73c7af5ad", "ref_doc_id": "414b333b-aa29-4e5b-b413-386f76d75009"}, "29f053dc-3e4b-4871-8e91-ba18e5c36cea": {"doc_hash": "d49a512c1f59a7e8137cc6a8c9d54da025414ce830ea6af427d4050bf4b536bf", "ref_doc_id": "414b333b-aa29-4e5b-b413-386f76d75009"}, "65555ce6-8473-4fa6-9138-3ec6a81fc09f": {"doc_hash": "7fd0ce7172f839e6e1e7e8724fec06a229a271c740e8122100c5f89bf2fd0d7f", "ref_doc_id": "b2b7670a-e539-4d40-850f-6f81029442dd"}, "7fda9c3d-8ad9-4946-89cd-01817e8a9782": {"doc_hash": "019fb5ccecdbe4f91ceb1df628a85b444b591d211570a074a5a442a6da248259", "ref_doc_id": "7ffed025-161a-4fb2-8640-980f9c8e8ed3"}, "4c20d69c-cf97-4b7d-a4b2-b1b16e78f617": {"doc_hash": "e4305cd6d1ccb9838d1555c9446a0c53915f16a25741c3b7d6c5afe1ed393a49", "ref_doc_id": "73805f0a-6b4d-4957-9e4b-b3b1eda85abc"}, "f5e46357-54de-4f59-a019-298e8a30a1d7": {"doc_hash": "b72c13a8857fe7e6660e4a287c2623a504356617896bfd29412eaa3604d49e9d", "ref_doc_id": "73805f0a-6b4d-4957-9e4b-b3b1eda85abc"}, "84fb1872-054a-4e5f-8788-e33c05c61bed": {"doc_hash": "056af0836c6d56c186d0035d60059453c7e71beb27c15822f0fae30adea3658a", "ref_doc_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd"}, "84c0925b-728a-47e4-86e1-50cf15a9bf70": {"doc_hash": "83e28aa07e28b869229cf96bc9890eddc6cff0613cbeefc639c7ff2cbd897d62", "ref_doc_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd"}, "80c65da4-a51f-4e75-91cf-50fa6218752b": {"doc_hash": "637949a073ee677269dd69451d809c210cee3d21664e0dcceff63f4e49b6bf70", "ref_doc_id": "d2a4cdde-a1dc-4a72-972e-43783c8b2efd"}, "d5eeb7a0-87ae-4b66-b9d6-5c79ba5c600b": {"doc_hash": "8d5fa15cd4b5974df9deca5ef9384770e96c22c77a0d19fa8bc4c31be47e6e24", "ref_doc_id": "ccf44bc5-eaf7-4cec-89c9-4946b4632f31"}, "9cd23081-026e-4a39-bcd9-32335c843a28": {"doc_hash": "1e2c51ea3866809c5f76619abb40230f4f1e235f0f93c9491da323fd48f72589", "ref_doc_id": "55fb72cd-945a-4318-b50e-11f2cd4e8919"}, "c08e61a2-8902-4287-b8fe-00fef6186bff": {"doc_hash": "d78e918b2a033020744f03f4ee0ba74ade91b08166e7a74951dc6de5c09ae412", "ref_doc_id": "55fb72cd-945a-4318-b50e-11f2cd4e8919"}, "350524d7-b9f8-4b81-a7f9-4b096129edeb": {"doc_hash": "047fcef7937817e7309e6d9c9d5f660744736d69c7a00764207ccc733d9f5407", "ref_doc_id": "1ac34e7d-2c35-4af3-8e30-0721cfa9e90f"}, "accb5b15-dea6-4ba5-a525-ce566fc503eb": {"doc_hash": "b138f5dd1c26b578641800154621d356d691e4017159b21dcd04efcb961c3e66", "ref_doc_id": "d3eda5a5-be0f-4567-8beb-90d5658a9b20"}, "876113dd-2d70-488c-b423-af4381373abc": {"doc_hash": "3f9a8d25e4aa6f8e913770567c7b40a68c6df14730ddedb72c1e37af9b5bad31", "ref_doc_id": "c1353923-f196-45a9-915b-166c5aa69c7f"}, "28a9b5b1-2b92-411e-867a-7eff22fc9b9a": {"doc_hash": "669aafd561bcc6d5cff3656f589bc4c51dada1be089725b89a9b823649defe74", "ref_doc_id": "c1353923-f196-45a9-915b-166c5aa69c7f"}, "26cf1656-80fc-472e-8e5f-7b9e63e0732e": {"doc_hash": "26facdf9c537d200e582d3384f23d73b7b05c9be63949785d1345ebb70bd3334", "ref_doc_id": "c1353923-f196-45a9-915b-166c5aa69c7f"}, "6360467d-c0db-467e-9330-bb180218927e": {"doc_hash": "fa87b39129f2f5344d0a3d29df236bc898940661e2ab3467fbbade36446d110b", "ref_doc_id": "c1353923-f196-45a9-915b-166c5aa69c7f"}, "365e645a-9e22-40be-bea2-777c83512dbf": {"doc_hash": "54b8fcfe7740cc8a39f1c5230b11420d7142496922b190a0a00bb9445e7ed332", "ref_doc_id": "c1353923-f196-45a9-915b-166c5aa69c7f"}, "d79fa99e-1110-42ca-abce-007ada47b9f6": {"doc_hash": "fa2ffaffaf77e2c44b40f180cc6ce900a404e8987cb155e76048b077bd8b45c6", "ref_doc_id": "aaeff0aa-dfe9-4c80-bb28-181a7a19c0d7"}, "ef0ed8ee-4bc3-4c84-bc0d-86f2ee5c5a58": {"doc_hash": "0f9c9d0134ac31cf4d8d7afe1231670f2beed2c18dd5b058eab9ab30a30cf1f2", "ref_doc_id": "ddc600fe-68f9-41ff-949a-a76af047f85e"}, "01e6c4a8-f0fc-4cda-b522-b18af056a8bc": {"doc_hash": "170183666ba8a9486a580c4fd4fc9b2b93c7c38a55010a84e23f52b504185bae", "ref_doc_id": "ddc600fe-68f9-41ff-949a-a76af047f85e"}, "b5185e4b-ea1e-409f-a90c-0619c1acea3d": {"doc_hash": "cf65f6fb692c2fe78f5473831167545dc39443524fe6fa4d8e420bb70564ae03", "ref_doc_id": "2a1ecd6b-5648-4099-8050-0aa12cbaa5f1"}, "641efc54-02c7-4112-b45d-b76d83807040": {"doc_hash": "18a82f77eba5786e9e334b2bdf1a4530d345c653623e4de519cdb61950771be5", "ref_doc_id": "028ccb9c-9fa7-4f00-a8d8-0fe2c27533ab"}, "cb5e46ac-708e-4b5e-a9d4-87a1a24aa859": {"doc_hash": "91a846718b035986dd69a929c39974c00bf53a00296d6856995d9b1cda7ccdf6", "ref_doc_id": "c960851a-f693-4d7d-bfe5-384094fae798"}, "b9e7625f-b071-4b68-983a-0e89bf14ddea": {"doc_hash": "e77606e6d6f53399291cfa2006ee453f69205caca3fd696095acfed283b10065", "ref_doc_id": "c960851a-f693-4d7d-bfe5-384094fae798"}, "e785356a-8805-4591-8a94-5b259257130b": {"doc_hash": "ba8d487eb9fe5282f2a38bc3a38f9f5c3b34082270bcd4d05bec5d0ad0fd09f4", "ref_doc_id": "fc309922-289e-4671-8182-59c0e23c8adb"}, "0e88a5c4-ca0f-4b9e-ad78-b6ca6917f996": {"doc_hash": "a5d3baf498151cbeaf757c091a9953c7eac82d66f4b84f2cc6b257b7c00d4b0c", "ref_doc_id": "fc309922-289e-4671-8182-59c0e23c8adb"}, "af4ad4f2-c1e9-4289-90af-0f1e994746e2": {"doc_hash": "03166e91fe52f769d06d66410acd3abc530416d79bb6abcc4e6059c542b802e8", "ref_doc_id": "bf2a9af9-7270-47cd-aeea-3b53774d1e2c"}, "05bccf93-b57d-4f32-bbb2-2bd57f51b860": {"doc_hash": "d6f536b3a084ca431b02301e49f7d483e0109bd30e03aa12d5a13564c2080aa0", "ref_doc_id": "bf2a9af9-7270-47cd-aeea-3b53774d1e2c"}, "f1aeed01-3dc6-48f0-b335-5c81f7eb3b98": {"doc_hash": "2df92266f91005b57a1fa83da602d0a28173088655d0d598ca208e37dd454046", "ref_doc_id": "37d34887-1b48-486e-8cb6-acaf8734d4f1"}, "8d3dcd4d-5772-4048-b323-b801473e70c3": {"doc_hash": "2ef6c59250af77fd479af7a981e4e1cfa10b8411c7bd2fae62d61993b8275684", "ref_doc_id": "37d34887-1b48-486e-8cb6-acaf8734d4f1"}, "a175d1ba-4ab0-4694-9a07-c62342846fa1": {"doc_hash": "f13124d4baa0c5b635022d6b086fa1839632fcf253cad12e19d5717f65ff3c74", "ref_doc_id": "b5b1a345-1092-4bb4-94c4-a1a92e091e76"}, "9c4e69b3-413c-417a-a155-2dd3c0dcd41b": {"doc_hash": "19fc396fb49f52991e45227c7794f6ae46be2bd0a639ce693bc63d65bb02d9bf", "ref_doc_id": "b5b1a345-1092-4bb4-94c4-a1a92e091e76"}, "619f7580-dc9e-459d-bab0-97ce2617bd3d": {"doc_hash": "d9c87fd3c552ad47bdd9d2bc37c2d1749ee03863609827568d6ed6f705c29a01", "ref_doc_id": "0692058a-430b-4fd5-9e6a-0d92fc0d4b9c"}, "1f9e9eb7-d7fb-455b-a516-216d1cbcb656": {"doc_hash": "34643c26b3e574154abc207a6c5201617b4311cfe41cd090e2a8eb6521e0db40", "ref_doc_id": "0692058a-430b-4fd5-9e6a-0d92fc0d4b9c"}, "f29f1a2e-21bd-4b0f-b57d-59e4a33fac88": {"doc_hash": "9570f202b797ef5366535fe8ffbdd3778bbd33693dc83bbd77ad66bc08e38914", "ref_doc_id": "05959813-46de-47de-b480-227edfbc1403"}, "19bb19e9-cbf2-43a7-9b71-ddf760646a39": {"doc_hash": "091afc5426112077567a37a98bf9344bd702dffad99c41a9fedd731c1d8fb592", "ref_doc_id": "05959813-46de-47de-b480-227edfbc1403"}, "580c151d-75a7-4190-ad84-b7e448f711e5": {"doc_hash": "7d966cf0421b18e3bf43c61ae235705ab158c6a8174f16902b9f5c7e90b5c536", "ref_doc_id": "9268e9f4-0348-4664-acc5-4939a1ee056c"}, "426818ff-842f-48fd-86f2-be8a7c65de23": {"doc_hash": "36e5ddfc0758b58455a484b68bbece444cf4482a0260b221124a5df7b2948b58", "ref_doc_id": "1f7d1fef-9184-4c27-aa28-f1eead203125"}, "506faca4-8611-47fc-96ec-c143e8116c10": {"doc_hash": "4f7723b71f5c185f45d343c8cb2e03d2ca368349dd99122c117a70aef5c400fc", "ref_doc_id": "1f7d1fef-9184-4c27-aa28-f1eead203125"}, "46c33a9c-947a-4f2d-b5e6-40c66dbc1a78": {"doc_hash": "63243e74cf8bdf26e49e2561fb93d530c089e2525a04f092efbd7251a3369c86", "ref_doc_id": "22e775c4-5bfc-4534-9a98-5e70cc9220ed"}, "88a4aba9-e65a-4f0a-a745-b71d70129331": {"doc_hash": "a6a957358e2f16f23dece1a4abefbd4c232c74580995539f84abf98d1deb3991", "ref_doc_id": "8707c59d-9c11-4bdf-8e53-544c99186523"}, "cd15e0f8-b286-4a6d-8546-23ba67a0bf6a": {"doc_hash": "7105348310ec9afd377377f5002cee5182bb36aae9d20e249997ad8a5c730832", "ref_doc_id": "3f6bae1f-ffec-4528-a7cc-dcbe19db39ab"}, "d4c48173-1914-42a7-8345-bba575666846": {"doc_hash": "aa2f96480ca5736c2fe68c1504306698aefd2698d6305c261ea204b0fbc43c2f", "ref_doc_id": "e41f550f-90f2-414c-8604-1546b5ca187a"}, "b77ab1fe-c816-4011-a1bc-c76e8e5676ea": {"doc_hash": "695bd6c6e70fde5c0ce8b7827e949d141e62a737db26b0bb4727abf1772ad403", "ref_doc_id": "58f63029-0e23-4aec-acd3-f4da9263a8aa"}, "b91e0417-d273-4f27-8cd9-d2422a38a641": {"doc_hash": "b3d6f3f38bfece3699bc6911e1c61a6a23a6f568794b3b9c2b4aa52e34e584be", "ref_doc_id": "58f63029-0e23-4aec-acd3-f4da9263a8aa"}, "42921c89-35d4-4e60-b682-f3080a99e76d": {"doc_hash": "9dbd959229f1f78897f344c8fe1e7c8bb3b2f381cda3f070c5a7c87ddd432ecd", "ref_doc_id": "2e67adf9-c949-4658-95f9-ab35036e1e7f"}, "1453a19b-f181-4aea-9971-bb0c42f8990e": {"doc_hash": "2b39ad3a11dfff981ca55d7a635b228e93baf9d361d3fa47a79027183c2e93e3", "ref_doc_id": "924a6a3d-85a9-47fd-a3f9-1d719c04ce2d"}, "7bf5cbfd-13fd-4bce-b117-91e335ded852": {"doc_hash": "89aeaa98557138d48248dd3da95188d37e6e35c47ec1a672965cba2cb7d77a56", "ref_doc_id": "c6b05237-0399-4108-b9c0-20271f73a8c9"}, "e7223684-a1d0-4a6e-846b-da6fe07be03b": {"doc_hash": "caf9b4710d46533e5f3c3bbf2f9bab62e7aa2fe26ddfacac4683946671d678e2", "ref_doc_id": "c6b05237-0399-4108-b9c0-20271f73a8c9"}, "10033e50-a69d-4517-bc9e-929425aaf98b": {"doc_hash": "179d1745e95fd02bceca88bbef046263406adf740109a13d9f7813b2b3de93fe", "ref_doc_id": "049b9932-b473-4cf1-a30a-392e71674d94"}, "349b62d6-58a9-4454-bb28-aafb500ea2d8": {"doc_hash": "5ccfe8e137223da35836547796ab9d4e35487e6a863bc2667e7fb5729d623125", "ref_doc_id": "049b9932-b473-4cf1-a30a-392e71674d94"}, "3b87de7a-0e1d-4d5f-a840-813b70d29f14": {"doc_hash": "6cf92908084078a2cfc813adcae8113fc03262d3cba4fb3fcdf447ae9edeac0d", "ref_doc_id": "d830eb6a-d70b-4ff8-ae6a-4f7935c1c729"}, "06684fbd-38cf-4812-a9b3-f9aa3324893f": {"doc_hash": "da36f19d82debac400c0477017bd88dfaab45fecc2d624b9c24d139c896dcad2", "ref_doc_id": "f790a3e9-7d0f-4252-a3c9-8734364f96f3"}, "222133ca-97a8-45fe-afb0-094a17fd8000": {"doc_hash": "044bd918b002f3cf4349f77dc41388d87fa991b785034a70f1850d89c93ecee0", "ref_doc_id": "304c1bae-1027-48b0-8529-67fef42010e9"}, "5e834ad7-b773-4411-af47-2b4bcda0e6da": {"doc_hash": "14ab7a5ce2ae2697997d133942014ad630d414ce2365e3bd9a69831e9c88314d", "ref_doc_id": "180da81f-aabd-4790-aaab-35e7add82b3f"}, "8f46c265-5c52-4b2d-9c5e-0ff8c31f9987": {"doc_hash": "d17baff77185eef976c614ddc2df35e606c619807e462c7bf4928d3bced7bcb9", "ref_doc_id": "0c39c442-7084-4d4c-b256-5b1a14cbbda9"}, "eb23ec53-58fd-41c8-b88e-b1637841ffa7": {"doc_hash": "185433976081fcc277ca569c4be0004e499ea6b99ca012443ba1470eafcfec0b", "ref_doc_id": "d4c7b444-9e97-445a-a5da-ea6a5252076d"}, "f2af5035-6e7f-4660-aaba-46cecdd64c57": {"doc_hash": "72b76485eb62584f61fe24b6d73ea26a0d1fe93ea50eaff5e43c4c4ec9fb491e", "ref_doc_id": "5a010431-0dd5-4236-9df8-532d123c7884"}, "83d3ff59-b33d-4a5b-b915-ed11b87c1b88": {"doc_hash": "a6cb8c24a7107b6ac94ebaa90070fdbd17cc177501242b856282eee189dc11cc", "ref_doc_id": "5aa11672-2e24-4cb2-9969-bfb2216dcf8f"}, "82043aab-ba90-4fa8-9c34-9b2d47ad7d7b": {"doc_hash": "19689388fd151b7a8ffcd576de5be9122f574a96c36c10d5466984ce36192485", "ref_doc_id": "c71f1a99-d486-4ef1-9dec-3f5eb711c8c2"}, "60646944-c492-4115-a5c9-3d5c3bb60783": {"doc_hash": "7ae12607a78a3dc5080108a1e3dfce7180615f224faf554858caa114774f1848", "ref_doc_id": "76da110a-95ac-4aa5-a855-5bb719f045f7"}, "e3b783d1-c8b2-4254-a1a2-230b860b6879": {"doc_hash": "4195d75db4302beadefed8ca17a1741c2f1230748a768e8a73c7bece0a9e2433", "ref_doc_id": "ce597fae-849d-4561-ac33-f6f27fd1bfa2"}, "9517a28a-a65c-4ea7-b58c-0628a7104b4d": {"doc_hash": "632b982ef3736241565982b0c7c312e52ee922aa28d4bb2995974d298cf8f5df", "ref_doc_id": "748bc204-476b-4074-a648-3d659e07b165"}, "df2b68f7-bf75-43a1-8c32-a4f3a543c4b4": {"doc_hash": "7b038ad480a7702630825e1f8df692c0532652db36efa436b6a0903dea75b715", "ref_doc_id": "748bc204-476b-4074-a648-3d659e07b165"}, "08dca518-ddf1-4380-b62c-85df75f2e3ca": {"doc_hash": "ee80fa636c9f392ad4d38a8b48966ef0dcd4842741314e15184114e21233f72c", "ref_doc_id": "260b7be8-0a99-4379-96ff-ab7906a492cd"}, "5a95db40-1469-40d1-a1c1-0c240154d3e6": {"doc_hash": "5632ff319910e9240dfd7ed99481497245b82bd2111479d2b61b301092f8320a", "ref_doc_id": "6f46fec1-4041-4b68-a6b7-cce13699898e"}, "5098be58-8027-4524-866d-80ec073d9d75": {"doc_hash": "8e1bc11b6fabd47775ff87666e8613732e2d90baa315b17f54d520c7edc98638", "ref_doc_id": "735e890f-8307-41d3-a5de-fb99fbf335bc"}, "6dc02ce8-a2b3-42f1-8ddd-82a4a1e0e39f": {"doc_hash": "68c14937b345ef2ae557ce4268137c7b1c648b4617c3e61071e6d14e81b0af33", "ref_doc_id": "735e890f-8307-41d3-a5de-fb99fbf335bc"}, "1ea64d01-8701-4195-987a-ca21df4d1c5e": {"doc_hash": "052631b54ab28bcba98ff01f46100848d807ed5f514e635769e0c5631b971972", "ref_doc_id": "906ef3d6-09ca-484e-8753-ba6dc50fa9f9"}, "c080e82e-3558-4876-a978-d7f4d5fcd7ab": {"doc_hash": "42a80433889170f6f3c888c21884a4ed9750608a967c7c09a8baf3ade155f280", "ref_doc_id": "0aeb2d90-5dac-4c51-93b7-326540a233a3"}, "84699106-2432-4048-8750-4e2be63e48c6": {"doc_hash": "d2b6a2522bfe30ecde2f0b019c4b465102e0efaab0ad843556d06f37d2936886", "ref_doc_id": "9d2b621d-07ab-41ca-9518-a07141454a6e"}, "97a54811-0f27-4ec4-922f-23516ffeb5a0": {"doc_hash": "1861594be8041686fafaf02ec7c47f07c4945051461703c110c80207b980411f", "ref_doc_id": "d0f57afd-b130-465c-a9fb-b22004f6b3ff"}, "93ffcb8e-0e82-4e88-992a-2263e287b879": {"doc_hash": "1879f6ad967ad8a764b3271e35fc05b102b237fdc51a0e61e64a5c300d632c63", "ref_doc_id": "a04b55ec-0418-4970-8fc9-6421eaffcd7a"}, "57fa9bdc-031b-44b6-a172-110a17480d78": {"doc_hash": "07ac5dc00ef4b976249f25548df270c2a71acfc691f64077c96b9574a77d1ed8", "ref_doc_id": "d9474079-16d1-455f-9456-e1bc84430565"}, "08ccaf81-dee9-489f-98e4-403a20ede888": {"doc_hash": "398ec88aaf591f41003df3dee23887692b52266ebfd1d6ad4039d60811d65c1d", "ref_doc_id": "23e673fa-2239-4ebd-92cf-35da1cb7ab9d"}, "1063440c-3d07-4af3-9481-920af9aa0531": {"doc_hash": "94c26bdada21dede4410334fc1a83927c16088ccda330cc4c39b50a6cadcfda0", "ref_doc_id": "23e673fa-2239-4ebd-92cf-35da1cb7ab9d"}, "6aae5dbd-b15c-421a-a4d3-743ae88a1d10": {"doc_hash": "725eabe57536e59913d1dc3e37dcd6f8c967e3dd4fce5bc004ad0871a38cba72", "ref_doc_id": "9dbcc6cb-5a60-4e6b-b3f1-5c6b5d8ad578"}, "4d0d7642-858a-4352-aad6-78381bd0f963": {"doc_hash": "404d4a59bc543b2ff0e92a18bc8550be89b0350f02bf3ea5b83eebe6f19acdb3", "ref_doc_id": "b785648c-c907-432a-a3f1-d636d7f65172"}, "073267bd-96c6-4f03-b63a-1dcc7e059625": {"doc_hash": "bba338d35e888740d8d2b93bf8fafe756863bbeaba5c76713eaa1905f2bb12a8", "ref_doc_id": "e79940f0-1d98-49fd-852e-3daf6a9a319c"}, "68a50699-9944-4d40-acd7-fbc0aaf7123d": {"doc_hash": "70ff91d54c6efb7c6dfba1262d52fc8feffea4e7e646dcba8ece301a7d70066f", "ref_doc_id": "118db4c0-2d07-4a21-9282-6e9e0b9f7e89"}, "278babb4-b596-4355-9cb7-3b66e61f72ab": {"doc_hash": "0fa261431f48d590f36fc56dfdf1e9a58d8fbff24a6e04c02999ad72d80c27b8", "ref_doc_id": "118db4c0-2d07-4a21-9282-6e9e0b9f7e89"}, "0f4ad5a5-528f-489a-93aa-45f993aa8d95": {"doc_hash": "5d4a86f9f82ec48b55d2fa1a6cc75b312bc9c366f4910dbfd11c8e4a5d772a16", "ref_doc_id": "a7d4d2bd-e685-4663-b7dc-dda2622a9237"}, "fa43a101-31a6-43a0-96f3-01b37a0ed21a": {"doc_hash": "8878a806b4e02f69ec28814f7e958451d03e6c640d0bd54670a89c40c250789d", "ref_doc_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4"}, "9b512b54-d163-481e-8a3b-1e28e16b0059": {"doc_hash": "82b7d3defce577d082ba64d3bbe82e4e042650155097824db0a3cedccba68788", "ref_doc_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4"}, "5a4d6dbe-974e-439a-ac7a-afb5a1406543": {"doc_hash": "d14e29e7840f85b95e3c85f811cb114de6265455aef996c6b507f06bb9bd5549", "ref_doc_id": "d685c8c5-2f03-4742-98fd-5b523b15ecc4"}, "06a637df-0553-4e55-8063-7a859c308a25": {"doc_hash": "7139da13ee7fb5b95f0e2e987fb872036ded1c78b412d385da55a0fb598fa875", "ref_doc_id": "70c500cb-9350-476a-b085-b5869f8a655b"}, "e3381666-8a88-43c2-974f-1553477edd03": {"doc_hash": "990de14e19860a1049a1f4a74e317d6bae3fba45ec010a8eb5dba01708263b4b", "ref_doc_id": "e7638f3b-a378-455b-b84d-a42828b1f875"}, "3c1fad62-c326-421b-9ccf-e9f348454393": {"doc_hash": "a79bc71523d3cc97dadf45532b986927c5692f9431b83c44d2708453b69add2b", "ref_doc_id": "e7638f3b-a378-455b-b84d-a42828b1f875"}, "d73071d9-026f-46f2-abb4-aa65df3ca774": {"doc_hash": "39747e699fa9415951562adf028336f38f2b2cdf5cd68162996528c9627cb58f", "ref_doc_id": "0f548f54-6b44-41c2-b277-f1b82a519347"}, "e6b458ed-bca6-4700-abd4-aa3dff0b96c5": {"doc_hash": "4b7a2cda5924a34a646f5f6691261647eb40e7ee7ace64dffb754a8e16e89b5d", "ref_doc_id": "0f548f54-6b44-41c2-b277-f1b82a519347"}, "e142128c-14e8-40f9-8df9-720a6e69ac55": {"doc_hash": "12105ef3b9f0c709ec2a87bfbf38fd13e16db840be04b26ecf36e160b81b91bf", "ref_doc_id": "70e9ad5e-7ec6-491f-bc72-5f93e943a341"}, "0b43ed45-9991-4187-a4e6-db816a6a1dcd": {"doc_hash": "ad4626aa1f20ad95af7f7f32eccff5013a24b3a2fb5213c8da3609e3318c72c3", "ref_doc_id": "70e9ad5e-7ec6-491f-bc72-5f93e943a341"}, "dbd9a112-6758-4875-b19b-f6855a6edf24": {"doc_hash": "31d3bdb9f373f63138cbd682b380bcdad38c21fb504f5b6b6c22378085fd9b44", "ref_doc_id": "d30adf46-894f-4541-a25c-c43400a511db"}, "15697f82-90a9-4130-bffa-808babca9d07": {"doc_hash": "e1f011171db19c4be8937f650bb6927da909c71e2bdc5852935d8de6de68c383", "ref_doc_id": "8597bae9-c2bd-41ce-ae26-8bd8d61ce816"}, "4bd2ac03-c738-4d36-b32c-52221946fbe6": {"doc_hash": "a828693b8c5c5f4ff2cd2b97a29ed9a80230701199be7130dbd6c94c2b964ec0", "ref_doc_id": "1057fd60-2309-4564-89a6-1f037bc04e45"}, "af9a2b1f-f909-4fc1-bb7e-41995316e217": {"doc_hash": "c57949cfb00225cff26ebe2efb7730a5a70cba1fc10ac78bb7deb6f49568aaab", "ref_doc_id": "c2ab1e7b-c9df-4669-8a20-b68245c034f4"}, "9ba1d5b8-21ad-415a-b528-9273c4078035": {"doc_hash": "4d73565ddf8043150f40cbb50ffc9528d6bc9ccae56c6344da10e9e60fac498c", "ref_doc_id": "9a859b43-375a-4027-9392-5eba5c9df418"}, "a289db9f-3096-4ecc-ae37-ca91e2cbc2c8": {"doc_hash": "3b40cd4fc61e1c3511f6437aa03a6b0e69683598d46f9bfb82dbfa329aabd22d", "ref_doc_id": "9a859b43-375a-4027-9392-5eba5c9df418"}, "729e5c5c-bc82-4011-aff1-5d22b2c8b350": {"doc_hash": "7c09ca4913303f590d8a4d37db6358b8e09cf2ac7427c806b60e99b033e7641f", "ref_doc_id": "a0ee1405-edc2-4433-8f63-e1953e1156d7"}, "95ce2bd7-3899-47a8-a624-3dfff646d115": {"doc_hash": "690a63fa5b17c766345d57e49eeeded65cf01c09b7363035349a5f26f2a7c4bc", "ref_doc_id": "a0ee1405-edc2-4433-8f63-e1953e1156d7"}, "4b2034fb-7800-45ef-88e4-93c5c6fb6424": {"doc_hash": "114d7c15600a2a48b78683a8a1eb0fe6cd0813eef0108d681c986c32a7850cfd", "ref_doc_id": "58089885-f316-4164-bc99-bdde2116f371"}, "3a554674-5523-4965-9e68-97292a1ccda3": {"doc_hash": "93957cefe2cb1aa75bb618db0f9296f4adf8a38bce5e4a51be07e70c544ebee5", "ref_doc_id": "afae243d-1d48-4bce-be11-1730eadd5be4"}, "a01e7261-cf3f-4307-a306-afe4c115731c": {"doc_hash": "15cf4feef6dbfee45499b4a46fd988793537f107282a7753817fd760cc08d288", "ref_doc_id": "8e69cb74-dd0d-4953-ae1e-87c2bb9cc3df"}, "b76a9f17-c0e0-4a93-81ec-3e68fc361ee0": {"doc_hash": "c2af76312ad8c1affe755563048c0104c75a7c2146d7584544676e832eb43fcc", "ref_doc_id": "41ffb412-8d71-486c-83cd-31e0ae7ad0b7"}, "87a0af5d-0901-420f-896f-8696097a3d39": {"doc_hash": "d41c180fdd695f875680208918e73821e1a9b52a1f604ac8ece8aee7b568359d", "ref_doc_id": "783870bf-2ce0-4d9c-802f-caf7bc786409"}, "05405d0e-5b2e-49ed-a545-08acf9caf065": {"doc_hash": "ad1a69bfbf972db3e7940258a309d99cc7e4aa9f3062b533248c0c6620977f5e", "ref_doc_id": "eb06e579-e72a-4f1e-b824-414b9b637dd5"}, "7fe51cdf-8ff7-4ea0-944d-7e77095456c2": {"doc_hash": "644e109075a00a858e1315c34ebd4b59e5efa8f095ffeeb55a5a007698df51e5", "ref_doc_id": "56f31f00-b684-40e9-acb5-b5e30f01568d"}, "9c93bd3c-59a9-4836-83ab-672b20b6c8a8": {"doc_hash": "aa34a743d620ecdb869cbf45dd484d128dbfec95a33a6042031362191092ef2e", "ref_doc_id": "bf21135a-de9a-41a0-af12-0e33611ca000"}, "5abc1ffe-683e-43c1-8257-79daba457189": {"doc_hash": "e7b4d2ad129166242034f641a09d5f3bf7c4f6662025cb9f3f3d21b9d38fd23f", "ref_doc_id": "48896621-9b83-4f8b-800f-fdc387260f99"}, "ba7ae850-1512-4b82-a7cf-6dbc4f38f7fd": {"doc_hash": "da25a3c5e40a6d73f1b4778729330a946573d8fdda0ff0562a553ef2127ede61", "ref_doc_id": "48896621-9b83-4f8b-800f-fdc387260f99"}, "d90886d0-265a-43d2-86cb-83299a6f0aa6": {"doc_hash": "55c6b2691e0b147dbf5e24da1ab5326d472d73e6242d44b524a79691dd7a1947", "ref_doc_id": "bf7e3674-a267-4685-8e56-9d4bb5888e92"}, "50c39b7b-f1d3-4579-aa27-0c43ebf10444": {"doc_hash": "58a293c4661b9d8499ebeb2de7f09a6a1a8af5e49b85d99088d687192088c12f", "ref_doc_id": "bf7e3674-a267-4685-8e56-9d4bb5888e92"}, "8951ba30-63b9-41aa-a093-40ecc5a1c8ea": {"doc_hash": "c4cd8079b7219bfc3ccf9d19457be5137f3f952656e78fb5e86080f4bf004841", "ref_doc_id": "e541b8bf-7da2-414d-8f74-d68ed88cd044"}, "da1a7295-10db-450a-8a6d-69b4a1321f77": {"doc_hash": "acd6f39abf2813b7ca5f1939ac3fd540b94998b8c06436636353efc9f180d7e6", "ref_doc_id": "dfbfb421-2fd4-44da-8a3f-a07455b47093"}, "a9acc3a3-44aa-4993-b5d5-cf6073236488": {"doc_hash": "95b38952b89dfeb3b6e63cc2ef7733f1a4d2c72dba2ec7c2279d12a8ea98f4ea", "ref_doc_id": "69f6c3f1-2eb4-4268-a5ea-6ed6a4d18f30"}, "e52397b9-fbcb-4823-82a1-a6ecedbb6c4c": {"doc_hash": "e9046acb08368e8aa68bbdb736f2ac3b1da3fef73038c342734a55d62ea3e67e", "ref_doc_id": "c2d39c09-4bd7-4fcd-9c0a-0fd7046489f7"}, "be602cc2-1634-4937-aa58-760ca4ca6223": {"doc_hash": "2982a5d90c4a135acc1f417d63e5d7ae7bb66f2f86585754c9deacfa5df75839", "ref_doc_id": "e02e0904-9276-42c1-b2ac-5e8b4b7d95c6"}, "d5a8b73a-1ab5-47a9-a1f0-7285e245c617": {"doc_hash": "890d6f2f4de5d7d82b20a2ab7430133137b0af1eb72084bebc720c6d7d22646e", "ref_doc_id": "219825ff-0e55-4cb5-86f5-56b946b8be05"}, "c6cc2e35-aa38-4d2b-b395-2bde200f6fed": {"doc_hash": "9936fce676cfc0b8e3aa6b9d3f24fe0e37600b585c15012fc41bab858cc7a947", "ref_doc_id": "badcaae8-e7f2-4af1-b721-2e0701a3bcc3"}, "024f1e88-dd1f-4150-ad24-ca0549749352": {"doc_hash": "c83cbd3bc92d1ea918c515b2fcc2b0ce5cf914e6812cfa827f8a79594c8dc389", "ref_doc_id": "a9c1cfc8-ef22-413b-8ae9-d71f45673b15"}, "4ff35440-99ea-4166-80a9-349a7965834f": {"doc_hash": "3bf9aa4420a79ec3554b82a8c7cd7727ddb50a4da2d3dc766daf6d82bd9b4ad0", "ref_doc_id": "cd857c5a-1fd1-45e8-b942-193e6e75442e"}, "d7f18fc0-9953-4672-bb97-1f082607fa59": {"doc_hash": "f514bcfa58a8585d01ebc53d2d37899602db8004808040ea65b256214b631718", "ref_doc_id": "1103ebe6-8bea-4ea4-b86b-a681434598ce"}, "5dc1321d-7d0d-4789-9fd8-b96162a25223": {"doc_hash": "0fadbce8b363c9fc806fb36ed39572c8c2f48fc452cd54fbebff1d8abc7d765b", "ref_doc_id": "f2964e91-937c-4d33-80c2-06b338f61070"}, "66749c87-ae52-4559-ac24-048e3ef40202": {"doc_hash": "135282f7704ca9342e419b3f273a82ab073f2061d916af3d3c2afb86269697e2", "ref_doc_id": "4dd61e0c-2858-400a-b621-1b0f47655bf5"}, "95578f21-3247-4384-b4ba-353d60e0e444": {"doc_hash": "1253af82fb4b3f7a07420162a72844b64b3ff5f21d7651deaec141fb6cd9f306", "ref_doc_id": "d5fd8253-ceeb-4262-8a4a-95e8bea1dea3"}, "d0163aa9-f03a-4f55-8694-ab178773eef7": {"doc_hash": "908e3f8b962e474683f56940b3c968a5876f5448d19a39cd9519bdf4eb5db59f", "ref_doc_id": "dcde8e85-8f2c-4597-bacd-59982631eff2"}, "3f0a1f20-36f5-43d6-bba6-2d9441bf65bd": {"doc_hash": "c3ceee89a0c950870b43751c2aa4727b5d21fad49bce0215da1babd4e8ec3be1", "ref_doc_id": "ccfaabeb-d828-4d5e-ba30-7e73e73dfe39"}, "dd12e28f-6f50-430e-ae77-f987d8d9f024": {"doc_hash": "4d1440ec1113c2319de6f84a362ab0f581e7e52553fe355cad9e579b2da63fd2", "ref_doc_id": "5d37d42b-b518-47c4-9c42-60fee2dc354a"}, "00ecca9f-4abe-4e2b-ab8e-eb2a7ee64524": {"doc_hash": "0a277f37e0a202d8493a817333f9227acde895ac42b010686142e9e6b34c9621", "ref_doc_id": "96c70afa-6c7c-4e3c-9f10-be0d77a327d4"}, "538259db-ffe5-40ce-9ff4-d44b4cf5aa0b": {"doc_hash": "9167485536113374423975dfccb0c8d0098df099989297cb796288d50998e658", "ref_doc_id": "9fb7e68c-4a10-43a0-a772-f0654ca74244"}, "a2fe763e-6ddb-4187-bfa9-94e30671beb0": {"doc_hash": "2e6ace7c84a579603b9f7ae1e74fa5bc79ddd295e9ef6c63be3e0053108f59a4", "ref_doc_id": "1898ae68-5586-4446-8d4e-ca3f775e4849"}, "cec313b2-c3cf-41d3-90cb-8bf85ca3f58e": {"doc_hash": "14c58ac976fa7792f94fcd0c68cf70e7bc73689ca08ddf088c64eea482b2ae78", "ref_doc_id": "bb1adff4-9674-4241-8e04-ed85392592bc"}, "2684e6cb-1144-4735-b973-9f1a7046fcc4": {"doc_hash": "c9855b9d9e56dc55836b4a918316b16524dd6a64ded5ee9c0f9f6a428f5790f4", "ref_doc_id": "5d5d50ce-315e-4813-996d-b1f9a7fa6bd4"}, "a2b93ec2-19ef-4b9e-badf-8614f5d45c00": {"doc_hash": "864e0f3c2cf86711ad8af7f8b22f15bd2bcfe1ea9d161f34df188605ff1cd748", "ref_doc_id": "b1e0d094-602a-4616-a138-e1e652e65e69"}, "32326f3f-1502-4a1f-adc8-5f125292842e": {"doc_hash": "1144aa80f4c1cc05fac698d9ebe33f7c6e41fb1b1f40b7950de896c79b51cd21", "ref_doc_id": "fe8a78e1-762c-406d-9846-9b166ddc3f72"}, "393ca83b-83cf-4b5c-8885-68a455d311eb": {"doc_hash": "90645d382da13d86687da7a2d4ffb37b37eba95196107727f6da0925e1a4926b", "ref_doc_id": "2772a7e1-8e38-43e5-a6b6-8bd709a1f2d4"}, "c2079423-78d7-48dd-88d1-fb2c0b4be0de": {"doc_hash": "fc097032c59f26b5c2c83055b9f1953325f015c2a30165da4414e610f2616849", "ref_doc_id": "d0d5761b-d1fd-4b2d-a30b-9e0e6a415da7"}, "689fe355-521f-409f-885d-90ca24c44426": {"doc_hash": "960474e82fde622ed3ae249a8d6f2b151ba6dfbff0a516dd8cd14147bd751292", "ref_doc_id": "d0d5761b-d1fd-4b2d-a30b-9e0e6a415da7"}, "3e62db98-efe5-4ea1-a28c-1dc375f62337": {"doc_hash": "58639181593c6174faed918b123a974fed69f76ca85764649d1b5f889a3e25ec", "ref_doc_id": "43912db0-6d9b-4768-8d1b-2c2bdc1a64cf"}, "c938f1b0-9822-40e0-a1cc-8ee9372dc395": {"doc_hash": "ceb4917758c2729859a2ac80f2471090ca6d3b2c45355f7d5a79291e2544accc", "ref_doc_id": "ca3494d5-a0c1-41ff-b7ae-dae66a92a60a"}, "a613825a-0230-4b5d-8b8b-366c2c582b5a": {"doc_hash": "c9292b3d1d4e88ee73006cfb9f7e1d18f334ecefeb2e547942af080ee24fe70d", "ref_doc_id": "ca3494d5-a0c1-41ff-b7ae-dae66a92a60a"}, "f8310802-5d0c-46f6-a971-117dbef645e9": {"doc_hash": "e2619b6f4bc930fb906aaaf9438ebc160a632fa9a1e1c771cdcbd2a496b55bb2", "ref_doc_id": "32f4439a-5512-41ec-a1ea-be3a98120421"}, "e84b70e6-e64c-4fa6-a6bf-4c2a1ea69c9b": {"doc_hash": "c9411eca8a5ca84e7cbd44b0cafd0337b51e8afef27614de4afb735237873836", "ref_doc_id": "83958b99-e400-4d3c-9238-5aa02082f746"}, "1f5578de-3e69-488f-a449-d1771d2fb3bb": {"doc_hash": "7535d404b91b766be38ee807ec5d0811d427d82243f2c4ba5a8c36d9dd43a241", "ref_doc_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b"}, "e9b3dfa9-f8ed-44e2-803c-7b5ea683db1d": {"doc_hash": "7921bf105f502b39b354f6945921d473946d8e82d359c935c646d3022f7ed1f8", "ref_doc_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b"}, "1c9a9194-920e-4a59-9b16-55e785aee575": {"doc_hash": "5a67020d5fbefbb453a3c7848fe3cbfab86229ad3bcaadc4a6301ff7cbf861f4", "ref_doc_id": "87f14a1a-8cde-4470-8583-22665fc8ed0b"}, "bb9eb2b3-3ae6-446d-89bc-81588bc1db4c": {"doc_hash": "3d02808dd05256048d86897b9eaa841e65e196dac99f0e8bf64c11de1fa37469", "ref_doc_id": "c7c44560-8e23-4c1c-8e67-3cc833495b08"}, "a704e9e5-2222-4a91-9a9f-31f51369071c": {"doc_hash": "62c63463af261551272ef0575dc2554dd8b653e024cd09f7de3052cb251ec7fa", "ref_doc_id": "1c3bc399-3304-4b80-812b-dbde1d93cdee"}, "efdf8449-9a28-4fc2-ac7e-b1bcb1c57993": {"doc_hash": "cb9044363d16af542411d338821a7b9883a4afa7707d552c0642283387d2e411", "ref_doc_id": "9d42c874-e19e-4a0d-a3ec-02ee523d51a9"}, "e8b2fc05-f427-42ab-bc58-cb602c0f7446": {"doc_hash": "2f61bec8a70ddf032c0aec1a2f68842cfe0fd64adcaa969d742e60ff5aa1218a", "ref_doc_id": "724fddd8-f6a3-4e9e-9339-817e1b071b79"}, "052d0636-00bd-47b0-9242-724c2c9a1aa5": {"doc_hash": "218d886cdff5e2e94fb8dfcd585415bdfe9c0bb59213ce39bfee933a9d77a6e2", "ref_doc_id": "f138b696-0282-4c52-9636-2d44afa3e6c2"}, "2e827067-64b1-45dd-b8bb-cf78c4467126": {"doc_hash": "a131d3571bd63c90ad77d96a0206d1faaceeb2d90e91b9b4775a0eef60b10f82", "ref_doc_id": "f4ccd784-7f52-4f27-b207-d84e1c6cac23"}, "d3ec6e6a-80fe-4951-bf09-6c4c985d3a78": {"doc_hash": "2d89ee194ff6a065874408c2a7d190aa7f0f6491d078a1cd4f81c679129939d3", "ref_doc_id": "834b94d3-33f1-4321-a602-6c5e523cad92"}, "a2ed4e24-0db3-40e5-853a-33f62e5af7a2": {"doc_hash": "e3347ca6925b2b6f63b357e86286e29c09f02076cb500afb83ffee04439d2653", "ref_doc_id": "b68a0820-be12-4895-9093-4a8031a1b219"}, "116d8ee5-a3b5-4ca8-826a-efafde854497": {"doc_hash": "3d78e14d7e498fa818e4363cfd5f27527110d7f6ed1787052010e4bc45322c3d", "ref_doc_id": "81b47198-7d21-47c7-af35-50ac5f5a7b98"}, "af3a7040-07d5-4210-8b4e-6f87f67502a0": {"doc_hash": "20e3bf686b6e8f3b641a3b0498e1c1a67a9b76a50ea1abce85adfd1004c0080e", "ref_doc_id": "5f1e57b2-517a-4dce-9845-a6b822082f3d"}, "d15c4be1-401e-40dc-b8d0-ed683287ea1d": {"doc_hash": "204f59a16f5e3d3bbde2720753c6d4909a17420818dd9ff42ba730f709d9fbb9", "ref_doc_id": "89485e37-b4d9-4eea-b53f-a2ff20a405fc"}, "9a054106-1025-400c-8ee2-dd8b0e070ed0": {"doc_hash": "173bd9c75452db2951c9d43697a33549c80ef529e4f9ef9b84cde70388fb320b", "ref_doc_id": "9f28e5b6-ab72-4945-9081-4f0d61654dbf"}, "6d627ff6-2388-4ba9-bf57-bdb3a8d83f80": {"doc_hash": "3f154aa6fba53f16b1ef679900431fbe9bf37c8ececfa166fa2713f15eaccf7b", "ref_doc_id": "c6b75f90-4a5d-4f30-a35e-50e4d624414b"}, "feebe11b-e06c-468b-b55e-6e0aff62c240": {"doc_hash": "5064c7605c65235ae0ec8a0c1c8948aaaa0e807e358ff52a2e134c688c5f1152", "ref_doc_id": "e7bcf91d-cbe0-47cd-bf92-2f5c3ea53d2f"}, "8f8d151c-5ab2-440e-bbc2-4a08a5568112": {"doc_hash": "e4f11d5a996008f8176bbe1febe67abe10cbe3e791a7d3b2ebec0da116ac604a", "ref_doc_id": "074f3a7d-35b4-4b22-b667-2eb1b12e7b8e"}, "6a121da9-0719-4354-8497-e8f64d45b035": {"doc_hash": "935aec83f9c450c64a4faa23b1b47169aa00c8c82005375ecc16e73ba3f2b9e9", "ref_doc_id": "d64278c3-267f-4fad-b29e-1b288c379d81"}, "62dc2bdb-1b83-4cbb-ab93-78832de8258d": {"doc_hash": "149607d4a8e3172d27fc5973ec405ae6d464bfc6a34ebabf82f64f2efca21ad1", "ref_doc_id": "9a824a66-adab-4712-8427-a8aa6d1f5eab"}, "2bc1fbbe-c413-4da2-ab00-236dce85e0ba": {"doc_hash": "c00f14cd2ea9d90091584d9a98a8fec8d3efc15f201f5af6277c91e287a3a43d", "ref_doc_id": "26fefcaa-0799-4f67-bd1d-a5c924c65a06"}, "67dbc6df-e3f2-4fa2-8514-0ebe41f10fc0": {"doc_hash": "1a3013d0a905c2f920bb5fb2633796218563470f21016e09f323b2acd86d7942", "ref_doc_id": "4784cd69-9bde-40e1-b4f2-0286a955ab4e"}, "a4274c0c-9ddb-4529-9625-2f507d8a1205": {"doc_hash": "7931dc04ae8c6add27f55306735012a16ed6e26f06f649bde2d63e2632d15609", "ref_doc_id": "fed4ba86-42f4-4c34-bfe6-8c436fd66ef1"}, "9abba4d8-8dea-41ab-9a2e-54b5ee4212ef": {"doc_hash": "ea7010d21be3e817e3cad25ac69ffd055dd577b92b3f3a8b71a57bf6a7532f1c", "ref_doc_id": "b5a51a65-d950-41cc-b9f2-b9a3a2543e26"}}}